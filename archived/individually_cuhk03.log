exec 'nq' 'scripts/exp_individually.sh' 'cuhk03'

I0416 11:55:55.158712   977 caffe.cpp:170] Use GPU with device ID 0
I0416 11:55:55.159513   977 caffe.cpp:178] Starting Optimization
I0416 11:55:55.160032   977 solver.cpp:41] Initializing solver from parameters:
test_iter: 263
test_interval: 200
base_lr: 0.1
display: 20
max_iter: 50000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 10000
snapshot_prefix: "external/exp/snapshots/individually/cuhk03"
solver_mode: GPU
net: "models/individually/cuhk03_trainval.prototxt"
test_initialization: true
average_loss: 20
iter_size: 2
I0416 11:55:55.160049   977 solver.cpp:79] Creating training net from net file: models/individually/cuhk03_trainval.prototxt
I0416 11:55:55.162727   977 net.cpp:330] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0416 11:55:55.162780   977 net.cpp:330] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0416 11:55:55.163389   977 net.cpp:47] Initializing net from parameters:
name: "CUHK03"
state {
  phase: TRAIN
}
richness: 1000
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 102
    mean_value: 102
    mean_value: 101
    crop_height: 144
    crop_width: 56
  }
  data_param {
    source: "external/exp/db/cuhk03/train_lmdb"
    batch_size: 50
    backend: LMDB
    shuffle_pool_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BN"
  bottom: "conv1"
  top: "conv1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_bn"
  top: "conv1_bn"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_bn"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2_bn"
  type: "BN"
  bottom: "conv2"
  top: "conv2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_bn"
  top: "conv2_bn"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_bn"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3_bn"
  type: "BN"
  bottom: "conv3"
  top: "conv3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_bn"
  top: "conv3_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv3_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "inception_1a/1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/1x1_bn"
  type: "BN"
  bottom: "inception_1a/1x1"
  top: "inception_1a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_1x1"
  type: "ReLU"
  bottom: "inception_1a/1x1_bn"
  top: "inception_1a/1x1_bn"
}
layer {
  name: "inception_1a/3x3_reduce"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1a/3x3_reduce"
  top: "inception_1a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1a/3x3_reduce_bn"
  top: "inception_1a/3x3_reduce_bn"
}
layer {
  name: "inception_1a/3x3"
  type: "Convolution"
  bottom: "inception_1a/3x3_reduce_bn"
  top: "inception_1a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/3x3_bn"
  type: "BN"
  bottom: "inception_1a/3x3"
  top: "inception_1a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_3x3"
  type: "ReLU"
  bottom: "inception_1a/3x3_bn"
  top: "inception_1a/3x3_bn"
}
layer {
  name: "inception_1a/double_3x3_reduce"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_reduce"
  top: "inception_1a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_reduce_bn"
  top: "inception_1a/double_3x3_reduce_bn"
}
layer {
  name: "inception_1a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_1a/double_3x3_reduce_bn"
  top: "inception_1a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_1"
  top: "inception_1a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_1_bn"
  top: "inception_1a/double_3x3_1_bn"
}
layer {
  name: "inception_1a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_1a/double_3x3_1_bn"
  top: "inception_1a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_2"
  top: "inception_1a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_2_bn"
  top: "inception_1a/double_3x3_2_bn"
}
layer {
  name: "inception_1a/pool"
  type: "Pooling"
  bottom: "pool1"
  top: "inception_1a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_1a/pool_proj"
  type: "Convolution"
  bottom: "inception_1a/pool"
  top: "inception_1a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/pool_proj_bn"
  type: "BN"
  bottom: "inception_1a/pool_proj"
  top: "inception_1a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_1a/pool_proj_bn"
  top: "inception_1a/pool_proj_bn"
}
layer {
  name: "inception_1a/output"
  type: "Concat"
  bottom: "inception_1a/1x1_bn"
  bottom: "inception_1a/3x3_bn"
  bottom: "inception_1a/double_3x3_2_bn"
  bottom: "inception_1a/pool_proj_bn"
  top: "inception_1a/output"
}
layer {
  name: "inception_1b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_1a/output"
  top: "inception_1b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1b/3x3_reduce"
  top: "inception_1b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1b/3x3_reduce_bn"
  top: "inception_1b/3x3_reduce_bn"
}
layer {
  name: "inception_1b/3x3"
  type: "Convolution"
  bottom: "inception_1b/3x3_reduce_bn"
  top: "inception_1b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/3x3_bn"
  type: "BN"
  bottom: "inception_1b/3x3"
  top: "inception_1b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_3x3"
  type: "ReLU"
  bottom: "inception_1b/3x3_bn"
  top: "inception_1b/3x3_bn"
}
layer {
  name: "inception_1b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_1a/output"
  top: "inception_1b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_reduce"
  top: "inception_1b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_reduce_bn"
  top: "inception_1b/double_3x3_reduce_bn"
}
layer {
  name: "inception_1b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_1b/double_3x3_reduce_bn"
  top: "inception_1b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_1"
  top: "inception_1b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_1_bn"
  top: "inception_1b/double_3x3_1_bn"
}
layer {
  name: "inception_1b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_1b/double_3x3_1_bn"
  top: "inception_1b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_2"
  top: "inception_1b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_2_bn"
  top: "inception_1b/double_3x3_2_bn"
}
layer {
  name: "inception_1b/pool"
  type: "Pooling"
  bottom: "inception_1a/output"
  top: "inception_1b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_1b/output"
  type: "Concat"
  bottom: "inception_1b/3x3_bn"
  bottom: "inception_1b/double_3x3_2_bn"
  bottom: "inception_1b/pool"
  top: "inception_1b/output"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1_bn"
  type: "BN"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_1x1"
  type: "ReLU"
  bottom: "inception_2a/1x1_bn"
  top: "inception_2a/1x1_bn"
}
layer {
  name: "inception_2a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2a/3x3_reduce"
  top: "inception_2a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2a/3x3_reduce_bn"
  top: "inception_2a/3x3_reduce_bn"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "inception_2a/3x3_reduce_bn"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3_bn"
  type: "BN"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_3x3"
  type: "ReLU"
  bottom: "inception_2a/3x3_bn"
  top: "inception_2a/3x3_bn"
}
layer {
  name: "inception_2a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_reduce"
  top: "inception_2a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_reduce_bn"
  top: "inception_2a/double_3x3_reduce_bn"
}
layer {
  name: "inception_2a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_2a/double_3x3_reduce_bn"
  top: "inception_2a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_1"
  top: "inception_2a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_1_bn"
  top: "inception_2a/double_3x3_1_bn"
}
layer {
  name: "inception_2a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_2a/double_3x3_1_bn"
  top: "inception_2a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_2"
  top: "inception_2a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_2_bn"
  top: "inception_2a/double_3x3_2_bn"
}
layer {
  name: "inception_2a/pool"
  type: "Pooling"
  bottom: "inception_1b/output"
  top: "inception_2a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_2a/pool_proj"
  type: "Convolution"
  bottom: "inception_2a/pool"
  top: "inception_2a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/pool_proj_bn"
  type: "BN"
  bottom: "inception_2a/pool_proj"
  top: "inception_2a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_2a/pool_proj_bn"
  top: "inception_2a/pool_proj_bn"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1_bn"
  bottom: "inception_2a/3x3_bn"
  bottom: "inception_2a/double_3x3_2_bn"
  bottom: "inception_2a/pool_proj_bn"
  top: "inception_2a/output"
}
layer {
  name: "inception_2b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_2b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2b/3x3_reduce"
  top: "inception_2b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2b/3x3_reduce_bn"
  top: "inception_2b/3x3_reduce_bn"
}
layer {
  name: "inception_2b/3x3"
  type: "Convolution"
  bottom: "inception_2b/3x3_reduce_bn"
  top: "inception_2b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/3x3_bn"
  type: "BN"
  bottom: "inception_2b/3x3"
  top: "inception_2b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_3x3"
  type: "ReLU"
  bottom: "inception_2b/3x3_bn"
  top: "inception_2b/3x3_bn"
}
layer {
  name: "inception_2b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_2b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_reduce"
  top: "inception_2b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_reduce_bn"
  top: "inception_2b/double_3x3_reduce_bn"
}
layer {
  name: "inception_2b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_2b/double_3x3_reduce_bn"
  top: "inception_2b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_1"
  top: "inception_2b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_1_bn"
  top: "inception_2b/double_3x3_1_bn"
}
layer {
  name: "inception_2b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_2b/double_3x3_1_bn"
  top: "inception_2b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_2"
  top: "inception_2b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_2_bn"
  top: "inception_2b/double_3x3_2_bn"
}
layer {
  name: "inception_2b/pool"
  type: "Pooling"
  bottom: "inception_2a/output"
  top: "inception_2b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_2b/output"
  type: "Concat"
  bottom: "inception_2b/3x3_bn"
  bottom: "inception_2b/double_3x3_2_bn"
  bottom: "inception_2b/pool"
  top: "inception_2b/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1_bn"
  type: "BN"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1_bn"
  top: "inception_3a/1x1_bn"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3_reduce_bn"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_bn"
  type: "BN"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3_bn"
  top: "inception_3a/3x3_bn"
}
layer {
  name: "inception_3a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_reduce"
  top: "inception_3a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"

I0416 11:55:55.165524   977 layer_factory.hpp:74] Creating layer data
I0416 11:55:55.165550   977 net.cpp:133] Creating Layer data
I0416 11:55:55.165555   977 net.cpp:411] data -> data
I0416 11:55:55.165566   977 net.cpp:411] data -> label
I0416 11:55:55.165575   977 net.cpp:163] Setting up data
I0416 11:55:55.165892   977 db_lmdb.cpp:22] Opened lmdb external/exp/db/cuhk03/train_lmdb
I0416 11:55:55.166014   977 data_layer.cpp:55] Skipping first 0 data points.
I0416 11:55:55.166034   977 data_layer.cpp:100] output data size: 25,3,144,56
I0416 11:55:55.166093   977 net.cpp:170] Top shape: 25 3 144 56 (604800)
I0416 11:55:55.166103   977 net.cpp:170] Top shape: 25 (25)
I0416 11:55:55.166107   977 layer_factory.hpp:74] Creating layer conv1
I0416 11:55:55.166115   977 net.cpp:133] Creating Layer conv1
I0416 11:55:55.166117   977 net.cpp:453] conv1 <- data
I0416 11:55:55.166126   977 net.cpp:411] conv1 -> conv1
I0416 11:55:55.166134   977 net.cpp:163] Setting up conv1
I0416 11:55:55.469202   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.469233   977 layer_factory.hpp:74] Creating layer conv1_bn
I0416 11:55:55.469236   977 layer_factory.cpp:191] Layer conv1_bn is using CAFFE engine.
I0416 11:55:55.469257   977 net.cpp:133] Creating Layer conv1_bn
I0416 11:55:55.469261   977 net.cpp:453] conv1_bn <- conv1
I0416 11:55:55.469265   977 net.cpp:411] conv1_bn -> conv1_bn
I0416 11:55:55.469272   977 net.cpp:163] Setting up conv1_bn
I0416 11:55:55.469293   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.469300   977 layer_factory.hpp:74] Creating layer relu1
I0416 11:55:55.469305   977 net.cpp:133] Creating Layer relu1
I0416 11:55:55.469305   977 net.cpp:453] relu1 <- conv1_bn
I0416 11:55:55.469308   977 net.cpp:400] relu1 -> conv1_bn (in-place)
I0416 11:55:55.469315   977 net.cpp:163] Setting up relu1
I0416 11:55:55.469425   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.469434   977 layer_factory.hpp:74] Creating layer conv2
I0416 11:55:55.469440   977 net.cpp:133] Creating Layer conv2
I0416 11:55:55.469441   977 net.cpp:453] conv2 <- conv1_bn
I0416 11:55:55.469445   977 net.cpp:411] conv2 -> conv2
I0416 11:55:55.469449   977 net.cpp:163] Setting up conv2
I0416 11:55:55.632365   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.632375   977 layer_factory.hpp:74] Creating layer conv2_bn
I0416 11:55:55.632377   977 layer_factory.cpp:191] Layer conv2_bn is using CAFFE engine.
I0416 11:55:55.632381   977 net.cpp:133] Creating Layer conv2_bn
I0416 11:55:55.632383   977 net.cpp:453] conv2_bn <- conv2
I0416 11:55:55.632386   977 net.cpp:411] conv2_bn -> conv2_bn
I0416 11:55:55.632390   977 net.cpp:163] Setting up conv2_bn
I0416 11:55:55.632403   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.632411   977 layer_factory.hpp:74] Creating layer relu2
I0416 11:55:55.632413   977 net.cpp:133] Creating Layer relu2
I0416 11:55:55.632416   977 net.cpp:453] relu2 <- conv2_bn
I0416 11:55:55.632417   977 net.cpp:400] relu2 -> conv2_bn (in-place)
I0416 11:55:55.632421   977 net.cpp:163] Setting up relu2
I0416 11:55:55.632589   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.632596   977 layer_factory.hpp:74] Creating layer conv3
I0416 11:55:55.632599   977 net.cpp:133] Creating Layer conv3
I0416 11:55:55.632601   977 net.cpp:453] conv3 <- conv2_bn
I0416 11:55:55.632604   977 net.cpp:411] conv3 -> conv3
I0416 11:55:55.632608   977 net.cpp:163] Setting up conv3
I0416 11:55:55.787689   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.787699   977 layer_factory.hpp:74] Creating layer conv3_bn
I0416 11:55:55.787703   977 layer_factory.cpp:191] Layer conv3_bn is using CAFFE engine.
I0416 11:55:55.787706   977 net.cpp:133] Creating Layer conv3_bn
I0416 11:55:55.787708   977 net.cpp:453] conv3_bn <- conv3
I0416 11:55:55.787713   977 net.cpp:411] conv3_bn -> conv3_bn
I0416 11:55:55.787716   977 net.cpp:163] Setting up conv3_bn
I0416 11:55:55.787734   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.787740   977 layer_factory.hpp:74] Creating layer relu3
I0416 11:55:55.787744   977 net.cpp:133] Creating Layer relu3
I0416 11:55:55.787745   977 net.cpp:453] relu3 <- conv3_bn
I0416 11:55:55.787747   977 net.cpp:400] relu3 -> conv3_bn (in-place)
I0416 11:55:55.787750   977 net.cpp:163] Setting up relu3
I0416 11:55:55.787858   977 net.cpp:170] Top shape: 25 32 144 56 (6451200)
I0416 11:55:55.787863   977 layer_factory.hpp:74] Creating layer pool1
I0416 11:55:55.787868   977 net.cpp:133] Creating Layer pool1
I0416 11:55:55.787869   977 net.cpp:453] pool1 <- conv3_bn
I0416 11:55:55.787873   977 net.cpp:411] pool1 -> pool1
I0416 11:55:55.787878   977 net.cpp:163] Setting up pool1
I0416 11:55:55.788065   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:55.788072   977 layer_factory.hpp:74] Creating layer pool1_pool1_0_split
I0416 11:55:55.788076   977 net.cpp:133] Creating Layer pool1_pool1_0_split
I0416 11:55:55.788079   977 net.cpp:453] pool1_pool1_0_split <- pool1
I0416 11:55:55.788082   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0416 11:55:55.788086   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0416 11:55:55.788090   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_2
I0416 11:55:55.788092   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_3
I0416 11:55:55.788105   977 net.cpp:163] Setting up pool1_pool1_0_split
I0416 11:55:55.788110   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:55.788113   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:55.788115   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:55.788117   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:55.788118   977 layer_factory.hpp:74] Creating layer inception_1a/1x1
I0416 11:55:55.788123   977 net.cpp:133] Creating Layer inception_1a/1x1
I0416 11:55:55.788125   977 net.cpp:453] inception_1a/1x1 <- pool1_pool1_0_split_0
I0416 11:55:55.788128   977 net.cpp:411] inception_1a/1x1 -> inception_1a/1x1
I0416 11:55:55.788132   977 net.cpp:163] Setting up inception_1a/1x1
I0416 11:55:55.841331   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.841341   977 layer_factory.hpp:74] Creating layer inception_1a/1x1_bn
I0416 11:55:55.841343   977 layer_factory.cpp:191] Layer inception_1a/1x1_bn is using CAFFE engine.
I0416 11:55:55.841347   977 net.cpp:133] Creating Layer inception_1a/1x1_bn
I0416 11:55:55.841349   977 net.cpp:453] inception_1a/1x1_bn <- inception_1a/1x1
I0416 11:55:55.841353   977 net.cpp:411] inception_1a/1x1_bn -> inception_1a/1x1_bn
I0416 11:55:55.841363   977 net.cpp:163] Setting up inception_1a/1x1_bn
I0416 11:55:55.841375   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.841383   977 layer_factory.hpp:74] Creating layer inception_1a/relu_1x1
I0416 11:55:55.841387   977 net.cpp:133] Creating Layer inception_1a/relu_1x1
I0416 11:55:55.841390   977 net.cpp:453] inception_1a/relu_1x1 <- inception_1a/1x1_bn
I0416 11:55:55.841394   977 net.cpp:400] inception_1a/relu_1x1 -> inception_1a/1x1_bn (in-place)
I0416 11:55:55.841401   977 net.cpp:163] Setting up inception_1a/relu_1x1
I0416 11:55:55.841588   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.841595   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_reduce
I0416 11:55:55.841603   977 net.cpp:133] Creating Layer inception_1a/3x3_reduce
I0416 11:55:55.841606   977 net.cpp:453] inception_1a/3x3_reduce <- pool1_pool1_0_split_1
I0416 11:55:55.841612   977 net.cpp:411] inception_1a/3x3_reduce -> inception_1a/3x3_reduce
I0416 11:55:55.841619   977 net.cpp:163] Setting up inception_1a/3x3_reduce
I0416 11:55:55.894856   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.894868   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_reduce_bn
I0416 11:55:55.894872   977 layer_factory.cpp:191] Layer inception_1a/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:55.894881   977 net.cpp:133] Creating Layer inception_1a/3x3_reduce_bn
I0416 11:55:55.894884   977 net.cpp:453] inception_1a/3x3_reduce_bn <- inception_1a/3x3_reduce
I0416 11:55:55.894892   977 net.cpp:411] inception_1a/3x3_reduce_bn -> inception_1a/3x3_reduce_bn
I0416 11:55:55.894901   977 net.cpp:163] Setting up inception_1a/3x3_reduce_bn
I0416 11:55:55.894918   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.894925   977 layer_factory.hpp:74] Creating layer inception_1a/relu_3x3_reduce
I0416 11:55:55.894932   977 net.cpp:133] Creating Layer inception_1a/relu_3x3_reduce
I0416 11:55:55.894934   977 net.cpp:453] inception_1a/relu_3x3_reduce <- inception_1a/3x3_reduce_bn
I0416 11:55:55.894938   977 net.cpp:400] inception_1a/relu_3x3_reduce -> inception_1a/3x3_reduce_bn (in-place)
I0416 11:55:55.894944   977 net.cpp:163] Setting up inception_1a/relu_3x3_reduce
I0416 11:55:55.895053   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:55.895058   977 layer_factory.hpp:74] Creating layer inception_1a/3x3
I0416 11:55:55.895066   977 net.cpp:133] Creating Layer inception_1a/3x3
I0416 11:55:55.895069   977 net.cpp:453] inception_1a/3x3 <- inception_1a/3x3_reduce_bn
I0416 11:55:55.895076   977 net.cpp:411] inception_1a/3x3 -> inception_1a/3x3
I0416 11:55:55.895084   977 net.cpp:163] Setting up inception_1a/3x3
I0416 11:55:56.008076   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.008087   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_bn
I0416 11:55:56.008091   977 layer_factory.cpp:191] Layer inception_1a/3x3_bn is using CAFFE engine.
I0416 11:55:56.008097   977 net.cpp:133] Creating Layer inception_1a/3x3_bn
I0416 11:55:56.008101   977 net.cpp:453] inception_1a/3x3_bn <- inception_1a/3x3
I0416 11:55:56.008107   977 net.cpp:411] inception_1a/3x3_bn -> inception_1a/3x3_bn
I0416 11:55:56.008114   977 net.cpp:163] Setting up inception_1a/3x3_bn
I0416 11:55:56.008132   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.008144   977 layer_factory.hpp:74] Creating layer inception_1a/relu_3x3
I0416 11:55:56.008152   977 net.cpp:133] Creating Layer inception_1a/relu_3x3
I0416 11:55:56.008157   977 net.cpp:453] inception_1a/relu_3x3 <- inception_1a/3x3_bn
I0416 11:55:56.008162   977 net.cpp:400] inception_1a/relu_3x3 -> inception_1a/3x3_bn (in-place)
I0416 11:55:56.008167   977 net.cpp:163] Setting up inception_1a/relu_3x3
I0416 11:55:56.008348   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.008355   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_reduce
I0416 11:55:56.008363   977 net.cpp:133] Creating Layer inception_1a/double_3x3_reduce
I0416 11:55:56.008366   977 net.cpp:453] inception_1a/double_3x3_reduce <- pool1_pool1_0_split_2
I0416 11:55:56.008373   977 net.cpp:411] inception_1a/double_3x3_reduce -> inception_1a/double_3x3_reduce
I0416 11:55:56.008379   977 net.cpp:163] Setting up inception_1a/double_3x3_reduce
I0416 11:55:56.061280   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.061291   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061295   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:56.061301   977 net.cpp:133] Creating Layer inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061305   977 net.cpp:453] inception_1a/double_3x3_reduce_bn <- inception_1a/double_3x3_reduce
I0416 11:55:56.061311   977 net.cpp:411] inception_1a/double_3x3_reduce_bn -> inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061318   977 net.cpp:163] Setting up inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061334   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.061342   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_reduce
I0416 11:55:56.061348   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_reduce
I0416 11:55:56.061352   977 net.cpp:453] inception_1a/relu_double_3x3_reduce <- inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061362   977 net.cpp:400] inception_1a/relu_double_3x3_reduce -> inception_1a/double_3x3_reduce_bn (in-place)
I0416 11:55:56.061367   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_reduce
I0416 11:55:56.061563   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.061570   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_1
I0416 11:55:56.061576   977 net.cpp:133] Creating Layer inception_1a/double_3x3_1
I0416 11:55:56.061581   977 net.cpp:453] inception_1a/double_3x3_1 <- inception_1a/double_3x3_reduce_bn
I0416 11:55:56.061588   977 net.cpp:411] inception_1a/double_3x3_1 -> inception_1a/double_3x3_1
I0416 11:55:56.061594   977 net.cpp:163] Setting up inception_1a/double_3x3_1
I0416 11:55:56.174518   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.174530   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_1_bn
I0416 11:55:56.174533   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:56.174540   977 net.cpp:133] Creating Layer inception_1a/double_3x3_1_bn
I0416 11:55:56.174543   977 net.cpp:453] inception_1a/double_3x3_1_bn <- inception_1a/double_3x3_1
I0416 11:55:56.174549   977 net.cpp:411] inception_1a/double_3x3_1_bn -> inception_1a/double_3x3_1_bn
I0416 11:55:56.174556   977 net.cpp:163] Setting up inception_1a/double_3x3_1_bn
I0416 11:55:56.174571   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.174579   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_1
I0416 11:55:56.174585   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_1
I0416 11:55:56.174588   977 net.cpp:453] inception_1a/relu_double_3x3_1 <- inception_1a/double_3x3_1_bn
I0416 11:55:56.174593   977 net.cpp:400] inception_1a/relu_double_3x3_1 -> inception_1a/double_3x3_1_bn (in-place)
I0416 11:55:56.174597   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_1
I0416 11:55:56.174718   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.174724   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_2
I0416 11:55:56.174731   977 net.cpp:133] Creating Layer inception_1a/double_3x3_2
I0416 11:55:56.174736   977 net.cpp:453] inception_1a/double_3x3_2 <- inception_1a/double_3x3_1_bn
I0416 11:55:56.174741   977 net.cpp:411] inception_1a/double_3x3_2 -> inception_1a/double_3x3_2
I0416 11:55:56.174747   977 net.cpp:163] Setting up inception_1a/double_3x3_2
I0416 11:55:56.287968   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.287981   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_2_bn
I0416 11:55:56.287983   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:56.287989   977 net.cpp:133] Creating Layer inception_1a/double_3x3_2_bn
I0416 11:55:56.287993   977 net.cpp:453] inception_1a/double_3x3_2_bn <- inception_1a/double_3x3_2
I0416 11:55:56.287999   977 net.cpp:411] inception_1a/double_3x3_2_bn -> inception_1a/double_3x3_2_bn
I0416 11:55:56.288007   977 net.cpp:163] Setting up inception_1a/double_3x3_2_bn
I0416 11:55:56.288029   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.288038   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_2
I0416 11:55:56.288043   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_2
I0416 11:55:56.288045   977 net.cpp:453] inception_1a/relu_double_3x3_2 <- inception_1a/double_3x3_2_bn
I0416 11:55:56.288050   977 net.cpp:400] inception_1a/relu_double_3x3_2 -> inception_1a/double_3x3_2_bn (in-place)
I0416 11:55:56.288056   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_2
I0416 11:55:56.288244   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.288250   977 layer_factory.hpp:74] Creating layer inception_1a/pool
I0416 11:55:56.288254   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:55:56.288259   977 net.cpp:133] Creating Layer inception_1a/pool
I0416 11:55:56.288262   977 net.cpp:453] inception_1a/pool <- pool1_pool1_0_split_3
I0416 11:55:56.288269   977 net.cpp:411] inception_1a/pool -> inception_1a/pool
I0416 11:55:56.288275   977 net.cpp:163] Setting up inception_1a/pool
I0416 11:55:56.288280   977 net.cpp:170] Top shape: 25 32 72 28 (1612800)
I0416 11:55:56.288283   977 layer_factory.hpp:74] Creating layer inception_1a/pool_proj
I0416 11:55:56.288290   977 net.cpp:133] Creating Layer inception_1a/pool_proj
I0416 11:55:56.288292   977 net.cpp:453] inception_1a/pool_proj <- inception_1a/pool
I0416 11:55:56.288298   977 net.cpp:411] inception_1a/pool_proj -> inception_1a/pool_proj
I0416 11:55:56.288305   977 net.cpp:163] Setting up inception_1a/pool_proj
I0416 11:55:56.341153   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.341164   977 layer_factory.hpp:74] Creating layer inception_1a/pool_proj_bn
I0416 11:55:56.341168   977 layer_factory.cpp:191] Layer inception_1a/pool_proj_bn is using CAFFE engine.
I0416 11:55:56.341178   977 net.cpp:133] Creating Layer inception_1a/pool_proj_bn
I0416 11:55:56.341182   977 net.cpp:453] inception_1a/pool_proj_bn <- inception_1a/pool_proj
I0416 11:55:56.341188   977 net.cpp:411] inception_1a/pool_proj_bn -> inception_1a/pool_proj_bn
I0416 11:55:56.341195   977 net.cpp:163] Setting up inception_1a/pool_proj_bn
I0416 11:55:56.341212   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.341219   977 layer_factory.hpp:74] Creating layer inception_1a/relu_pool_proj
I0416 11:55:56.341224   977 net.cpp:133] Creating Layer inception_1a/relu_pool_proj
I0416 11:55:56.341228   977 net.cpp:453] inception_1a/relu_pool_proj <- inception_1a/pool_proj_bn
I0416 11:55:56.341234   977 net.cpp:400] inception_1a/relu_pool_proj -> inception_1a/pool_proj_bn (in-place)
I0416 11:55:56.341238   977 net.cpp:163] Setting up inception_1a/relu_pool_proj
I0416 11:55:56.341428   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.341435   977 layer_factory.hpp:74] Creating layer inception_1a/output
I0416 11:55:56.341441   977 net.cpp:133] Creating Layer inception_1a/output
I0416 11:55:56.341444   977 net.cpp:453] inception_1a/output <- inception_1a/1x1_bn
I0416 11:55:56.341449   977 net.cpp:453] inception_1a/output <- inception_1a/3x3_bn
I0416 11:55:56.341452   977 net.cpp:453] inception_1a/output <- inception_1a/double_3x3_2_bn
I0416 11:55:56.341456   977 net.cpp:453] inception_1a/output <- inception_1a/pool_proj_bn
I0416 11:55:56.341462   977 net.cpp:411] inception_1a/output -> inception_1a/output
I0416 11:55:56.341469   977 net.cpp:163] Setting up inception_1a/output
I0416 11:55:56.341475   977 net.cpp:170] Top shape: 25 256 72 28 (12902400)
I0416 11:55:56.341477   977 layer_factory.hpp:74] Creating layer inception_1a/output_inception_1a/output_0_split
I0416 11:55:56.341482   977 net.cpp:133] Creating Layer inception_1a/output_inception_1a/output_0_split
I0416 11:55:56.341485   977 net.cpp:453] inception_1a/output_inception_1a/output_0_split <- inception_1a/output
I0416 11:55:56.341491   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_0
I0416 11:55:56.341497   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_1
I0416 11:55:56.341503   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_2
I0416 11:55:56.341508   977 net.cpp:163] Setting up inception_1a/output_inception_1a/output_0_split
I0416 11:55:56.341514   977 net.cpp:170] Top shape: 25 256 72 28 (12902400)
I0416 11:55:56.341518   977 net.cpp:170] Top shape: 25 256 72 28 (12902400)
I0416 11:55:56.341521   977 net.cpp:170] Top shape: 25 256 72 28 (12902400)
I0416 11:55:56.341524   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_reduce
I0416 11:55:56.341531   977 net.cpp:133] Creating Layer inception_1b/3x3_reduce
I0416 11:55:56.341534   977 net.cpp:453] inception_1b/3x3_reduce <- inception_1a/output_inception_1a/output_0_split_0
I0416 11:55:56.341541   977 net.cpp:411] inception_1b/3x3_reduce -> inception_1b/3x3_reduce
I0416 11:55:56.341552   977 net.cpp:163] Setting up inception_1b/3x3_reduce
I0416 11:55:56.636333   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.636344   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_reduce_bn
I0416 11:55:56.636348   977 layer_factory.cpp:191] Layer inception_1b/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:56.636355   977 net.cpp:133] Creating Layer inception_1b/3x3_reduce_bn
I0416 11:55:56.636358   977 net.cpp:453] inception_1b/3x3_reduce_bn <- inception_1b/3x3_reduce
I0416 11:55:56.636365   977 net.cpp:411] inception_1b/3x3_reduce_bn -> inception_1b/3x3_reduce_bn
I0416 11:55:56.636373   977 net.cpp:163] Setting up inception_1b/3x3_reduce_bn
I0416 11:55:56.636389   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.636404   977 layer_factory.hpp:74] Creating layer inception_1b/relu_3x3_reduce
I0416 11:55:56.636410   977 net.cpp:133] Creating Layer inception_1b/relu_3x3_reduce
I0416 11:55:56.636415   977 net.cpp:453] inception_1b/relu_3x3_reduce <- inception_1b/3x3_reduce_bn
I0416 11:55:56.636420   977 net.cpp:400] inception_1b/relu_3x3_reduce -> inception_1b/3x3_reduce_bn (in-place)
I0416 11:55:56.636425   977 net.cpp:163] Setting up inception_1b/relu_3x3_reduce
I0416 11:55:56.636540   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.636545   977 layer_factory.hpp:74] Creating layer inception_1b/3x3
I0416 11:55:56.636553   977 net.cpp:133] Creating Layer inception_1b/3x3
I0416 11:55:56.636556   977 net.cpp:453] inception_1b/3x3 <- inception_1b/3x3_reduce_bn
I0416 11:55:56.636564   977 net.cpp:411] inception_1b/3x3 -> inception_1b/3x3
I0416 11:55:56.636569   977 net.cpp:163] Setting up inception_1b/3x3
I0416 11:55:56.656360   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:56.656371   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_bn
I0416 11:55:56.656376   977 layer_factory.cpp:191] Layer inception_1b/3x3_bn is using CAFFE engine.
I0416 11:55:56.656383   977 net.cpp:133] Creating Layer inception_1b/3x3_bn
I0416 11:55:56.656385   977 net.cpp:453] inception_1b/3x3_bn <- inception_1b/3x3
I0416 11:55:56.656391   977 net.cpp:411] inception_1b/3x3_bn -> inception_1b/3x3_bn
I0416 11:55:56.656399   977 net.cpp:163] Setting up inception_1b/3x3_bn
I0416 11:55:56.656414   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:56.656421   977 layer_factory.hpp:74] Creating layer inception_1b/relu_3x3
I0416 11:55:56.656426   977 net.cpp:133] Creating Layer inception_1b/relu_3x3
I0416 11:55:56.656430   977 net.cpp:453] inception_1b/relu_3x3 <- inception_1b/3x3_bn
I0416 11:55:56.656435   977 net.cpp:400] inception_1b/relu_3x3 -> inception_1b/3x3_bn (in-place)
I0416 11:55:56.656440   977 net.cpp:163] Setting up inception_1b/relu_3x3
I0416 11:55:56.656626   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:56.656633   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_reduce
I0416 11:55:56.656641   977 net.cpp:133] Creating Layer inception_1b/double_3x3_reduce
I0416 11:55:56.656644   977 net.cpp:453] inception_1b/double_3x3_reduce <- inception_1a/output_inception_1a/output_0_split_1
I0416 11:55:56.656651   977 net.cpp:411] inception_1b/double_3x3_reduce -> inception_1b/double_3x3_reduce
I0416 11:55:56.656657   977 net.cpp:163] Setting up inception_1b/double_3x3_reduce
I0416 11:55:56.952649   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.952661   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952664   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:56.952671   977 net.cpp:133] Creating Layer inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952674   977 net.cpp:453] inception_1b/double_3x3_reduce_bn <- inception_1b/double_3x3_reduce
I0416 11:55:56.952680   977 net.cpp:411] inception_1b/double_3x3_reduce_bn -> inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952687   977 net.cpp:163] Setting up inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952704   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.952713   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_reduce
I0416 11:55:56.952718   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_reduce
I0416 11:55:56.952723   977 net.cpp:453] inception_1b/relu_double_3x3_reduce <- inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952726   977 net.cpp:400] inception_1b/relu_double_3x3_reduce -> inception_1b/double_3x3_reduce_bn (in-place)
I0416 11:55:56.952733   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_reduce
I0416 11:55:56.952921   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:56.952929   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_1
I0416 11:55:56.952936   977 net.cpp:133] Creating Layer inception_1b/double_3x3_1
I0416 11:55:56.952940   977 net.cpp:453] inception_1b/double_3x3_1 <- inception_1b/double_3x3_reduce_bn
I0416 11:55:56.952945   977 net.cpp:411] inception_1b/double_3x3_1 -> inception_1b/double_3x3_1
I0416 11:55:56.952952   977 net.cpp:163] Setting up inception_1b/double_3x3_1
I0416 11:55:57.065572   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:57.065583   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_1_bn
I0416 11:55:57.065587   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:57.065593   977 net.cpp:133] Creating Layer inception_1b/double_3x3_1_bn
I0416 11:55:57.065598   977 net.cpp:453] inception_1b/double_3x3_1_bn <- inception_1b/double_3x3_1
I0416 11:55:57.065603   977 net.cpp:411] inception_1b/double_3x3_1_bn -> inception_1b/double_3x3_1_bn
I0416 11:55:57.065610   977 net.cpp:163] Setting up inception_1b/double_3x3_1_bn
I0416 11:55:57.065629   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:57.065636   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_1
I0416 11:55:57.065641   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_1
I0416 11:55:57.065644   977 net.cpp:453] inception_1b/relu_double_3x3_1 <- inception_1b/double_3x3_1_bn
I0416 11:55:57.065649   977 net.cpp:400] inception_1b/relu_double_3x3_1 -> inception_1b/double_3x3_1_bn (in-place)
I0416 11:55:57.065654   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_1
I0416 11:55:57.065768   977 net.cpp:170] Top shape: 25 64 72 28 (3225600)
I0416 11:55:57.065773   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_2
I0416 11:55:57.065780   977 net.cpp:133] Creating Layer inception_1b/double_3x3_2
I0416 11:55:57.065784   977 net.cpp:453] inception_1b/double_3x3_2 <- inception_1b/double_3x3_1_bn
I0416 11:55:57.065790   977 net.cpp:411] inception_1b/double_3x3_2 -> inception_1b/double_3x3_2
I0416 11:55:57.065798   977 net.cpp:163] Setting up inception_1b/double_3x3_2
I0416 11:55:57.085563   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:57.085574   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_2_bn
I0416 11:55:57.085577   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:57.085584   977 net.cpp:133] Creating Layer inception_1b/double_3x3_2_bn
I0416 11:55:57.085587   977 net.cpp:453] inception_1b/double_3x3_2_bn <- inception_1b/double_3x3_2
I0416 11:55:57.085594   977 net.cpp:411] inception_1b/double_3x3_2_bn -> inception_1b/double_3x3_2_bn
I0416 11:55:57.085603   977 net.cpp:163] Setting up inception_1b/double_3x3_2_bn
I0416 11:55:57.085618   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:57.085626   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_2
I0416 11:55:57.085631   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_2
I0416 11:55:57.085634   977 net.cpp:453] inception_1b/relu_double_3x3_2 <- inception_1b/double_3x3_2_bn
I0416 11:55:57.085641   977 net.cpp:400] inception_1b/relu_double_3x3_2 -> inception_1b/double_3x3_2_bn (in-place)
I0416 11:55:57.085646   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_2
I0416 11:55:57.085834   977 net.cpp:170] Top shape: 25 64 36 14 (806400)
I0416 11:55:57.085840   977 layer_factory.hpp:74] Creating layer inception_1b/pool
I0416 11:55:57.085846   977 net.cpp:133] Creating Layer inception_1b/pool
I0416 11:55:57.085850   977 net.cpp:453] inception_1b/pool <- inception_1a/output_inception_1a/output_0_split_2
I0416 11:55:57.085857   977 net.cpp:411] inception_1b/pool -> inception_1b/pool
I0416 11:55:57.085865   977 net.cpp:163] Setting up inception_1b/pool
I0416 11:55:57.085980   977 net.cpp:170] Top shape: 25 256 36 14 (3225600)
I0416 11:55:57.085986   977 layer_factory.hpp:74] Creating layer inception_1b/output
I0416 11:55:57.085993   977 net.cpp:133] Creating Layer inception_1b/output
I0416 11:55:57.085995   977 net.cpp:453] inception_1b/output <- inception_1b/3x3_bn
I0416 11:55:57.085999   977 net.cpp:453] inception_1b/output <- inception_1b/double_3x3_2_bn
I0416 11:55:57.086004   977 net.cpp:453] inception_1b/output <- inception_1b/pool
I0416 11:55:57.086009   977 net.cpp:411] inception_1b/output -> inception_1b/output
I0416 11:55:57.086015   977 net.cpp:163] Setting up inception_1b/output
I0416 11:55:57.086020   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.086024   977 layer_factory.hpp:74] Creating layer inception_1b/output_inception_1b/output_0_split
I0416 11:55:57.086030   977 net.cpp:133] Creating Layer inception_1b/output_inception_1b/output_0_split
I0416 11:55:57.086031   977 net.cpp:453] inception_1b/output_inception_1b/output_0_split <- inception_1b/output
I0416 11:55:57.086037   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_0
I0416 11:55:57.086043   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_1
I0416 11:55:57.086050   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_2
I0416 11:55:57.086055   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_3
I0416 11:55:57.086061   977 net.cpp:163] Setting up inception_1b/output_inception_1b/output_0_split
I0416 11:55:57.086066   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.086069   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.086073   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.086076   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.086079   977 layer_factory.hpp:74] Creating layer inception_2a/1x1
I0416 11:55:57.086086   977 net.cpp:133] Creating Layer inception_2a/1x1
I0416 11:55:57.086091   977 net.cpp:453] inception_2a/1x1 <- inception_1b/output_inception_1b/output_0_split_0
I0416 11:55:57.086097   977 net.cpp:411] inception_2a/1x1 -> inception_2a/1x1
I0416 11:55:57.086103   977 net.cpp:163] Setting up inception_2a/1x1
I0416 11:55:57.241233   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.241245   977 layer_factory.hpp:74] Creating layer inception_2a/1x1_bn
I0416 11:55:57.241248   977 layer_factory.cpp:191] Layer inception_2a/1x1_bn is using CAFFE engine.
I0416 11:55:57.241255   977 net.cpp:133] Creating Layer inception_2a/1x1_bn
I0416 11:55:57.241258   977 net.cpp:453] inception_2a/1x1_bn <- inception_2a/1x1
I0416 11:55:57.241264   977 net.cpp:411] inception_2a/1x1_bn -> inception_2a/1x1_bn
I0416 11:55:57.241271   977 net.cpp:163] Setting up inception_2a/1x1_bn
I0416 11:55:57.241286   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.241296   977 layer_factory.hpp:74] Creating layer inception_2a/relu_1x1
I0416 11:55:57.241300   977 net.cpp:133] Creating Layer inception_2a/relu_1x1
I0416 11:55:57.241303   977 net.cpp:453] inception_2a/relu_1x1 <- inception_2a/1x1_bn
I0416 11:55:57.241308   977 net.cpp:400] inception_2a/relu_1x1 -> inception_2a/1x1_bn (in-place)
I0416 11:55:57.241313   977 net.cpp:163] Setting up inception_2a/relu_1x1
I0416 11:55:57.241433   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.241439   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_reduce
I0416 11:55:57.241447   977 net.cpp:133] Creating Layer inception_2a/3x3_reduce
I0416 11:55:57.241451   977 net.cpp:453] inception_2a/3x3_reduce <- inception_1b/output_inception_1b/output_0_split_1
I0416 11:55:57.241456   977 net.cpp:411] inception_2a/3x3_reduce -> inception_2a/3x3_reduce
I0416 11:55:57.241462   977 net.cpp:163] Setting up inception_2a/3x3_reduce
I0416 11:55:57.396194   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.396206   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_reduce_bn
I0416 11:55:57.396210   977 layer_factory.cpp:191] Layer inception_2a/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:57.396216   977 net.cpp:133] Creating Layer inception_2a/3x3_reduce_bn
I0416 11:55:57.396220   977 net.cpp:453] inception_2a/3x3_reduce_bn <- inception_2a/3x3_reduce
I0416 11:55:57.396226   977 net.cpp:411] inception_2a/3x3_reduce_bn -> inception_2a/3x3_reduce_bn
I0416 11:55:57.396235   977 net.cpp:163] Setting up inception_2a/3x3_reduce_bn
I0416 11:55:57.396250   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.396258   977 layer_factory.hpp:74] Creating layer inception_2a/relu_3x3_reduce
I0416 11:55:57.396265   977 net.cpp:133] Creating Layer inception_2a/relu_3x3_reduce
I0416 11:55:57.396268   977 net.cpp:453] inception_2a/relu_3x3_reduce <- inception_2a/3x3_reduce_bn
I0416 11:55:57.396272   977 net.cpp:400] inception_2a/relu_3x3_reduce -> inception_2a/3x3_reduce_bn (in-place)
I0416 11:55:57.396276   977 net.cpp:163] Setting up inception_2a/relu_3x3_reduce
I0416 11:55:57.396471   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.396477   977 layer_factory.hpp:74] Creating layer inception_2a/3x3
I0416 11:55:57.396486   977 net.cpp:133] Creating Layer inception_2a/3x3
I0416 11:55:57.396489   977 net.cpp:453] inception_2a/3x3 <- inception_2a/3x3_reduce_bn
I0416 11:55:57.396497   977 net.cpp:411] inception_2a/3x3 -> inception_2a/3x3
I0416 11:55:57.396502   977 net.cpp:163] Setting up inception_2a/3x3
I0416 11:55:57.468760   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.468770   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_bn
I0416 11:55:57.468775   977 layer_factory.cpp:191] Layer inception_2a/3x3_bn is using CAFFE engine.
I0416 11:55:57.468781   977 net.cpp:133] Creating Layer inception_2a/3x3_bn
I0416 11:55:57.468785   977 net.cpp:453] inception_2a/3x3_bn <- inception_2a/3x3
I0416 11:55:57.468791   977 net.cpp:411] inception_2a/3x3_bn -> inception_2a/3x3_bn
I0416 11:55:57.468798   977 net.cpp:163] Setting up inception_2a/3x3_bn
I0416 11:55:57.468814   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.468822   977 layer_factory.hpp:74] Creating layer inception_2a/relu_3x3
I0416 11:55:57.468827   977 net.cpp:133] Creating Layer inception_2a/relu_3x3
I0416 11:55:57.468830   977 net.cpp:453] inception_2a/relu_3x3 <- inception_2a/3x3_bn
I0416 11:55:57.468835   977 net.cpp:400] inception_2a/relu_3x3 -> inception_2a/3x3_bn (in-place)
I0416 11:55:57.468839   977 net.cpp:163] Setting up inception_2a/relu_3x3
I0416 11:55:57.468956   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.468964   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_reduce
I0416 11:55:57.468971   977 net.cpp:133] Creating Layer inception_2a/double_3x3_reduce
I0416 11:55:57.468973   977 net.cpp:453] inception_2a/double_3x3_reduce <- inception_1b/output_inception_1b/output_0_split_2
I0416 11:55:57.468981   977 net.cpp:411] inception_2a/double_3x3_reduce -> inception_2a/double_3x3_reduce
I0416 11:55:57.468988   977 net.cpp:163] Setting up inception_2a/double_3x3_reduce
I0416 11:55:57.623136   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.623147   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623152   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:57.623172   977 net.cpp:133] Creating Layer inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623177   977 net.cpp:453] inception_2a/double_3x3_reduce_bn <- inception_2a/double_3x3_reduce
I0416 11:55:57.623183   977 net.cpp:411] inception_2a/double_3x3_reduce_bn -> inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623189   977 net.cpp:163] Setting up inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623204   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.623213   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_reduce
I0416 11:55:57.623219   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_reduce
I0416 11:55:57.623221   977 net.cpp:453] inception_2a/relu_double_3x3_reduce <- inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623226   977 net.cpp:400] inception_2a/relu_double_3x3_reduce -> inception_2a/double_3x3_reduce_bn (in-place)
I0416 11:55:57.623231   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_reduce
I0416 11:55:57.623350   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.623356   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_1
I0416 11:55:57.623364   977 net.cpp:133] Creating Layer inception_2a/double_3x3_1
I0416 11:55:57.623368   977 net.cpp:453] inception_2a/double_3x3_1 <- inception_2a/double_3x3_reduce_bn
I0416 11:55:57.623374   977 net.cpp:411] inception_2a/double_3x3_1 -> inception_2a/double_3x3_1
I0416 11:55:57.623380   977 net.cpp:163] Setting up inception_2a/double_3x3_1
I0416 11:55:57.695225   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.695236   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_1_bn
I0416 11:55:57.695240   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:57.695246   977 net.cpp:133] Creating Layer inception_2a/double_3x3_1_bn
I0416 11:55:57.695250   977 net.cpp:453] inception_2a/double_3x3_1_bn <- inception_2a/double_3x3_1
I0416 11:55:57.695256   977 net.cpp:411] inception_2a/double_3x3_1_bn -> inception_2a/double_3x3_1_bn
I0416 11:55:57.695263   977 net.cpp:163] Setting up inception_2a/double_3x3_1_bn
I0416 11:55:57.695278   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.695286   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_1
I0416 11:55:57.695291   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_1
I0416 11:55:57.695294   977 net.cpp:453] inception_2a/relu_double_3x3_1 <- inception_2a/double_3x3_1_bn
I0416 11:55:57.695299   977 net.cpp:400] inception_2a/relu_double_3x3_1 -> inception_2a/double_3x3_1_bn (in-place)
I0416 11:55:57.695305   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_1
I0416 11:55:57.695499   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.695505   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_2
I0416 11:55:57.695513   977 net.cpp:133] Creating Layer inception_2a/double_3x3_2
I0416 11:55:57.695516   977 net.cpp:453] inception_2a/double_3x3_2 <- inception_2a/double_3x3_1_bn
I0416 11:55:57.695524   977 net.cpp:411] inception_2a/double_3x3_2 -> inception_2a/double_3x3_2
I0416 11:55:57.695530   977 net.cpp:163] Setting up inception_2a/double_3x3_2
I0416 11:55:57.767465   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.767477   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_2_bn
I0416 11:55:57.767480   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:57.767487   977 net.cpp:133] Creating Layer inception_2a/double_3x3_2_bn
I0416 11:55:57.767490   977 net.cpp:453] inception_2a/double_3x3_2_bn <- inception_2a/double_3x3_2
I0416 11:55:57.767496   977 net.cpp:411] inception_2a/double_3x3_2_bn -> inception_2a/double_3x3_2_bn
I0416 11:55:57.767503   977 net.cpp:163] Setting up inception_2a/double_3x3_2_bn
I0416 11:55:57.767519   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.767526   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_2
I0416 11:55:57.767532   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_2
I0416 11:55:57.767535   977 net.cpp:453] inception_2a/relu_double_3x3_2 <- inception_2a/double_3x3_2_bn
I0416 11:55:57.767541   977 net.cpp:400] inception_2a/relu_double_3x3_2 -> inception_2a/double_3x3_2_bn (in-place)
I0416 11:55:57.767545   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_2
I0416 11:55:57.767665   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.767673   977 layer_factory.hpp:74] Creating layer inception_2a/pool
I0416 11:55:57.767676   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:55:57.767681   977 net.cpp:133] Creating Layer inception_2a/pool
I0416 11:55:57.767684   977 net.cpp:453] inception_2a/pool <- inception_1b/output_inception_1b/output_0_split_3
I0416 11:55:57.767689   977 net.cpp:411] inception_2a/pool -> inception_2a/pool
I0416 11:55:57.767696   977 net.cpp:163] Setting up inception_2a/pool
I0416 11:55:57.767704   977 net.cpp:170] Top shape: 25 384 36 14 (4838400)
I0416 11:55:57.767706   977 layer_factory.hpp:74] Creating layer inception_2a/pool_proj
I0416 11:55:57.767712   977 net.cpp:133] Creating Layer inception_2a/pool_proj
I0416 11:55:57.767715   977 net.cpp:453] inception_2a/pool_proj <- inception_2a/pool
I0416 11:55:57.767722   977 net.cpp:411] inception_2a/pool_proj -> inception_2a/pool_proj
I0416 11:55:57.767727   977 net.cpp:163] Setting up inception_2a/pool_proj
I0416 11:55:57.923708   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.923720   977 layer_factory.hpp:74] Creating layer inception_2a/pool_proj_bn
I0416 11:55:57.923723   977 layer_factory.cpp:191] Layer inception_2a/pool_proj_bn is using CAFFE engine.
I0416 11:55:57.923730   977 net.cpp:133] Creating Layer inception_2a/pool_proj_bn
I0416 11:55:57.923734   977 net.cpp:453] inception_2a/pool_proj_bn <- inception_2a/pool_proj
I0416 11:55:57.923740   977 net.cpp:411] inception_2a/pool_proj_bn -> inception_2a/pool_proj_bn
I0416 11:55:57.923748   977 net.cpp:163] Setting up inception_2a/pool_proj_bn
I0416 11:55:57.923763   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.923784   977 layer_factory.hpp:74] Creating layer inception_2a/relu_pool_proj
I0416 11:55:57.923789   977 net.cpp:133] Creating Layer inception_2a/relu_pool_proj
I0416 11:55:57.923792   977 net.cpp:453] inception_2a/relu_pool_proj <- inception_2a/pool_proj_bn
I0416 11:55:57.923799   977 net.cpp:400] inception_2a/relu_pool_proj -> inception_2a/pool_proj_bn (in-place)
I0416 11:55:57.923804   977 net.cpp:163] Setting up inception_2a/relu_pool_proj
I0416 11:55:57.923923   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:57.923929   977 layer_factory.hpp:74] Creating layer inception_2a/output
I0416 11:55:57.923935   977 net.cpp:133] Creating Layer inception_2a/output
I0416 11:55:57.923938   977 net.cpp:453] inception_2a/output <- inception_2a/1x1_bn
I0416 11:55:57.923943   977 net.cpp:453] inception_2a/output <- inception_2a/3x3_bn
I0416 11:55:57.923946   977 net.cpp:453] inception_2a/output <- inception_2a/double_3x3_2_bn
I0416 11:55:57.923950   977 net.cpp:453] inception_2a/output <- inception_2a/pool_proj_bn
I0416 11:55:57.923956   977 net.cpp:411] inception_2a/output -> inception_2a/output
I0416 11:55:57.923962   977 net.cpp:163] Setting up inception_2a/output
I0416 11:55:57.923969   977 net.cpp:170] Top shape: 25 512 36 14 (6451200)
I0416 11:55:57.923971   977 layer_factory.hpp:74] Creating layer inception_2a/output_inception_2a/output_0_split
I0416 11:55:57.923976   977 net.cpp:133] Creating Layer inception_2a/output_inception_2a/output_0_split
I0416 11:55:57.923979   977 net.cpp:453] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0416 11:55:57.923985   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0416 11:55:57.924003   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0416 11:55:57.924010   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_2
I0416 11:55:57.924015   977 net.cpp:163] Setting up inception_2a/output_inception_2a/output_0_split
I0416 11:55:57.924020   977 net.cpp:170] Top shape: 25 512 36 14 (6451200)
I0416 11:55:57.924023   977 net.cpp:170] Top shape: 25 512 36 14 (6451200)
I0416 11:55:57.924026   977 net.cpp:170] Top shape: 25 512 36 14 (6451200)
I0416 11:55:57.924028   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_reduce
I0416 11:55:57.924034   977 net.cpp:133] Creating Layer inception_2b/3x3_reduce
I0416 11:55:57.924037   977 net.cpp:453] inception_2b/3x3_reduce <- inception_2a/output_inception_2a/output_0_split_0
I0416 11:55:57.924043   977 net.cpp:411] inception_2b/3x3_reduce -> inception_2b/3x3_reduce
I0416 11:55:57.924051   977 net.cpp:163] Setting up inception_2b/3x3_reduce
I0416 11:55:58.124349   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.124361   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_reduce_bn
I0416 11:55:58.124366   977 layer_factory.cpp:191] Layer inception_2b/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:58.124372   977 net.cpp:133] Creating Layer inception_2b/3x3_reduce_bn
I0416 11:55:58.124374   977 net.cpp:453] inception_2b/3x3_reduce_bn <- inception_2b/3x3_reduce
I0416 11:55:58.124382   977 net.cpp:411] inception_2b/3x3_reduce_bn -> inception_2b/3x3_reduce_bn
I0416 11:55:58.124388   977 net.cpp:163] Setting up inception_2b/3x3_reduce_bn
I0416 11:55:58.124403   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.124411   977 layer_factory.hpp:74] Creating layer inception_2b/relu_3x3_reduce
I0416 11:55:58.124418   977 net.cpp:133] Creating Layer inception_2b/relu_3x3_reduce
I0416 11:55:58.124420   977 net.cpp:453] inception_2b/relu_3x3_reduce <- inception_2b/3x3_reduce_bn
I0416 11:55:58.124425   977 net.cpp:400] inception_2b/relu_3x3_reduce -> inception_2b/3x3_reduce_bn (in-place)
I0416 11:55:58.124430   977 net.cpp:163] Setting up inception_2b/relu_3x3_reduce
I0416 11:55:58.124634   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.124641   977 layer_factory.hpp:74] Creating layer inception_2b/3x3
I0416 11:55:58.124649   977 net.cpp:133] Creating Layer inception_2b/3x3
I0416 11:55:58.124652   977 net.cpp:453] inception_2b/3x3 <- inception_2b/3x3_reduce_bn
I0416 11:55:58.124660   977 net.cpp:411] inception_2b/3x3 -> inception_2b/3x3
I0416 11:55:58.124665   977 net.cpp:163] Setting up inception_2b/3x3
I0416 11:55:58.137136   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.137148   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_bn
I0416 11:55:58.137152   977 layer_factory.cpp:191] Layer inception_2b/3x3_bn is using CAFFE engine.
I0416 11:55:58.137158   977 net.cpp:133] Creating Layer inception_2b/3x3_bn
I0416 11:55:58.137162   977 net.cpp:453] inception_2b/3x3_bn <- inception_2b/3x3
I0416 11:55:58.137168   977 net.cpp:411] inception_2b/3x3_bn -> inception_2b/3x3_bn
I0416 11:55:58.137176   977 net.cpp:163] Setting up inception_2b/3x3_bn
I0416 11:55:58.137189   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.137198   977 layer_factory.hpp:74] Creating layer inception_2b/relu_3x3
I0416 11:55:58.137203   977 net.cpp:133] Creating Layer inception_2b/relu_3x3
I0416 11:55:58.137207   977 net.cpp:453] inception_2b/relu_3x3 <- inception_2b/3x3_bn
I0416 11:55:58.137212   977 net.cpp:400] inception_2b/relu_3x3 -> inception_2b/3x3_bn (in-place)
I0416 11:55:58.137217   977 net.cpp:163] Setting up inception_2b/relu_3x3
I0416 11:55:58.137336   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.137343   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_reduce
I0416 11:55:58.137351   977 net.cpp:133] Creating Layer inception_2b/double_3x3_reduce
I0416 11:55:58.137354   977 net.cpp:453] inception_2b/double_3x3_reduce <- inception_2a/output_inception_2a/output_0_split_1
I0416 11:55:58.137361   977 net.cpp:411] inception_2b/double_3x3_reduce -> inception_2b/double_3x3_reduce
I0416 11:55:58.137368   977 net.cpp:163] Setting up inception_2b/double_3x3_reduce
I0416 11:55:58.337677   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.337688   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337692   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:58.337699   977 net.cpp:133] Creating Layer inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337702   977 net.cpp:453] inception_2b/double_3x3_reduce_bn <- inception_2b/double_3x3_reduce
I0416 11:55:58.337709   977 net.cpp:411] inception_2b/double_3x3_reduce_bn -> inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337716   977 net.cpp:163] Setting up inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337731   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.337740   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_reduce
I0416 11:55:58.337745   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_reduce
I0416 11:55:58.337749   977 net.cpp:453] inception_2b/relu_double_3x3_reduce <- inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337754   977 net.cpp:400] inception_2b/relu_double_3x3_reduce -> inception_2b/double_3x3_reduce_bn (in-place)
I0416 11:55:58.337759   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_reduce
I0416 11:55:58.337880   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.337885   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_1
I0416 11:55:58.337893   977 net.cpp:133] Creating Layer inception_2b/double_3x3_1
I0416 11:55:58.337895   977 net.cpp:453] inception_2b/double_3x3_1 <- inception_2b/double_3x3_reduce_bn
I0416 11:55:58.337903   977 net.cpp:411] inception_2b/double_3x3_1 -> inception_2b/double_3x3_1
I0416 11:55:58.337910   977 net.cpp:163] Setting up inception_2b/double_3x3_1
I0416 11:55:58.409931   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.409943   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_1_bn
I0416 11:55:58.409947   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:58.409953   977 net.cpp:133] Creating Layer inception_2b/double_3x3_1_bn
I0416 11:55:58.409957   977 net.cpp:453] inception_2b/double_3x3_1_bn <- inception_2b/double_3x3_1
I0416 11:55:58.409963   977 net.cpp:411] inception_2b/double_3x3_1_bn -> inception_2b/double_3x3_1_bn
I0416 11:55:58.409970   977 net.cpp:163] Setting up inception_2b/double_3x3_1_bn
I0416 11:55:58.409984   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.409992   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_1
I0416 11:55:58.409997   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_1
I0416 11:55:58.410001   977 net.cpp:453] inception_2b/relu_double_3x3_1 <- inception_2b/double_3x3_1_bn
I0416 11:55:58.410004   977 net.cpp:400] inception_2b/relu_double_3x3_1 -> inception_2b/double_3x3_1_bn (in-place)
I0416 11:55:58.410009   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_1
I0416 11:55:58.410277   977 net.cpp:170] Top shape: 25 128 36 14 (1612800)
I0416 11:55:58.410284   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_2
I0416 11:55:58.410291   977 net.cpp:133] Creating Layer inception_2b/double_3x3_2
I0416 11:55:58.410295   977 net.cpp:453] inception_2b/double_3x3_2 <- inception_2b/double_3x3_1_bn
I0416 11:55:58.410302   977 net.cpp:411] inception_2b/double_3x3_2 -> inception_2b/double_3x3_2
I0416 11:55:58.410310   977 net.cpp:163] Setting up inception_2b/double_3x3_2
I0416 11:55:58.422590   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.422600   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_2_bn
I0416 11:55:58.422605   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:58.422610   977 net.cpp:133] Creating Layer inception_2b/double_3x3_2_bn
I0416 11:55:58.422615   977 net.cpp:453] inception_2b/double_3x3_2_bn <- inception_2b/double_3x3_2
I0416 11:55:58.422621   977 net.cpp:411] inception_2b/double_3x3_2_bn -> inception_2b/double_3x3_2_bn
I0416 11:55:58.422627   977 net.cpp:163] Setting up inception_2b/double_3x3_2_bn
I0416 11:55:58.422643   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.422651   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_2
I0416 11:55:58.422657   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_2
I0416 11:55:58.422659   977 net.cpp:453] inception_2b/relu_double_3x3_2 <- inception_2b/double_3x3_2_bn
I0416 11:55:58.422665   977 net.cpp:400] inception_2b/relu_double_3x3_2 -> inception_2b/double_3x3_2_bn (in-place)
I0416 11:55:58.422669   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_2
I0416 11:55:58.422791   977 net.cpp:170] Top shape: 25 128 18 7 (403200)
I0416 11:55:58.422796   977 layer_factory.hpp:74] Creating layer inception_2b/pool
I0416 11:55:58.422803   977 net.cpp:133] Creating Layer inception_2b/pool
I0416 11:55:58.422806   977 net.cpp:453] inception_2b/pool <- inception_2a/output_inception_2a/output_0_split_2
I0416 11:55:58.422811   977 net.cpp:411] inception_2b/pool -> inception_2b/pool
I0416 11:55:58.422818   977 net.cpp:163] Setting up inception_2b/pool
I0416 11:55:58.423007   977 net.cpp:170] Top shape: 25 512 18 7 (1612800)
I0416 11:55:58.423012   977 layer_factory.hpp:74] Creating layer inception_2b/output
I0416 11:55:58.423018   977 net.cpp:133] Creating Layer inception_2b/output
I0416 11:55:58.423022   977 net.cpp:453] inception_2b/output <- inception_2b/3x3_bn
I0416 11:55:58.423027   977 net.cpp:453] inception_2b/output <- inception_2b/double_3x3_2_bn
I0416 11:55:58.423029   977 net.cpp:453] inception_2b/output <- inception_2b/pool
I0416 11:55:58.423037   977 net.cpp:411] inception_2b/output -> inception_2b/output
I0416 11:55:58.423041   977 net.cpp:163] Setting up inception_2b/output
I0416 11:55:58.423048   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:58.423050   977 layer_factory.hpp:74] Creating layer inception_2b/output_inception_2b/output_0_split
I0416 11:55:58.423056   977 net.cpp:133] Creating Layer inception_2b/output_inception_2b/output_0_split
I0416 11:55:58.423059   977 net.cpp:453] inception_2b/output_inception_2b/output_0_split <- inception_2b/output
I0416 11:55:58.423064   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_0
I0416 11:55:58.423070   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_1
I0416 11:55:58.423077   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_2
I0416 11:55:58.423084   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_3
I0416 11:55:58.423089   977 net.cpp:163] Setting up inception_2b/output_inception_2b/output_0_split
I0416 11:55:58.423094   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:58.423097   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:58.423100   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:58.423105   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:58.423106   977 layer_factory.hpp:74] Creating layer inception_3a/1x1
I0416 11:55:58.423115   977 net.cpp:133] Creating Layer inception_3a/1x1
I0416 11:55:58.423117   977 net.cpp:453] inception_3a/1x1 <- inception_2b/output_inception_2b/output_0_split_0
I0416 11:55:58.423122   977 net.cpp:411] inception_3a/1x1 -> inception_3a/1x1
I0416 11:55:58.423128   977 net.cpp:163] Setting up inception_3a/1x1
I0416 11:55:58.578413   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.578425   977 layer_factory.hpp:74] Creating layer inception_3a/1x1_bn
I0416 11:55:58.578429   977 layer_factory.cpp:191] Layer inception_3a/1x1_bn is using CAFFE engine.
I0416 11:55:58.578435   977 net.cpp:133] Creating Layer inception_3a/1x1_bn
I0416 11:55:58.578438   977 net.cpp:453] inception_3a/1x1_bn <- inception_3a/1x1
I0416 11:55:58.578444   977 net.cpp:411] inception_3a/1x1_bn -> inception_3a/1x1_bn
I0416 11:55:58.578451   977 net.cpp:163] Setting up inception_3a/1x1_bn
I0416 11:55:58.578466   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.578475   977 layer_factory.hpp:74] Creating layer inception_3a/relu_1x1
I0416 11:55:58.578480   977 net.cpp:133] Creating Layer inception_3a/relu_1x1
I0416 11:55:58.578483   977 net.cpp:453] inception_3a/relu_1x1 <- inception_3a/1x1_bn
I0416 11:55:58.578487   977 net.cpp:400] inception_3a/relu_1x1 -> inception_3a/1x1_bn (in-place)
I0416 11:55:58.578492   977 net.cpp:163] Setting up inception_3a/relu_1x1
I0416 11:55:58.578680   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.578687   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce
I0416 11:55:58.578693   977 net.cpp:133] Creating Layer inception_3a/3x3_reduce
I0416 11:55:58.578697   977 net.cpp:453] inception_3a/3x3_reduce <- inception_2b/output_inception_2b/output_0_split_1
I0416 11:55:58.578704   977 net.cpp:411] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0416 11:55:58.578711   977 net.cpp:163] Setting up inception_3a/3x3_reduce
I0416 11:55:58.733022   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.733034   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce_bn
I0416 11:55:58.733038   977 layer_factory.cpp:191] Layer inception_3a/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:58.733044   977 net.cpp:133] Creating Layer inception_3a/3x3_reduce_bn
I0416 11:55:58.733047   977 net.cpp:453] inception_3a/3x3_reduce_bn <- inception_3a/3x3_reduce
I0416 11:55:58.733054   977 net.cpp:411] inception_3a/3x3_reduce_bn -> inception_3a/3x3_reduce_bn
I0416 11:55:58.733062   977 net.cpp:163] Setting up inception_3a/3x3_reduce_bn
I0416 11:55:58.733078   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.733085   977 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3_reduce
I0416 11:55:58.733091   977 net.cpp:133] Creating Layer inception_3a/relu_3x3_reduce
I0416 11:55:58.733094   977 net.cpp:453] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce_bn
I0416 11:55:58.733099   977 net.cpp:400] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce_bn (in-place)
I0416 11:55:58.733104   977 net.cpp:163] Setting up inception_3a/relu_3x3_reduce
I0416 11:55:58.733227   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.733232   977 layer_factory.hpp:74] Creating layer inception_3a/3x3
I0416 11:55:58.733239   977 net.cpp:133] Creating Layer inception_3a/3x3
I0416 11:55:58.733242   977 net.cpp:453] inception_3a/3x3 <- inception_3a/3x3_reduce_bn
I0416 11:55:58.733248   977 net.cpp:411] inception_3a/3x3 -> inception_3a/3x3
I0416 11:55:58.733254   977 net.cpp:163] Setting up inception_3a/3x3
I0416 11:55:58.809334   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.809345   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_bn
I0416 11:55:58.809350   977 layer_factory.cpp:191] Layer inception_3a/3x3_bn is using CAFFE engine.
I0416 11:55:58.809356   977 net.cpp:133] Creating Layer inception_3a/3x3_bn
I0416 11:55:58.809360   977 net.cpp:453] inception_3a/3x3_bn <- inception_3a/3x3
I0416 11:55:58.809366   977 net.cpp:411] inception_3a/3x3_bn -> inception_3a/3x3_bn
I0416 11:55:58.809373   977 net.cpp:163] Setting up inception_3a/3x3_bn
I0416 11:55:58.809388   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.809396   977 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3
I0416 11:55:58.809402   977 net.cpp:133] Creating Layer inception_3a/relu_3x3
I0416 11:55:58.809406   977 net.cpp:453] inception_3a/relu_3x3 <- inception_3a/3x3_bn
I0416 11:55:58.809411   977 net.cpp:400] inception_3a/relu_3x3 -> inception_3a/3x3_bn (in-place)
I0416 11:55:58.809415   977 net.cpp:163] Setting up inception_3a/relu_3x3
I0416 11:55:58.809609   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.809617   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce
I0416 11:55:58.809623   977 net.cpp:133] Creating Layer inception_3a/double_3x3_reduce
I0416 11:55:58.809628   977 net.cpp:453] inception_3a/double_3x3_reduce <- inception_2b/output_inception_2b/output_0_split_2
I0416 11:55:58.809634   977 net.cpp:411] inception_3a/double_3x3_reduce -> inception_3a/double_3x3_reduce
I0416 11:55:58.809640   977 net.cpp:163] Setting up inception_3a/double_3x3_reduce
I0416 11:55:58.963835   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.963847   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce_bn
I0416 11:55:58.963851   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:58.963857   977 net.cpp:133] Creating Layer inception_3a/double_3x3_reduce_bn
I0416 11:55:58.963861   977 net.cpp:453] inception_3a/double_3x3_reduce_bn <- inception_3a/double_3x3_reduce
I0416 11:55:58.963868   977 net.cpp:411] inception_3a/double_3x3_reduce_bn -> inception_3a/double_3x3_reduce_bn
I0416 11:55:58.963876   977 net.cpp:163] Setting up inception_3a/double_3x3_reduce_bn
I0416 11:55:58.963891   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.963899   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_reduce
I0416 11:55:58.963904   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_reduce
I0416 11:55:58.963907   977 net.cpp:453] inception_3a/relu_double_3x3_reduce <- inception_3a/double_3x3_reduce_bn
I0416 11:55:58.963913   977 net.cpp:400] inception_3a/relu_double_3x3_reduce -> inception_3a/double_3x3_reduce_bn (in-place)
I0416 11:55:58.963918   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_reduce
I0416 11:55:58.964110   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:58.964118   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1
I0416 11:55:58.964125   977 net.cpp:133] Creating Layer inception_3a/double_3x3_1
I0416 11:55:58.964128   977 net.cpp:453] inception_3a/double_3x3_1 <- inception_3a/double_3x3_reduce_bn
I0416 11:55:58.964134   977 net.cpp:411] inception_3a/double_3x3_1 -> inception_3a/double_3x3_1
I0416 11:55:58.964143   977 net.cpp:163] Setting up inception_3a/double_3x3_1
I0416 11:55:59.040402   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.040415   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1_bn
I0416 11:55:59.040418   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:59.040424   977 net.cpp:133] Creating Layer inception_3a/double_3x3_1_bn
I0416 11:55:59.040429   977 net.cpp:453] inception_3a/double_3x3_1_bn <- inception_3a/double_3x3_1
I0416 11:55:59.040436   977 net.cpp:411] inception_3a/double_3x3_1_bn -> inception_3a/double_3x3_1_bn
I0416 11:55:59.040446   977 net.cpp:163] Setting up inception_3a/double_3x3_1_bn
I0416 11:55:59.040462   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.040469   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_1
I0416 11:55:59.040474   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_1
I0416 11:55:59.040477   977 net.cpp:453] inception_3a/relu_double_3x3_1 <- inception_3a/double_3x3_1_bn
I0416 11:55:59.040482   977 net.cpp:400] inception_3a/relu_double_3x3_1 -> inception_3a/double_3x3_1_bn (in-place)
I0416 11:55:59.040488   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_1
I0416 11:55:59.040606   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.040613   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2
I0416 11:55:59.040621   977 net.cpp:133] Creating Layer inception_3a/double_3x3_2
I0416 11:55:59.040624   977 net.cpp:453] inception_3a/double_3x3_2 <- inception_3a/double_3x3_1_bn
I0416 11:55:59.040629   977 net.cpp:411] inception_3a/double_3x3_2 -> inception_3a/double_3x3_2
I0416 11:55:59.040637   977 net.cpp:163] Setting up inception_3a/double_3x3_2
I0416 11:55:59.117075   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.117087   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2_bn
I0416 11:55:59.117091   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:59.117097   977 net.cpp:133] Creating Layer inception_3a/double_3x3_2_bn
I0416 11:55:59.117101   977 net.cpp:453] inception_3a/double_3x3_2_bn <- inception_3a/double_3x3_2
I0416 11:55:59.117107   977 net.cpp:411] inception_3a/double_3x3_2_bn -> inception_3a/double_3x3_2_bn
I0416 11:55:59.117115   977 net.cpp:163] Setting up inception_3a/double_3x3_2_bn
I0416 11:55:59.117130   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.117138   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_2
I0416 11:55:59.117146   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_2
I0416 11:55:59.117148   977 net.cpp:453] inception_3a/relu_double_3x3_2 <- inception_3a/double_3x3_2_bn
I0416 11:55:59.117153   977 net.cpp:400] inception_3a/relu_double_3x3_2 -> inception_3a/double_3x3_2_bn (in-place)
I0416 11:55:59.117158   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_2
I0416 11:55:59.117357   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.117363   977 layer_factory.hpp:74] Creating layer inception_3a/pool
I0416 11:55:59.117367   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:55:59.117372   977 net.cpp:133] Creating Layer inception_3a/pool
I0416 11:55:59.117377   977 net.cpp:453] inception_3a/pool <- inception_2b/output_inception_2b/output_0_split_3
I0416 11:55:59.117382   977 net.cpp:411] inception_3a/pool -> inception_3a/pool
I0416 11:55:59.117388   977 net.cpp:163] Setting up inception_3a/pool
I0416 11:55:59.117395   977 net.cpp:170] Top shape: 25 768 18 7 (2419200)
I0416 11:55:59.117398   977 layer_factory.hpp:74] Creating layer inception_3a/pool_proj
I0416 11:55:59.117404   977 net.cpp:133] Creating Layer inception_3a/pool_proj
I0416 11:55:59.117408   977 net.cpp:453] inception_3a/pool_proj <- inception_3a/pool
I0416 11:55:59.117414   977 net.cpp:411] inception_3a/pool_proj -> inception_3a/pool_proj
I0416 11:55:59.117420   977 net.cpp:163] Setting up inception_3a/pool_proj
I0416 11:55:59.271930   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.271941   977 layer_factory.hpp:74] Creating layer inception_3a/pool_proj_bn
I0416 11:55:59.271945   977 layer_factory.cpp:191] Layer inception_3a/pool_proj_bn is using CAFFE engine.
I0416 11:55:59.271952   977 net.cpp:133] Creating Layer inception_3a/pool_proj_bn
I0416 11:55:59.271956   977 net.cpp:453] inception_3a/pool_proj_bn <- inception_3a/pool_proj
I0416 11:55:59.271962   977 net.cpp:411] inception_3a/pool_proj_bn -> inception_3a/pool_proj_bn
I0416 11:55:59.271970   977 net.cpp:163] Setting up inception_3a/pool_proj_bn
I0416 11:55:59.271986   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.271993   977 layer_factory.hpp:74] Creating layer inception_3a/relu_pool_proj
I0416 11:55:59.272001   977 net.cpp:133] Creating Layer inception_3a/relu_pool_proj
I0416 11:55:59.272003   977 net.cpp:453] inception_3a/relu_pool_proj <- inception_3a/pool_proj_bn
I0416 11:55:59.272008   977 net.cpp:400] inception_3a/relu_pool_proj -> inception_3a/pool_proj_bn (in-place)
I0416 11:55:59.272013   977 net.cpp:163] Setting up inception_3a/relu_pool_proj
I0416 11:55:59.272203   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.272210   977 layer_factory.hpp:74] Creating layer inception_3a/output
I0416 11:55:59.272217   977 net.cpp:133] Creating Layer inception_3a/output
I0416 11:55:59.272220   977 net.cpp:453] inception_3a/output <- inception_3a/1x1_bn
I0416 11:55:59.272224   977 net.cpp:453] inception_3a/output <- inception_3a/3x3_bn
I0416 11:55:59.272228   977 net.cpp:453] inception_3a/output <- inception_3a/double_3x3_2_bn
I0416 11:55:59.272233   977 net.cpp:453] inception_3a/output <- inception_3a/pool_proj_bn
I0416 11:55:59.272238   977 net.cpp:411] inception_3a/output -> inception_3a/output
I0416 11:55:59.272244   977 net.cpp:163] Setting up inception_3a/output
I0416 11:55:59.272250   977 net.cpp:170] Top shape: 25 1024 18 7 (3225600)
I0416 11:55:59.272253   977 layer_factory.hpp:74] Creating layer inception_3a/output_inception_3a/output_0_split
I0416 11:55:59.272258   977 net.cpp:133] Creating Layer inception_3a/output_inception_3a/output_0_split
I0416 11:55:59.272261   977 net.cpp:453] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0416 11:55:59.272266   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0416 11:55:59.272272   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0416 11:55:59.272279   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0416 11:55:59.272284   977 net.cpp:163] Setting up inception_3a/output_inception_3a/output_0_split
I0416 11:55:59.272289   977 net.cpp:170] Top shape: 25 1024 18 7 (3225600)
I0416 11:55:59.272294   977 net.cpp:170] Top shape: 25 1024 18 7 (3225600)
I0416 11:55:59.272296   977 net.cpp:170] Top shape: 25 1024 18 7 (3225600)
I0416 11:55:59.272300   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce
I0416 11:55:59.272306   977 net.cpp:133] Creating Layer inception_3b/3x3_reduce
I0416 11:55:59.272310   977 net.cpp:453] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_0
I0416 11:55:59.272316   977 net.cpp:411] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0416 11:55:59.272322   977 net.cpp:163] Setting up inception_3b/3x3_reduce
I0416 11:55:59.478793   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.478806   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce_bn
I0416 11:55:59.478809   977 layer_factory.cpp:191] Layer inception_3b/3x3_reduce_bn is using CAFFE engine.
I0416 11:55:59.478816   977 net.cpp:133] Creating Layer inception_3b/3x3_reduce_bn
I0416 11:55:59.478819   977 net.cpp:453] inception_3b/3x3_reduce_bn <- inception_3b/3x3_reduce
I0416 11:55:59.478826   977 net.cpp:411] inception_3b/3x3_reduce_bn -> inception_3b/3x3_reduce_bn
I0416 11:55:59.478833   977 net.cpp:163] Setting up inception_3b/3x3_reduce_bn
I0416 11:55:59.478849   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.478857   977 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3_reduce
I0416 11:55:59.478863   977 net.cpp:133] Creating Layer inception_3b/relu_3x3_reduce
I0416 11:55:59.478865   977 net.cpp:453] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce_bn
I0416 11:55:59.478871   977 net.cpp:400] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce_bn (in-place)
I0416 11:55:59.478876   977 net.cpp:163] Setting up inception_3b/relu_3x3_reduce
I0416 11:55:59.478999   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.479006   977 layer_factory.hpp:74] Creating layer inception_3b/3x3
I0416 11:55:59.479012   977 net.cpp:133] Creating Layer inception_3b/3x3
I0416 11:55:59.479015   977 net.cpp:453] inception_3b/3x3 <- inception_3b/3x3_reduce_bn
I0416 11:55:59.479022   977 net.cpp:411] inception_3b/3x3 -> inception_3b/3x3
I0416 11:55:59.479029   977 net.cpp:163] Setting up inception_3b/3x3
I0416 11:55:59.497238   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.497249   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_bn
I0416 11:55:59.497253   977 layer_factory.cpp:191] Layer inception_3b/3x3_bn is using CAFFE engine.
I0416 11:55:59.497259   977 net.cpp:133] Creating Layer inception_3b/3x3_bn
I0416 11:55:59.497263   977 net.cpp:453] inception_3b/3x3_bn <- inception_3b/3x3
I0416 11:55:59.497269   977 net.cpp:411] inception_3b/3x3_bn -> inception_3b/3x3_bn
I0416 11:55:59.497277   977 net.cpp:163] Setting up inception_3b/3x3_bn
I0416 11:55:59.497292   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.497301   977 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3
I0416 11:55:59.497305   977 net.cpp:133] Creating Layer inception_3b/relu_3x3
I0416 11:55:59.497308   977 net.cpp:453] inception_3b/relu_3x3 <- inception_3b/3x3_bn
I0416 11:55:59.497310   977 net.cpp:400] inception_3b/relu_3x3 -> inception_3b/3x3_bn (in-place)
I0416 11:55:59.497313   977 net.cpp:163] Setting up inception_3b/relu_3x3
I0416 11:55:59.497509   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.497516   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce
I0416 11:55:59.497522   977 net.cpp:133] Creating Layer inception_3b/double_3x3_reduce
I0416 11:55:59.497524   977 net.cpp:453] inception_3b/double_3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0416 11:55:59.497529   977 net.cpp:411] inception_3b/double_3x3_reduce -> inception_3b/double_3x3_reduce
I0416 11:55:59.497534   977 net.cpp:163] Setting up inception_3b/double_3x3_reduce
I0416 11:55:59.704255   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.704265   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704267   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:55:59.704272   977 net.cpp:133] Creating Layer inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704274   977 net.cpp:453] inception_3b/double_3x3_reduce_bn <- inception_3b/double_3x3_reduce
I0416 11:55:59.704278   977 net.cpp:411] inception_3b/double_3x3_reduce_bn -> inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704283   977 net.cpp:163] Setting up inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704293   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.704298   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_reduce
I0416 11:55:59.704319   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_reduce
I0416 11:55:59.704322   977 net.cpp:453] inception_3b/relu_double_3x3_reduce <- inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704325   977 net.cpp:400] inception_3b/relu_double_3x3_reduce -> inception_3b/double_3x3_reduce_bn (in-place)
I0416 11:55:59.704329   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_reduce
I0416 11:55:59.704519   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.704524   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1
I0416 11:55:59.704530   977 net.cpp:133] Creating Layer inception_3b/double_3x3_1
I0416 11:55:59.704531   977 net.cpp:453] inception_3b/double_3x3_1 <- inception_3b/double_3x3_reduce_bn
I0416 11:55:59.704535   977 net.cpp:411] inception_3b/double_3x3_1 -> inception_3b/double_3x3_1
I0416 11:55:59.704540   977 net.cpp:163] Setting up inception_3b/double_3x3_1
I0416 11:55:59.780270   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.780280   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1_bn
I0416 11:55:59.780282   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_1_bn is using CAFFE engine.
I0416 11:55:59.780287   977 net.cpp:133] Creating Layer inception_3b/double_3x3_1_bn
I0416 11:55:59.780289   977 net.cpp:453] inception_3b/double_3x3_1_bn <- inception_3b/double_3x3_1
I0416 11:55:59.780293   977 net.cpp:411] inception_3b/double_3x3_1_bn -> inception_3b/double_3x3_1_bn
I0416 11:55:59.780298   977 net.cpp:163] Setting up inception_3b/double_3x3_1_bn
I0416 11:55:59.780308   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.780313   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_1
I0416 11:55:59.780316   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_1
I0416 11:55:59.780318   977 net.cpp:453] inception_3b/relu_double_3x3_1 <- inception_3b/double_3x3_1_bn
I0416 11:55:59.780321   977 net.cpp:400] inception_3b/relu_double_3x3_1 -> inception_3b/double_3x3_1_bn (in-place)
I0416 11:55:59.780324   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_1
I0416 11:55:59.780439   977 net.cpp:170] Top shape: 25 256 18 7 (806400)
I0416 11:55:59.780444   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2
I0416 11:55:59.780449   977 net.cpp:133] Creating Layer inception_3b/double_3x3_2
I0416 11:55:59.780452   977 net.cpp:453] inception_3b/double_3x3_2 <- inception_3b/double_3x3_1_bn
I0416 11:55:59.780455   977 net.cpp:411] inception_3b/double_3x3_2 -> inception_3b/double_3x3_2
I0416 11:55:59.780459   977 net.cpp:163] Setting up inception_3b/double_3x3_2
I0416 11:55:59.798717   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.798727   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2_bn
I0416 11:55:59.798728   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_2_bn is using CAFFE engine.
I0416 11:55:59.798732   977 net.cpp:133] Creating Layer inception_3b/double_3x3_2_bn
I0416 11:55:59.798735   977 net.cpp:453] inception_3b/double_3x3_2_bn <- inception_3b/double_3x3_2
I0416 11:55:59.798739   977 net.cpp:411] inception_3b/double_3x3_2_bn -> inception_3b/double_3x3_2_bn
I0416 11:55:59.798743   977 net.cpp:163] Setting up inception_3b/double_3x3_2_bn
I0416 11:55:59.798753   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.798758   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_2
I0416 11:55:59.798760   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_2
I0416 11:55:59.798763   977 net.cpp:453] inception_3b/relu_double_3x3_2 <- inception_3b/double_3x3_2_bn
I0416 11:55:59.798765   977 net.cpp:400] inception_3b/relu_double_3x3_2 -> inception_3b/double_3x3_2_bn (in-place)
I0416 11:55:59.798768   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_2
I0416 11:55:59.798959   977 net.cpp:170] Top shape: 25 256 9 4 (230400)
I0416 11:55:59.798966   977 layer_factory.hpp:74] Creating layer inception_3b/pool
I0416 11:55:59.798969   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:55:59.798972   977 net.cpp:133] Creating Layer inception_3b/pool
I0416 11:55:59.798974   977 net.cpp:453] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_2
I0416 11:55:59.798979   977 net.cpp:411] inception_3b/pool -> inception_3b/pool
I0416 11:55:59.798982   977 net.cpp:163] Setting up inception_3b/pool
I0416 11:55:59.798986   977 net.cpp:170] Top shape: 25 1024 9 4 (921600)
I0416 11:55:59.798988   977 layer_factory.hpp:74] Creating layer inception_3b/output
I0416 11:55:59.798991   977 net.cpp:133] Creating Layer inception_3b/output
I0416 11:55:59.798992   977 net.cpp:453] inception_3b/output <- inception_3b/3x3_bn
I0416 11:55:59.798995   977 net.cpp:453] inception_3b/output <- inception_3b/double_3x3_2_bn
I0416 11:55:59.798997   977 net.cpp:453] inception_3b/output <- inception_3b/pool
I0416 11:55:59.799000   977 net.cpp:411] inception_3b/output -> inception_3b/output
I0416 11:55:59.799003   977 net.cpp:163] Setting up inception_3b/output
I0416 11:55:59.799006   977 net.cpp:170] Top shape: 25 1536 9 4 (1382400)
I0416 11:55:59.799008   977 layer_factory.hpp:74] Creating layer global_pool
I0416 11:55:59.799010   977 net.cpp:133] Creating Layer global_pool
I0416 11:55:59.799012   977 net.cpp:453] global_pool <- inception_3b/output
I0416 11:55:59.799015   977 net.cpp:411] global_pool -> global_pool
I0416 11:55:59.799018   977 net.cpp:163] Setting up global_pool
I0416 11:55:59.799199   977 net.cpp:170] Top shape: 25 1536 1 1 (38400)
I0416 11:55:59.799206   977 layer_factory.hpp:74] Creating layer gather_global_pool_to_fc7
I0416 11:55:59.799209   977 net.cpp:133] Creating Layer gather_global_pool_to_fc7
I0416 11:55:59.799211   977 net.cpp:453] gather_global_pool_to_fc7 <- global_pool
I0416 11:55:59.799214   977 net.cpp:411] gather_global_pool_to_fc7 -> gathered_global_pool
I0416 11:55:59.799218   977 net.cpp:163] Setting up gather_global_pool_to_fc7
I0416 11:55:59.799221   977 net.cpp:170] Top shape: 50 1536 1 1 (76800)
I0416 11:55:59.799222   977 layer_factory.hpp:74] Creating layer fc7
I0416 11:55:59.799226   977 net.cpp:133] Creating Layer fc7
I0416 11:55:59.799228   977 net.cpp:453] fc7 <- gathered_global_pool
I0416 11:55:59.799232   977 net.cpp:411] fc7 -> fc7
I0416 11:55:59.799234   977 net.cpp:163] Setting up fc7
I0416 11:55:59.800776   977 net.cpp:170] Top shape: 50 256 (12800)
I0416 11:55:59.800782   977 layer_factory.hpp:74] Creating layer fc7_bn
I0416 11:55:59.800784   977 layer_factory.cpp:191] Layer fc7_bn is using CAFFE engine.
I0416 11:55:59.800788   977 net.cpp:133] Creating Layer fc7_bn
I0416 11:55:59.800791   977 net.cpp:453] fc7_bn <- fc7
I0416 11:55:59.800793   977 net.cpp:411] fc7_bn -> fc7_bn
I0416 11:55:59.800797   977 net.cpp:163] Setting up fc7_bn
I0416 11:55:59.800806   977 net.cpp:170] Top shape: 50 256 (12800)
I0416 11:55:59.800809   977 layer_factory.hpp:74] Creating layer relu7
I0416 11:55:59.800812   977 net.cpp:133] Creating Layer relu7
I0416 11:55:59.800813   977 net.cpp:453] relu7 <- fc7_bn
I0416 11:55:59.800817   977 net.cpp:400] relu7 -> fc7_bn (in-place)
I0416 11:55:59.800818   977 net.cpp:163] Setting up relu7
I0416 11:55:59.801012   977 net.cpp:170] Top shape: 50 256 (12800)
I0416 11:55:59.801017   977 layer_factory.hpp:74] Creating layer drop7
I0416 11:55:59.801022   977 net.cpp:133] Creating Layer drop7
I0416 11:55:59.801023   977 net.cpp:453] drop7 <- fc7_bn
I0416 11:55:59.801026   977 net.cpp:400] drop7 -> fc7_bn (in-place)
I0416 11:55:59.801029   977 net.cpp:163] Setting up drop7
I0416 11:55:59.801035   977 net.cpp:170] Top shape: 50 256 (12800)
I0416 11:55:59.801036   977 layer_factory.hpp:74] Creating layer fc8_cuhk03
I0416 11:55:59.801039   977 net.cpp:133] Creating Layer fc8_cuhk03
I0416 11:55:59.801041   977 net.cpp:453] fc8_cuhk03 <- fc7_bn
I0416 11:55:59.801045   977 net.cpp:411] fc8_cuhk03 -> fc8_cuhk03
I0416 11:55:59.801048   977 net.cpp:163] Setting up fc8_cuhk03
I0416 11:55:59.803606   977 net.cpp:170] Top shape: 50 1467 (73350)
I0416 11:55:59.803612   977 layer_factory.hpp:74] Creating layer gather_data_to_loss
I0416 11:55:59.803616   977 net.cpp:133] Creating Layer gather_data_to_loss
I0416 11:55:59.803617   977 net.cpp:453] gather_data_to_loss <- label
I0416 11:55:59.803620   977 net.cpp:411] gather_data_to_loss -> gathered_label
I0416 11:55:59.803623   977 net.cpp:163] Setting up gather_data_to_loss
I0416 11:55:59.803627   977 net.cpp:170] Top shape: 50 (50)
I0416 11:55:59.803628   977 layer_factory.hpp:74] Creating layer loss
I0416 11:55:59.803632   977 net.cpp:133] Creating Layer loss
I0416 11:55:59.803633   977 net.cpp:453] loss <- fc8_cuhk03
I0416 11:55:59.803635   977 net.cpp:453] loss <- gathered_label
I0416 11:55:59.803637   977 net.cpp:411] loss -> loss
I0416 11:55:59.803640   977 net.cpp:163] Setting up loss
I0416 11:55:59.803649   977 layer_factory.hpp:74] Creating layer loss
I0416 11:55:59.803838   977 net.cpp:170] Top shape: (1)
I0416 11:55:59.803843   977 net.cpp:172]     with loss weight 1
I0416 11:55:59.803855   977 net.cpp:235] loss needs backward computation.
I0416 11:55:59.803858   977 net.cpp:237] gather_data_to_loss does not need backward computation.
I0416 11:55:59.803860   977 net.cpp:235] fc8_cuhk03 needs backward computation.
I0416 11:55:59.803863   977 net.cpp:235] drop7 needs backward computation.
I0416 11:55:59.803864   977 net.cpp:235] relu7 needs backward computation.
I0416 11:55:59.803864   977 net.cpp:235] fc7_bn needs backward computation.
I0416 11:55:59.803866   977 net.cpp:235] fc7 needs backward computation.
I0416 11:55:59.803869   977 net.cpp:235] gather_global_pool_to_fc7 needs backward computation.
I0416 11:55:59.803870   977 net.cpp:235] global_pool needs backward computation.
I0416 11:55:59.803872   977 net.cpp:235] inception_3b/output needs backward computation.
I0416 11:55:59.803875   977 net.cpp:235] inception_3b/pool needs backward computation.
I0416 11:55:59.803877   977 net.cpp:235] inception_3b/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.803879   977 net.cpp:235] inception_3b/double_3x3_2_bn needs backward computation.
I0416 11:55:59.803880   977 net.cpp:235] inception_3b/double_3x3_2 needs backward computation.
I0416 11:55:59.803884   977 net.cpp:235] inception_3b/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.803885   977 net.cpp:235] inception_3b/double_3x3_1_bn needs backward computation.
I0416 11:55:59.803887   977 net.cpp:235] inception_3b/double_3x3_1 needs backward computation.
I0416 11:55:59.803889   977 net.cpp:235] inception_3b/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.803891   977 net.cpp:235] inception_3b/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.803892   977 net.cpp:235] inception_3b/double_3x3_reduce needs backward computation.
I0416 11:55:59.803894   977 net.cpp:235] inception_3b/relu_3x3 needs backward computation.
I0416 11:55:59.803896   977 net.cpp:235] inception_3b/3x3_bn needs backward computation.
I0416 11:55:59.803899   977 net.cpp:235] inception_3b/3x3 needs backward computation.
I0416 11:55:59.803900   977 net.cpp:235] inception_3b/relu_3x3_reduce needs backward computation.
I0416 11:55:59.803902   977 net.cpp:235] inception_3b/3x3_reduce_bn needs backward computation.
I0416 11:55:59.803905   977 net.cpp:235] inception_3b/3x3_reduce needs backward computation.
I0416 11:55:59.803906   977 net.cpp:235] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0416 11:55:59.803908   977 net.cpp:235] inception_3a/output needs backward computation.
I0416 11:55:59.803912   977 net.cpp:235] inception_3a/relu_pool_proj needs backward computation.
I0416 11:55:59.803915   977 net.cpp:235] inception_3a/pool_proj_bn needs backward computation.
I0416 11:55:59.803916   977 net.cpp:235] inception_3a/pool_proj needs backward computation.
I0416 11:55:59.803918   977 net.cpp:235] inception_3a/pool needs backward computation.
I0416 11:55:59.803920   977 net.cpp:235] inception_3a/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.803922   977 net.cpp:235] inception_3a/double_3x3_2_bn needs backward computation.
I0416 11:55:59.803925   977 net.cpp:235] inception_3a/double_3x3_2 needs backward computation.
I0416 11:55:59.803927   977 net.cpp:235] inception_3a/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.803930   977 net.cpp:235] inception_3a/double_3x3_1_bn needs backward computation.
I0416 11:55:59.803931   977 net.cpp:235] inception_3a/double_3x3_1 needs backward computation.
I0416 11:55:59.803933   977 net.cpp:235] inception_3a/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.803936   977 net.cpp:235] inception_3a/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.803937   977 net.cpp:235] inception_3a/double_3x3_reduce needs backward computation.
I0416 11:55:59.803941   977 net.cpp:235] inception_3a/relu_3x3 needs backward computation.
I0416 11:55:59.803944   977 net.cpp:235] inception_3a/3x3_bn needs backward computation.
I0416 11:55:59.803948   977 net.cpp:235] inception_3a/3x3 needs backward computation.
I0416 11:55:59.803952   977 net.cpp:235] inception_3a/relu_3x3_reduce needs backward computation.
I0416 11:55:59.803954   977 net.cpp:235] inception_3a/3x3_reduce_bn needs backward computation.
I0416 11:55:59.803956   977 net.cpp:235] inception_3a/3x3_reduce needs backward computation.
I0416 11:55:59.803958   977 net.cpp:235] inception_3a/relu_1x1 needs backward computation.
I0416 11:55:59.803961   977 net.cpp:235] inception_3a/1x1_bn needs backward computation.
I0416 11:55:59.803962   977 net.cpp:235] inception_3a/1x1 needs backward computation.
I0416 11:55:59.803966   977 net.cpp:235] inception_2b/output_inception_2b/output_0_split needs backward computation.
I0416 11:55:59.803967   977 net.cpp:235] inception_2b/output needs backward computation.
I0416 11:55:59.803971   977 net.cpp:235] inception_2b/pool needs backward computation.
I0416 11:55:59.803973   977 net.cpp:235] inception_2b/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.803975   977 net.cpp:235] inception_2b/double_3x3_2_bn needs backward computation.
I0416 11:55:59.803978   977 net.cpp:235] inception_2b/double_3x3_2 needs backward computation.
I0416 11:55:59.803980   977 net.cpp:235] inception_2b/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.803982   977 net.cpp:235] inception_2b/double_3x3_1_bn needs backward computation.
I0416 11:55:59.803984   977 net.cpp:235] inception_2b/double_3x3_1 needs backward computation.
I0416 11:55:59.803987   977 net.cpp:235] inception_2b/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.803989   977 net.cpp:235] inception_2b/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.803992   977 net.cpp:235] inception_2b/double_3x3_reduce needs backward computation.
I0416 11:55:59.803995   977 net.cpp:235] inception_2b/relu_3x3 needs backward computation.
I0416 11:55:59.803997   977 net.cpp:235] inception_2b/3x3_bn needs backward computation.
I0416 11:55:59.803999   977 net.cpp:235] inception_2b/3x3 needs backward computation.
I0416 11:55:59.804002   977 net.cpp:235] inception_2b/relu_3x3_reduce needs backward computation.
I0416 11:55:59.804003   977 net.cpp:235] inception_2b/3x3_reduce_bn needs backward computation.
I0416 11:55:59.804005   977 net.cpp:235] inception_2b/3x3_reduce needs backward computation.
I0416 11:55:59.804008   977 net.cpp:235] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0416 11:55:59.804010   977 net.cpp:235] inception_2a/output needs backward computation.
I0416 11:55:59.804013   977 net.cpp:235] inception_2a/relu_pool_proj needs backward computation.
I0416 11:55:59.804015   977 net.cpp:235] inception_2a/pool_proj_bn needs backward computation.
I0416 11:55:59.804018   977 net.cpp:235] inception_2a/pool_proj needs backward computation.
I0416 11:55:59.804019   977 net.cpp:235] inception_2a/pool needs backward computation.
I0416 11:55:59.804023   977 net.cpp:235] inception_2a/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.804024   977 net.cpp:235] inception_2a/double_3x3_2_bn needs backward computation.
I0416 11:55:59.804026   977 net.cpp:235] inception_2a/double_3x3_2 needs backward computation.
I0416 11:55:59.804028   977 net.cpp:235] inception_2a/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.804030   977 net.cpp:235] inception_2a/double_3x3_1_bn needs backward computation.
I0416 11:55:59.804033   977 net.cpp:235] inception_2a/double_3x3_1 needs backward computation.
I0416 11:55:59.804034   977 net.cpp:235] inception_2a/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.804036   977 net.cpp:235] inception_2a/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.804039   977 net.cpp:235] inception_2a/double_3x3_reduce needs backward computation.
I0416 11:55:59.804042   977 net.cpp:235] inception_2a/relu_3x3 needs backward computation.
I0416 11:55:59.804044   977 net.cpp:235] inception_2a/3x3_bn needs backward computation.
I0416 11:55:59.804046   977 net.cpp:235] inception_2a/3x3 needs backward computation.
I0416 11:55:59.804049   977 net.cpp:235] inception_2a/relu_3x3_reduce needs backward computation.
I0416 11:55:59.804050   977 net.cpp:235] inception_2a/3x3_reduce_bn needs backward computation.
I0416 11:55:59.804054   977 net.cpp:235] inception_2a/3x3_reduce needs backward computation.
I0416 11:55:59.804055   977 net.cpp:235] inception_2a/relu_1x1 needs backward computation.
I0416 11:55:59.804057   977 net.cpp:235] inception_2a/1x1_bn needs backward computation.
I0416 11:55:59.804059   977 net.cpp:235] inception_2a/1x1 needs backward computation.
I0416 11:55:59.804061   977 net.cpp:235] inception_1b/output_inception_1b/output_0_split needs backward computation.
I0416 11:55:59.804064   977 net.cpp:235] inception_1b/output needs backward computation.
I0416 11:55:59.804067   977 net.cpp:235] inception_1b/pool needs backward computation.
I0416 11:55:59.804069   977 net.cpp:235] inception_1b/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.804071   977 net.cpp:235] inception_1b/double_3x3_2_bn needs backward computation.
I0416 11:55:59.804075   977 net.cpp:235] inception_1b/double_3x3_2 needs backward computation.
I0416 11:55:59.804076   977 net.cpp:235] inception_1b/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.804078   977 net.cpp:235] inception_1b/double_3x3_1_bn needs backward computation.
I0416 11:55:59.804080   977 net.cpp:235] inception_1b/double_3x3_1 needs backward computation.
I0416 11:55:59.804082   977 net.cpp:235] inception_1b/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.804085   977 net.cpp:235] inception_1b/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.804086   977 net.cpp:235] inception_1b/double_3x3_reduce needs backward computation.
I0416 11:55:59.804090   977 net.cpp:235] inception_1b/relu_3x3 needs backward computation.
I0416 11:55:59.804091   977 net.cpp:235] inception_1b/3x3_bn needs backward computation.
I0416 11:55:59.804095   977 net.cpp:235] inception_1b/3x3 needs backward computation.
I0416 11:55:59.804096   977 net.cpp:235] inception_1b/relu_3x3_reduce needs backward computation.
I0416 11:55:59.804098   977 net.cpp:235] inception_1b/3x3_reduce_bn needs backward computation.
I0416 11:55:59.804101   977 net.cpp:235] inception_1b/3x3_reduce needs backward computation.
I0416 11:55:59.804103   977 net.cpp:235] inception_1a/output_inception_1a/output_0_split needs backward computation.
I0416 11:55:59.804105   977 net.cpp:235] inception_1a/output needs backward computation.
I0416 11:55:59.804110   977 net.cpp:235] inception_1a/relu_pool_proj needs backward computation.
I0416 11:55:59.804111   977 net.cpp:235] inception_1a/pool_proj_bn needs backward computation.
I0416 11:55:59.804113   977 net.cpp:235] inception_1a/pool_proj needs backward computation.
I0416 11:55:59.804116   977 net.cpp:235] inception_1a/pool needs backward computation.
I0416 11:55:59.804117   977 net.cpp:235] inception_1a/relu_double_3x3_2 needs backward computation.
I0416 11:55:59.804119   977 net.cpp:235] inception_1a/double_3x3_2_bn needs backward computation.
I0416 11:55:59.804121   977 net.cpp:235] inception_1a/double_3x3_2 needs backward computation.
I0416 11:55:59.804123   977 net.cpp:235] inception_1a/relu_double_3x3_1 needs backward computation.
I0416 11:55:59.804126   977 net.cpp:235] inception_1a/double_3x3_1_bn needs backward computation.
I0416 11:55:59.804127   977 net.cpp:235] inception_1a/double_3x3_1 needs backward computation.
I0416 11:55:59.804129   977 net.cpp:235] inception_1a/relu_double_3x3_reduce needs backward computation.
I0416 11:55:59.804131   977 net.cpp:235] inception_1a/double_3x3_reduce_bn needs backward computation.
I0416 11:55:59.804133   977 net.cpp:235] inception_1a/double_3x3_reduce needs backward computation.
I0416 11:55:59.804136   977 net.cpp:235] inception_1a/relu_3x3 needs backward computation.
I0416 11:55:59.804137   977 net.cpp:235] inception_1a/3x3_bn needs backward computation.
I0416 11:55:59.804139   977 net.cpp:235] inception_1a/3x3 needs backward computation.
I0416 11:55:59.804141   977 net.cpp:235] inception_1a/relu_3x3_reduce needs backward computation.
I0416 11:55:59.804143   977 net.cpp:235] inception_1a/3x3_reduce_bn needs backward computation.
I0416 11:55:59.804147   977 net.cpp:235] inception_1a/3x3_reduce needs backward computation.
I0416 11:55:59.804148   977 net.cpp:235] inception_1a/relu_1x1 needs backward computation.
I0416 11:55:59.804150   977 net.cpp:235] inception_1a/1x1_bn needs backward computation.
I0416 11:55:59.804152   977 net.cpp:235] inception_1a/1x1 needs backward computation.
I0416 11:55:59.804154   977 net.cpp:235] pool1_pool1_0_split needs backward computation.
I0416 11:55:59.804157   977 net.cpp:235] pool1 needs backward computation.
I0416 11:55:59.804159   977 net.cpp:235] relu3 needs backward computation.
I0416 11:55:59.804162   977 net.cpp:235] conv3_bn needs backward computation.
I0416 11:55:59.804163   977 net.cpp:235] conv3 needs backward computation.
I0416 11:55:59.804165   977 net.cpp:235] relu2 needs backward computation.
I0416 11:55:59.804167   977 net.cpp:235] conv2_bn needs backward computation.
I0416 11:55:59.804168   977 net.cpp:235] conv2 needs backward computation.
I0416 11:55:59.804170   977 net.cpp:235] relu1 needs backward computation.
I0416 11:55:59.804172   977 net.cpp:235] conv1_bn needs backward computation.
I0416 11:55:59.804174   977 net.cpp:235] conv1 needs backward computation.
I0416 11:55:59.804177   977 net.cpp:237] data does not need backward computation.
I0416 11:55:59.804178   977 net.cpp:278] This network produces output loss
I0416 11:55:59.804266   977 net.cpp:290] Network initialization done.
I0416 11:55:59.804270   977 net.cpp:291] Memory required for data: 1550284104
I0416 11:55:59.809721   977 solver.cpp:166] Creating test net (#0) specified by net file: models/individually/cuhk03_trainval.prototxt
I0416 11:55:59.809829   977 net.cpp:330] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0416 11:55:59.810474   977 net.cpp:47] Initializing net from parameters:
name: "CUHK03"
state {
  phase: TEST
}
richness: 1000
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 102
    mean_value: 102
    mean_value: 101
    crop_height: 144
    crop_width: 56
  }
  data_param {
    source: "external/exp/db/cuhk03/val_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BN"
  bottom: "conv1"
  top: "conv1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_bn"
  top: "conv1_bn"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_bn"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2_bn"
  type: "BN"
  bottom: "conv2"
  top: "conv2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_bn"
  top: "conv2_bn"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_bn"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3_bn"
  type: "BN"
  bottom: "conv3"
  top: "conv3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_bn"
  top: "conv3_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv3_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "inception_1a/1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/1x1_bn"
  type: "BN"
  bottom: "inception_1a/1x1"
  top: "inception_1a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_1x1"
  type: "ReLU"
  bottom: "inception_1a/1x1_bn"
  top: "inception_1a/1x1_bn"
}
layer {
  name: "inception_1a/3x3_reduce"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1a/3x3_reduce"
  top: "inception_1a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1a/3x3_reduce_bn"
  top: "inception_1a/3x3_reduce_bn"
}
layer {
  name: "inception_1a/3x3"
  type: "Convolution"
  bottom: "inception_1a/3x3_reduce_bn"
  top: "inception_1a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/3x3_bn"
  type: "BN"
  bottom: "inception_1a/3x3"
  top: "inception_1a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_3x3"
  type: "ReLU"
  bottom: "inception_1a/3x3_bn"
  top: "inception_1a/3x3_bn"
}
layer {
  name: "inception_1a/double_3x3_reduce"
  type: "Convolution"
  bottom: "pool1"
  top: "inception_1a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_reduce"
  top: "inception_1a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_reduce_bn"
  top: "inception_1a/double_3x3_reduce_bn"
}
layer {
  name: "inception_1a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_1a/double_3x3_reduce_bn"
  top: "inception_1a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_1"
  top: "inception_1a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_1_bn"
  top: "inception_1a/double_3x3_1_bn"
}
layer {
  name: "inception_1a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_1a/double_3x3_1_bn"
  top: "inception_1a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_1a/double_3x3_2"
  top: "inception_1a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_1a/double_3x3_2_bn"
  top: "inception_1a/double_3x3_2_bn"
}
layer {
  name: "inception_1a/pool"
  type: "Pooling"
  bottom: "pool1"
  top: "inception_1a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_1a/pool_proj"
  type: "Convolution"
  bottom: "inception_1a/pool"
  top: "inception_1a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1a/pool_proj_bn"
  type: "BN"
  bottom: "inception_1a/pool_proj"
  top: "inception_1a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_1a/pool_proj_bn"
  top: "inception_1a/pool_proj_bn"
}
layer {
  name: "inception_1a/output"
  type: "Concat"
  bottom: "inception_1a/1x1_bn"
  bottom: "inception_1a/3x3_bn"
  bottom: "inception_1a/double_3x3_2_bn"
  bottom: "inception_1a/pool_proj_bn"
  top: "inception_1a/output"
}
layer {
  name: "inception_1b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_1a/output"
  top: "inception_1b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1b/3x3_reduce"
  top: "inception_1b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1b/3x3_reduce_bn"
  top: "inception_1b/3x3_reduce_bn"
}
layer {
  name: "inception_1b/3x3"
  type: "Convolution"
  bottom: "inception_1b/3x3_reduce_bn"
  top: "inception_1b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/3x3_bn"
  type: "BN"
  bottom: "inception_1b/3x3"
  top: "inception_1b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_3x3"
  type: "ReLU"
  bottom: "inception_1b/3x3_bn"
  top: "inception_1b/3x3_bn"
}
layer {
  name: "inception_1b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_1a/output"
  top: "inception_1b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_reduce"
  top: "inception_1b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_reduce_bn"
  top: "inception_1b/double_3x3_reduce_bn"
}
layer {
  name: "inception_1b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_1b/double_3x3_reduce_bn"
  top: "inception_1b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_1"
  top: "inception_1b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_1_bn"
  top: "inception_1b/double_3x3_1_bn"
}
layer {
  name: "inception_1b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_1b/double_3x3_1_bn"
  top: "inception_1b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_1b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_1b/double_3x3_2"
  top: "inception_1b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_1b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_1b/double_3x3_2_bn"
  top: "inception_1b/double_3x3_2_bn"
}
layer {
  name: "inception_1b/pool"
  type: "Pooling"
  bottom: "inception_1a/output"
  top: "inception_1b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_1b/output"
  type: "Concat"
  bottom: "inception_1b/3x3_bn"
  bottom: "inception_1b/double_3x3_2_bn"
  bottom: "inception_1b/pool"
  top: "inception_1b/output"
}
layer {
  name: "inception_2a/1x1"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/1x1_bn"
  type: "BN"
  bottom: "inception_2a/1x1"
  top: "inception_2a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_1x1"
  type: "ReLU"
  bottom: "inception_2a/1x1_bn"
  top: "inception_2a/1x1_bn"
}
layer {
  name: "inception_2a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2a/3x3_reduce"
  top: "inception_2a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2a/3x3_reduce_bn"
  top: "inception_2a/3x3_reduce_bn"
}
layer {
  name: "inception_2a/3x3"
  type: "Convolution"
  bottom: "inception_2a/3x3_reduce_bn"
  top: "inception_2a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/3x3_bn"
  type: "BN"
  bottom: "inception_2a/3x3"
  top: "inception_2a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_3x3"
  type: "ReLU"
  bottom: "inception_2a/3x3_bn"
  top: "inception_2a/3x3_bn"
}
layer {
  name: "inception_2a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_1b/output"
  top: "inception_2a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_reduce"
  top: "inception_2a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_reduce_bn"
  top: "inception_2a/double_3x3_reduce_bn"
}
layer {
  name: "inception_2a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_2a/double_3x3_reduce_bn"
  top: "inception_2a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_1"
  top: "inception_2a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_1_bn"
  top: "inception_2a/double_3x3_1_bn"
}
layer {
  name: "inception_2a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_2a/double_3x3_1_bn"
  top: "inception_2a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_2a/double_3x3_2"
  top: "inception_2a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_2a/double_3x3_2_bn"
  top: "inception_2a/double_3x3_2_bn"
}
layer {
  name: "inception_2a/pool"
  type: "Pooling"
  bottom: "inception_1b/output"
  top: "inception_2a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_2a/pool_proj"
  type: "Convolution"
  bottom: "inception_2a/pool"
  top: "inception_2a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2a/pool_proj_bn"
  type: "BN"
  bottom: "inception_2a/pool_proj"
  top: "inception_2a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_2a/pool_proj_bn"
  top: "inception_2a/pool_proj_bn"
}
layer {
  name: "inception_2a/output"
  type: "Concat"
  bottom: "inception_2a/1x1_bn"
  bottom: "inception_2a/3x3_bn"
  bottom: "inception_2a/double_3x3_2_bn"
  bottom: "inception_2a/pool_proj_bn"
  top: "inception_2a/output"
}
layer {
  name: "inception_2b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_2b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2b/3x3_reduce"
  top: "inception_2b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2b/3x3_reduce_bn"
  top: "inception_2b/3x3_reduce_bn"
}
layer {
  name: "inception_2b/3x3"
  type: "Convolution"
  bottom: "inception_2b/3x3_reduce_bn"
  top: "inception_2b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/3x3_bn"
  type: "BN"
  bottom: "inception_2b/3x3"
  top: "inception_2b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_3x3"
  type: "ReLU"
  bottom: "inception_2b/3x3_bn"
  top: "inception_2b/3x3_bn"
}
layer {
  name: "inception_2b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_2a/output"
  top: "inception_2b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_reduce"
  top: "inception_2b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_reduce_bn"
  top: "inception_2b/double_3x3_reduce_bn"
}
layer {
  name: "inception_2b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_2b/double_3x3_reduce_bn"
  top: "inception_2b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_1"
  top: "inception_2b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_1_bn"
  top: "inception_2b/double_3x3_1_bn"
}
layer {
  name: "inception_2b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_2b/double_3x3_1_bn"
  top: "inception_2b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_2b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_2b/double_3x3_2"
  top: "inception_2b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_2b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_2b/double_3x3_2_bn"
  top: "inception_2b/double_3x3_2_bn"
}
layer {
  name: "inception_2b/pool"
  type: "Pooling"
  bottom: "inception_2a/output"
  top: "inception_2b/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_2b/output"
  type: "Concat"
  bottom: "inception_2b/3x3_bn"
  bottom: "inception_2b/double_3x3_2_bn"
  bottom: "inception_2b/pool"
  top: "inception_2b/output"
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1_bn"
  type: "BN"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1_bn"
  top: "inception_3a/1x1_bn"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3_reduce_bn"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_bn"
  type: "BN"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3_bn"
  top: "inception_3a/3x3_bn"
}
layer {
  name: "inception_3a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_2b/output"
  top: "inception_3a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_reduce"
  top: "inception_3a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
I0416 11:55:59.811396   977 layer_factory.hpp:74] Creating layer data
I0416 11:55:59.811408   977 net.cpp:133] Creating Layer data
I0416 11:55:59.811410   977 net.cpp:411] data -> data
I0416 11:55:59.811416   977 net.cpp:411] data -> label
I0416 11:55:59.811419   977 net.cpp:163] Setting up data
I0416 11:55:59.811466   977 db_lmdb.cpp:22] Opened lmdb external/exp/db/cuhk03/val_lmdb
I0416 11:55:59.811480   977 data_layer.cpp:55] Skipping first 0 data points.
I0416 11:55:59.811493   977 data_layer.cpp:100] output data size: 10,3,144,56
I0416 11:55:59.811619   977 net.cpp:170] Top shape: 10 3 144 56 (241920)
I0416 11:55:59.811625   977 net.cpp:170] Top shape: 10 (10)
I0416 11:55:59.811628   977 layer_factory.hpp:74] Creating layer label_data_1_split
I0416 11:55:59.811633   977 net.cpp:133] Creating Layer label_data_1_split
I0416 11:55:59.811637   977 net.cpp:453] label_data_1_split <- label
I0416 11:55:59.811642   977 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0416 11:55:59.811648   977 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0416 11:55:59.811653   977 net.cpp:163] Setting up label_data_1_split
I0416 11:55:59.811660   977 net.cpp:170] Top shape: 10 (10)
I0416 11:55:59.811662   977 net.cpp:170] Top shape: 10 (10)
I0416 11:55:59.811666   977 layer_factory.hpp:74] Creating layer conv1
I0416 11:55:59.811672   977 net.cpp:133] Creating Layer conv1
I0416 11:55:59.811676   977 net.cpp:453] conv1 <- data
I0416 11:55:59.811681   977 net.cpp:411] conv1 -> conv1
I0416 11:55:59.811686   977 net.cpp:163] Setting up conv1
I0416 11:55:59.842111   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.842124   977 layer_factory.hpp:74] Creating layer conv1_bn
I0416 11:55:59.842128   977 layer_factory.cpp:191] Layer conv1_bn is using CAFFE engine.
I0416 11:55:59.842133   977 net.cpp:133] Creating Layer conv1_bn
I0416 11:55:59.842133   977 net.cpp:453] conv1_bn <- conv1
I0416 11:55:59.842138   977 net.cpp:411] conv1_bn -> conv1_bn
I0416 11:55:59.842141   977 net.cpp:163] Setting up conv1_bn
I0416 11:55:59.842159   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.842165   977 layer_factory.hpp:74] Creating layer relu1
I0416 11:55:59.842170   977 net.cpp:133] Creating Layer relu1
I0416 11:55:59.842171   977 net.cpp:453] relu1 <- conv1_bn
I0416 11:55:59.842175   977 net.cpp:400] relu1 -> conv1_bn (in-place)
I0416 11:55:59.842176   977 net.cpp:163] Setting up relu1
I0416 11:55:59.842480   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.842486   977 layer_factory.hpp:74] Creating layer conv2
I0416 11:55:59.842490   977 net.cpp:133] Creating Layer conv2
I0416 11:55:59.842492   977 net.cpp:453] conv2 <- conv1_bn
I0416 11:55:59.842496   977 net.cpp:411] conv2 -> conv2
I0416 11:55:59.842500   977 net.cpp:163] Setting up conv2
I0416 11:55:59.925039   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.925048   977 layer_factory.hpp:74] Creating layer conv2_bn
I0416 11:55:59.925051   977 layer_factory.cpp:191] Layer conv2_bn is using CAFFE engine.
I0416 11:55:59.925055   977 net.cpp:133] Creating Layer conv2_bn
I0416 11:55:59.925057   977 net.cpp:453] conv2_bn <- conv2
I0416 11:55:59.925061   977 net.cpp:411] conv2_bn -> conv2_bn
I0416 11:55:59.925065   977 net.cpp:163] Setting up conv2_bn
I0416 11:55:59.925082   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.925089   977 layer_factory.hpp:74] Creating layer relu2
I0416 11:55:59.925092   977 net.cpp:133] Creating Layer relu2
I0416 11:55:59.925094   977 net.cpp:453] relu2 <- conv2_bn
I0416 11:55:59.925097   977 net.cpp:400] relu2 -> conv2_bn (in-place)
I0416 11:55:59.925101   977 net.cpp:163] Setting up relu2
I0416 11:55:59.925308   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:55:59.925315   977 layer_factory.hpp:74] Creating layer conv3
I0416 11:55:59.925321   977 net.cpp:133] Creating Layer conv3
I0416 11:55:59.925323   977 net.cpp:453] conv3 <- conv2_bn
I0416 11:55:59.925328   977 net.cpp:411] conv3 -> conv3
I0416 11:55:59.925333   977 net.cpp:163] Setting up conv3
I0416 11:56:00.007834   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:56:00.007844   977 layer_factory.hpp:74] Creating layer conv3_bn
I0416 11:56:00.007848   977 layer_factory.cpp:191] Layer conv3_bn is using CAFFE engine.
I0416 11:56:00.007851   977 net.cpp:133] Creating Layer conv3_bn
I0416 11:56:00.007853   977 net.cpp:453] conv3_bn <- conv3
I0416 11:56:00.007856   977 net.cpp:411] conv3_bn -> conv3_bn
I0416 11:56:00.007860   977 net.cpp:163] Setting up conv3_bn
I0416 11:56:00.007879   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:56:00.007886   977 layer_factory.hpp:74] Creating layer relu3
I0416 11:56:00.007891   977 net.cpp:133] Creating Layer relu3
I0416 11:56:00.007894   977 net.cpp:453] relu3 <- conv3_bn
I0416 11:56:00.007895   977 net.cpp:400] relu3 -> conv3_bn (in-place)
I0416 11:56:00.007899   977 net.cpp:163] Setting up relu3
I0416 11:56:00.008026   977 net.cpp:170] Top shape: 10 32 144 56 (2580480)
I0416 11:56:00.008033   977 layer_factory.hpp:74] Creating layer pool1
I0416 11:56:00.008036   977 net.cpp:133] Creating Layer pool1
I0416 11:56:00.008038   977 net.cpp:453] pool1 <- conv3_bn
I0416 11:56:00.008040   977 net.cpp:411] pool1 -> pool1
I0416 11:56:00.008044   977 net.cpp:163] Setting up pool1
I0416 11:56:00.008344   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.008352   977 layer_factory.hpp:74] Creating layer pool1_pool1_0_split
I0416 11:56:00.008357   977 net.cpp:133] Creating Layer pool1_pool1_0_split
I0416 11:56:00.008358   977 net.cpp:453] pool1_pool1_0_split <- pool1
I0416 11:56:00.008361   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0416 11:56:00.008366   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0416 11:56:00.008369   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_2
I0416 11:56:00.008373   977 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_3
I0416 11:56:00.008375   977 net.cpp:163] Setting up pool1_pool1_0_split
I0416 11:56:00.008378   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.008380   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.008383   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.008384   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.008385   977 layer_factory.hpp:74] Creating layer inception_1a/1x1
I0416 11:56:00.008390   977 net.cpp:133] Creating Layer inception_1a/1x1
I0416 11:56:00.008393   977 net.cpp:453] inception_1a/1x1 <- pool1_pool1_0_split_0
I0416 11:56:00.008395   977 net.cpp:411] inception_1a/1x1 -> inception_1a/1x1
I0416 11:56:00.008399   977 net.cpp:163] Setting up inception_1a/1x1
I0416 11:56:00.043509   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.043519   977 layer_factory.hpp:74] Creating layer inception_1a/1x1_bn
I0416 11:56:00.043520   977 layer_factory.cpp:191] Layer inception_1a/1x1_bn is using CAFFE engine.
I0416 11:56:00.043524   977 net.cpp:133] Creating Layer inception_1a/1x1_bn
I0416 11:56:00.043527   977 net.cpp:453] inception_1a/1x1_bn <- inception_1a/1x1
I0416 11:56:00.043530   977 net.cpp:411] inception_1a/1x1_bn -> inception_1a/1x1_bn
I0416 11:56:00.043536   977 net.cpp:163] Setting up inception_1a/1x1_bn
I0416 11:56:00.043547   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.043552   977 layer_factory.hpp:74] Creating layer inception_1a/relu_1x1
I0416 11:56:00.043557   977 net.cpp:133] Creating Layer inception_1a/relu_1x1
I0416 11:56:00.043558   977 net.cpp:453] inception_1a/relu_1x1 <- inception_1a/1x1_bn
I0416 11:56:00.043561   977 net.cpp:400] inception_1a/relu_1x1 -> inception_1a/1x1_bn (in-place)
I0416 11:56:00.043565   977 net.cpp:163] Setting up inception_1a/relu_1x1
I0416 11:56:00.043684   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.043689   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_reduce
I0416 11:56:00.043695   977 net.cpp:133] Creating Layer inception_1a/3x3_reduce
I0416 11:56:00.043699   977 net.cpp:453] inception_1a/3x3_reduce <- pool1_pool1_0_split_1
I0416 11:56:00.043704   977 net.cpp:411] inception_1a/3x3_reduce -> inception_1a/3x3_reduce
I0416 11:56:00.043707   977 net.cpp:163] Setting up inception_1a/3x3_reduce
I0416 11:56:00.078753   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.078763   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_reduce_bn
I0416 11:56:00.078766   977 layer_factory.cpp:191] Layer inception_1a/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:00.078770   977 net.cpp:133] Creating Layer inception_1a/3x3_reduce_bn
I0416 11:56:00.078773   977 net.cpp:453] inception_1a/3x3_reduce_bn <- inception_1a/3x3_reduce
I0416 11:56:00.078776   977 net.cpp:411] inception_1a/3x3_reduce_bn -> inception_1a/3x3_reduce_bn
I0416 11:56:00.078780   977 net.cpp:163] Setting up inception_1a/3x3_reduce_bn
I0416 11:56:00.078791   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.078797   977 layer_factory.hpp:74] Creating layer inception_1a/relu_3x3_reduce
I0416 11:56:00.078800   977 net.cpp:133] Creating Layer inception_1a/relu_3x3_reduce
I0416 11:56:00.078802   977 net.cpp:453] inception_1a/relu_3x3_reduce <- inception_1a/3x3_reduce_bn
I0416 11:56:00.078804   977 net.cpp:400] inception_1a/relu_3x3_reduce -> inception_1a/3x3_reduce_bn (in-place)
I0416 11:56:00.078807   977 net.cpp:163] Setting up inception_1a/relu_3x3_reduce
I0416 11:56:00.078925   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.078932   977 layer_factory.hpp:74] Creating layer inception_1a/3x3
I0416 11:56:00.078936   977 net.cpp:133] Creating Layer inception_1a/3x3
I0416 11:56:00.078938   977 net.cpp:453] inception_1a/3x3 <- inception_1a/3x3_reduce_bn
I0416 11:56:00.078943   977 net.cpp:411] inception_1a/3x3 -> inception_1a/3x3
I0416 11:56:00.078946   977 net.cpp:163] Setting up inception_1a/3x3
I0416 11:56:00.147928   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.147938   977 layer_factory.hpp:74] Creating layer inception_1a/3x3_bn
I0416 11:56:00.147941   977 layer_factory.cpp:191] Layer inception_1a/3x3_bn is using CAFFE engine.
I0416 11:56:00.147945   977 net.cpp:133] Creating Layer inception_1a/3x3_bn
I0416 11:56:00.147948   977 net.cpp:453] inception_1a/3x3_bn <- inception_1a/3x3
I0416 11:56:00.147951   977 net.cpp:411] inception_1a/3x3_bn -> inception_1a/3x3_bn
I0416 11:56:00.147956   977 net.cpp:163] Setting up inception_1a/3x3_bn
I0416 11:56:00.147967   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.147976   977 layer_factory.hpp:74] Creating layer inception_1a/relu_3x3
I0416 11:56:00.147980   977 net.cpp:133] Creating Layer inception_1a/relu_3x3
I0416 11:56:00.147982   977 net.cpp:453] inception_1a/relu_3x3 <- inception_1a/3x3_bn
I0416 11:56:00.147985   977 net.cpp:400] inception_1a/relu_3x3 -> inception_1a/3x3_bn (in-place)
I0416 11:56:00.147987   977 net.cpp:163] Setting up inception_1a/relu_3x3
I0416 11:56:00.148301   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.148309   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_reduce
I0416 11:56:00.148314   977 net.cpp:133] Creating Layer inception_1a/double_3x3_reduce
I0416 11:56:00.148316   977 net.cpp:453] inception_1a/double_3x3_reduce <- pool1_pool1_0_split_2
I0416 11:56:00.148320   977 net.cpp:411] inception_1a/double_3x3_reduce -> inception_1a/double_3x3_reduce
I0416 11:56:00.148325   977 net.cpp:163] Setting up inception_1a/double_3x3_reduce
I0416 11:56:00.183431   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.183441   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183444   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:00.183449   977 net.cpp:133] Creating Layer inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183450   977 net.cpp:453] inception_1a/double_3x3_reduce_bn <- inception_1a/double_3x3_reduce
I0416 11:56:00.183454   977 net.cpp:411] inception_1a/double_3x3_reduce_bn -> inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183459   977 net.cpp:163] Setting up inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183470   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.183475   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_reduce
I0416 11:56:00.183477   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_reduce
I0416 11:56:00.183480   977 net.cpp:453] inception_1a/relu_double_3x3_reduce <- inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183481   977 net.cpp:400] inception_1a/relu_double_3x3_reduce -> inception_1a/double_3x3_reduce_bn (in-place)
I0416 11:56:00.183485   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_reduce
I0416 11:56:00.183605   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.183611   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_1
I0416 11:56:00.183616   977 net.cpp:133] Creating Layer inception_1a/double_3x3_1
I0416 11:56:00.183617   977 net.cpp:453] inception_1a/double_3x3_1 <- inception_1a/double_3x3_reduce_bn
I0416 11:56:00.183622   977 net.cpp:411] inception_1a/double_3x3_1 -> inception_1a/double_3x3_1
I0416 11:56:00.183626   977 net.cpp:163] Setting up inception_1a/double_3x3_1
I0416 11:56:00.252099   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.252109   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_1_bn
I0416 11:56:00.252111   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:00.252115   977 net.cpp:133] Creating Layer inception_1a/double_3x3_1_bn
I0416 11:56:00.252117   977 net.cpp:453] inception_1a/double_3x3_1_bn <- inception_1a/double_3x3_1
I0416 11:56:00.252121   977 net.cpp:411] inception_1a/double_3x3_1_bn -> inception_1a/double_3x3_1_bn
I0416 11:56:00.252125   977 net.cpp:163] Setting up inception_1a/double_3x3_1_bn
I0416 11:56:00.252136   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.252142   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_1
I0416 11:56:00.252146   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_1
I0416 11:56:00.252146   977 net.cpp:453] inception_1a/relu_double_3x3_1 <- inception_1a/double_3x3_1_bn
I0416 11:56:00.252149   977 net.cpp:400] inception_1a/relu_double_3x3_1 -> inception_1a/double_3x3_1_bn (in-place)
I0416 11:56:00.252152   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_1
I0416 11:56:00.252270   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.252275   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_2
I0416 11:56:00.252280   977 net.cpp:133] Creating Layer inception_1a/double_3x3_2
I0416 11:56:00.252282   977 net.cpp:453] inception_1a/double_3x3_2 <- inception_1a/double_3x3_1_bn
I0416 11:56:00.252285   977 net.cpp:411] inception_1a/double_3x3_2 -> inception_1a/double_3x3_2
I0416 11:56:00.252290   977 net.cpp:163] Setting up inception_1a/double_3x3_2
I0416 11:56:00.321696   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.321707   977 layer_factory.hpp:74] Creating layer inception_1a/double_3x3_2_bn
I0416 11:56:00.321709   977 layer_factory.cpp:191] Layer inception_1a/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:00.321713   977 net.cpp:133] Creating Layer inception_1a/double_3x3_2_bn
I0416 11:56:00.321715   977 net.cpp:453] inception_1a/double_3x3_2_bn <- inception_1a/double_3x3_2
I0416 11:56:00.321720   977 net.cpp:411] inception_1a/double_3x3_2_bn -> inception_1a/double_3x3_2_bn
I0416 11:56:00.321724   977 net.cpp:163] Setting up inception_1a/double_3x3_2_bn
I0416 11:56:00.321734   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.321740   977 layer_factory.hpp:74] Creating layer inception_1a/relu_double_3x3_2
I0416 11:56:00.321743   977 net.cpp:133] Creating Layer inception_1a/relu_double_3x3_2
I0416 11:56:00.321744   977 net.cpp:453] inception_1a/relu_double_3x3_2 <- inception_1a/double_3x3_2_bn
I0416 11:56:00.321748   977 net.cpp:400] inception_1a/relu_double_3x3_2 -> inception_1a/double_3x3_2_bn (in-place)
I0416 11:56:00.321750   977 net.cpp:163] Setting up inception_1a/relu_double_3x3_2
I0416 11:56:00.321945   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.321951   977 layer_factory.hpp:74] Creating layer inception_1a/pool
I0416 11:56:00.321954   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:56:00.321956   977 net.cpp:133] Creating Layer inception_1a/pool
I0416 11:56:00.321959   977 net.cpp:453] inception_1a/pool <- pool1_pool1_0_split_3
I0416 11:56:00.321962   977 net.cpp:411] inception_1a/pool -> inception_1a/pool
I0416 11:56:00.321966   977 net.cpp:163] Setting up inception_1a/pool
I0416 11:56:00.321970   977 net.cpp:170] Top shape: 10 32 72 28 (645120)
I0416 11:56:00.321971   977 layer_factory.hpp:74] Creating layer inception_1a/pool_proj
I0416 11:56:00.321980   977 net.cpp:133] Creating Layer inception_1a/pool_proj
I0416 11:56:00.321984   977 net.cpp:453] inception_1a/pool_proj <- inception_1a/pool
I0416 11:56:00.321986   977 net.cpp:411] inception_1a/pool_proj -> inception_1a/pool_proj
I0416 11:56:00.321990   977 net.cpp:163] Setting up inception_1a/pool_proj
I0416 11:56:00.357125   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.357134   977 layer_factory.hpp:74] Creating layer inception_1a/pool_proj_bn
I0416 11:56:00.357136   977 layer_factory.cpp:191] Layer inception_1a/pool_proj_bn is using CAFFE engine.
I0416 11:56:00.357141   977 net.cpp:133] Creating Layer inception_1a/pool_proj_bn
I0416 11:56:00.357143   977 net.cpp:453] inception_1a/pool_proj_bn <- inception_1a/pool_proj
I0416 11:56:00.357147   977 net.cpp:411] inception_1a/pool_proj_bn -> inception_1a/pool_proj_bn
I0416 11:56:00.357151   977 net.cpp:163] Setting up inception_1a/pool_proj_bn
I0416 11:56:00.357162   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.357167   977 layer_factory.hpp:74] Creating layer inception_1a/relu_pool_proj
I0416 11:56:00.357172   977 net.cpp:133] Creating Layer inception_1a/relu_pool_proj
I0416 11:56:00.357172   977 net.cpp:453] inception_1a/relu_pool_proj <- inception_1a/pool_proj_bn
I0416 11:56:00.357175   977 net.cpp:400] inception_1a/relu_pool_proj -> inception_1a/pool_proj_bn (in-place)
I0416 11:56:00.357178   977 net.cpp:163] Setting up inception_1a/relu_pool_proj
I0416 11:56:00.357296   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.357301   977 layer_factory.hpp:74] Creating layer inception_1a/output
I0416 11:56:00.357306   977 net.cpp:133] Creating Layer inception_1a/output
I0416 11:56:00.357307   977 net.cpp:453] inception_1a/output <- inception_1a/1x1_bn
I0416 11:56:00.357309   977 net.cpp:453] inception_1a/output <- inception_1a/3x3_bn
I0416 11:56:00.357312   977 net.cpp:453] inception_1a/output <- inception_1a/double_3x3_2_bn
I0416 11:56:00.357314   977 net.cpp:453] inception_1a/output <- inception_1a/pool_proj_bn
I0416 11:56:00.357317   977 net.cpp:411] inception_1a/output -> inception_1a/output
I0416 11:56:00.357321   977 net.cpp:163] Setting up inception_1a/output
I0416 11:56:00.357324   977 net.cpp:170] Top shape: 10 256 72 28 (5160960)
I0416 11:56:00.357326   977 layer_factory.hpp:74] Creating layer inception_1a/output_inception_1a/output_0_split
I0416 11:56:00.357329   977 net.cpp:133] Creating Layer inception_1a/output_inception_1a/output_0_split
I0416 11:56:00.357331   977 net.cpp:453] inception_1a/output_inception_1a/output_0_split <- inception_1a/output
I0416 11:56:00.357334   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_0
I0416 11:56:00.357337   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_1
I0416 11:56:00.357344   977 net.cpp:411] inception_1a/output_inception_1a/output_0_split -> inception_1a/output_inception_1a/output_0_split_2
I0416 11:56:00.357352   977 net.cpp:163] Setting up inception_1a/output_inception_1a/output_0_split
I0416 11:56:00.357354   977 net.cpp:170] Top shape: 10 256 72 28 (5160960)
I0416 11:56:00.357357   977 net.cpp:170] Top shape: 10 256 72 28 (5160960)
I0416 11:56:00.357358   977 net.cpp:170] Top shape: 10 256 72 28 (5160960)
I0416 11:56:00.357360   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_reduce
I0416 11:56:00.357363   977 net.cpp:133] Creating Layer inception_1b/3x3_reduce
I0416 11:56:00.357365   977 net.cpp:453] inception_1b/3x3_reduce <- inception_1a/output_inception_1a/output_0_split_0
I0416 11:56:00.357369   977 net.cpp:411] inception_1b/3x3_reduce -> inception_1b/3x3_reduce
I0416 11:56:00.357372   977 net.cpp:163] Setting up inception_1b/3x3_reduce
I0416 11:56:00.563838   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.563848   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_reduce_bn
I0416 11:56:00.563850   977 layer_factory.cpp:191] Layer inception_1b/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:00.563854   977 net.cpp:133] Creating Layer inception_1b/3x3_reduce_bn
I0416 11:56:00.563856   977 net.cpp:453] inception_1b/3x3_reduce_bn <- inception_1b/3x3_reduce
I0416 11:56:00.563860   977 net.cpp:411] inception_1b/3x3_reduce_bn -> inception_1b/3x3_reduce_bn
I0416 11:56:00.563865   977 net.cpp:163] Setting up inception_1b/3x3_reduce_bn
I0416 11:56:00.563876   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.563886   977 layer_factory.hpp:74] Creating layer inception_1b/relu_3x3_reduce
I0416 11:56:00.563890   977 net.cpp:133] Creating Layer inception_1b/relu_3x3_reduce
I0416 11:56:00.563891   977 net.cpp:453] inception_1b/relu_3x3_reduce <- inception_1b/3x3_reduce_bn
I0416 11:56:00.563895   977 net.cpp:400] inception_1b/relu_3x3_reduce -> inception_1b/3x3_reduce_bn (in-place)
I0416 11:56:00.563897   977 net.cpp:163] Setting up inception_1b/relu_3x3_reduce
I0416 11:56:00.564018   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.564024   977 layer_factory.hpp:74] Creating layer inception_1b/3x3
I0416 11:56:00.564028   977 net.cpp:133] Creating Layer inception_1b/3x3
I0416 11:56:00.564030   977 net.cpp:453] inception_1b/3x3 <- inception_1b/3x3_reduce_bn
I0416 11:56:00.564034   977 net.cpp:411] inception_1b/3x3 -> inception_1b/3x3
I0416 11:56:00.564038   977 net.cpp:163] Setting up inception_1b/3x3
I0416 11:56:00.575286   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.575296   977 layer_factory.hpp:74] Creating layer inception_1b/3x3_bn
I0416 11:56:00.575299   977 layer_factory.cpp:191] Layer inception_1b/3x3_bn is using CAFFE engine.
I0416 11:56:00.575304   977 net.cpp:133] Creating Layer inception_1b/3x3_bn
I0416 11:56:00.575305   977 net.cpp:453] inception_1b/3x3_bn <- inception_1b/3x3
I0416 11:56:00.575309   977 net.cpp:411] inception_1b/3x3_bn -> inception_1b/3x3_bn
I0416 11:56:00.575314   977 net.cpp:163] Setting up inception_1b/3x3_bn
I0416 11:56:00.575322   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.575328   977 layer_factory.hpp:74] Creating layer inception_1b/relu_3x3
I0416 11:56:00.575331   977 net.cpp:133] Creating Layer inception_1b/relu_3x3
I0416 11:56:00.575333   977 net.cpp:453] inception_1b/relu_3x3 <- inception_1b/3x3_bn
I0416 11:56:00.575335   977 net.cpp:400] inception_1b/relu_3x3 -> inception_1b/3x3_bn (in-place)
I0416 11:56:00.575338   977 net.cpp:163] Setting up inception_1b/relu_3x3
I0416 11:56:00.575534   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.575541   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_reduce
I0416 11:56:00.575546   977 net.cpp:133] Creating Layer inception_1b/double_3x3_reduce
I0416 11:56:00.575548   977 net.cpp:453] inception_1b/double_3x3_reduce <- inception_1a/output_inception_1a/output_0_split_1
I0416 11:56:00.575552   977 net.cpp:411] inception_1b/double_3x3_reduce -> inception_1b/double_3x3_reduce
I0416 11:56:00.575557   977 net.cpp:163] Setting up inception_1b/double_3x3_reduce
I0416 11:56:00.782997   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.783007   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783010   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:00.783015   977 net.cpp:133] Creating Layer inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783016   977 net.cpp:453] inception_1b/double_3x3_reduce_bn <- inception_1b/double_3x3_reduce
I0416 11:56:00.783020   977 net.cpp:411] inception_1b/double_3x3_reduce_bn -> inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783025   977 net.cpp:163] Setting up inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783035   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.783041   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_reduce
I0416 11:56:00.783043   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_reduce
I0416 11:56:00.783046   977 net.cpp:453] inception_1b/relu_double_3x3_reduce <- inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783048   977 net.cpp:400] inception_1b/relu_double_3x3_reduce -> inception_1b/double_3x3_reduce_bn (in-place)
I0416 11:56:00.783051   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_reduce
I0416 11:56:00.783169   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.783175   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_1
I0416 11:56:00.783181   977 net.cpp:133] Creating Layer inception_1b/double_3x3_1
I0416 11:56:00.783185   977 net.cpp:453] inception_1b/double_3x3_1 <- inception_1b/double_3x3_reduce_bn
I0416 11:56:00.783188   977 net.cpp:411] inception_1b/double_3x3_1 -> inception_1b/double_3x3_1
I0416 11:56:00.783192   977 net.cpp:163] Setting up inception_1b/double_3x3_1
I0416 11:56:00.852555   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.852566   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_1_bn
I0416 11:56:00.852568   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:00.852572   977 net.cpp:133] Creating Layer inception_1b/double_3x3_1_bn
I0416 11:56:00.852574   977 net.cpp:453] inception_1b/double_3x3_1_bn <- inception_1b/double_3x3_1
I0416 11:56:00.852578   977 net.cpp:411] inception_1b/double_3x3_1_bn -> inception_1b/double_3x3_1_bn
I0416 11:56:00.852583   977 net.cpp:163] Setting up inception_1b/double_3x3_1_bn
I0416 11:56:00.852598   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.852604   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_1
I0416 11:56:00.852607   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_1
I0416 11:56:00.852609   977 net.cpp:453] inception_1b/relu_double_3x3_1 <- inception_1b/double_3x3_1_bn
I0416 11:56:00.852613   977 net.cpp:400] inception_1b/relu_double_3x3_1 -> inception_1b/double_3x3_1_bn (in-place)
I0416 11:56:00.852617   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_1
I0416 11:56:00.852735   977 net.cpp:170] Top shape: 10 64 72 28 (1290240)
I0416 11:56:00.852740   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_2
I0416 11:56:00.852746   977 net.cpp:133] Creating Layer inception_1b/double_3x3_2
I0416 11:56:00.852747   977 net.cpp:453] inception_1b/double_3x3_2 <- inception_1b/double_3x3_1_bn
I0416 11:56:00.852751   977 net.cpp:411] inception_1b/double_3x3_2 -> inception_1b/double_3x3_2
I0416 11:56:00.852756   977 net.cpp:163] Setting up inception_1b/double_3x3_2
I0416 11:56:00.863526   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.863538   977 layer_factory.hpp:74] Creating layer inception_1b/double_3x3_2_bn
I0416 11:56:00.863539   977 layer_factory.cpp:191] Layer inception_1b/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:00.863544   977 net.cpp:133] Creating Layer inception_1b/double_3x3_2_bn
I0416 11:56:00.863546   977 net.cpp:453] inception_1b/double_3x3_2_bn <- inception_1b/double_3x3_2
I0416 11:56:00.863550   977 net.cpp:411] inception_1b/double_3x3_2_bn -> inception_1b/double_3x3_2_bn
I0416 11:56:00.863554   977 net.cpp:163] Setting up inception_1b/double_3x3_2_bn
I0416 11:56:00.863564   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.863569   977 layer_factory.hpp:74] Creating layer inception_1b/relu_double_3x3_2
I0416 11:56:00.863572   977 net.cpp:133] Creating Layer inception_1b/relu_double_3x3_2
I0416 11:56:00.863574   977 net.cpp:453] inception_1b/relu_double_3x3_2 <- inception_1b/double_3x3_2_bn
I0416 11:56:00.863576   977 net.cpp:400] inception_1b/relu_double_3x3_2 -> inception_1b/double_3x3_2_bn (in-place)
I0416 11:56:00.863579   977 net.cpp:163] Setting up inception_1b/relu_double_3x3_2
I0416 11:56:00.863817   977 net.cpp:170] Top shape: 10 64 36 14 (322560)
I0416 11:56:00.863824   977 layer_factory.hpp:74] Creating layer inception_1b/pool
I0416 11:56:00.863829   977 net.cpp:133] Creating Layer inception_1b/pool
I0416 11:56:00.863832   977 net.cpp:453] inception_1b/pool <- inception_1a/output_inception_1a/output_0_split_2
I0416 11:56:00.863837   977 net.cpp:411] inception_1b/pool -> inception_1b/pool
I0416 11:56:00.863839   977 net.cpp:163] Setting up inception_1b/pool
I0416 11:56:00.864034   977 net.cpp:170] Top shape: 10 256 36 14 (1290240)
I0416 11:56:00.864040   977 layer_factory.hpp:74] Creating layer inception_1b/output
I0416 11:56:00.864044   977 net.cpp:133] Creating Layer inception_1b/output
I0416 11:56:00.864047   977 net.cpp:453] inception_1b/output <- inception_1b/3x3_bn
I0416 11:56:00.864048   977 net.cpp:453] inception_1b/output <- inception_1b/double_3x3_2_bn
I0416 11:56:00.864050   977 net.cpp:453] inception_1b/output <- inception_1b/pool
I0416 11:56:00.864054   977 net.cpp:411] inception_1b/output -> inception_1b/output
I0416 11:56:00.864058   977 net.cpp:163] Setting up inception_1b/output
I0416 11:56:00.864061   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:00.864063   977 layer_factory.hpp:74] Creating layer inception_1b/output_inception_1b/output_0_split
I0416 11:56:00.864066   977 net.cpp:133] Creating Layer inception_1b/output_inception_1b/output_0_split
I0416 11:56:00.864068   977 net.cpp:453] inception_1b/output_inception_1b/output_0_split <- inception_1b/output
I0416 11:56:00.864071   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_0
I0416 11:56:00.864074   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_1
I0416 11:56:00.864078   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_2
I0416 11:56:00.864081   977 net.cpp:411] inception_1b/output_inception_1b/output_0_split -> inception_1b/output_inception_1b/output_0_split_3
I0416 11:56:00.864084   977 net.cpp:163] Setting up inception_1b/output_inception_1b/output_0_split
I0416 11:56:00.864087   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:00.864089   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:00.864091   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:00.864094   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:00.864095   977 layer_factory.hpp:74] Creating layer inception_2a/1x1
I0416 11:56:00.864100   977 net.cpp:133] Creating Layer inception_2a/1x1
I0416 11:56:00.864101   977 net.cpp:453] inception_2a/1x1 <- inception_1b/output_inception_1b/output_0_split_0
I0416 11:56:00.864104   977 net.cpp:411] inception_2a/1x1 -> inception_2a/1x1
I0416 11:56:00.864107   977 net.cpp:163] Setting up inception_2a/1x1
I0416 11:56:00.959127   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:00.959138   977 layer_factory.hpp:74] Creating layer inception_2a/1x1_bn
I0416 11:56:00.959141   977 layer_factory.cpp:191] Layer inception_2a/1x1_bn is using CAFFE engine.
I0416 11:56:00.959146   977 net.cpp:133] Creating Layer inception_2a/1x1_bn
I0416 11:56:00.959147   977 net.cpp:453] inception_2a/1x1_bn <- inception_2a/1x1
I0416 11:56:00.959151   977 net.cpp:411] inception_2a/1x1_bn -> inception_2a/1x1_bn
I0416 11:56:00.959156   977 net.cpp:163] Setting up inception_2a/1x1_bn
I0416 11:56:00.959164   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:00.959170   977 layer_factory.hpp:74] Creating layer inception_2a/relu_1x1
I0416 11:56:00.959173   977 net.cpp:133] Creating Layer inception_2a/relu_1x1
I0416 11:56:00.959174   977 net.cpp:453] inception_2a/relu_1x1 <- inception_2a/1x1_bn
I0416 11:56:00.959177   977 net.cpp:400] inception_2a/relu_1x1 -> inception_2a/1x1_bn (in-place)
I0416 11:56:00.959182   977 net.cpp:163] Setting up inception_2a/relu_1x1
I0416 11:56:00.959512   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:00.959522   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_reduce
I0416 11:56:00.959528   977 net.cpp:133] Creating Layer inception_2a/3x3_reduce
I0416 11:56:00.959530   977 net.cpp:453] inception_2a/3x3_reduce <- inception_1b/output_inception_1b/output_0_split_1
I0416 11:56:00.959535   977 net.cpp:411] inception_2a/3x3_reduce -> inception_2a/3x3_reduce
I0416 11:56:00.959540   977 net.cpp:163] Setting up inception_2a/3x3_reduce
I0416 11:56:01.055135   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.055145   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_reduce_bn
I0416 11:56:01.055147   977 layer_factory.cpp:191] Layer inception_2a/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:01.055151   977 net.cpp:133] Creating Layer inception_2a/3x3_reduce_bn
I0416 11:56:01.055153   977 net.cpp:453] inception_2a/3x3_reduce_bn <- inception_2a/3x3_reduce
I0416 11:56:01.055157   977 net.cpp:411] inception_2a/3x3_reduce_bn -> inception_2a/3x3_reduce_bn
I0416 11:56:01.055162   977 net.cpp:163] Setting up inception_2a/3x3_reduce_bn
I0416 11:56:01.055171   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.055176   977 layer_factory.hpp:74] Creating layer inception_2a/relu_3x3_reduce
I0416 11:56:01.055179   977 net.cpp:133] Creating Layer inception_2a/relu_3x3_reduce
I0416 11:56:01.055181   977 net.cpp:453] inception_2a/relu_3x3_reduce <- inception_2a/3x3_reduce_bn
I0416 11:56:01.055184   977 net.cpp:400] inception_2a/relu_3x3_reduce -> inception_2a/3x3_reduce_bn (in-place)
I0416 11:56:01.055188   977 net.cpp:163] Setting up inception_2a/relu_3x3_reduce
I0416 11:56:01.055392   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.055397   977 layer_factory.hpp:74] Creating layer inception_2a/3x3
I0416 11:56:01.055403   977 net.cpp:133] Creating Layer inception_2a/3x3
I0416 11:56:01.055405   977 net.cpp:453] inception_2a/3x3 <- inception_2a/3x3_reduce_bn
I0416 11:56:01.055409   977 net.cpp:411] inception_2a/3x3 -> inception_2a/3x3
I0416 11:56:01.055413   977 net.cpp:163] Setting up inception_2a/3x3
I0416 11:56:01.099443   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.099452   977 layer_factory.hpp:74] Creating layer inception_2a/3x3_bn
I0416 11:56:01.099455   977 layer_factory.cpp:191] Layer inception_2a/3x3_bn is using CAFFE engine.
I0416 11:56:01.099459   977 net.cpp:133] Creating Layer inception_2a/3x3_bn
I0416 11:56:01.099462   977 net.cpp:453] inception_2a/3x3_bn <- inception_2a/3x3
I0416 11:56:01.099465   977 net.cpp:411] inception_2a/3x3_bn -> inception_2a/3x3_bn
I0416 11:56:01.099469   977 net.cpp:163] Setting up inception_2a/3x3_bn
I0416 11:56:01.099478   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.099483   977 layer_factory.hpp:74] Creating layer inception_2a/relu_3x3
I0416 11:56:01.099485   977 net.cpp:133] Creating Layer inception_2a/relu_3x3
I0416 11:56:01.099488   977 net.cpp:453] inception_2a/relu_3x3 <- inception_2a/3x3_bn
I0416 11:56:01.099490   977 net.cpp:400] inception_2a/relu_3x3 -> inception_2a/3x3_bn (in-place)
I0416 11:56:01.099493   977 net.cpp:163] Setting up inception_2a/relu_3x3
I0416 11:56:01.099622   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.099628   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_reduce
I0416 11:56:01.099642   977 net.cpp:133] Creating Layer inception_2a/double_3x3_reduce
I0416 11:56:01.099643   977 net.cpp:453] inception_2a/double_3x3_reduce <- inception_1b/output_inception_1b/output_0_split_2
I0416 11:56:01.099647   977 net.cpp:411] inception_2a/double_3x3_reduce -> inception_2a/double_3x3_reduce
I0416 11:56:01.099652   977 net.cpp:163] Setting up inception_2a/double_3x3_reduce
I0416 11:56:01.195214   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.195225   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195227   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:01.195231   977 net.cpp:133] Creating Layer inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195233   977 net.cpp:453] inception_2a/double_3x3_reduce_bn <- inception_2a/double_3x3_reduce
I0416 11:56:01.195238   977 net.cpp:411] inception_2a/double_3x3_reduce_bn -> inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195242   977 net.cpp:163] Setting up inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195251   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.195257   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_reduce
I0416 11:56:01.195261   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_reduce
I0416 11:56:01.195262   977 net.cpp:453] inception_2a/relu_double_3x3_reduce <- inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195266   977 net.cpp:400] inception_2a/relu_double_3x3_reduce -> inception_2a/double_3x3_reduce_bn (in-place)
I0416 11:56:01.195269   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_reduce
I0416 11:56:01.195483   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.195490   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_1
I0416 11:56:01.195495   977 net.cpp:133] Creating Layer inception_2a/double_3x3_1
I0416 11:56:01.195497   977 net.cpp:453] inception_2a/double_3x3_1 <- inception_2a/double_3x3_reduce_bn
I0416 11:56:01.195502   977 net.cpp:411] inception_2a/double_3x3_1 -> inception_2a/double_3x3_1
I0416 11:56:01.195507   977 net.cpp:163] Setting up inception_2a/double_3x3_1
I0416 11:56:01.239459   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.239469   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_1_bn
I0416 11:56:01.239470   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:01.239475   977 net.cpp:133] Creating Layer inception_2a/double_3x3_1_bn
I0416 11:56:01.239477   977 net.cpp:453] inception_2a/double_3x3_1_bn <- inception_2a/double_3x3_1
I0416 11:56:01.239481   977 net.cpp:411] inception_2a/double_3x3_1_bn -> inception_2a/double_3x3_1_bn
I0416 11:56:01.239485   977 net.cpp:163] Setting up inception_2a/double_3x3_1_bn
I0416 11:56:01.239495   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.239500   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_1
I0416 11:56:01.239503   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_1
I0416 11:56:01.239506   977 net.cpp:453] inception_2a/relu_double_3x3_1 <- inception_2a/double_3x3_1_bn
I0416 11:56:01.239508   977 net.cpp:400] inception_2a/relu_double_3x3_1 -> inception_2a/double_3x3_1_bn (in-place)
I0416 11:56:01.239513   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_1
I0416 11:56:01.239717   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.239724   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_2
I0416 11:56:01.239729   977 net.cpp:133] Creating Layer inception_2a/double_3x3_2
I0416 11:56:01.239732   977 net.cpp:453] inception_2a/double_3x3_2 <- inception_2a/double_3x3_1_bn
I0416 11:56:01.239735   977 net.cpp:411] inception_2a/double_3x3_2 -> inception_2a/double_3x3_2
I0416 11:56:01.239739   977 net.cpp:163] Setting up inception_2a/double_3x3_2
I0416 11:56:01.283517   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.283527   977 layer_factory.hpp:74] Creating layer inception_2a/double_3x3_2_bn
I0416 11:56:01.283530   977 layer_factory.cpp:191] Layer inception_2a/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:01.283535   977 net.cpp:133] Creating Layer inception_2a/double_3x3_2_bn
I0416 11:56:01.283536   977 net.cpp:453] inception_2a/double_3x3_2_bn <- inception_2a/double_3x3_2
I0416 11:56:01.283540   977 net.cpp:411] inception_2a/double_3x3_2_bn -> inception_2a/double_3x3_2_bn
I0416 11:56:01.283545   977 net.cpp:163] Setting up inception_2a/double_3x3_2_bn
I0416 11:56:01.283555   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.283560   977 layer_factory.hpp:74] Creating layer inception_2a/relu_double_3x3_2
I0416 11:56:01.283563   977 net.cpp:133] Creating Layer inception_2a/relu_double_3x3_2
I0416 11:56:01.283565   977 net.cpp:453] inception_2a/relu_double_3x3_2 <- inception_2a/double_3x3_2_bn
I0416 11:56:01.283568   977 net.cpp:400] inception_2a/relu_double_3x3_2 -> inception_2a/double_3x3_2_bn (in-place)
I0416 11:56:01.283572   977 net.cpp:163] Setting up inception_2a/relu_double_3x3_2
I0416 11:56:01.283706   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.283711   977 layer_factory.hpp:74] Creating layer inception_2a/pool
I0416 11:56:01.283715   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:56:01.283717   977 net.cpp:133] Creating Layer inception_2a/pool
I0416 11:56:01.283720   977 net.cpp:453] inception_2a/pool <- inception_1b/output_inception_1b/output_0_split_3
I0416 11:56:01.283722   977 net.cpp:411] inception_2a/pool -> inception_2a/pool
I0416 11:56:01.283726   977 net.cpp:163] Setting up inception_2a/pool
I0416 11:56:01.283730   977 net.cpp:170] Top shape: 10 384 36 14 (1935360)
I0416 11:56:01.283732   977 layer_factory.hpp:74] Creating layer inception_2a/pool_proj
I0416 11:56:01.283736   977 net.cpp:133] Creating Layer inception_2a/pool_proj
I0416 11:56:01.283738   977 net.cpp:453] inception_2a/pool_proj <- inception_2a/pool
I0416 11:56:01.283741   977 net.cpp:411] inception_2a/pool_proj -> inception_2a/pool_proj
I0416 11:56:01.283745   977 net.cpp:163] Setting up inception_2a/pool_proj
I0416 11:56:01.379276   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.379286   977 layer_factory.hpp:74] Creating layer inception_2a/pool_proj_bn
I0416 11:56:01.379287   977 layer_factory.cpp:191] Layer inception_2a/pool_proj_bn is using CAFFE engine.
I0416 11:56:01.379292   977 net.cpp:133] Creating Layer inception_2a/pool_proj_bn
I0416 11:56:01.379294   977 net.cpp:453] inception_2a/pool_proj_bn <- inception_2a/pool_proj
I0416 11:56:01.379298   977 net.cpp:411] inception_2a/pool_proj_bn -> inception_2a/pool_proj_bn
I0416 11:56:01.379310   977 net.cpp:163] Setting up inception_2a/pool_proj_bn
I0416 11:56:01.379320   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.379338   977 layer_factory.hpp:74] Creating layer inception_2a/relu_pool_proj
I0416 11:56:01.379343   977 net.cpp:133] Creating Layer inception_2a/relu_pool_proj
I0416 11:56:01.379348   977 net.cpp:453] inception_2a/relu_pool_proj <- inception_2a/pool_proj_bn
I0416 11:56:01.379354   977 net.cpp:400] inception_2a/relu_pool_proj -> inception_2a/pool_proj_bn (in-place)
I0416 11:56:01.379359   977 net.cpp:163] Setting up inception_2a/relu_pool_proj
I0416 11:56:01.379575   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.379582   977 layer_factory.hpp:74] Creating layer inception_2a/output
I0416 11:56:01.379587   977 net.cpp:133] Creating Layer inception_2a/output
I0416 11:56:01.379590   977 net.cpp:453] inception_2a/output <- inception_2a/1x1_bn
I0416 11:56:01.379591   977 net.cpp:453] inception_2a/output <- inception_2a/3x3_bn
I0416 11:56:01.379595   977 net.cpp:453] inception_2a/output <- inception_2a/double_3x3_2_bn
I0416 11:56:01.379596   977 net.cpp:453] inception_2a/output <- inception_2a/pool_proj_bn
I0416 11:56:01.379600   977 net.cpp:411] inception_2a/output -> inception_2a/output
I0416 11:56:01.379603   977 net.cpp:163] Setting up inception_2a/output
I0416 11:56:01.379606   977 net.cpp:170] Top shape: 10 512 36 14 (2580480)
I0416 11:56:01.379608   977 layer_factory.hpp:74] Creating layer inception_2a/output_inception_2a/output_0_split
I0416 11:56:01.379611   977 net.cpp:133] Creating Layer inception_2a/output_inception_2a/output_0_split
I0416 11:56:01.379613   977 net.cpp:453] inception_2a/output_inception_2a/output_0_split <- inception_2a/output
I0416 11:56:01.379616   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_0
I0416 11:56:01.379621   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_1
I0416 11:56:01.379624   977 net.cpp:411] inception_2a/output_inception_2a/output_0_split -> inception_2a/output_inception_2a/output_0_split_2
I0416 11:56:01.379628   977 net.cpp:163] Setting up inception_2a/output_inception_2a/output_0_split
I0416 11:56:01.379633   977 net.cpp:170] Top shape: 10 512 36 14 (2580480)
I0416 11:56:01.379637   977 net.cpp:170] Top shape: 10 512 36 14 (2580480)
I0416 11:56:01.379642   977 net.cpp:170] Top shape: 10 512 36 14 (2580480)
I0416 11:56:01.379644   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_reduce
I0416 11:56:01.379650   977 net.cpp:133] Creating Layer inception_2b/3x3_reduce
I0416 11:56:01.379654   977 net.cpp:453] inception_2b/3x3_reduce <- inception_2a/output_inception_2a/output_0_split_0
I0416 11:56:01.379662   977 net.cpp:411] inception_2b/3x3_reduce -> inception_2b/3x3_reduce
I0416 11:56:01.379667   977 net.cpp:163] Setting up inception_2b/3x3_reduce
I0416 11:56:01.504815   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.504825   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_reduce_bn
I0416 11:56:01.504827   977 layer_factory.cpp:191] Layer inception_2b/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:01.504832   977 net.cpp:133] Creating Layer inception_2b/3x3_reduce_bn
I0416 11:56:01.504834   977 net.cpp:453] inception_2b/3x3_reduce_bn <- inception_2b/3x3_reduce
I0416 11:56:01.504840   977 net.cpp:411] inception_2b/3x3_reduce_bn -> inception_2b/3x3_reduce_bn
I0416 11:56:01.504847   977 net.cpp:163] Setting up inception_2b/3x3_reduce_bn
I0416 11:56:01.504863   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.504873   977 layer_factory.hpp:74] Creating layer inception_2b/relu_3x3_reduce
I0416 11:56:01.504876   977 net.cpp:133] Creating Layer inception_2b/relu_3x3_reduce
I0416 11:56:01.504879   977 net.cpp:453] inception_2b/relu_3x3_reduce <- inception_2b/3x3_reduce_bn
I0416 11:56:01.504884   977 net.cpp:400] inception_2b/relu_3x3_reduce -> inception_2b/3x3_reduce_bn (in-place)
I0416 11:56:01.504889   977 net.cpp:163] Setting up inception_2b/relu_3x3_reduce
I0416 11:56:01.505164   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.505172   977 layer_factory.hpp:74] Creating layer inception_2b/3x3
I0416 11:56:01.505177   977 net.cpp:133] Creating Layer inception_2b/3x3
I0416 11:56:01.505179   977 net.cpp:453] inception_2b/3x3 <- inception_2b/3x3_reduce_bn
I0416 11:56:01.505185   977 net.cpp:411] inception_2b/3x3 -> inception_2b/3x3
I0416 11:56:01.505192   977 net.cpp:163] Setting up inception_2b/3x3
I0416 11:56:01.512231   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.512243   977 layer_factory.hpp:74] Creating layer inception_2b/3x3_bn
I0416 11:56:01.512245   977 layer_factory.cpp:191] Layer inception_2b/3x3_bn is using CAFFE engine.
I0416 11:56:01.512250   977 net.cpp:133] Creating Layer inception_2b/3x3_bn
I0416 11:56:01.512254   977 net.cpp:453] inception_2b/3x3_bn <- inception_2b/3x3
I0416 11:56:01.512261   977 net.cpp:411] inception_2b/3x3_bn -> inception_2b/3x3_bn
I0416 11:56:01.512269   977 net.cpp:163] Setting up inception_2b/3x3_bn
I0416 11:56:01.512284   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.512291   977 layer_factory.hpp:74] Creating layer inception_2b/relu_3x3
I0416 11:56:01.512295   977 net.cpp:133] Creating Layer inception_2b/relu_3x3
I0416 11:56:01.512297   977 net.cpp:453] inception_2b/relu_3x3 <- inception_2b/3x3_bn
I0416 11:56:01.512301   977 net.cpp:400] inception_2b/relu_3x3 -> inception_2b/3x3_bn (in-place)
I0416 11:56:01.512306   977 net.cpp:163] Setting up inception_2b/relu_3x3
I0416 11:56:01.512435   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.512441   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_reduce
I0416 11:56:01.512446   977 net.cpp:133] Creating Layer inception_2b/double_3x3_reduce
I0416 11:56:01.512449   977 net.cpp:453] inception_2b/double_3x3_reduce <- inception_2a/output_inception_2a/output_0_split_1
I0416 11:56:01.512454   977 net.cpp:411] inception_2b/double_3x3_reduce -> inception_2b/double_3x3_reduce
I0416 11:56:01.512460   977 net.cpp:163] Setting up inception_2b/double_3x3_reduce
I0416 11:56:01.636744   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.636755   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_reduce_bn
I0416 11:56:01.636757   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:01.636762   977 net.cpp:133] Creating Layer inception_2b/double_3x3_reduce_bn
I0416 11:56:01.636766   977 net.cpp:453] inception_2b/double_3x3_reduce_bn <- inception_2b/double_3x3_reduce
I0416 11:56:01.636772   977 net.cpp:411] inception_2b/double_3x3_reduce_bn -> inception_2b/double_3x3_reduce_bn
I0416 11:56:01.636780   977 net.cpp:163] Setting up inception_2b/double_3x3_reduce_bn
I0416 11:56:01.636798   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.636806   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_reduce
I0416 11:56:01.636813   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_reduce
I0416 11:56:01.636817   977 net.cpp:453] inception_2b/relu_double_3x3_reduce <- inception_2b/double_3x3_reduce_bn
I0416 11:56:01.636822   977 net.cpp:400] inception_2b/relu_double_3x3_reduce -> inception_2b/double_3x3_reduce_bn (in-place)
I0416 11:56:01.636827   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_reduce
I0416 11:56:01.637037   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.637043   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_1
I0416 11:56:01.637048   977 net.cpp:133] Creating Layer inception_2b/double_3x3_1
I0416 11:56:01.637051   977 net.cpp:453] inception_2b/double_3x3_1 <- inception_2b/double_3x3_reduce_bn
I0416 11:56:01.637058   977 net.cpp:411] inception_2b/double_3x3_1 -> inception_2b/double_3x3_1
I0416 11:56:01.637063   977 net.cpp:163] Setting up inception_2b/double_3x3_1
I0416 11:56:01.680624   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.680634   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_1_bn
I0416 11:56:01.680636   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:01.680641   977 net.cpp:133] Creating Layer inception_2b/double_3x3_1_bn
I0416 11:56:01.680645   977 net.cpp:453] inception_2b/double_3x3_1_bn <- inception_2b/double_3x3_1
I0416 11:56:01.680651   977 net.cpp:411] inception_2b/double_3x3_1_bn -> inception_2b/double_3x3_1_bn
I0416 11:56:01.680657   977 net.cpp:163] Setting up inception_2b/double_3x3_1_bn
I0416 11:56:01.680675   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.680685   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_1
I0416 11:56:01.680691   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_1
I0416 11:56:01.680693   977 net.cpp:453] inception_2b/relu_double_3x3_1 <- inception_2b/double_3x3_1_bn
I0416 11:56:01.680698   977 net.cpp:400] inception_2b/relu_double_3x3_1 -> inception_2b/double_3x3_1_bn (in-place)
I0416 11:56:01.680703   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_1
I0416 11:56:01.680909   977 net.cpp:170] Top shape: 10 128 36 14 (645120)
I0416 11:56:01.680915   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_2
I0416 11:56:01.680919   977 net.cpp:133] Creating Layer inception_2b/double_3x3_2
I0416 11:56:01.680922   977 net.cpp:453] inception_2b/double_3x3_2 <- inception_2b/double_3x3_1_bn
I0416 11:56:01.680927   977 net.cpp:411] inception_2b/double_3x3_2 -> inception_2b/double_3x3_2
I0416 11:56:01.680937   977 net.cpp:163] Setting up inception_2b/double_3x3_2
I0416 11:56:01.688014   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.688026   977 layer_factory.hpp:74] Creating layer inception_2b/double_3x3_2_bn
I0416 11:56:01.688030   977 layer_factory.cpp:191] Layer inception_2b/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:01.688035   977 net.cpp:133] Creating Layer inception_2b/double_3x3_2_bn
I0416 11:56:01.688040   977 net.cpp:453] inception_2b/double_3x3_2_bn <- inception_2b/double_3x3_2
I0416 11:56:01.688045   977 net.cpp:411] inception_2b/double_3x3_2_bn -> inception_2b/double_3x3_2_bn
I0416 11:56:01.688053   977 net.cpp:163] Setting up inception_2b/double_3x3_2_bn
I0416 11:56:01.688071   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.688077   977 layer_factory.hpp:74] Creating layer inception_2b/relu_double_3x3_2
I0416 11:56:01.688081   977 net.cpp:133] Creating Layer inception_2b/relu_double_3x3_2
I0416 11:56:01.688083   977 net.cpp:453] inception_2b/relu_double_3x3_2 <- inception_2b/double_3x3_2_bn
I0416 11:56:01.688088   977 net.cpp:400] inception_2b/relu_double_3x3_2 -> inception_2b/double_3x3_2_bn (in-place)
I0416 11:56:01.688096   977 net.cpp:163] Setting up inception_2b/relu_double_3x3_2
I0416 11:56:01.688223   977 net.cpp:170] Top shape: 10 128 18 7 (161280)
I0416 11:56:01.688230   977 layer_factory.hpp:74] Creating layer inception_2b/pool
I0416 11:56:01.688233   977 net.cpp:133] Creating Layer inception_2b/pool
I0416 11:56:01.688235   977 net.cpp:453] inception_2b/pool <- inception_2a/output_inception_2a/output_0_split_2
I0416 11:56:01.688241   977 net.cpp:411] inception_2b/pool -> inception_2b/pool
I0416 11:56:01.688246   977 net.cpp:163] Setting up inception_2b/pool
I0416 11:56:01.688453   977 net.cpp:170] Top shape: 10 512 18 7 (645120)
I0416 11:56:01.688459   977 layer_factory.hpp:74] Creating layer inception_2b/output
I0416 11:56:01.688463   977 net.cpp:133] Creating Layer inception_2b/output
I0416 11:56:01.688465   977 net.cpp:453] inception_2b/output <- inception_2b/3x3_bn
I0416 11:56:01.688468   977 net.cpp:453] inception_2b/output <- inception_2b/double_3x3_2_bn
I0416 11:56:01.688472   977 net.cpp:453] inception_2b/output <- inception_2b/pool
I0416 11:56:01.688478   977 net.cpp:411] inception_2b/output -> inception_2b/output
I0416 11:56:01.688485   977 net.cpp:163] Setting up inception_2b/output
I0416 11:56:01.688491   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:01.688495   977 layer_factory.hpp:74] Creating layer inception_2b/output_inception_2b/output_0_split
I0416 11:56:01.688501   977 net.cpp:133] Creating Layer inception_2b/output_inception_2b/output_0_split
I0416 11:56:01.688504   977 net.cpp:453] inception_2b/output_inception_2b/output_0_split <- inception_2b/output
I0416 11:56:01.688510   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_0
I0416 11:56:01.688516   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_1
I0416 11:56:01.688524   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_2
I0416 11:56:01.688532   977 net.cpp:411] inception_2b/output_inception_2b/output_0_split -> inception_2b/output_inception_2b/output_0_split_3
I0416 11:56:01.688539   977 net.cpp:163] Setting up inception_2b/output_inception_2b/output_0_split
I0416 11:56:01.688544   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:01.688549   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:01.688554   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:01.688556   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:01.688560   977 layer_factory.hpp:74] Creating layer inception_3a/1x1
I0416 11:56:01.688566   977 net.cpp:133] Creating Layer inception_3a/1x1
I0416 11:56:01.688571   977 net.cpp:453] inception_3a/1x1 <- inception_2b/output_inception_2b/output_0_split_0
I0416 11:56:01.688576   977 net.cpp:411] inception_3a/1x1 -> inception_3a/1x1
I0416 11:56:01.688585   977 net.cpp:163] Setting up inception_3a/1x1
I0416 11:56:01.798647   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.798658   977 layer_factory.hpp:74] Creating layer inception_3a/1x1_bn
I0416 11:56:01.798660   977 layer_factory.cpp:191] Layer inception_3a/1x1_bn is using CAFFE engine.
I0416 11:56:01.798665   977 net.cpp:133] Creating Layer inception_3a/1x1_bn
I0416 11:56:01.798667   977 net.cpp:453] inception_3a/1x1_bn <- inception_3a/1x1
I0416 11:56:01.798673   977 net.cpp:411] inception_3a/1x1_bn -> inception_3a/1x1_bn
I0416 11:56:01.798681   977 net.cpp:163] Setting up inception_3a/1x1_bn
I0416 11:56:01.798697   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.798705   977 layer_factory.hpp:74] Creating layer inception_3a/relu_1x1
I0416 11:56:01.798709   977 net.cpp:133] Creating Layer inception_3a/relu_1x1
I0416 11:56:01.798712   977 net.cpp:453] inception_3a/relu_1x1 <- inception_3a/1x1_bn
I0416 11:56:01.798714   977 net.cpp:400] inception_3a/relu_1x1 -> inception_3a/1x1_bn (in-place)
I0416 11:56:01.798719   977 net.cpp:163] Setting up inception_3a/relu_1x1
I0416 11:56:01.798851   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.798856   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce
I0416 11:56:01.798861   977 net.cpp:133] Creating Layer inception_3a/3x3_reduce
I0416 11:56:01.798864   977 net.cpp:453] inception_3a/3x3_reduce <- inception_2b/output_inception_2b/output_0_split_1
I0416 11:56:01.798869   977 net.cpp:411] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0416 11:56:01.798878   977 net.cpp:163] Setting up inception_3a/3x3_reduce
I0416 11:56:01.909245   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.909255   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce_bn
I0416 11:56:01.909258   977 layer_factory.cpp:191] Layer inception_3a/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:01.909262   977 net.cpp:133] Creating Layer inception_3a/3x3_reduce_bn
I0416 11:56:01.909265   977 net.cpp:453] inception_3a/3x3_reduce_bn <- inception_3a/3x3_reduce
I0416 11:56:01.909272   977 net.cpp:411] inception_3a/3x3_reduce_bn -> inception_3a/3x3_reduce_bn
I0416 11:56:01.909278   977 net.cpp:163] Setting up inception_3a/3x3_reduce_bn
I0416 11:56:01.909296   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.909304   977 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3_reduce
I0416 11:56:01.909308   977 net.cpp:133] Creating Layer inception_3a/relu_3x3_reduce
I0416 11:56:01.909310   977 net.cpp:453] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce_bn
I0416 11:56:01.909314   977 net.cpp:400] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce_bn (in-place)
I0416 11:56:01.909319   977 net.cpp:163] Setting up inception_3a/relu_3x3_reduce
I0416 11:56:01.909531   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.909538   977 layer_factory.hpp:74] Creating layer inception_3a/3x3
I0416 11:56:01.909543   977 net.cpp:133] Creating Layer inception_3a/3x3
I0416 11:56:01.909546   977 net.cpp:453] inception_3a/3x3 <- inception_3a/3x3_reduce_bn
I0416 11:56:01.909553   977 net.cpp:411] inception_3a/3x3 -> inception_3a/3x3
I0416 11:56:01.909560   977 net.cpp:163] Setting up inception_3a/3x3
I0416 11:56:01.958780   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.958789   977 layer_factory.hpp:74] Creating layer inception_3a/3x3_bn
I0416 11:56:01.958792   977 layer_factory.cpp:191] Layer inception_3a/3x3_bn is using CAFFE engine.
I0416 11:56:01.958796   977 net.cpp:133] Creating Layer inception_3a/3x3_bn
I0416 11:56:01.958798   977 net.cpp:453] inception_3a/3x3_bn <- inception_3a/3x3
I0416 11:56:01.958803   977 net.cpp:411] inception_3a/3x3_bn -> inception_3a/3x3_bn
I0416 11:56:01.958811   977 net.cpp:163] Setting up inception_3a/3x3_bn
I0416 11:56:01.958825   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.958834   977 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3
I0416 11:56:01.958838   977 net.cpp:133] Creating Layer inception_3a/relu_3x3
I0416 11:56:01.958840   977 net.cpp:453] inception_3a/relu_3x3 <- inception_3a/3x3_bn
I0416 11:56:01.958844   977 net.cpp:400] inception_3a/relu_3x3 -> inception_3a/3x3_bn (in-place)
I0416 11:56:01.958849   977 net.cpp:163] Setting up inception_3a/relu_3x3
I0416 11:56:01.959064   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:01.959071   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce
I0416 11:56:01.959077   977 net.cpp:133] Creating Layer inception_3a/double_3x3_reduce
I0416 11:56:01.959080   977 net.cpp:453] inception_3a/double_3x3_reduce <- inception_2b/output_inception_2b/output_0_split_2
I0416 11:56:01.959085   977 net.cpp:411] inception_3a/double_3x3_reduce -> inception_3a/double_3x3_reduce
I0416 11:56:01.959094   977 net.cpp:163] Setting up inception_3a/double_3x3_reduce
I0416 11:56:02.068859   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.068869   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce_bn
I0416 11:56:02.068872   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:02.068876   977 net.cpp:133] Creating Layer inception_3a/double_3x3_reduce_bn
I0416 11:56:02.068879   977 net.cpp:453] inception_3a/double_3x3_reduce_bn <- inception_3a/double_3x3_reduce
I0416 11:56:02.068883   977 net.cpp:411] inception_3a/double_3x3_reduce_bn -> inception_3a/double_3x3_reduce_bn
I0416 11:56:02.068891   977 net.cpp:163] Setting up inception_3a/double_3x3_reduce_bn
I0416 11:56:02.068907   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.068917   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_reduce
I0416 11:56:02.068922   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_reduce
I0416 11:56:02.068923   977 net.cpp:453] inception_3a/relu_double_3x3_reduce <- inception_3a/double_3x3_reduce_bn
I0416 11:56:02.068927   977 net.cpp:400] inception_3a/relu_double_3x3_reduce -> inception_3a/double_3x3_reduce_bn (in-place)
I0416 11:56:02.068931   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_reduce
I0416 11:56:02.069069   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.069077   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1
I0416 11:56:02.069082   977 net.cpp:133] Creating Layer inception_3a/double_3x3_1
I0416 11:56:02.069084   977 net.cpp:453] inception_3a/double_3x3_1 <- inception_3a/double_3x3_reduce_bn
I0416 11:56:02.069089   977 net.cpp:411] inception_3a/double_3x3_1 -> inception_3a/double_3x3_1
I0416 11:56:02.069097   977 net.cpp:163] Setting up inception_3a/double_3x3_1
I0416 11:56:02.118383   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.118394   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1_bn
I0416 11:56:02.118396   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:02.118401   977 net.cpp:133] Creating Layer inception_3a/double_3x3_1_bn
I0416 11:56:02.118403   977 net.cpp:453] inception_3a/double_3x3_1_bn <- inception_3a/double_3x3_1
I0416 11:56:02.118408   977 net.cpp:411] inception_3a/double_3x3_1_bn -> inception_3a/double_3x3_1_bn
I0416 11:56:02.118417   977 net.cpp:163] Setting up inception_3a/double_3x3_1_bn
I0416 11:56:02.118432   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.118441   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_1
I0416 11:56:02.118445   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_1
I0416 11:56:02.118448   977 net.cpp:453] inception_3a/relu_double_3x3_1 <- inception_3a/double_3x3_1_bn
I0416 11:56:02.118453   977 net.cpp:400] inception_3a/relu_double_3x3_1 -> inception_3a/double_3x3_1_bn (in-place)
I0416 11:56:02.118460   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_1
I0416 11:56:02.118676   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.118682   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2
I0416 11:56:02.118687   977 net.cpp:133] Creating Layer inception_3a/double_3x3_2
I0416 11:56:02.118691   977 net.cpp:453] inception_3a/double_3x3_2 <- inception_3a/double_3x3_1_bn
I0416 11:56:02.118697   977 net.cpp:411] inception_3a/double_3x3_2 -> inception_3a/double_3x3_2
I0416 11:56:02.118705   977 net.cpp:163] Setting up inception_3a/double_3x3_2
I0416 11:56:02.167871   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.167881   977 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2_bn
I0416 11:56:02.167884   977 layer_factory.cpp:191] Layer inception_3a/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:02.167888   977 net.cpp:133] Creating Layer inception_3a/double_3x3_2_bn
I0416 11:56:02.167891   977 net.cpp:453] inception_3a/double_3x3_2_bn <- inception_3a/double_3x3_2
I0416 11:56:02.167897   977 net.cpp:411] inception_3a/double_3x3_2_bn -> inception_3a/double_3x3_2_bn
I0416 11:56:02.167904   977 net.cpp:163] Setting up inception_3a/double_3x3_2_bn
I0416 11:56:02.167922   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.167928   977 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_2
I0416 11:56:02.167932   977 net.cpp:133] Creating Layer inception_3a/relu_double_3x3_2
I0416 11:56:02.167934   977 net.cpp:453] inception_3a/relu_double_3x3_2 <- inception_3a/double_3x3_2_bn
I0416 11:56:02.167939   977 net.cpp:400] inception_3a/relu_double_3x3_2 -> inception_3a/double_3x3_2_bn (in-place)
I0416 11:56:02.167944   977 net.cpp:163] Setting up inception_3a/relu_double_3x3_2
I0416 11:56:02.168179   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.168184   977 layer_factory.hpp:74] Creating layer inception_3a/pool
I0416 11:56:02.168187   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:56:02.168190   977 net.cpp:133] Creating Layer inception_3a/pool
I0416 11:56:02.168193   977 net.cpp:453] inception_3a/pool <- inception_2b/output_inception_2b/output_0_split_3
I0416 11:56:02.168197   977 net.cpp:411] inception_3a/pool -> inception_3a/pool
I0416 11:56:02.168203   977 net.cpp:163] Setting up inception_3a/pool
I0416 11:56:02.168210   977 net.cpp:170] Top shape: 10 768 18 7 (967680)
I0416 11:56:02.168213   977 layer_factory.hpp:74] Creating layer inception_3a/pool_proj
I0416 11:56:02.168220   977 net.cpp:133] Creating Layer inception_3a/pool_proj
I0416 11:56:02.168223   977 net.cpp:453] inception_3a/pool_proj <- inception_3a/pool
I0416 11:56:02.168231   977 net.cpp:411] inception_3a/pool_proj -> inception_3a/pool_proj
I0416 11:56:02.168236   977 net.cpp:163] Setting up inception_3a/pool_proj
I0416 11:56:02.278694   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.278704   977 layer_factory.hpp:74] Creating layer inception_3a/pool_proj_bn
I0416 11:56:02.278707   977 layer_factory.cpp:191] Layer inception_3a/pool_proj_bn is using CAFFE engine.
I0416 11:56:02.278712   977 net.cpp:133] Creating Layer inception_3a/pool_proj_bn
I0416 11:56:02.278713   977 net.cpp:453] inception_3a/pool_proj_bn <- inception_3a/pool_proj
I0416 11:56:02.278718   977 net.cpp:411] inception_3a/pool_proj_bn -> inception_3a/pool_proj_bn
I0416 11:56:02.278725   977 net.cpp:163] Setting up inception_3a/pool_proj_bn
I0416 11:56:02.278741   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.278750   977 layer_factory.hpp:74] Creating layer inception_3a/relu_pool_proj
I0416 11:56:02.278754   977 net.cpp:133] Creating Layer inception_3a/relu_pool_proj
I0416 11:56:02.278758   977 net.cpp:453] inception_3a/relu_pool_proj <- inception_3a/pool_proj_bn
I0416 11:56:02.278761   977 net.cpp:400] inception_3a/relu_pool_proj -> inception_3a/pool_proj_bn (in-place)
I0416 11:56:02.278766   977 net.cpp:163] Setting up inception_3a/relu_pool_proj
I0416 11:56:02.278900   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.278906   977 layer_factory.hpp:74] Creating layer inception_3a/output
I0416 11:56:02.278910   977 net.cpp:133] Creating Layer inception_3a/output
I0416 11:56:02.278913   977 net.cpp:453] inception_3a/output <- inception_3a/1x1_bn
I0416 11:56:02.278915   977 net.cpp:453] inception_3a/output <- inception_3a/3x3_bn
I0416 11:56:02.278918   977 net.cpp:453] inception_3a/output <- inception_3a/double_3x3_2_bn
I0416 11:56:02.278923   977 net.cpp:453] inception_3a/output <- inception_3a/pool_proj_bn
I0416 11:56:02.278928   977 net.cpp:411] inception_3a/output -> inception_3a/output
I0416 11:56:02.278934   977 net.cpp:163] Setting up inception_3a/output
I0416 11:56:02.278940   977 net.cpp:170] Top shape: 10 1024 18 7 (1290240)
I0416 11:56:02.278944   977 layer_factory.hpp:74] Creating layer inception_3a/output_inception_3a/output_0_split
I0416 11:56:02.278949   977 net.cpp:133] Creating Layer inception_3a/output_inception_3a/output_0_split
I0416 11:56:02.278951   977 net.cpp:453] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0416 11:56:02.278959   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0416 11:56:02.278964   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0416 11:56:02.278970   977 net.cpp:411] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0416 11:56:02.278975   977 net.cpp:163] Setting up inception_3a/output_inception_3a/output_0_split
I0416 11:56:02.278980   977 net.cpp:170] Top shape: 10 1024 18 7 (1290240)
I0416 11:56:02.278985   977 net.cpp:170] Top shape: 10 1024 18 7 (1290240)
I0416 11:56:02.278987   977 net.cpp:170] Top shape: 10 1024 18 7 (1290240)
I0416 11:56:02.278990   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce
I0416 11:56:02.278998   977 net.cpp:133] Creating Layer inception_3b/3x3_reduce
I0416 11:56:02.279001   977 net.cpp:453] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_0
I0416 11:56:02.279008   977 net.cpp:411] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0416 11:56:02.279016   977 net.cpp:163] Setting up inception_3b/3x3_reduce
I0416 11:56:02.426558   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.426568   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce_bn
I0416 11:56:02.426570   977 layer_factory.cpp:191] Layer inception_3b/3x3_reduce_bn is using CAFFE engine.
I0416 11:56:02.426574   977 net.cpp:133] Creating Layer inception_3b/3x3_reduce_bn
I0416 11:56:02.426578   977 net.cpp:453] inception_3b/3x3_reduce_bn <- inception_3b/3x3_reduce
I0416 11:56:02.426583   977 net.cpp:411] inception_3b/3x3_reduce_bn -> inception_3b/3x3_reduce_bn
I0416 11:56:02.426589   977 net.cpp:163] Setting up inception_3b/3x3_reduce_bn
I0416 11:56:02.426604   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.426614   977 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3_reduce
I0416 11:56:02.426617   977 net.cpp:133] Creating Layer inception_3b/relu_3x3_reduce
I0416 11:56:02.426620   977 net.cpp:453] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce_bn
I0416 11:56:02.426625   977 net.cpp:400] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce_bn (in-place)
I0416 11:56:02.426630   977 net.cpp:163] Setting up inception_3b/relu_3x3_reduce
I0416 11:56:02.426851   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.426857   977 layer_factory.hpp:74] Creating layer inception_3b/3x3
I0416 11:56:02.426863   977 net.cpp:133] Creating Layer inception_3b/3x3
I0416 11:56:02.426867   977 net.cpp:453] inception_3b/3x3 <- inception_3b/3x3_reduce_bn
I0416 11:56:02.426873   977 net.cpp:411] inception_3b/3x3 -> inception_3b/3x3
I0416 11:56:02.426882   977 net.cpp:163] Setting up inception_3b/3x3
I0416 11:56:02.438428   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.438437   977 layer_factory.hpp:74] Creating layer inception_3b/3x3_bn
I0416 11:56:02.438441   977 layer_factory.cpp:191] Layer inception_3b/3x3_bn is using CAFFE engine.
I0416 11:56:02.438444   977 net.cpp:133] Creating Layer inception_3b/3x3_bn
I0416 11:56:02.438446   977 net.cpp:453] inception_3b/3x3_bn <- inception_3b/3x3
I0416 11:56:02.438452   977 net.cpp:411] inception_3b/3x3_bn -> inception_3b/3x3_bn
I0416 11:56:02.438458   977 net.cpp:163] Setting up inception_3b/3x3_bn
I0416 11:56:02.438475   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.438484   977 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3
I0416 11:56:02.438488   977 net.cpp:133] Creating Layer inception_3b/relu_3x3
I0416 11:56:02.438489   977 net.cpp:453] inception_3b/relu_3x3 <- inception_3b/3x3_bn
I0416 11:56:02.438493   977 net.cpp:400] inception_3b/relu_3x3 -> inception_3b/3x3_bn (in-place)
I0416 11:56:02.438498   977 net.cpp:163] Setting up inception_3b/relu_3x3
I0416 11:56:02.438714   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.438720   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce
I0416 11:56:02.438724   977 net.cpp:133] Creating Layer inception_3b/double_3x3_reduce
I0416 11:56:02.438729   977 net.cpp:453] inception_3b/double_3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0416 11:56:02.438733   977 net.cpp:411] inception_3b/double_3x3_reduce -> inception_3b/double_3x3_reduce
I0416 11:56:02.438741   977 net.cpp:163] Setting up inception_3b/double_3x3_reduce
I0416 11:56:02.586179   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.586190   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586192   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_reduce_bn is using CAFFE engine.
I0416 11:56:02.586222   977 net.cpp:133] Creating Layer inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586230   977 net.cpp:453] inception_3b/double_3x3_reduce_bn <- inception_3b/double_3x3_reduce
I0416 11:56:02.586233   977 net.cpp:411] inception_3b/double_3x3_reduce_bn -> inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586238   977 net.cpp:163] Setting up inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586248   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.586253   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_reduce
I0416 11:56:02.586257   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_reduce
I0416 11:56:02.586261   977 net.cpp:453] inception_3b/relu_double_3x3_reduce <- inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586266   977 net.cpp:400] inception_3b/relu_double_3x3_reduce -> inception_3b/double_3x3_reduce_bn (in-place)
I0416 11:56:02.586271   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_reduce
I0416 11:56:02.586407   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.586412   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1
I0416 11:56:02.586418   977 net.cpp:133] Creating Layer inception_3b/double_3x3_1
I0416 11:56:02.586421   977 net.cpp:453] inception_3b/double_3x3_1 <- inception_3b/double_3x3_reduce_bn
I0416 11:56:02.586424   977 net.cpp:411] inception_3b/double_3x3_1 -> inception_3b/double_3x3_1
I0416 11:56:02.586429   977 net.cpp:163] Setting up inception_3b/double_3x3_1
I0416 11:56:02.635757   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.635768   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1_bn
I0416 11:56:02.635771   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_1_bn is using CAFFE engine.
I0416 11:56:02.635774   977 net.cpp:133] Creating Layer inception_3b/double_3x3_1_bn
I0416 11:56:02.635777   977 net.cpp:453] inception_3b/double_3x3_1_bn <- inception_3b/double_3x3_1
I0416 11:56:02.635782   977 net.cpp:411] inception_3b/double_3x3_1_bn -> inception_3b/double_3x3_1_bn
I0416 11:56:02.635785   977 net.cpp:163] Setting up inception_3b/double_3x3_1_bn
I0416 11:56:02.635797   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.635807   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_1
I0416 11:56:02.635810   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_1
I0416 11:56:02.635813   977 net.cpp:453] inception_3b/relu_double_3x3_1 <- inception_3b/double_3x3_1_bn
I0416 11:56:02.635819   977 net.cpp:400] inception_3b/relu_double_3x3_1 -> inception_3b/double_3x3_1_bn (in-place)
I0416 11:56:02.635824   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_1
I0416 11:56:02.636044   977 net.cpp:170] Top shape: 10 256 18 7 (322560)
I0416 11:56:02.636049   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2
I0416 11:56:02.636055   977 net.cpp:133] Creating Layer inception_3b/double_3x3_2
I0416 11:56:02.636059   977 net.cpp:453] inception_3b/double_3x3_2 <- inception_3b/double_3x3_1_bn
I0416 11:56:02.636062   977 net.cpp:411] inception_3b/double_3x3_2 -> inception_3b/double_3x3_2
I0416 11:56:02.636066   977 net.cpp:163] Setting up inception_3b/double_3x3_2
I0416 11:56:02.646961   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.646972   977 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2_bn
I0416 11:56:02.646975   977 layer_factory.cpp:191] Layer inception_3b/double_3x3_2_bn is using CAFFE engine.
I0416 11:56:02.646980   977 net.cpp:133] Creating Layer inception_3b/double_3x3_2_bn
I0416 11:56:02.646982   977 net.cpp:453] inception_3b/double_3x3_2_bn <- inception_3b/double_3x3_2
I0416 11:56:02.646986   977 net.cpp:411] inception_3b/double_3x3_2_bn -> inception_3b/double_3x3_2_bn
I0416 11:56:02.646991   977 net.cpp:163] Setting up inception_3b/double_3x3_2_bn
I0416 11:56:02.646999   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.647003   977 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_2
I0416 11:56:02.647007   977 net.cpp:133] Creating Layer inception_3b/relu_double_3x3_2
I0416 11:56:02.647009   977 net.cpp:453] inception_3b/relu_double_3x3_2 <- inception_3b/double_3x3_2_bn
I0416 11:56:02.647012   977 net.cpp:400] inception_3b/relu_double_3x3_2 -> inception_3b/double_3x3_2_bn (in-place)
I0416 11:56:02.647014   977 net.cpp:163] Setting up inception_3b/relu_double_3x3_2
I0416 11:56:02.647238   977 net.cpp:170] Top shape: 10 256 9 4 (92160)
I0416 11:56:02.647244   977 layer_factory.hpp:74] Creating layer inception_3b/pool
I0416 11:56:02.647248   977 layer_factory.cpp:64] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0416 11:56:02.647251   977 net.cpp:133] Creating Layer inception_3b/pool
I0416 11:56:02.647254   977 net.cpp:453] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_2
I0416 11:56:02.647258   977 net.cpp:411] inception_3b/pool -> inception_3b/pool
I0416 11:56:02.647261   977 net.cpp:163] Setting up inception_3b/pool
I0416 11:56:02.647266   977 net.cpp:170] Top shape: 10 1024 9 4 (368640)
I0416 11:56:02.647269   977 layer_factory.hpp:74] Creating layer inception_3b/output
I0416 11:56:02.647271   977 net.cpp:133] Creating Layer inception_3b/output
I0416 11:56:02.647274   977 net.cpp:453] inception_3b/output <- inception_3b/3x3_bn
I0416 11:56:02.647275   977 net.cpp:453] inception_3b/output <- inception_3b/double_3x3_2_bn
I0416 11:56:02.647279   977 net.cpp:453] inception_3b/output <- inception_3b/pool
I0416 11:56:02.647280   977 net.cpp:411] inception_3b/output -> inception_3b/output
I0416 11:56:02.647284   977 net.cpp:163] Setting up inception_3b/output
I0416 11:56:02.647287   977 net.cpp:170] Top shape: 10 1536 9 4 (552960)
I0416 11:56:02.647290   977 layer_factory.hpp:74] Creating layer global_pool
I0416 11:56:02.647294   977 net.cpp:133] Creating Layer global_pool
I0416 11:56:02.647297   977 net.cpp:453] global_pool <- inception_3b/output
I0416 11:56:02.647302   977 net.cpp:411] global_pool -> global_pool
I0416 11:56:02.647310   977 net.cpp:163] Setting up global_pool
I0416 11:56:02.647441   977 net.cpp:170] Top shape: 10 1536 1 1 (15360)
I0416 11:56:02.647447   977 layer_factory.hpp:74] Creating layer gather_global_pool_to_fc7
I0416 11:56:02.647451   977 net.cpp:133] Creating Layer gather_global_pool_to_fc7
I0416 11:56:02.647454   977 net.cpp:453] gather_global_pool_to_fc7 <- global_pool
I0416 11:56:02.647456   977 net.cpp:411] gather_global_pool_to_fc7 -> gathered_global_pool
I0416 11:56:02.647459   977 net.cpp:163] Setting up gather_global_pool_to_fc7
I0416 11:56:02.647462   977 net.cpp:170] Top shape: 20 1536 1 1 (30720)
I0416 11:56:02.647464   977 layer_factory.hpp:74] Creating layer fc7
I0416 11:56:02.647469   977 net.cpp:133] Creating Layer fc7
I0416 11:56:02.647469   977 net.cpp:453] fc7 <- gathered_global_pool
I0416 11:56:02.647472   977 net.cpp:411] fc7 -> fc7
I0416 11:56:02.647476   977 net.cpp:163] Setting up fc7
I0416 11:56:02.649040   977 net.cpp:170] Top shape: 20 256 (5120)
I0416 11:56:02.649049   977 layer_factory.hpp:74] Creating layer fc7_bn
I0416 11:56:02.649050   977 layer_factory.cpp:191] Layer fc7_bn is using CAFFE engine.
I0416 11:56:02.649055   977 net.cpp:133] Creating Layer fc7_bn
I0416 11:56:02.649056   977 net.cpp:453] fc7_bn <- fc7
I0416 11:56:02.649060   977 net.cpp:411] fc7_bn -> fc7_bn
I0416 11:56:02.649065   977 net.cpp:163] Setting up fc7_bn
I0416 11:56:02.649072   977 net.cpp:170] Top shape: 20 256 (5120)
I0416 11:56:02.649076   977 layer_factory.hpp:74] Creating layer relu7
I0416 11:56:02.649085   977 net.cpp:133] Creating Layer relu7
I0416 11:56:02.649087   977 net.cpp:453] relu7 <- fc7_bn
I0416 11:56:02.649091   977 net.cpp:400] relu7 -> fc7_bn (in-place)
I0416 11:56:02.649096   977 net.cpp:163] Setting up relu7
I0416 11:56:02.649310   977 net.cpp:170] Top shape: 20 256 (5120)
I0416 11:56:02.649317   977 layer_factory.hpp:74] Creating layer drop7
I0416 11:56:02.649320   977 net.cpp:133] Creating Layer drop7
I0416 11:56:02.649322   977 net.cpp:453] drop7 <- fc7_bn
I0416 11:56:02.649325   977 net.cpp:400] drop7 -> fc7_bn (in-place)
I0416 11:56:02.649328   977 net.cpp:163] Setting up drop7
I0416 11:56:02.649332   977 net.cpp:170] Top shape: 20 256 (5120)
I0416 11:56:02.649333   977 layer_factory.hpp:74] Creating layer fc8_cuhk03
I0416 11:56:02.649336   977 net.cpp:133] Creating Layer fc8_cuhk03
I0416 11:56:02.649338   977 net.cpp:453] fc8_cuhk03 <- fc7_bn
I0416 11:56:02.649341   977 net.cpp:411] fc8_cuhk03 -> fc8_cuhk03
I0416 11:56:02.649345   977 net.cpp:163] Setting up fc8_cuhk03
I0416 11:56:02.651907   977 net.cpp:170] Top shape: 20 1467 (29340)
I0416 11:56:02.651914   977 layer_factory.hpp:74] Creating layer fc8_cuhk03_fc8_cuhk03_0_split
I0416 11:56:02.651918   977 net.cpp:133] Creating Layer fc8_cuhk03_fc8_cuhk03_0_split
I0416 11:56:02.651921   977 net.cpp:453] fc8_cuhk03_fc8_cuhk03_0_split <- fc8_cuhk03
I0416 11:56:02.651924   977 net.cpp:411] fc8_cuhk03_fc8_cuhk03_0_split -> fc8_cuhk03_fc8_cuhk03_0_split_0
I0416 11:56:02.651927   977 net.cpp:411] fc8_cuhk03_fc8_cuhk03_0_split -> fc8_cuhk03_fc8_cuhk03_0_split_1
I0416 11:56:02.651932   977 net.cpp:163] Setting up fc8_cuhk03_fc8_cuhk03_0_split
I0416 11:56:02.651933   977 net.cpp:170] Top shape: 20 1467 (29340)
I0416 11:56:02.651935   977 net.cpp:170] Top shape: 20 1467 (29340)
I0416 11:56:02.651937   977 layer_factory.hpp:74] Creating layer gather_label_data_1_split_to_loss
I0416 11:56:02.651940   977 net.cpp:133] Creating Layer gather_label_data_1_split_to_loss
I0416 11:56:02.651942   977 net.cpp:453] gather_label_data_1_split_to_loss <- label_data_1_split_0
I0416 11:56:02.651944   977 net.cpp:411] gather_label_data_1_split_to_loss -> gathered_label_data_1_split_0
I0416 11:56:02.651947   977 net.cpp:163] Setting up gather_label_data_1_split_to_loss
I0416 11:56:02.651950   977 net.cpp:170] Top shape: 20 (20)
I0416 11:56:02.651952   977 layer_factory.hpp:74] Creating layer loss
I0416 11:56:02.651955   977 net.cpp:133] Creating Layer loss
I0416 11:56:02.651959   977 net.cpp:453] loss <- fc8_cuhk03_fc8_cuhk03_0_split_0
I0416 11:56:02.651964   977 net.cpp:453] loss <- gathered_label_data_1_split_0
I0416 11:56:02.651968   977 net.cpp:411] loss -> loss
I0416 11:56:02.651973   977 net.cpp:163] Setting up loss
I0416 11:56:02.651978   977 layer_factory.hpp:74] Creating layer loss
I0416 11:56:02.652144   977 net.cpp:170] Top shape: (1)
I0416 11:56:02.652149   977 net.cpp:172]     with loss weight 1
I0416 11:56:02.652154   977 layer_factory.hpp:74] Creating layer gather_label_data_1_split_to_accuracy
I0416 11:56:02.652158   977 net.cpp:133] Creating Layer gather_label_data_1_split_to_accuracy
I0416 11:56:02.652159   977 net.cpp:453] gather_label_data_1_split_to_accuracy <- label_data_1_split_1
I0416 11:56:02.652163   977 net.cpp:411] gather_label_data_1_split_to_accuracy -> gathered_label_data_1_split_1
I0416 11:56:02.652166   977 net.cpp:163] Setting up gather_label_data_1_split_to_accuracy
I0416 11:56:02.652169   977 net.cpp:170] Top shape: 20 (20)
I0416 11:56:02.652170   977 layer_factory.hpp:74] Creating layer accuracy
I0416 11:56:02.652173   977 net.cpp:133] Creating Layer accuracy
I0416 11:56:02.652175   977 net.cpp:453] accuracy <- fc8_cuhk03_fc8_cuhk03_0_split_1
I0416 11:56:02.652178   977 net.cpp:453] accuracy <- gathered_label_data_1_split_1
I0416 11:56:02.652184   977 net.cpp:411] accuracy -> accuracy
I0416 11:56:02.652187   977 net.cpp:163] Setting up accuracy
I0416 11:56:02.652191   977 net.cpp:170] Top shape: (1)
I0416 11:56:02.652194   977 net.cpp:237] accuracy does not need backward computation.
I0416 11:56:02.652197   977 net.cpp:237] gather_label_data_1_split_to_accuracy does not need backward computation.
I0416 11:56:02.652201   977 net.cpp:235] loss needs backward computation.
I0416 11:56:02.652204   977 net.cpp:237] gather_label_data_1_split_to_loss does not need backward computation.
I0416 11:56:02.652207   977 net.cpp:235] fc8_cuhk03_fc8_cuhk03_0_split needs backward computation.
I0416 11:56:02.652211   977 net.cpp:235] fc8_cuhk03 needs backward computation.
I0416 11:56:02.652215   977 net.cpp:235] drop7 needs backward computation.
I0416 11:56:02.652217   977 net.cpp:235] relu7 needs backward computation.
I0416 11:56:02.652220   977 net.cpp:235] fc7_bn needs backward computation.
I0416 11:56:02.652222   977 net.cpp:235] fc7 needs backward computation.
I0416 11:56:02.652225   977 net.cpp:235] gather_global_pool_to_fc7 needs backward computation.
I0416 11:56:02.652228   977 net.cpp:235] global_pool needs backward computation.
I0416 11:56:02.652231   977 net.cpp:235] inception_3b/output needs backward computation.
I0416 11:56:02.652235   977 net.cpp:235] inception_3b/pool needs backward computation.
I0416 11:56:02.652238   977 net.cpp:235] inception_3b/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652241   977 net.cpp:235] inception_3b/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652245   977 net.cpp:235] inception_3b/double_3x3_2 needs backward computation.
I0416 11:56:02.652248   977 net.cpp:235] inception_3b/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652251   977 net.cpp:235] inception_3b/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652254   977 net.cpp:235] inception_3b/double_3x3_1 needs backward computation.
I0416 11:56:02.652257   977 net.cpp:235] inception_3b/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652261   977 net.cpp:235] inception_3b/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652264   977 net.cpp:235] inception_3b/double_3x3_reduce needs backward computation.
I0416 11:56:02.652269   977 net.cpp:235] inception_3b/relu_3x3 needs backward computation.
I0416 11:56:02.652272   977 net.cpp:235] inception_3b/3x3_bn needs backward computation.
I0416 11:56:02.652276   977 net.cpp:235] inception_3b/3x3 needs backward computation.
I0416 11:56:02.652279   977 net.cpp:235] inception_3b/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652282   977 net.cpp:235] inception_3b/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652286   977 net.cpp:235] inception_3b/3x3_reduce needs backward computation.
I0416 11:56:02.652288   977 net.cpp:235] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0416 11:56:02.652292   977 net.cpp:235] inception_3a/output needs backward computation.
I0416 11:56:02.652297   977 net.cpp:235] inception_3a/relu_pool_proj needs backward computation.
I0416 11:56:02.652302   977 net.cpp:235] inception_3a/pool_proj_bn needs backward computation.
I0416 11:56:02.652305   977 net.cpp:235] inception_3a/pool_proj needs backward computation.
I0416 11:56:02.652309   977 net.cpp:235] inception_3a/pool needs backward computation.
I0416 11:56:02.652312   977 net.cpp:235] inception_3a/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652315   977 net.cpp:235] inception_3a/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652318   977 net.cpp:235] inception_3a/double_3x3_2 needs backward computation.
I0416 11:56:02.652323   977 net.cpp:235] inception_3a/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652326   977 net.cpp:235] inception_3a/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652329   977 net.cpp:235] inception_3a/double_3x3_1 needs backward computation.
I0416 11:56:02.652333   977 net.cpp:235] inception_3a/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652336   977 net.cpp:235] inception_3a/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652339   977 net.cpp:235] inception_3a/double_3x3_reduce needs backward computation.
I0416 11:56:02.652343   977 net.cpp:235] inception_3a/relu_3x3 needs backward computation.
I0416 11:56:02.652345   977 net.cpp:235] inception_3a/3x3_bn needs backward computation.
I0416 11:56:02.652349   977 net.cpp:235] inception_3a/3x3 needs backward computation.
I0416 11:56:02.652353   977 net.cpp:235] inception_3a/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652355   977 net.cpp:235] inception_3a/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652359   977 net.cpp:235] inception_3a/3x3_reduce needs backward computation.
I0416 11:56:02.652362   977 net.cpp:235] inception_3a/relu_1x1 needs backward computation.
I0416 11:56:02.652365   977 net.cpp:235] inception_3a/1x1_bn needs backward computation.
I0416 11:56:02.652369   977 net.cpp:235] inception_3a/1x1 needs backward computation.
I0416 11:56:02.652372   977 net.cpp:235] inception_2b/output_inception_2b/output_0_split needs backward computation.
I0416 11:56:02.652376   977 net.cpp:235] inception_2b/output needs backward computation.
I0416 11:56:02.652380   977 net.cpp:235] inception_2b/pool needs backward computation.
I0416 11:56:02.652384   977 net.cpp:235] inception_2b/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652387   977 net.cpp:235] inception_2b/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652390   977 net.cpp:235] inception_2b/double_3x3_2 needs backward computation.
I0416 11:56:02.652395   977 net.cpp:235] inception_2b/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652397   977 net.cpp:235] inception_2b/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652401   977 net.cpp:235] inception_2b/double_3x3_1 needs backward computation.
I0416 11:56:02.652405   977 net.cpp:235] inception_2b/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652410   977 net.cpp:235] inception_2b/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652415   977 net.cpp:235] inception_2b/double_3x3_reduce needs backward computation.
I0416 11:56:02.652417   977 net.cpp:235] inception_2b/relu_3x3 needs backward computation.
I0416 11:56:02.652420   977 net.cpp:235] inception_2b/3x3_bn needs backward computation.
I0416 11:56:02.652422   977 net.cpp:235] inception_2b/3x3 needs backward computation.
I0416 11:56:02.652426   977 net.cpp:235] inception_2b/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652431   977 net.cpp:235] inception_2b/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652433   977 net.cpp:235] inception_2b/3x3_reduce needs backward computation.
I0416 11:56:02.652436   977 net.cpp:235] inception_2a/output_inception_2a/output_0_split needs backward computation.
I0416 11:56:02.652439   977 net.cpp:235] inception_2a/output needs backward computation.
I0416 11:56:02.652444   977 net.cpp:235] inception_2a/relu_pool_proj needs backward computation.
I0416 11:56:02.652447   977 net.cpp:235] inception_2a/pool_proj_bn needs backward computation.
I0416 11:56:02.652451   977 net.cpp:235] inception_2a/pool_proj needs backward computation.
I0416 11:56:02.652454   977 net.cpp:235] inception_2a/pool needs backward computation.
I0416 11:56:02.652459   977 net.cpp:235] inception_2a/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652462   977 net.cpp:235] inception_2a/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652465   977 net.cpp:235] inception_2a/double_3x3_2 needs backward computation.
I0416 11:56:02.652468   977 net.cpp:235] inception_2a/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652472   977 net.cpp:235] inception_2a/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652475   977 net.cpp:235] inception_2a/double_3x3_1 needs backward computation.
I0416 11:56:02.652478   977 net.cpp:235] inception_2a/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652482   977 net.cpp:235] inception_2a/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652485   977 net.cpp:235] inception_2a/double_3x3_reduce needs backward computation.
I0416 11:56:02.652488   977 net.cpp:235] inception_2a/relu_3x3 needs backward computation.
I0416 11:56:02.652492   977 net.cpp:235] inception_2a/3x3_bn needs backward computation.
I0416 11:56:02.652494   977 net.cpp:235] inception_2a/3x3 needs backward computation.
I0416 11:56:02.652498   977 net.cpp:235] inception_2a/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652501   977 net.cpp:235] inception_2a/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652504   977 net.cpp:235] inception_2a/3x3_reduce needs backward computation.
I0416 11:56:02.652508   977 net.cpp:235] inception_2a/relu_1x1 needs backward computation.
I0416 11:56:02.652511   977 net.cpp:235] inception_2a/1x1_bn needs backward computation.
I0416 11:56:02.652514   977 net.cpp:235] inception_2a/1x1 needs backward computation.
I0416 11:56:02.652518   977 net.cpp:235] inception_1b/output_inception_1b/output_0_split needs backward computation.
I0416 11:56:02.652521   977 net.cpp:235] inception_1b/output needs backward computation.
I0416 11:56:02.652525   977 net.cpp:235] inception_1b/pool needs backward computation.
I0416 11:56:02.652529   977 net.cpp:235] inception_1b/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652532   977 net.cpp:235] inception_1b/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652537   977 net.cpp:235] inception_1b/double_3x3_2 needs backward computation.
I0416 11:56:02.652540   977 net.cpp:235] inception_1b/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652544   977 net.cpp:235] inception_1b/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652547   977 net.cpp:235] inception_1b/double_3x3_1 needs backward computation.
I0416 11:56:02.652550   977 net.cpp:235] inception_1b/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652554   977 net.cpp:235] inception_1b/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652557   977 net.cpp:235] inception_1b/double_3x3_reduce needs backward computation.
I0416 11:56:02.652560   977 net.cpp:235] inception_1b/relu_3x3 needs backward computation.
I0416 11:56:02.652564   977 net.cpp:235] inception_1b/3x3_bn needs backward computation.
I0416 11:56:02.652567   977 net.cpp:235] inception_1b/3x3 needs backward computation.
I0416 11:56:02.652571   977 net.cpp:235] inception_1b/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652575   977 net.cpp:235] inception_1b/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652578   977 net.cpp:235] inception_1b/3x3_reduce needs backward computation.
I0416 11:56:02.652582   977 net.cpp:235] inception_1a/output_inception_1a/output_0_split needs backward computation.
I0416 11:56:02.652585   977 net.cpp:235] inception_1a/output needs backward computation.
I0416 11:56:02.652590   977 net.cpp:235] inception_1a/relu_pool_proj needs backward computation.
I0416 11:56:02.652595   977 net.cpp:235] inception_1a/pool_proj_bn needs backward computation.
I0416 11:56:02.652597   977 net.cpp:235] inception_1a/pool_proj needs backward computation.
I0416 11:56:02.652601   977 net.cpp:235] inception_1a/pool needs backward computation.
I0416 11:56:02.652604   977 net.cpp:235] inception_1a/relu_double_3x3_2 needs backward computation.
I0416 11:56:02.652607   977 net.cpp:235] inception_1a/double_3x3_2_bn needs backward computation.
I0416 11:56:02.652611   977 net.cpp:235] inception_1a/double_3x3_2 needs backward computation.
I0416 11:56:02.652614   977 net.cpp:235] inception_1a/relu_double_3x3_1 needs backward computation.
I0416 11:56:02.652617   977 net.cpp:235] inception_1a/double_3x3_1_bn needs backward computation.
I0416 11:56:02.652621   977 net.cpp:235] inception_1a/double_3x3_1 needs backward computation.
I0416 11:56:02.652624   977 net.cpp:235] inception_1a/relu_double_3x3_reduce needs backward computation.
I0416 11:56:02.652627   977 net.cpp:235] inception_1a/double_3x3_reduce_bn needs backward computation.
I0416 11:56:02.652631   977 net.cpp:235] inception_1a/double_3x3_reduce needs backward computation.
I0416 11:56:02.652634   977 net.cpp:235] inception_1a/relu_3x3 needs backward computation.
I0416 11:56:02.652637   977 net.cpp:235] inception_1a/3x3_bn needs backward computation.
I0416 11:56:02.652640   977 net.cpp:235] inception_1a/3x3 needs backward computation.
I0416 11:56:02.652644   977 net.cpp:235] inception_1a/relu_3x3_reduce needs backward computation.
I0416 11:56:02.652647   977 net.cpp:235] inception_1a/3x3_reduce_bn needs backward computation.
I0416 11:56:02.652652   977 net.cpp:235] inception_1a/3x3_reduce needs backward computation.
I0416 11:56:02.652654   977 net.cpp:235] inception_1a/relu_1x1 needs backward computation.
I0416 11:56:02.652657   977 net.cpp:235] inception_1a/1x1_bn needs backward computation.
I0416 11:56:02.652660   977 net.cpp:235] inception_1a/1x1 needs backward computation.
I0416 11:56:02.652664   977 net.cpp:235] pool1_pool1_0_split needs backward computation.
I0416 11:56:02.652667   977 net.cpp:235] pool1 needs backward computation.
I0416 11:56:02.652670   977 net.cpp:235] relu3 needs backward computation.
I0416 11:56:02.652673   977 net.cpp:235] conv3_bn needs backward computation.
I0416 11:56:02.652678   977 net.cpp:235] conv3 needs backward computation.
I0416 11:56:02.652680   977 net.cpp:235] relu2 needs backward computation.
I0416 11:56:02.652683   977 net.cpp:235] conv2_bn needs backward computation.
I0416 11:56:02.652686   977 net.cpp:235] conv2 needs backward computation.
I0416 11:56:02.652689   977 net.cpp:235] relu1 needs backward computation.
I0416 11:56:02.652693   977 net.cpp:235] conv1_bn needs backward computation.
I0416 11:56:02.652698   977 net.cpp:235] conv1 needs backward computation.
I0416 11:56:02.652701   977 net.cpp:237] label_data_1_split does not need backward computation.
I0416 11:56:02.652705   977 net.cpp:237] data does not need backward computation.
I0416 11:56:02.652707   977 net.cpp:278] This network produces output accuracy
I0416 11:56:02.652710   977 net.cpp:278] This network produces output loss
I0416 11:56:02.652792   977 net.cpp:290] Network initialization done.
I0416 11:56:02.652798   977 net.cpp:291] Memory required for data: 620348528
I0416 11:56:02.657526   977 solver.cpp:51] Solver scaffolding done.
I0416 11:56:02.657742   977 solver.cpp:257] Solving CUHK03
I0416 11:56:02.657747   977 solver.cpp:258] Learning Rate Policy: step
I0416 11:56:02.666570   977 solver.cpp:316] Iteration 0, Testing net (#0)
I0416 11:56:02.825023   977 cudnn_conv_layer.cpp:179] Optimized cudnn conv
I0416 11:56:12.913391   977 solver.cpp:373]     Test net output #0: accuracy = 0.000570342
I0416 11:56:12.913414   977 solver.cpp:373]     Test net output #1: loss = 7.2934 (* 1 = 7.2934 loss)
I0416 11:56:13.535109   977 solver.cpp:221] Iteration 0, loss = 7.29173
I0416 11:56:13.535136   977 solver.cpp:236]     Train net output #0: loss = 7.2909 (* 1 = 7.2909 loss)
I0416 11:56:13.535152   977 solver.cpp:542] Iteration 0, lr = 0.1
I0416 11:56:25.466193   977 solver.cpp:221] Iteration 20, loss = 7.19722
I0416 11:56:25.466223   977 solver.cpp:236]     Train net output #0: loss = 7.27996 (* 1 = 7.27996 loss)
I0416 11:56:25.466228   977 solver.cpp:542] Iteration 20, lr = 0.1
I0416 11:56:37.399644   977 solver.cpp:221] Iteration 40, loss = 7.22544
I0416 11:56:37.399672   977 solver.cpp:236]     Train net output #0: loss = 7.05362 (* 1 = 7.05362 loss)
I0416 11:56:37.399677   977 solver.cpp:542] Iteration 40, lr = 0.1
I0416 11:56:49.391418   977 solver.cpp:221] Iteration 60, loss = 7.06384
I0416 11:56:49.391445   977 solver.cpp:236]     Train net output #0: loss = 6.85543 (* 1 = 6.85543 loss)
I0416 11:56:49.391450   977 solver.cpp:542] Iteration 60, lr = 0.1
I0416 11:57:01.400041   977 solver.cpp:221] Iteration 80, loss = 6.84175
I0416 11:57:01.400069   977 solver.cpp:236]     Train net output #0: loss = 6.62699 (* 1 = 6.62699 loss)
I0416 11:57:01.400074   977 solver.cpp:542] Iteration 80, lr = 0.1
I0416 11:57:14.226145   977 solver.cpp:221] Iteration 100, loss = 6.68343
I0416 11:57:14.226173   977 solver.cpp:236]     Train net output #0: loss = 6.46997 (* 1 = 6.46997 loss)
I0416 11:57:14.226178   977 solver.cpp:542] Iteration 100, lr = 0.1
I0416 11:57:27.679373   977 solver.cpp:221] Iteration 120, loss = 6.50774
I0416 11:57:27.679400   977 solver.cpp:236]     Train net output #0: loss = 6.59036 (* 1 = 6.59036 loss)
I0416 11:57:27.679405   977 solver.cpp:542] Iteration 120, lr = 0.1
I0416 11:57:41.122529   977 solver.cpp:221] Iteration 140, loss = 6.35358
I0416 11:57:41.122556   977 solver.cpp:236]     Train net output #0: loss = 6.13585 (* 1 = 6.13585 loss)
I0416 11:57:41.122561   977 solver.cpp:542] Iteration 140, lr = 0.1
I0416 11:57:54.564564   977 solver.cpp:221] Iteration 160, loss = 6.20572
I0416 11:57:54.564591   977 solver.cpp:236]     Train net output #0: loss = 6.02846 (* 1 = 6.02846 loss)
I0416 11:57:54.564595   977 solver.cpp:542] Iteration 160, lr = 0.1
I0416 11:58:08.007705   977 solver.cpp:221] Iteration 180, loss = 6.08471
I0416 11:58:08.007731   977 solver.cpp:236]     Train net output #0: loss = 5.72042 (* 1 = 5.72042 loss)
I0416 11:58:08.007736   977 solver.cpp:542] Iteration 180, lr = 0.1
I0416 11:58:20.788887   977 solver.cpp:316] Iteration 200, Testing net (#0)
I0416 11:58:32.268290   977 solver.cpp:373]     Test net output #0: accuracy = 0.0121673
I0416 11:58:32.268312   977 solver.cpp:373]     Test net output #1: loss = 6.23953 (* 1 = 6.23953 loss)
I0416 11:58:32.931598   977 solver.cpp:221] Iteration 200, loss = 5.96076
I0416 11:58:32.931624   977 solver.cpp:236]     Train net output #0: loss = 5.7215 (* 1 = 5.7215 loss)
I0416 11:58:32.931629   977 solver.cpp:542] Iteration 200, lr = 0.1
I0416 11:58:46.405870   977 solver.cpp:221] Iteration 220, loss = 5.86567
I0416 11:58:46.405897   977 solver.cpp:236]     Train net output #0: loss = 5.83041 (* 1 = 5.83041 loss)
I0416 11:58:46.405901   977 solver.cpp:542] Iteration 220, lr = 0.1
I0416 11:58:59.851294   977 solver.cpp:221] Iteration 240, loss = 5.69979
I0416 11:58:59.851321   977 solver.cpp:236]     Train net output #0: loss = 5.52746 (* 1 = 5.52746 loss)
I0416 11:58:59.851327   977 solver.cpp:542] Iteration 240, lr = 0.1
I0416 11:59:13.316293   977 solver.cpp:221] Iteration 260, loss = 5.64735
I0416 11:59:13.316319   977 solver.cpp:236]     Train net output #0: loss = 5.58743 (* 1 = 5.58743 loss)
I0416 11:59:13.316325   977 solver.cpp:542] Iteration 260, lr = 0.1
I0416 11:59:26.760874   977 solver.cpp:221] Iteration 280, loss = 5.57411
I0416 11:59:26.760901   977 solver.cpp:236]     Train net output #0: loss = 5.65648 (* 1 = 5.65648 loss)
I0416 11:59:26.760907   977 solver.cpp:542] Iteration 280, lr = 0.1
I0416 11:59:40.195319   977 solver.cpp:221] Iteration 300, loss = 5.43517
I0416 11:59:40.195346   977 solver.cpp:236]     Train net output #0: loss = 4.86223 (* 1 = 4.86223 loss)
I0416 11:59:40.195351   977 solver.cpp:542] Iteration 300, lr = 0.1
I0416 11:59:53.631084   977 solver.cpp:221] Iteration 320, loss = 5.3176
I0416 11:59:53.631110   977 solver.cpp:236]     Train net output #0: loss = 5.19079 (* 1 = 5.19079 loss)
I0416 11:59:53.631114   977 solver.cpp:542] Iteration 320, lr = 0.1
I0416 12:00:07.084257   977 solver.cpp:221] Iteration 340, loss = 5.28264
I0416 12:00:07.084285   977 solver.cpp:236]     Train net output #0: loss = 5.1566 (* 1 = 5.1566 loss)
I0416 12:00:07.084290   977 solver.cpp:542] Iteration 340, lr = 0.1
I0416 12:00:20.531321   977 solver.cpp:221] Iteration 360, loss = 5.16207
I0416 12:00:20.531352   977 solver.cpp:236]     Train net output #0: loss = 5.45186 (* 1 = 5.45186 loss)
I0416 12:00:20.531358   977 solver.cpp:542] Iteration 360, lr = 0.1
I0416 12:00:33.995112   977 solver.cpp:221] Iteration 380, loss = 5.09811
I0416 12:00:33.995139   977 solver.cpp:236]     Train net output #0: loss = 4.92264 (* 1 = 4.92264 loss)
I0416 12:00:33.995144   977 solver.cpp:542] Iteration 380, lr = 0.1
I0416 12:00:46.774778   977 solver.cpp:316] Iteration 400, Testing net (#0)
I0416 12:00:58.247997   977 solver.cpp:373]     Test net output #0: accuracy = 0.0302282
I0416 12:00:58.248019   977 solver.cpp:373]     Test net output #1: loss = 5.98019 (* 1 = 5.98019 loss)
I0416 12:00:58.912328   977 solver.cpp:221] Iteration 400, loss = 5.06387
I0416 12:00:58.912353   977 solver.cpp:236]     Train net output #0: loss = 5.13775 (* 1 = 5.13775 loss)
I0416 12:00:58.912358   977 solver.cpp:542] Iteration 400, lr = 0.1
I0416 12:01:12.354290   977 solver.cpp:221] Iteration 420, loss = 5.01668
I0416 12:01:12.354317   977 solver.cpp:236]     Train net output #0: loss = 5.28083 (* 1 = 5.28083 loss)
I0416 12:01:12.354321   977 solver.cpp:542] Iteration 420, lr = 0.1
I0416 12:01:25.792253   977 solver.cpp:221] Iteration 440, loss = 4.89039
I0416 12:01:25.792279   977 solver.cpp:236]     Train net output #0: loss = 4.63776 (* 1 = 4.63776 loss)
I0416 12:01:25.792284   977 solver.cpp:542] Iteration 440, lr = 0.1
I0416 12:01:39.254892   977 solver.cpp:221] Iteration 460, loss = 4.84417
I0416 12:01:39.254920   977 solver.cpp:236]     Train net output #0: loss = 4.77818 (* 1 = 4.77818 loss)
I0416 12:01:39.254925   977 solver.cpp:542] Iteration 460, lr = 0.1
I0416 12:01:52.713605   977 solver.cpp:221] Iteration 480, loss = 4.80541
I0416 12:01:52.713631   977 solver.cpp:236]     Train net output #0: loss = 4.86577 (* 1 = 4.86577 loss)
I0416 12:01:52.713636   977 solver.cpp:542] Iteration 480, lr = 0.1
I0416 12:02:06.165297   977 solver.cpp:221] Iteration 500, loss = 4.67358
I0416 12:02:06.165324   977 solver.cpp:236]     Train net output #0: loss = 4.74967 (* 1 = 4.74967 loss)
I0416 12:02:06.165328   977 solver.cpp:542] Iteration 500, lr = 0.1
I0416 12:02:19.613281   977 solver.cpp:221] Iteration 520, loss = 4.6955
I0416 12:02:19.613307   977 solver.cpp:236]     Train net output #0: loss = 4.81438 (* 1 = 4.81438 loss)
I0416 12:02:19.613312   977 solver.cpp:542] Iteration 520, lr = 0.1
I0416 12:02:33.073156   977 solver.cpp:221] Iteration 540, loss = 4.59907
I0416 12:02:33.073184   977 solver.cpp:236]     Train net output #0: loss = 4.43196 (* 1 = 4.43196 loss)
I0416 12:02:33.073189   977 solver.cpp:542] Iteration 540, lr = 0.1
I0416 12:02:46.538327   977 solver.cpp:221] Iteration 560, loss = 4.53005
I0416 12:02:46.538354   977 solver.cpp:236]     Train net output #0: loss = 4.52246 (* 1 = 4.52246 loss)
I0416 12:02:46.538359   977 solver.cpp:542] Iteration 560, lr = 0.1
I0416 12:02:59.966320   977 solver.cpp:221] Iteration 580, loss = 4.44202
I0416 12:02:59.966346   977 solver.cpp:236]     Train net output #0: loss = 4.64338 (* 1 = 4.64338 loss)
I0416 12:02:59.966351   977 solver.cpp:542] Iteration 580, lr = 0.1
I0416 12:03:12.745297   977 solver.cpp:316] Iteration 600, Testing net (#0)
I0416 12:03:24.223176   977 solver.cpp:373]     Test net output #0: accuracy = 0.0437263
I0416 12:03:24.223198   977 solver.cpp:373]     Test net output #1: loss = 6.30604 (* 1 = 6.30604 loss)
I0416 12:03:24.887387   977 solver.cpp:221] Iteration 600, loss = 4.39993
I0416 12:03:24.887415   977 solver.cpp:236]     Train net output #0: loss = 4.1977 (* 1 = 4.1977 loss)
I0416 12:03:24.887419   977 solver.cpp:542] Iteration 600, lr = 0.1
I0416 12:03:38.324621   977 solver.cpp:221] Iteration 620, loss = 4.33378
I0416 12:03:38.324653   977 solver.cpp:236]     Train net output #0: loss = 4.30936 (* 1 = 4.30936 loss)
I0416 12:03:38.324658   977 solver.cpp:542] Iteration 620, lr = 0.1
I0416 12:03:51.764330   977 solver.cpp:221] Iteration 640, loss = 4.25012
I0416 12:03:51.764356   977 solver.cpp:236]     Train net output #0: loss = 3.90348 (* 1 = 3.90348 loss)
I0416 12:03:51.764360   977 solver.cpp:542] Iteration 640, lr = 0.1
I0416 12:04:05.218893   977 solver.cpp:221] Iteration 660, loss = 4.2093
I0416 12:04:05.218919   977 solver.cpp:236]     Train net output #0: loss = 4.14048 (* 1 = 4.14048 loss)
I0416 12:04:05.218924   977 solver.cpp:542] Iteration 660, lr = 0.1
I0416 12:04:18.652251   977 solver.cpp:221] Iteration 680, loss = 4.19311
I0416 12:04:18.652278   977 solver.cpp:236]     Train net output #0: loss = 4.11554 (* 1 = 4.11554 loss)
I0416 12:04:18.652283   977 solver.cpp:542] Iteration 680, lr = 0.1
I0416 12:04:32.083230   977 solver.cpp:221] Iteration 700, loss = 4.15903
I0416 12:04:32.083256   977 solver.cpp:236]     Train net output #0: loss = 4.19673 (* 1 = 4.19673 loss)
I0416 12:04:32.083261   977 solver.cpp:542] Iteration 700, lr = 0.1
I0416 12:04:45.546875   977 solver.cpp:221] Iteration 720, loss = 4.02305
I0416 12:04:45.546901   977 solver.cpp:236]     Train net output #0: loss = 4.1071 (* 1 = 4.1071 loss)
I0416 12:04:45.546905   977 solver.cpp:542] Iteration 720, lr = 0.1
I0416 12:04:58.981947   977 solver.cpp:221] Iteration 740, loss = 3.96367
I0416 12:04:58.981973   977 solver.cpp:236]     Train net output #0: loss = 3.85096 (* 1 = 3.85096 loss)
I0416 12:04:58.981978   977 solver.cpp:542] Iteration 740, lr = 0.1
I0416 12:05:12.443967   977 solver.cpp:221] Iteration 760, loss = 3.97013
I0416 12:05:12.443994   977 solver.cpp:236]     Train net output #0: loss = 3.74921 (* 1 = 3.74921 loss)
I0416 12:05:12.444000   977 solver.cpp:542] Iteration 760, lr = 0.1
I0416 12:05:25.919417   977 solver.cpp:221] Iteration 780, loss = 3.93219
I0416 12:05:25.919445   977 solver.cpp:236]     Train net output #0: loss = 3.80237 (* 1 = 3.80237 loss)
I0416 12:05:25.919448   977 solver.cpp:542] Iteration 780, lr = 0.1
I0416 12:05:38.721941   977 solver.cpp:316] Iteration 800, Testing net (#0)
I0416 12:05:50.209511   977 solver.cpp:373]     Test net output #0: accuracy = 0.0813688
I0416 12:05:50.209530   977 solver.cpp:373]     Test net output #1: loss = 5.44462 (* 1 = 5.44462 loss)
I0416 12:05:50.872882   977 solver.cpp:221] Iteration 800, loss = 3.85408
I0416 12:05:50.872908   977 solver.cpp:236]     Train net output #0: loss = 4.10739 (* 1 = 4.10739 loss)
I0416 12:05:50.872913   977 solver.cpp:542] Iteration 800, lr = 0.1
I0416 12:06:04.312039   977 solver.cpp:221] Iteration 820, loss = 3.73951
I0416 12:06:04.312067   977 solver.cpp:236]     Train net output #0: loss = 4.13047 (* 1 = 4.13047 loss)
I0416 12:06:04.312072   977 solver.cpp:542] Iteration 820, lr = 0.1
I0416 12:06:17.732743   977 solver.cpp:221] Iteration 840, loss = 3.73614
I0416 12:06:17.732770   977 solver.cpp:236]     Train net output #0: loss = 3.61095 (* 1 = 3.61095 loss)
I0416 12:06:17.732775   977 solver.cpp:542] Iteration 840, lr = 0.1
I0416 12:06:31.151108   977 solver.cpp:221] Iteration 860, loss = 3.71487
I0416 12:06:31.151134   977 solver.cpp:236]     Train net output #0: loss = 3.56364 (* 1 = 3.56364 loss)
I0416 12:06:31.151139   977 solver.cpp:542] Iteration 860, lr = 0.1
I0416 12:06:44.569195   977 solver.cpp:221] Iteration 880, loss = 3.59275
I0416 12:06:44.569221   977 solver.cpp:236]     Train net output #0: loss = 3.57629 (* 1 = 3.57629 loss)
I0416 12:06:44.569226   977 solver.cpp:542] Iteration 880, lr = 0.1
I0416 12:06:57.988423   977 solver.cpp:221] Iteration 900, loss = 3.66623
I0416 12:06:57.988451   977 solver.cpp:236]     Train net output #0: loss = 3.78595 (* 1 = 3.78595 loss)
I0416 12:06:57.988454   977 solver.cpp:542] Iteration 900, lr = 0.1
I0416 12:07:11.427603   977 solver.cpp:221] Iteration 920, loss = 3.57568
I0416 12:07:11.427629   977 solver.cpp:236]     Train net output #0: loss = 3.63224 (* 1 = 3.63224 loss)
I0416 12:07:11.427634   977 solver.cpp:542] Iteration 920, lr = 0.1
I0416 12:07:24.870245   977 solver.cpp:221] Iteration 940, loss = 3.53057
I0416 12:07:24.870271   977 solver.cpp:236]     Train net output #0: loss = 3.44071 (* 1 = 3.44071 loss)
I0416 12:07:24.870276   977 solver.cpp:542] Iteration 940, lr = 0.1
I0416 12:07:38.299124   977 solver.cpp:221] Iteration 960, loss = 3.44536
I0416 12:07:38.299150   977 solver.cpp:236]     Train net output #0: loss = 3.31843 (* 1 = 3.31843 loss)
I0416 12:07:38.299155   977 solver.cpp:542] Iteration 960, lr = 0.1
I0416 12:07:51.751010   977 solver.cpp:221] Iteration 980, loss = 3.46455
I0416 12:07:51.751037   977 solver.cpp:236]     Train net output #0: loss = 3.42689 (* 1 = 3.42689 loss)
I0416 12:07:51.751042   977 solver.cpp:542] Iteration 980, lr = 0.1
I0416 12:08:04.545593   977 solver.cpp:316] Iteration 1000, Testing net (#0)
I0416 12:08:16.021605   977 solver.cpp:373]     Test net output #0: accuracy = 0.172243
I0416 12:08:16.021626   977 solver.cpp:373]     Test net output #1: loss = 4.06514 (* 1 = 4.06514 loss)
I0416 12:08:16.686866   977 solver.cpp:221] Iteration 1000, loss = 3.44183
I0416 12:08:16.686893   977 solver.cpp:236]     Train net output #0: loss = 3.2126 (* 1 = 3.2126 loss)
I0416 12:08:16.686898   977 solver.cpp:542] Iteration 1000, lr = 0.1
I0416 12:08:30.114581   977 solver.cpp:221] Iteration 1020, loss = 3.30046
I0416 12:08:30.114609   977 solver.cpp:236]     Train net output #0: loss = 2.89422 (* 1 = 2.89422 loss)
I0416 12:08:30.114620   977 solver.cpp:542] Iteration 1020, lr = 0.1
I0416 12:08:43.563827   977 solver.cpp:221] Iteration 1040, loss = 3.36314
I0416 12:08:43.563853   977 solver.cpp:236]     Train net output #0: loss = 3.71636 (* 1 = 3.71636 loss)
I0416 12:08:43.563858   977 solver.cpp:542] Iteration 1040, lr = 0.1
I0416 12:08:57.032604   977 solver.cpp:221] Iteration 1060, loss = 3.23029
I0416 12:08:57.032631   977 solver.cpp:236]     Train net output #0: loss = 3.48089 (* 1 = 3.48089 loss)
I0416 12:08:57.032636   977 solver.cpp:542] Iteration 1060, lr = 0.1
I0416 12:09:10.460319   977 solver.cpp:221] Iteration 1080, loss = 3.13675
I0416 12:09:10.460347   977 solver.cpp:236]     Train net output #0: loss = 3.60317 (* 1 = 3.60317 loss)
I0416 12:09:10.460351   977 solver.cpp:542] Iteration 1080, lr = 0.1
I0416 12:09:23.934588   977 solver.cpp:221] Iteration 1100, loss = 3.2164
I0416 12:09:23.934623   977 solver.cpp:236]     Train net output #0: loss = 2.93493 (* 1 = 2.93493 loss)
I0416 12:09:23.934628   977 solver.cpp:542] Iteration 1100, lr = 0.1
I0416 12:09:37.378093   977 solver.cpp:221] Iteration 1120, loss = 3.1034
I0416 12:09:37.378119   977 solver.cpp:236]     Train net output #0: loss = 3.09698 (* 1 = 3.09698 loss)
I0416 12:09:37.378123   977 solver.cpp:542] Iteration 1120, lr = 0.1
I0416 12:09:50.841265   977 solver.cpp:221] Iteration 1140, loss = 3.20107
I0416 12:09:50.841297   977 solver.cpp:236]     Train net output #0: loss = 3.32717 (* 1 = 3.32717 loss)
I0416 12:09:50.841302   977 solver.cpp:542] Iteration 1140, lr = 0.1
I0416 12:10:04.292230   977 solver.cpp:221] Iteration 1160, loss = 2.9966
I0416 12:10:04.292258   977 solver.cpp:236]     Train net output #0: loss = 3.07791 (* 1 = 3.07791 loss)
I0416 12:10:04.292263   977 solver.cpp:542] Iteration 1160, lr = 0.1
I0416 12:10:17.726713   977 solver.cpp:221] Iteration 1180, loss = 2.99232
I0416 12:10:17.726742   977 solver.cpp:236]     Train net output #0: loss = 3.06436 (* 1 = 3.06436 loss)
I0416 12:10:17.726745   977 solver.cpp:542] Iteration 1180, lr = 0.1
I0416 12:10:30.516149   977 solver.cpp:316] Iteration 1200, Testing net (#0)
I0416 12:10:41.992064   977 solver.cpp:373]     Test net output #0: accuracy = 0.0920152
I0416 12:10:41.992086   977 solver.cpp:373]     Test net output #1: loss = 6.25328 (* 1 = 6.25328 loss)
I0416 12:10:42.656816   977 solver.cpp:221] Iteration 1200, loss = 2.98154
I0416 12:10:42.656841   977 solver.cpp:236]     Train net output #0: loss = 2.87123 (* 1 = 2.87123 loss)
I0416 12:10:42.656847   977 solver.cpp:542] Iteration 1200, lr = 0.1
I0416 12:10:56.110780   977 solver.cpp:221] Iteration 1220, loss = 2.9125
I0416 12:10:56.110806   977 solver.cpp:236]     Train net output #0: loss = 2.51789 (* 1 = 2.51789 loss)
I0416 12:10:56.110811   977 solver.cpp:542] Iteration 1220, lr = 0.1
I0416 12:11:09.559485   977 solver.cpp:221] Iteration 1240, loss = 2.93211
I0416 12:11:09.559512   977 solver.cpp:236]     Train net output #0: loss = 3.18357 (* 1 = 3.18357 loss)
I0416 12:11:09.559517   977 solver.cpp:542] Iteration 1240, lr = 0.1
I0416 12:11:22.992514   977 solver.cpp:221] Iteration 1260, loss = 2.95509
I0416 12:11:22.992542   977 solver.cpp:236]     Train net output #0: loss = 2.99487 (* 1 = 2.99487 loss)
I0416 12:11:22.992547   977 solver.cpp:542] Iteration 1260, lr = 0.1
I0416 12:11:36.418303   977 solver.cpp:221] Iteration 1280, loss = 2.89279
I0416 12:11:36.418329   977 solver.cpp:236]     Train net output #0: loss = 2.50228 (* 1 = 2.50228 loss)
I0416 12:11:36.418334   977 solver.cpp:542] Iteration 1280, lr = 0.1
I0416 12:11:49.900064   977 solver.cpp:221] Iteration 1300, loss = 2.82466
I0416 12:11:49.900091   977 solver.cpp:236]     Train net output #0: loss = 2.74932 (* 1 = 2.74932 loss)
I0416 12:11:49.900095   977 solver.cpp:542] Iteration 1300, lr = 0.1
I0416 12:12:03.373412   977 solver.cpp:221] Iteration 1320, loss = 2.72493
I0416 12:12:03.373440   977 solver.cpp:236]     Train net output #0: loss = 2.6746 (* 1 = 2.6746 loss)
I0416 12:12:03.373443   977 solver.cpp:542] Iteration 1320, lr = 0.1
I0416 12:12:16.823721   977 solver.cpp:221] Iteration 1340, loss = 2.86543
I0416 12:12:16.823748   977 solver.cpp:236]     Train net output #0: loss = 3.35658 (* 1 = 3.35658 loss)
I0416 12:12:16.823752   977 solver.cpp:542] Iteration 1340, lr = 0.1
I0416 12:12:30.298833   977 solver.cpp:221] Iteration 1360, loss = 2.87184
I0416 12:12:30.298861   977 solver.cpp:236]     Train net output #0: loss = 2.74072 (* 1 = 2.74072 loss)
I0416 12:12:30.298866   977 solver.cpp:542] Iteration 1360, lr = 0.1
I0416 12:12:43.744247   977 solver.cpp:221] Iteration 1380, loss = 2.65546
I0416 12:12:43.744274   977 solver.cpp:236]     Train net output #0: loss = 2.22881 (* 1 = 2.22881 loss)
I0416 12:12:43.744278   977 solver.cpp:542] Iteration 1380, lr = 0.1
I0416 12:12:56.529105   977 solver.cpp:316] Iteration 1400, Testing net (#0)
I0416 12:13:08.007886   977 solver.cpp:373]     Test net output #0: accuracy = 0.404563
I0416 12:13:08.007907   977 solver.cpp:373]     Test net output #1: loss = 2.43014 (* 1 = 2.43014 loss)
I0416 12:13:08.671730   977 solver.cpp:221] Iteration 1400, loss = 2.61014
I0416 12:13:08.671756   977 solver.cpp:236]     Train net output #0: loss = 2.03464 (* 1 = 2.03464 loss)
I0416 12:13:08.671761   977 solver.cpp:542] Iteration 1400, lr = 0.1
I0416 12:13:22.136265   977 solver.cpp:221] Iteration 1420, loss = 2.6798
I0416 12:13:22.136293   977 solver.cpp:236]     Train net output #0: loss = 2.67843 (* 1 = 2.67843 loss)
I0416 12:13:22.136298   977 solver.cpp:542] Iteration 1420, lr = 0.1
I0416 12:13:35.597622   977 solver.cpp:221] Iteration 1440, loss = 2.60155
I0416 12:13:35.597651   977 solver.cpp:236]     Train net output #0: loss = 2.68994 (* 1 = 2.68994 loss)
I0416 12:13:35.597654   977 solver.cpp:542] Iteration 1440, lr = 0.1
I0416 12:13:49.064126   977 solver.cpp:221] Iteration 1460, loss = 2.64064
I0416 12:13:49.064152   977 solver.cpp:236]     Train net output #0: loss = 2.60487 (* 1 = 2.60487 loss)
I0416 12:13:49.064157   977 solver.cpp:542] Iteration 1460, lr = 0.1
I0416 12:14:02.538825   977 solver.cpp:221] Iteration 1480, loss = 2.55098
I0416 12:14:02.538852   977 solver.cpp:236]     Train net output #0: loss = 2.28564 (* 1 = 2.28564 loss)
I0416 12:14:02.538857   977 solver.cpp:542] Iteration 1480, lr = 0.1
I0416 12:14:15.996477   977 solver.cpp:221] Iteration 1500, loss = 2.61431
I0416 12:14:15.996505   977 solver.cpp:236]     Train net output #0: loss = 2.60667 (* 1 = 2.60667 loss)
I0416 12:14:15.996510   977 solver.cpp:542] Iteration 1500, lr = 0.1
I0416 12:14:29.430758   977 solver.cpp:221] Iteration 1520, loss = 2.54116
I0416 12:14:29.430785   977 solver.cpp:236]     Train net output #0: loss = 2.41792 (* 1 = 2.41792 loss)
I0416 12:14:29.430790   977 solver.cpp:542] Iteration 1520, lr = 0.1
I0416 12:14:42.860302   977 solver.cpp:221] Iteration 1540, loss = 2.47237
I0416 12:14:42.860330   977 solver.cpp:236]     Train net output #0: loss = 2.2962 (* 1 = 2.2962 loss)
I0416 12:14:42.860334   977 solver.cpp:542] Iteration 1540, lr = 0.1
I0416 12:14:56.300068   977 solver.cpp:221] Iteration 1560, loss = 2.51998
I0416 12:14:56.300096   977 solver.cpp:236]     Train net output #0: loss = 2.67823 (* 1 = 2.67823 loss)
I0416 12:14:56.300101   977 solver.cpp:542] Iteration 1560, lr = 0.1
I0416 12:15:09.753175   977 solver.cpp:221] Iteration 1580, loss = 2.47696
I0416 12:15:09.753202   977 solver.cpp:236]     Train net output #0: loss = 2.76111 (* 1 = 2.76111 loss)
I0416 12:15:09.753207   977 solver.cpp:542] Iteration 1580, lr = 0.1
I0416 12:15:22.565466   977 solver.cpp:316] Iteration 1600, Testing net (#0)
I0416 12:15:34.044219   977 solver.cpp:373]     Test net output #0: accuracy = 0.390494
I0416 12:15:34.044241   977 solver.cpp:373]     Test net output #1: loss = 2.5494 (* 1 = 2.5494 loss)
I0416 12:15:34.708276   977 solver.cpp:221] Iteration 1600, loss = 2.41209
I0416 12:15:34.708302   977 solver.cpp:236]     Train net output #0: loss = 2.55588 (* 1 = 2.55588 loss)
I0416 12:15:34.708307   977 solver.cpp:542] Iteration 1600, lr = 0.1
I0416 12:15:48.152920   977 solver.cpp:221] Iteration 1620, loss = 2.40177
I0416 12:15:48.152946   977 solver.cpp:236]     Train net output #0: loss = 2.63511 (* 1 = 2.63511 loss)
I0416 12:15:48.152951   977 solver.cpp:542] Iteration 1620, lr = 0.1
I0416 12:16:01.582917   977 solver.cpp:221] Iteration 1640, loss = 2.42818
I0416 12:16:01.582944   977 solver.cpp:236]     Train net output #0: loss = 2.16244 (* 1 = 2.16244 loss)
I0416 12:16:01.582949   977 solver.cpp:542] Iteration 1640, lr = 0.1
I0416 12:16:15.005957   977 solver.cpp:221] Iteration 1660, loss = 2.42106
I0416 12:16:15.005985   977 solver.cpp:236]     Train net output #0: loss = 2.45369 (* 1 = 2.45369 loss)
I0416 12:16:15.005988   977 solver.cpp:542] Iteration 1660, lr = 0.1
I0416 12:16:28.447880   977 solver.cpp:221] Iteration 1680, loss = 2.42054
I0416 12:16:28.447913   977 solver.cpp:236]     Train net output #0: loss = 2.21741 (* 1 = 2.21741 loss)
I0416 12:16:28.447918   977 solver.cpp:542] Iteration 1680, lr = 0.1
I0416 12:16:41.908565   977 solver.cpp:221] Iteration 1700, loss = 2.31014
I0416 12:16:41.908592   977 solver.cpp:236]     Train net output #0: loss = 2.24423 (* 1 = 2.24423 loss)
I0416 12:16:41.908596   977 solver.cpp:542] Iteration 1700, lr = 0.1
I0416 12:16:55.359277   977 solver.cpp:221] Iteration 1720, loss = 2.2959
I0416 12:16:55.359302   977 solver.cpp:236]     Train net output #0: loss = 2.15728 (* 1 = 2.15728 loss)
I0416 12:16:55.359308   977 solver.cpp:542] Iteration 1720, lr = 0.1
I0416 12:17:08.806320   977 solver.cpp:221] Iteration 1740, loss = 2.2877
I0416 12:17:08.806346   977 solver.cpp:236]     Train net output #0: loss = 2.29309 (* 1 = 2.29309 loss)
I0416 12:17:08.806351   977 solver.cpp:542] Iteration 1740, lr = 0.1
I0416 12:17:22.266999   977 solver.cpp:221] Iteration 1760, loss = 2.35133
I0416 12:17:22.267026   977 solver.cpp:236]     Train net output #0: loss = 2.20037 (* 1 = 2.20037 loss)
I0416 12:17:22.267030   977 solver.cpp:542] Iteration 1760, lr = 0.1
I0416 12:17:35.725348   977 solver.cpp:221] Iteration 1780, loss = 2.23951
I0416 12:17:35.725376   977 solver.cpp:236]     Train net output #0: loss = 1.93536 (* 1 = 1.93536 loss)
I0416 12:17:35.725381   977 solver.cpp:542] Iteration 1780, lr = 0.1
I0416 12:17:48.527868   977 solver.cpp:316] Iteration 1800, Testing net (#0)
I0416 12:18:00.013020   977 solver.cpp:373]     Test net output #0: accuracy = 0.343536
I0416 12:18:00.013041   977 solver.cpp:373]     Test net output #1: loss = 3.08104 (* 1 = 3.08104 loss)
I0416 12:18:00.676578   977 solver.cpp:221] Iteration 1800, loss = 2.19208
I0416 12:18:00.676604   977 solver.cpp:236]     Train net output #0: loss = 2.13306 (* 1 = 2.13306 loss)
I0416 12:18:00.676609   977 solver.cpp:542] Iteration 1800, lr = 0.1
I0416 12:18:14.114218   977 solver.cpp:221] Iteration 1820, loss = 2.22236
I0416 12:18:14.114245   977 solver.cpp:236]     Train net output #0: loss = 2.83978 (* 1 = 2.83978 loss)
I0416 12:18:14.114250   977 solver.cpp:542] Iteration 1820, lr = 0.1
I0416 12:18:27.551023   977 solver.cpp:221] Iteration 1840, loss = 2.26647
I0416 12:18:27.551048   977 solver.cpp:236]     Train net output #0: loss = 2.6291 (* 1 = 2.6291 loss)
I0416 12:18:27.551053   977 solver.cpp:542] Iteration 1840, lr = 0.1
I0416 12:18:41.023670   977 solver.cpp:221] Iteration 1860, loss = 2.2608
I0416 12:18:41.023699   977 solver.cpp:236]     Train net output #0: loss = 2.36034 (* 1 = 2.36034 loss)
I0416 12:18:41.023702   977 solver.cpp:542] Iteration 1860, lr = 0.1
I0416 12:18:54.504467   977 solver.cpp:221] Iteration 1880, loss = 2.19749
I0416 12:18:54.504493   977 solver.cpp:236]     Train net output #0: loss = 2.16171 (* 1 = 2.16171 loss)
I0416 12:18:54.504498   977 solver.cpp:542] Iteration 1880, lr = 0.1
I0416 12:19:07.970016   977 solver.cpp:221] Iteration 1900, loss = 2.15177
I0416 12:19:07.970041   977 solver.cpp:236]     Train net output #0: loss = 2.15378 (* 1 = 2.15378 loss)
I0416 12:19:07.970046   977 solver.cpp:542] Iteration 1900, lr = 0.1
I0416 12:19:21.414567   977 solver.cpp:221] Iteration 1920, loss = 2.03479
I0416 12:19:21.414597   977 solver.cpp:236]     Train net output #0: loss = 2.17355 (* 1 = 2.17355 loss)
I0416 12:19:21.414603   977 solver.cpp:542] Iteration 1920, lr = 0.1
I0416 12:19:34.876273   977 solver.cpp:221] Iteration 1940, loss = 2.06123
I0416 12:19:34.876301   977 solver.cpp:236]     Train net output #0: loss = 1.69921 (* 1 = 1.69921 loss)
I0416 12:19:34.876304   977 solver.cpp:542] Iteration 1940, lr = 0.1
I0416 12:19:48.312775   977 solver.cpp:221] Iteration 1960, loss = 2.16935
I0416 12:19:48.312803   977 solver.cpp:236]     Train net output #0: loss = 2.13082 (* 1 = 2.13082 loss)
I0416 12:19:48.312808   977 solver.cpp:542] Iteration 1960, lr = 0.1
I0416 12:20:01.761479   977 solver.cpp:221] Iteration 1980, loss = 2.13854
I0416 12:20:01.761505   977 solver.cpp:236]     Train net output #0: loss = 1.85363 (* 1 = 1.85363 loss)
I0416 12:20:01.761510   977 solver.cpp:542] Iteration 1980, lr = 0.1
I0416 12:20:14.549015   977 solver.cpp:316] Iteration 2000, Testing net (#0)
I0416 12:20:26.032878   977 solver.cpp:373]     Test net output #0: accuracy = 0.408745
I0416 12:20:26.032901   977 solver.cpp:373]     Test net output #1: loss = 2.47601 (* 1 = 2.47601 loss)
I0416 12:20:26.695659   977 solver.cpp:221] Iteration 2000, loss = 2.07413
I0416 12:20:26.695685   977 solver.cpp:236]     Train net output #0: loss = 1.84225 (* 1 = 1.84225 loss)
I0416 12:20:26.695690   977 solver.cpp:542] Iteration 2000, lr = 0.1
I0416 12:20:40.148865   977 solver.cpp:221] Iteration 2020, loss = 2.05568
I0416 12:20:40.148892   977 solver.cpp:236]     Train net output #0: loss = 1.72542 (* 1 = 1.72542 loss)
I0416 12:20:40.148897   977 solver.cpp:542] Iteration 2020, lr = 0.1
I0416 12:20:53.586300   977 solver.cpp:221] Iteration 2040, loss = 2.02274
I0416 12:20:53.586328   977 solver.cpp:236]     Train net output #0: loss = 1.5161 (* 1 = 1.5161 loss)
I0416 12:20:53.586333   977 solver.cpp:542] Iteration 2040, lr = 0.1
I0416 12:21:07.028013   977 solver.cpp:221] Iteration 2060, loss = 1.99514
I0416 12:21:07.028039   977 solver.cpp:236]     Train net output #0: loss = 2.058 (* 1 = 2.058 loss)
I0416 12:21:07.028044   977 solver.cpp:542] Iteration 2060, lr = 0.1
I0416 12:21:20.476408   977 solver.cpp:221] Iteration 2080, loss = 1.98792
I0416 12:21:20.476433   977 solver.cpp:236]     Train net output #0: loss = 1.92821 (* 1 = 1.92821 loss)
I0416 12:21:20.476439   977 solver.cpp:542] Iteration 2080, lr = 0.1
I0416 12:21:33.908977   977 solver.cpp:221] Iteration 2100, loss = 1.99262
I0416 12:21:33.909003   977 solver.cpp:236]     Train net output #0: loss = 2.14486 (* 1 = 2.14486 loss)
I0416 12:21:33.909008   977 solver.cpp:542] Iteration 2100, lr = 0.1
I0416 12:21:47.378480   977 solver.cpp:221] Iteration 2120, loss = 1.95603
I0416 12:21:47.378506   977 solver.cpp:236]     Train net output #0: loss = 1.94935 (* 1 = 1.94935 loss)
I0416 12:21:47.378510   977 solver.cpp:542] Iteration 2120, lr = 0.1
I0416 12:22:00.857727   977 solver.cpp:221] Iteration 2140, loss = 1.90758
I0416 12:22:00.857753   977 solver.cpp:236]     Train net output #0: loss = 2.13139 (* 1 = 2.13139 loss)
I0416 12:22:00.857758   977 solver.cpp:542] Iteration 2140, lr = 0.1
I0416 12:22:14.289532   977 solver.cpp:221] Iteration 2160, loss = 1.99582
I0416 12:22:14.289559   977 solver.cpp:236]     Train net output #0: loss = 1.50597 (* 1 = 1.50597 loss)
I0416 12:22:14.289564   977 solver.cpp:542] Iteration 2160, lr = 0.1
I0416 12:22:27.739583   977 solver.cpp:221] Iteration 2180, loss = 2.0366
I0416 12:22:27.739609   977 solver.cpp:236]     Train net output #0: loss = 1.88958 (* 1 = 1.88958 loss)
I0416 12:22:27.739614   977 solver.cpp:542] Iteration 2180, lr = 0.1
I0416 12:22:40.574005   977 solver.cpp:316] Iteration 2200, Testing net (#0)
I0416 12:22:52.065006   977 solver.cpp:373]     Test net output #0: accuracy = 0.298859
I0416 12:22:52.065026   977 solver.cpp:373]     Test net output #1: loss = 3.95316 (* 1 = 3.95316 loss)
I0416 12:22:52.731956   977 solver.cpp:221] Iteration 2200, loss = 2.0325
I0416 12:22:52.731981   977 solver.cpp:236]     Train net output #0: loss = 2.19018 (* 1 = 2.19018 loss)
I0416 12:22:52.731986   977 solver.cpp:542] Iteration 2200, lr = 0.1
I0416 12:23:06.195071   977 solver.cpp:221] Iteration 2220, loss = 1.92514
I0416 12:23:06.195098   977 solver.cpp:236]     Train net output #0: loss = 2.10893 (* 1 = 2.10893 loss)
I0416 12:23:06.195102   977 solver.cpp:542] Iteration 2220, lr = 0.1
I0416 12:23:19.638782   977 solver.cpp:221] Iteration 2240, loss = 1.9159
I0416 12:23:19.638809   977 solver.cpp:236]     Train net output #0: loss = 2.12093 (* 1 = 2.12093 loss)
I0416 12:23:19.638814   977 solver.cpp:542] Iteration 2240, lr = 0.1
I0416 12:23:33.108341   977 solver.cpp:221] Iteration 2260, loss = 1.87124
I0416 12:23:33.108368   977 solver.cpp:236]     Train net output #0: loss = 1.95572 (* 1 = 1.95572 loss)
I0416 12:23:33.108372   977 solver.cpp:542] Iteration 2260, lr = 0.1
I0416 12:23:46.546916   977 solver.cpp:221] Iteration 2280, loss = 1.88621
I0416 12:23:46.546942   977 solver.cpp:236]     Train net output #0: loss = 2.00326 (* 1 = 2.00326 loss)
I0416 12:23:46.546947   977 solver.cpp:542] Iteration 2280, lr = 0.1
I0416 12:23:59.979918   977 solver.cpp:221] Iteration 2300, loss = 1.93684
I0416 12:23:59.979945   977 solver.cpp:236]     Train net output #0: loss = 2.32381 (* 1 = 2.32381 loss)
I0416 12:23:59.979950   977 solver.cpp:542] Iteration 2300, lr = 0.1
I0416 12:24:13.445647   977 solver.cpp:221] Iteration 2320, loss = 1.80829
I0416 12:24:13.445675   977 solver.cpp:236]     Train net output #0: loss = 1.62585 (* 1 = 1.62585 loss)
I0416 12:24:13.445682   977 solver.cpp:542] Iteration 2320, lr = 0.1
I0416 12:24:26.917122   977 solver.cpp:221] Iteration 2340, loss = 1.75555
I0416 12:24:26.917148   977 solver.cpp:236]     Train net output #0: loss = 1.70493 (* 1 = 1.70493 loss)
I0416 12:24:26.917153   977 solver.cpp:542] Iteration 2340, lr = 0.1
I0416 12:24:40.395403   977 solver.cpp:221] Iteration 2360, loss = 1.79211
I0416 12:24:40.395431   977 solver.cpp:236]     Train net output #0: loss = 2.05782 (* 1 = 2.05782 loss)
I0416 12:24:40.395434   977 solver.cpp:542] Iteration 2360, lr = 0.1
I0416 12:24:53.848691   977 solver.cpp:221] Iteration 2380, loss = 1.87244
I0416 12:24:53.848719   977 solver.cpp:236]     Train net output #0: loss = 1.73506 (* 1 = 1.73506 loss)
I0416 12:24:53.848724   977 solver.cpp:542] Iteration 2380, lr = 0.1
I0416 12:25:06.665205   977 solver.cpp:316] Iteration 2400, Testing net (#0)
I0416 12:25:18.148758   977 solver.cpp:373]     Test net output #0: accuracy = 0.702281
I0416 12:25:18.148779   977 solver.cpp:373]     Test net output #1: loss = 1.13086 (* 1 = 1.13086 loss)
I0416 12:25:18.812415   977 solver.cpp:221] Iteration 2400, loss = 1.82639
I0416 12:25:18.812441   977 solver.cpp:236]     Train net output #0: loss = 1.70681 (* 1 = 1.70681 loss)
I0416 12:25:18.812446   977 solver.cpp:542] Iteration 2400, lr = 0.1
I0416 12:25:32.251019   977 solver.cpp:221] Iteration 2420, loss = 1.72034
I0416 12:25:32.251046   977 solver.cpp:236]     Train net output #0: loss = 1.20009 (* 1 = 1.20009 loss)
I0416 12:25:32.251051   977 solver.cpp:542] Iteration 2420, lr = 0.1
I0416 12:25:45.712383   977 solver.cpp:221] Iteration 2440, loss = 1.75803
I0416 12:25:45.712409   977 solver.cpp:236]     Train net output #0: loss = 1.67688 (* 1 = 1.67688 loss)
I0416 12:25:45.712414   977 solver.cpp:542] Iteration 2440, lr = 0.1
I0416 12:25:59.178519   977 solver.cpp:221] Iteration 2460, loss = 1.74947
I0416 12:25:59.178545   977 solver.cpp:236]     Train net output #0: loss = 2.02152 (* 1 = 2.02152 loss)
I0416 12:25:59.178550   977 solver.cpp:542] Iteration 2460, lr = 0.1
I0416 12:26:12.663812   977 solver.cpp:221] Iteration 2480, loss = 1.77438
I0416 12:26:12.663839   977 solver.cpp:236]     Train net output #0: loss = 1.54611 (* 1 = 1.54611 loss)
I0416 12:26:12.663843   977 solver.cpp:542] Iteration 2480, lr = 0.1
I0416 12:26:26.139961   977 solver.cpp:221] Iteration 2500, loss = 1.78185
I0416 12:26:26.139988   977 solver.cpp:236]     Train net output #0: loss = 2.27005 (* 1 = 2.27005 loss)
I0416 12:26:26.139993   977 solver.cpp:542] Iteration 2500, lr = 0.1
I0416 12:26:39.589058   977 solver.cpp:221] Iteration 2520, loss = 1.77478
I0416 12:26:39.589084   977 solver.cpp:236]     Train net output #0: loss = 1.78436 (* 1 = 1.78436 loss)
I0416 12:26:39.589089   977 solver.cpp:542] Iteration 2520, lr = 0.1
I0416 12:26:53.045214   977 solver.cpp:221] Iteration 2540, loss = 1.68263
I0416 12:26:53.045241   977 solver.cpp:236]     Train net output #0: loss = 1.79119 (* 1 = 1.79119 loss)
I0416 12:26:53.045245   977 solver.cpp:542] Iteration 2540, lr = 0.1
I0416 12:27:06.505723   977 solver.cpp:221] Iteration 2560, loss = 1.7494
I0416 12:27:06.505750   977 solver.cpp:236]     Train net output #0: loss = 1.98327 (* 1 = 1.98327 loss)
I0416 12:27:06.505755   977 solver.cpp:542] Iteration 2560, lr = 0.1
I0416 12:27:19.956864   977 solver.cpp:221] Iteration 2580, loss = 1.77416
I0416 12:27:19.956892   977 solver.cpp:236]     Train net output #0: loss = 1.60315 (* 1 = 1.60315 loss)
I0416 12:27:19.956897   977 solver.cpp:542] Iteration 2580, lr = 0.1
I0416 12:27:32.766042   977 solver.cpp:316] Iteration 2600, Testing net (#0)
I0416 12:27:44.253180   977 solver.cpp:373]     Test net output #0: accuracy = 0.652471
I0416 12:27:44.253202   977 solver.cpp:373]     Test net output #1: loss = 1.2949 (* 1 = 1.2949 loss)
I0416 12:27:44.916895   977 solver.cpp:221] Iteration 2600, loss = 1.72286
I0416 12:27:44.916923   977 solver.cpp:236]     Train net output #0: loss = 1.89213 (* 1 = 1.89213 loss)
I0416 12:27:44.916926   977 solver.cpp:542] Iteration 2600, lr = 0.1
I0416 12:27:58.360011   977 solver.cpp:221] Iteration 2620, loss = 1.74065
I0416 12:27:58.360038   977 solver.cpp:236]     Train net output #0: loss = 1.98426 (* 1 = 1.98426 loss)
I0416 12:27:58.360044   977 solver.cpp:542] Iteration 2620, lr = 0.1
I0416 12:28:11.806236   977 solver.cpp:221] Iteration 2640, loss = 1.65344
I0416 12:28:11.806262   977 solver.cpp:236]     Train net output #0: loss = 1.5864 (* 1 = 1.5864 loss)
I0416 12:28:11.806267   977 solver.cpp:542] Iteration 2640, lr = 0.1
I0416 12:28:25.241989   977 solver.cpp:221] Iteration 2660, loss = 1.79439
I0416 12:28:25.242017   977 solver.cpp:236]     Train net output #0: loss = 1.2353 (* 1 = 1.2353 loss)
I0416 12:28:25.242022   977 solver.cpp:542] Iteration 2660, lr = 0.1
I0416 12:28:38.705585   977 solver.cpp:221] Iteration 2680, loss = 1.76058
I0416 12:28:38.705611   977 solver.cpp:236]     Train net output #0: loss = 1.49713 (* 1 = 1.49713 loss)
I0416 12:28:38.705615   977 solver.cpp:542] Iteration 2680, lr = 0.1
I0416 12:28:52.148010   977 solver.cpp:221] Iteration 2700, loss = 1.66039
I0416 12:28:52.148036   977 solver.cpp:236]     Train net output #0: loss = 1.74951 (* 1 = 1.74951 loss)
I0416 12:28:52.148041   977 solver.cpp:542] Iteration 2700, lr = 0.1
I0416 12:29:05.591557   977 solver.cpp:221] Iteration 2720, loss = 1.70814
I0416 12:29:05.591583   977 solver.cpp:236]     Train net output #0: loss = 2.22571 (* 1 = 2.22571 loss)
I0416 12:29:05.591588   977 solver.cpp:542] Iteration 2720, lr = 0.1
I0416 12:29:19.038712   977 solver.cpp:221] Iteration 2740, loss = 1.64368
I0416 12:29:19.038738   977 solver.cpp:236]     Train net output #0: loss = 1.61018 (* 1 = 1.61018 loss)
I0416 12:29:19.038743   977 solver.cpp:542] Iteration 2740, lr = 0.1
I0416 12:29:32.477419   977 solver.cpp:221] Iteration 2760, loss = 1.62941
I0416 12:29:32.477445   977 solver.cpp:236]     Train net output #0: loss = 1.69896 (* 1 = 1.69896 loss)
I0416 12:29:32.477450   977 solver.cpp:542] Iteration 2760, lr = 0.1
I0416 12:29:45.931670   977 solver.cpp:221] Iteration 2780, loss = 1.58988
I0416 12:29:45.931697   977 solver.cpp:236]     Train net output #0: loss = 1.5928 (* 1 = 1.5928 loss)
I0416 12:29:45.931702   977 solver.cpp:542] Iteration 2780, lr = 0.1
I0416 12:29:58.741950   977 solver.cpp:316] Iteration 2800, Testing net (#0)
I0416 12:30:10.236446   977 solver.cpp:373]     Test net output #0: accuracy = 0.539163
I0416 12:30:10.236469   977 solver.cpp:373]     Test net output #1: loss = 1.90234 (* 1 = 1.90234 loss)
I0416 12:30:10.904508   977 solver.cpp:221] Iteration 2800, loss = 1.63879
I0416 12:30:10.904536   977 solver.cpp:236]     Train net output #0: loss = 1.56758 (* 1 = 1.56758 loss)
I0416 12:30:10.904541   977 solver.cpp:542] Iteration 2800, lr = 0.1
I0416 12:30:24.381168   977 solver.cpp:221] Iteration 2820, loss = 1.60649
I0416 12:30:24.381196   977 solver.cpp:236]     Train net output #0: loss = 1.439 (* 1 = 1.439 loss)
I0416 12:30:24.381201   977 solver.cpp:542] Iteration 2820, lr = 0.1
I0416 12:30:37.822870   977 solver.cpp:221] Iteration 2840, loss = 1.53075
I0416 12:30:37.822896   977 solver.cpp:236]     Train net output #0: loss = 1.5443 (* 1 = 1.5443 loss)
I0416 12:30:37.822901   977 solver.cpp:542] Iteration 2840, lr = 0.1
I0416 12:30:51.289340   977 solver.cpp:221] Iteration 2860, loss = 1.54116
I0416 12:30:51.289367   977 solver.cpp:236]     Train net output #0: loss = 1.58657 (* 1 = 1.58657 loss)
I0416 12:30:51.289372   977 solver.cpp:542] Iteration 2860, lr = 0.1
I0416 12:31:04.760155   977 solver.cpp:221] Iteration 2880, loss = 1.59523
I0416 12:31:04.760181   977 solver.cpp:236]     Train net output #0: loss = 1.52316 (* 1 = 1.52316 loss)
I0416 12:31:04.760186   977 solver.cpp:542] Iteration 2880, lr = 0.1
I0416 12:31:18.220249   977 solver.cpp:221] Iteration 2900, loss = 1.56403
I0416 12:31:18.220276   977 solver.cpp:236]     Train net output #0: loss = 1.62026 (* 1 = 1.62026 loss)
I0416 12:31:18.220280   977 solver.cpp:542] Iteration 2900, lr = 0.1
I0416 12:31:31.690800   977 solver.cpp:221] Iteration 2920, loss = 1.64054
I0416 12:31:31.690827   977 solver.cpp:236]     Train net output #0: loss = 1.66928 (* 1 = 1.66928 loss)
I0416 12:31:31.690832   977 solver.cpp:542] Iteration 2920, lr = 0.1
I0416 12:31:45.142355   977 solver.cpp:221] Iteration 2940, loss = 1.63053
I0416 12:31:45.142382   977 solver.cpp:236]     Train net output #0: loss = 1.80336 (* 1 = 1.80336 loss)
I0416 12:31:45.142386   977 solver.cpp:542] Iteration 2940, lr = 0.1
I0416 12:31:58.602185   977 solver.cpp:221] Iteration 2960, loss = 1.56376
I0416 12:31:58.602211   977 solver.cpp:236]     Train net output #0: loss = 1.39453 (* 1 = 1.39453 loss)
I0416 12:31:58.602216   977 solver.cpp:542] Iteration 2960, lr = 0.1
I0416 12:32:12.051342   977 solver.cpp:221] Iteration 2980, loss = 1.53644
I0416 12:32:12.051368   977 solver.cpp:236]     Train net output #0: loss = 1.5582 (* 1 = 1.5582 loss)
I0416 12:32:12.051373   977 solver.cpp:542] Iteration 2980, lr = 0.1
I0416 12:32:24.845409   977 solver.cpp:316] Iteration 3000, Testing net (#0)
I0416 12:32:36.335274   977 solver.cpp:373]     Test net output #0: accuracy = 0.671103
I0416 12:32:36.335295   977 solver.cpp:373]     Test net output #1: loss = 1.19038 (* 1 = 1.19038 loss)
I0416 12:32:36.999707   977 solver.cpp:221] Iteration 3000, loss = 1.56301
I0416 12:32:36.999733   977 solver.cpp:236]     Train net output #0: loss = 1.58463 (* 1 = 1.58463 loss)
I0416 12:32:36.999738   977 solver.cpp:542] Iteration 3000, lr = 0.1
I0416 12:32:50.496139   977 solver.cpp:221] Iteration 3020, loss = 1.60627
I0416 12:32:50.496165   977 solver.cpp:236]     Train net output #0: loss = 1.912 (* 1 = 1.912 loss)
I0416 12:32:50.496170   977 solver.cpp:542] Iteration 3020, lr = 0.1
I0416 12:33:03.968101   977 solver.cpp:221] Iteration 3040, loss = 1.6053
I0416 12:33:03.968128   977 solver.cpp:236]     Train net output #0: loss = 1.92601 (* 1 = 1.92601 loss)
I0416 12:33:03.968133   977 solver.cpp:542] Iteration 3040, lr = 0.1
I0416 12:33:17.429888   977 solver.cpp:221] Iteration 3060, loss = 1.54904
I0416 12:33:17.429915   977 solver.cpp:236]     Train net output #0: loss = 1.50449 (* 1 = 1.50449 loss)
I0416 12:33:17.429919   977 solver.cpp:542] Iteration 3060, lr = 0.1
I0416 12:33:30.891644   977 solver.cpp:221] Iteration 3080, loss = 1.51159
I0416 12:33:30.891670   977 solver.cpp:236]     Train net output #0: loss = 1.1594 (* 1 = 1.1594 loss)
I0416 12:33:30.891675   977 solver.cpp:542] Iteration 3080, lr = 0.1
I0416 12:33:44.366029   977 solver.cpp:221] Iteration 3100, loss = 1.54813
I0416 12:33:44.366055   977 solver.cpp:236]     Train net output #0: loss = 1.29866 (* 1 = 1.29866 loss)
I0416 12:33:44.366060   977 solver.cpp:542] Iteration 3100, lr = 0.1
I0416 12:33:57.829892   977 solver.cpp:221] Iteration 3120, loss = 1.43061
I0416 12:33:57.829918   977 solver.cpp:236]     Train net output #0: loss = 1.42764 (* 1 = 1.42764 loss)
I0416 12:33:57.829923   977 solver.cpp:542] Iteration 3120, lr = 0.1
I0416 12:34:11.275115   977 solver.cpp:221] Iteration 3140, loss = 1.57949
I0416 12:34:11.275141   977 solver.cpp:236]     Train net output #0: loss = 1.55518 (* 1 = 1.55518 loss)
I0416 12:34:11.275146   977 solver.cpp:542] Iteration 3140, lr = 0.1
I0416 12:34:24.733909   977 solver.cpp:221] Iteration 3160, loss = 1.5383
I0416 12:34:24.733937   977 solver.cpp:236]     Train net output #0: loss = 1.61873 (* 1 = 1.61873 loss)
I0416 12:34:24.733940   977 solver.cpp:542] Iteration 3160, lr = 0.1
I0416 12:34:38.175530   977 solver.cpp:221] Iteration 3180, loss = 1.51839
I0416 12:34:38.175551   977 solver.cpp:236]     Train net output #0: loss = 1.48616 (* 1 = 1.48616 loss)
I0416 12:34:38.175556   977 solver.cpp:542] Iteration 3180, lr = 0.1
I0416 12:34:50.976758   977 solver.cpp:316] Iteration 3200, Testing net (#0)
I0416 12:35:02.464974   977 solver.cpp:373]     Test net output #0: accuracy = 0.597719
I0416 12:35:02.464996   977 solver.cpp:373]     Test net output #1: loss = 1.60985 (* 1 = 1.60985 loss)
I0416 12:35:03.131036   977 solver.cpp:221] Iteration 3200, loss = 1.52466
I0416 12:35:03.131062   977 solver.cpp:236]     Train net output #0: loss = 1.75141 (* 1 = 1.75141 loss)
I0416 12:35:03.131067   977 solver.cpp:542] Iteration 3200, lr = 0.1
I0416 12:35:16.601778   977 solver.cpp:221] Iteration 3220, loss = 1.59239
I0416 12:35:16.601804   977 solver.cpp:236]     Train net output #0: loss = 1.65802 (* 1 = 1.65802 loss)
I0416 12:35:16.601809   977 solver.cpp:542] Iteration 3220, lr = 0.1
I0416 12:35:30.094986   977 solver.cpp:221] Iteration 3240, loss = 1.55168
I0416 12:35:30.095013   977 solver.cpp:236]     Train net output #0: loss = 1.56467 (* 1 = 1.56467 loss)
I0416 12:35:30.095018   977 solver.cpp:542] Iteration 3240, lr = 0.1
I0416 12:35:43.603437   977 solver.cpp:221] Iteration 3260, loss = 1.51148
I0416 12:35:43.603464   977 solver.cpp:236]     Train net output #0: loss = 1.01496 (* 1 = 1.01496 loss)
I0416 12:35:43.603469   977 solver.cpp:542] Iteration 3260, lr = 0.1
I0416 12:35:57.094032   977 solver.cpp:221] Iteration 3280, loss = 1.48598
I0416 12:35:57.094058   977 solver.cpp:236]     Train net output #0: loss = 1.499 (* 1 = 1.499 loss)
I0416 12:35:57.094063   977 solver.cpp:542] Iteration 3280, lr = 0.1
I0416 12:36:10.567030   977 solver.cpp:221] Iteration 3300, loss = 1.42246
I0416 12:36:10.567057   977 solver.cpp:236]     Train net output #0: loss = 1.21295 (* 1 = 1.21295 loss)
I0416 12:36:10.567062   977 solver.cpp:542] Iteration 3300, lr = 0.1
I0416 12:36:24.031000   977 solver.cpp:221] Iteration 3320, loss = 1.43914
I0416 12:36:24.031028   977 solver.cpp:236]     Train net output #0: loss = 1.36964 (* 1 = 1.36964 loss)
I0416 12:36:24.031033   977 solver.cpp:542] Iteration 3320, lr = 0.1
I0416 12:36:37.510260   977 solver.cpp:221] Iteration 3340, loss = 1.51166
I0416 12:36:37.510288   977 solver.cpp:236]     Train net output #0: loss = 1.81523 (* 1 = 1.81523 loss)
I0416 12:36:37.510293   977 solver.cpp:542] Iteration 3340, lr = 0.1
I0416 12:36:50.988302   977 solver.cpp:221] Iteration 3360, loss = 1.50656
I0416 12:36:50.988328   977 solver.cpp:236]     Train net output #0: loss = 1.25823 (* 1 = 1.25823 loss)
I0416 12:36:50.988332   977 solver.cpp:542] Iteration 3360, lr = 0.1
I0416 12:37:04.444490   977 solver.cpp:221] Iteration 3380, loss = 1.46147
I0416 12:37:04.444517   977 solver.cpp:236]     Train net output #0: loss = 1.4179 (* 1 = 1.4179 loss)
I0416 12:37:04.444522   977 solver.cpp:542] Iteration 3380, lr = 0.1
I0416 12:37:17.276247   977 solver.cpp:316] Iteration 3400, Testing net (#0)
I0416 12:37:28.774986   977 solver.cpp:373]     Test net output #0: accuracy = 0.610646
I0416 12:37:28.775008   977 solver.cpp:373]     Test net output #1: loss = 1.5144 (* 1 = 1.5144 loss)
I0416 12:37:29.440579   977 solver.cpp:221] Iteration 3400, loss = 1.46398
I0416 12:37:29.440606   977 solver.cpp:236]     Train net output #0: loss = 1.53699 (* 1 = 1.53699 loss)
I0416 12:37:29.440611   977 solver.cpp:542] Iteration 3400, lr = 0.1
I0416 12:37:42.910326   977 solver.cpp:221] Iteration 3420, loss = 1.43135
I0416 12:37:42.910352   977 solver.cpp:236]     Train net output #0: loss = 1.42069 (* 1 = 1.42069 loss)
I0416 12:37:42.910357   977 solver.cpp:542] Iteration 3420, lr = 0.1
I0416 12:37:56.371397   977 solver.cpp:221] Iteration 3440, loss = 1.53567
I0416 12:37:56.371423   977 solver.cpp:236]     Train net output #0: loss = 1.38917 (* 1 = 1.38917 loss)
I0416 12:37:56.371428   977 solver.cpp:542] Iteration 3440, lr = 0.1
I0416 12:38:09.815486   977 solver.cpp:221] Iteration 3460, loss = 1.51248
I0416 12:38:09.815512   977 solver.cpp:236]     Train net output #0: loss = 1.78203 (* 1 = 1.78203 loss)
I0416 12:38:09.815517   977 solver.cpp:542] Iteration 3460, lr = 0.1
I0416 12:38:23.282109   977 solver.cpp:221] Iteration 3480, loss = 1.44222
I0416 12:38:23.282136   977 solver.cpp:236]     Train net output #0: loss = 1.18944 (* 1 = 1.18944 loss)
I0416 12:38:23.282141   977 solver.cpp:542] Iteration 3480, lr = 0.1
I0416 12:38:36.752656   977 solver.cpp:221] Iteration 3500, loss = 1.53397
I0416 12:38:36.752683   977 solver.cpp:236]     Train net output #0: loss = 1.78457 (* 1 = 1.78457 loss)
I0416 12:38:36.752687   977 solver.cpp:542] Iteration 3500, lr = 0.1
I0416 12:38:50.228363   977 solver.cpp:221] Iteration 3520, loss = 1.4647
I0416 12:38:50.228390   977 solver.cpp:236]     Train net output #0: loss = 1.82797 (* 1 = 1.82797 loss)
I0416 12:38:50.228395   977 solver.cpp:542] Iteration 3520, lr = 0.1
I0416 12:39:03.685583   977 solver.cpp:221] Iteration 3540, loss = 1.40642
I0416 12:39:03.685611   977 solver.cpp:236]     Train net output #0: loss = 1.50721 (* 1 = 1.50721 loss)
I0416 12:39:03.685616   977 solver.cpp:542] Iteration 3540, lr = 0.1
I0416 12:39:17.126761   977 solver.cpp:221] Iteration 3560, loss = 1.47056
I0416 12:39:17.126788   977 solver.cpp:236]     Train net output #0: loss = 1.64651 (* 1 = 1.64651 loss)
I0416 12:39:17.126792   977 solver.cpp:542] Iteration 3560, lr = 0.1
I0416 12:39:30.589278   977 solver.cpp:221] Iteration 3580, loss = 1.36585
I0416 12:39:30.589304   977 solver.cpp:236]     Train net output #0: loss = 1.42376 (* 1 = 1.42376 loss)
I0416 12:39:30.589309   977 solver.cpp:542] Iteration 3580, lr = 0.1
I0416 12:39:43.415269   977 solver.cpp:316] Iteration 3600, Testing net (#0)
I0416 12:39:54.914672   977 solver.cpp:373]     Test net output #0: accuracy = 0.731369
I0416 12:39:54.914693   977 solver.cpp:373]     Test net output #1: loss = 0.998284 (* 1 = 0.998284 loss)
I0416 12:39:55.581533   977 solver.cpp:221] Iteration 3600, loss = 1.42387
I0416 12:39:55.581559   977 solver.cpp:236]     Train net output #0: loss = 1.3847 (* 1 = 1.3847 loss)
I0416 12:39:55.581564   977 solver.cpp:542] Iteration 3600, lr = 0.1
I0416 12:40:09.058719   977 solver.cpp:221] Iteration 3620, loss = 1.40524
I0416 12:40:09.058746   977 solver.cpp:236]     Train net output #0: loss = 1.3803 (* 1 = 1.3803 loss)
I0416 12:40:09.058750   977 solver.cpp:542] Iteration 3620, lr = 0.1
I0416 12:40:22.523361   977 solver.cpp:221] Iteration 3640, loss = 1.3971
I0416 12:40:22.523388   977 solver.cpp:236]     Train net output #0: loss = 1.60691 (* 1 = 1.60691 loss)
I0416 12:40:22.523392   977 solver.cpp:542] Iteration 3640, lr = 0.1
I0416 12:40:35.980258   977 solver.cpp:221] Iteration 3660, loss = 1.43159
I0416 12:40:35.980285   977 solver.cpp:236]     Train net output #0: loss = 1.10563 (* 1 = 1.10563 loss)
I0416 12:40:35.980290   977 solver.cpp:542] Iteration 3660, lr = 0.1
I0416 12:40:49.465574   977 solver.cpp:221] Iteration 3680, loss = 1.39207
I0416 12:40:49.465600   977 solver.cpp:236]     Train net output #0: loss = 1.41298 (* 1 = 1.41298 loss)
I0416 12:40:49.465605   977 solver.cpp:542] Iteration 3680, lr = 0.1
I0416 12:41:02.919373   977 solver.cpp:221] Iteration 3700, loss = 1.41073
I0416 12:41:02.919400   977 solver.cpp:236]     Train net output #0: loss = 1.99229 (* 1 = 1.99229 loss)
I0416 12:41:02.919405   977 solver.cpp:542] Iteration 3700, lr = 0.1
I0416 12:41:16.400226   977 solver.cpp:221] Iteration 3720, loss = 1.46113
I0416 12:41:16.400254   977 solver.cpp:236]     Train net output #0: loss = 1.74471 (* 1 = 1.74471 loss)
I0416 12:41:16.400259   977 solver.cpp:542] Iteration 3720, lr = 0.1
I0416 12:41:29.864331   977 solver.cpp:221] Iteration 3740, loss = 1.44196
I0416 12:41:29.864358   977 solver.cpp:236]     Train net output #0: loss = 1.39093 (* 1 = 1.39093 loss)
I0416 12:41:29.864363   977 solver.cpp:542] Iteration 3740, lr = 0.1
I0416 12:41:43.334323   977 solver.cpp:221] Iteration 3760, loss = 1.36584
I0416 12:41:43.334350   977 solver.cpp:236]     Train net output #0: loss = 1.4366 (* 1 = 1.4366 loss)
I0416 12:41:43.334355   977 solver.cpp:542] Iteration 3760, lr = 0.1
I0416 12:41:56.801522   977 solver.cpp:221] Iteration 3780, loss = 1.4017
I0416 12:41:56.801549   977 solver.cpp:236]     Train net output #0: loss = 1.84342 (* 1 = 1.84342 loss)
I0416 12:41:56.801554   977 solver.cpp:542] Iteration 3780, lr = 0.1
I0416 12:42:09.596499   977 solver.cpp:316] Iteration 3800, Testing net (#0)
I0416 12:42:21.086864   977 solver.cpp:373]     Test net output #0: accuracy = 0.693916
I0416 12:42:21.086886   977 solver.cpp:373]     Test net output #1: loss = 1.14837 (* 1 = 1.14837 loss)
I0416 12:42:21.752207   977 solver.cpp:221] Iteration 3800, loss = 1.33066
I0416 12:42:21.752233   977 solver.cpp:236]     Train net output #0: loss = 1.29919 (* 1 = 1.29919 loss)
I0416 12:42:21.752238   977 solver.cpp:542] Iteration 3800, lr = 0.1
I0416 12:42:35.213210   977 solver.cpp:221] Iteration 3820, loss = 1.34661
I0416 12:42:35.213238   977 solver.cpp:236]     Train net output #0: loss = 1.21922 (* 1 = 1.21922 loss)
I0416 12:42:35.213243   977 solver.cpp:542] Iteration 3820, lr = 0.1
I0416 12:42:48.723054   977 solver.cpp:221] Iteration 3840, loss = 1.3886
I0416 12:42:48.723081   977 solver.cpp:236]     Train net output #0: loss = 1.31604 (* 1 = 1.31604 loss)
I0416 12:42:48.723085   977 solver.cpp:542] Iteration 3840, lr = 0.1
I0416 12:43:02.211277   977 solver.cpp:221] Iteration 3860, loss = 1.39519
I0416 12:43:02.211302   977 solver.cpp:236]     Train net output #0: loss = 1.1763 (* 1 = 1.1763 loss)
I0416 12:43:02.211308   977 solver.cpp:542] Iteration 3860, lr = 0.1
I0416 12:43:15.691725   977 solver.cpp:221] Iteration 3880, loss = 1.37357
I0416 12:43:15.691751   977 solver.cpp:236]     Train net output #0: loss = 1.39623 (* 1 = 1.39623 loss)
I0416 12:43:15.691756   977 solver.cpp:542] Iteration 3880, lr = 0.1
I0416 12:43:29.146812   977 solver.cpp:221] Iteration 3900, loss = 1.34489
I0416 12:43:29.146839   977 solver.cpp:236]     Train net output #0: loss = 1.50934 (* 1 = 1.50934 loss)
I0416 12:43:29.146844   977 solver.cpp:542] Iteration 3900, lr = 0.1
I0416 12:43:42.603108   977 solver.cpp:221] Iteration 3920, loss = 1.38243
I0416 12:43:42.603135   977 solver.cpp:236]     Train net output #0: loss = 1.56179 (* 1 = 1.56179 loss)
I0416 12:43:42.603139   977 solver.cpp:542] Iteration 3920, lr = 0.1
I0416 12:43:56.081601   977 solver.cpp:221] Iteration 3940, loss = 1.38182
I0416 12:43:56.081627   977 solver.cpp:236]     Train net output #0: loss = 1.52892 (* 1 = 1.52892 loss)
I0416 12:43:56.081632   977 solver.cpp:542] Iteration 3940, lr = 0.1
I0416 12:44:09.528372   977 solver.cpp:221] Iteration 3960, loss = 1.38813
I0416 12:44:09.528398   977 solver.cpp:236]     Train net output #0: loss = 1.31265 (* 1 = 1.31265 loss)
I0416 12:44:09.528403   977 solver.cpp:542] Iteration 3960, lr = 0.1
I0416 12:44:22.979491   977 solver.cpp:221] Iteration 3980, loss = 1.3742
I0416 12:44:22.979518   977 solver.cpp:236]     Train net output #0: loss = 1.38323 (* 1 = 1.38323 loss)
I0416 12:44:22.979523   977 solver.cpp:542] Iteration 3980, lr = 0.1
I0416 12:44:35.773192   977 solver.cpp:316] Iteration 4000, Testing net (#0)
I0416 12:44:47.274329   977 solver.cpp:373]     Test net output #0: accuracy = 0.698289
I0416 12:44:47.274350   977 solver.cpp:373]     Test net output #1: loss = 1.1497 (* 1 = 1.1497 loss)
I0416 12:44:47.942044   977 solver.cpp:221] Iteration 4000, loss = 1.33882
I0416 12:44:47.942070   977 solver.cpp:236]     Train net output #0: loss = 1.28078 (* 1 = 1.28078 loss)
I0416 12:44:47.942075   977 solver.cpp:542] Iteration 4000, lr = 0.1
I0416 12:45:01.436483   977 solver.cpp:221] Iteration 4020, loss = 1.28159
I0416 12:45:01.436509   977 solver.cpp:236]     Train net output #0: loss = 1.44333 (* 1 = 1.44333 loss)
I0416 12:45:01.436513   977 solver.cpp:542] Iteration 4020, lr = 0.1
I0416 12:45:14.909023   977 solver.cpp:221] Iteration 4040, loss = 1.32484
I0416 12:45:14.909049   977 solver.cpp:236]     Train net output #0: loss = 1.28487 (* 1 = 1.28487 loss)
I0416 12:45:14.909054   977 solver.cpp:542] Iteration 4040, lr = 0.1
I0416 12:45:28.363448   977 solver.cpp:221] Iteration 4060, loss = 1.32524
I0416 12:45:28.363476   977 solver.cpp:236]     Train net output #0: loss = 1.35407 (* 1 = 1.35407 loss)
I0416 12:45:28.363481   977 solver.cpp:542] Iteration 4060, lr = 0.1
I0416 12:45:41.824023   977 solver.cpp:221] Iteration 4080, loss = 1.31525
I0416 12:45:41.824048   977 solver.cpp:236]     Train net output #0: loss = 1.26474 (* 1 = 1.26474 loss)
I0416 12:45:41.824053   977 solver.cpp:542] Iteration 4080, lr = 0.1
I0416 12:45:55.271742   977 solver.cpp:221] Iteration 4100, loss = 1.31618
I0416 12:45:55.271770   977 solver.cpp:236]     Train net output #0: loss = 1.2864 (* 1 = 1.2864 loss)
I0416 12:45:55.271773   977 solver.cpp:542] Iteration 4100, lr = 0.1
I0416 12:46:08.708746   977 solver.cpp:221] Iteration 4120, loss = 1.25161
I0416 12:46:08.708773   977 solver.cpp:236]     Train net output #0: loss = 1.23198 (* 1 = 1.23198 loss)
I0416 12:46:08.708778   977 solver.cpp:542] Iteration 4120, lr = 0.1
I0416 12:46:22.200742   977 solver.cpp:221] Iteration 4140, loss = 1.34639
I0416 12:46:22.200768   977 solver.cpp:236]     Train net output #0: loss = 1.52301 (* 1 = 1.52301 loss)
I0416 12:46:22.200773   977 solver.cpp:542] Iteration 4140, lr = 0.1
I0416 12:46:35.687062   977 solver.cpp:221] Iteration 4160, loss = 1.33138
I0416 12:46:35.687088   977 solver.cpp:236]     Train net output #0: loss = 1.52745 (* 1 = 1.52745 loss)
I0416 12:46:35.687093   977 solver.cpp:542] Iteration 4160, lr = 0.1
I0416 12:46:49.163962   977 solver.cpp:221] Iteration 4180, loss = 1.33328
I0416 12:46:49.163990   977 solver.cpp:236]     Train net output #0: loss = 1.33251 (* 1 = 1.33251 loss)
I0416 12:46:49.163995   977 solver.cpp:542] Iteration 4180, lr = 0.1
I0416 12:47:01.991571   977 solver.cpp:316] Iteration 4200, Testing net (#0)
I0416 12:47:13.480962   977 solver.cpp:373]     Test net output #0: accuracy = 0.65
I0416 12:47:13.480983   977 solver.cpp:373]     Test net output #1: loss = 1.37007 (* 1 = 1.37007 loss)
I0416 12:47:14.146052   977 solver.cpp:221] Iteration 4200, loss = 1.31369
I0416 12:47:14.146078   977 solver.cpp:236]     Train net output #0: loss = 1.34322 (* 1 = 1.34322 loss)
I0416 12:47:14.146082   977 solver.cpp:542] Iteration 4200, lr = 0.1
I0416 12:47:27.593690   977 solver.cpp:221] Iteration 4220, loss = 1.29798
I0416 12:47:27.593716   977 solver.cpp:236]     Train net output #0: loss = 1.08062 (* 1 = 1.08062 loss)
I0416 12:47:27.593721   977 solver.cpp:542] Iteration 4220, lr = 0.1
I0416 12:47:41.062337   977 solver.cpp:221] Iteration 4240, loss = 1.26963
I0416 12:47:41.062366   977 solver.cpp:236]     Train net output #0: loss = 1.47074 (* 1 = 1.47074 loss)
I0416 12:47:41.062369   977 solver.cpp:542] Iteration 4240, lr = 0.1
I0416 12:47:54.542551   977 solver.cpp:221] Iteration 4260, loss = 1.28086
I0416 12:47:54.542577   977 solver.cpp:236]     Train net output #0: loss = 1.25819 (* 1 = 1.25819 loss)
I0416 12:47:54.542582   977 solver.cpp:542] Iteration 4260, lr = 0.1
I0416 12:48:08.023479   977 solver.cpp:221] Iteration 4280, loss = 1.26643
I0416 12:48:08.023506   977 solver.cpp:236]     Train net output #0: loss = 0.973577 (* 1 = 0.973577 loss)
I0416 12:48:08.023511   977 solver.cpp:542] Iteration 4280, lr = 0.1
I0416 12:48:21.499075   977 solver.cpp:221] Iteration 4300, loss = 1.26344
I0416 12:48:21.499101   977 solver.cpp:236]     Train net output #0: loss = 0.978787 (* 1 = 0.978787 loss)
I0416 12:48:21.499106   977 solver.cpp:542] Iteration 4300, lr = 0.1
I0416 12:48:34.976353   977 solver.cpp:221] Iteration 4320, loss = 1.26137
I0416 12:48:34.976379   977 solver.cpp:236]     Train net output #0: loss = 1.79828 (* 1 = 1.79828 loss)
I0416 12:48:34.976383   977 solver.cpp:542] Iteration 4320, lr = 0.1
I0416 12:48:48.427480   977 solver.cpp:221] Iteration 4340, loss = 1.35312
I0416 12:48:48.427507   977 solver.cpp:236]     Train net output #0: loss = 1.54704 (* 1 = 1.54704 loss)
I0416 12:48:48.427512   977 solver.cpp:542] Iteration 4340, lr = 0.1
I0416 12:49:01.880785   977 solver.cpp:221] Iteration 4360, loss = 1.28683
I0416 12:49:01.880812   977 solver.cpp:236]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0416 12:49:01.880816   977 solver.cpp:542] Iteration 4360, lr = 0.1
I0416 12:49:15.355434   977 solver.cpp:221] Iteration 4380, loss = 1.32792
I0416 12:49:15.355461   977 solver.cpp:236]     Train net output #0: loss = 1.29503 (* 1 = 1.29503 loss)
I0416 12:49:15.355465   977 solver.cpp:542] Iteration 4380, lr = 0.1
I0416 12:49:28.193032   977 solver.cpp:316] Iteration 4400, Testing net (#0)
I0416 12:49:39.695394   977 solver.cpp:373]     Test net output #0: accuracy = 0.80076
I0416 12:49:39.695416   977 solver.cpp:373]     Test net output #1: loss = 0.723864 (* 1 = 0.723864 loss)
I0416 12:49:40.362944   977 solver.cpp:221] Iteration 4400, loss = 1.25009
I0416 12:49:40.362972   977 solver.cpp:236]     Train net output #0: loss = 1.23757 (* 1 = 1.23757 loss)
I0416 12:49:40.362977   977 solver.cpp:542] Iteration 4400, lr = 0.1
I0416 12:49:53.833766   977 solver.cpp:221] Iteration 4420, loss = 1.29861
I0416 12:49:53.833793   977 solver.cpp:236]     Train net output #0: loss = 1.03816 (* 1 = 1.03816 loss)
I0416 12:49:53.833798   977 solver.cpp:542] Iteration 4420, lr = 0.1
I0416 12:50:07.314950   977 solver.cpp:221] Iteration 4440, loss = 1.24643
I0416 12:50:07.314976   977 solver.cpp:236]     Train net output #0: loss = 1.22251 (* 1 = 1.22251 loss)
I0416 12:50:07.314981   977 solver.cpp:542] Iteration 4440, lr = 0.1
I0416 12:50:20.796586   977 solver.cpp:221] Iteration 4460, loss = 1.25295
I0416 12:50:20.796613   977 solver.cpp:236]     Train net output #0: loss = 1.45478 (* 1 = 1.45478 loss)
I0416 12:50:20.796618   977 solver.cpp:542] Iteration 4460, lr = 0.1
I0416 12:50:34.272609   977 solver.cpp:221] Iteration 4480, loss = 1.30443
I0416 12:50:34.272635   977 solver.cpp:236]     Train net output #0: loss = 1.29155 (* 1 = 1.29155 loss)
I0416 12:50:34.272640   977 solver.cpp:542] Iteration 4480, lr = 0.1
I0416 12:50:47.737376   977 solver.cpp:221] Iteration 4500, loss = 1.37277
I0416 12:50:47.737402   977 solver.cpp:236]     Train net output #0: loss = 1.44691 (* 1 = 1.44691 loss)
I0416 12:50:47.737406   977 solver.cpp:542] Iteration 4500, lr = 0.1
I0416 12:51:01.203294   977 solver.cpp:221] Iteration 4520, loss = 1.30907
I0416 12:51:01.203321   977 solver.cpp:236]     Train net output #0: loss = 1.13464 (* 1 = 1.13464 loss)
I0416 12:51:01.203326   977 solver.cpp:542] Iteration 4520, lr = 0.1
I0416 12:51:14.694739   977 solver.cpp:221] Iteration 4540, loss = 1.22463
I0416 12:51:14.694766   977 solver.cpp:236]     Train net output #0: loss = 0.847241 (* 1 = 0.847241 loss)
I0416 12:51:14.694772   977 solver.cpp:542] Iteration 4540, lr = 0.1
I0416 12:51:28.172231   977 solver.cpp:221] Iteration 4560, loss = 1.25653
I0416 12:51:28.172258   977 solver.cpp:236]     Train net output #0: loss = 0.895252 (* 1 = 0.895252 loss)
I0416 12:51:28.172263   977 solver.cpp:542] Iteration 4560, lr = 0.1
I0416 12:51:41.634307   977 solver.cpp:221] Iteration 4580, loss = 1.25962
I0416 12:51:41.634333   977 solver.cpp:236]     Train net output #0: loss = 1.33101 (* 1 = 1.33101 loss)
I0416 12:51:41.634338   977 solver.cpp:542] Iteration 4580, lr = 0.1
I0416 12:51:54.445904   977 solver.cpp:316] Iteration 4600, Testing net (#0)
I0416 12:52:05.945864   977 solver.cpp:373]     Test net output #0: accuracy = 0.676996
I0416 12:52:05.945886   977 solver.cpp:373]     Test net output #1: loss = 1.31007 (* 1 = 1.31007 loss)
I0416 12:52:06.614214   977 solver.cpp:221] Iteration 4600, loss = 1.28755
I0416 12:52:06.614241   977 solver.cpp:236]     Train net output #0: loss = 1.6172 (* 1 = 1.6172 loss)
I0416 12:52:06.614246   977 solver.cpp:542] Iteration 4600, lr = 0.1
I0416 12:52:20.124686   977 solver.cpp:221] Iteration 4620, loss = 1.23289
I0416 12:52:20.124713   977 solver.cpp:236]     Train net output #0: loss = 1.39434 (* 1 = 1.39434 loss)
I0416 12:52:20.124718   977 solver.cpp:542] Iteration 4620, lr = 0.1
I0416 12:52:33.584008   977 solver.cpp:221] Iteration 4640, loss = 1.2154
I0416 12:52:33.584034   977 solver.cpp:236]     Train net output #0: loss = 1.0775 (* 1 = 1.0775 loss)
I0416 12:52:33.584038   977 solver.cpp:542] Iteration 4640, lr = 0.1
I0416 12:52:47.046614   977 solver.cpp:221] Iteration 4660, loss = 1.20433
I0416 12:52:47.046641   977 solver.cpp:236]     Train net output #0: loss = 1.11336 (* 1 = 1.11336 loss)
I0416 12:52:47.046646   977 solver.cpp:542] Iteration 4660, lr = 0.1
I0416 12:53:00.493690   977 solver.cpp:221] Iteration 4680, loss = 1.25376
I0416 12:53:00.493716   977 solver.cpp:236]     Train net output #0: loss = 1.17454 (* 1 = 1.17454 loss)
I0416 12:53:00.493721   977 solver.cpp:542] Iteration 4680, lr = 0.1
I0416 12:53:13.943047   977 solver.cpp:221] Iteration 4700, loss = 1.25492
I0416 12:53:13.943073   977 solver.cpp:236]     Train net output #0: loss = 1.71736 (* 1 = 1.71736 loss)
I0416 12:53:13.943078   977 solver.cpp:542] Iteration 4700, lr = 0.1
I0416 12:53:27.396726   977 solver.cpp:221] Iteration 4720, loss = 1.19957
I0416 12:53:27.396752   977 solver.cpp:236]     Train net output #0: loss = 1.17066 (* 1 = 1.17066 loss)
I0416 12:53:27.396757   977 solver.cpp:542] Iteration 4720, lr = 0.1
I0416 12:53:40.864506   977 solver.cpp:221] Iteration 4740, loss = 1.20359
I0416 12:53:40.864532   977 solver.cpp:236]     Train net output #0: loss = 0.951469 (* 1 = 0.951469 loss)
I0416 12:53:40.864537   977 solver.cpp:542] Iteration 4740, lr = 0.1
I0416 12:53:54.327559   977 solver.cpp:221] Iteration 4760, loss = 1.2336
I0416 12:53:54.327586   977 solver.cpp:236]     Train net output #0: loss = 1.35545 (* 1 = 1.35545 loss)
I0416 12:53:54.327590   977 solver.cpp:542] Iteration 4760, lr = 0.1
I0416 12:54:07.808727   977 solver.cpp:221] Iteration 4780, loss = 1.2187
I0416 12:54:07.808753   977 solver.cpp:236]     Train net output #0: loss = 1.63971 (* 1 = 1.63971 loss)
I0416 12:54:07.808758   977 solver.cpp:542] Iteration 4780, lr = 0.1
I0416 12:54:20.644579   977 solver.cpp:316] Iteration 4800, Testing net (#0)
I0416 12:54:32.134448   977 solver.cpp:373]     Test net output #0: accuracy = 0.645627
I0416 12:54:32.134469   977 solver.cpp:373]     Test net output #1: loss = 1.35135 (* 1 = 1.35135 loss)
I0416 12:54:32.798408   977 solver.cpp:221] Iteration 4800, loss = 1.27812
I0416 12:54:32.798435   977 solver.cpp:236]     Train net output #0: loss = 1.34068 (* 1 = 1.34068 loss)
I0416 12:54:32.798439   977 solver.cpp:542] Iteration 4800, lr = 0.1
I0416 12:54:46.256196   977 solver.cpp:221] Iteration 4820, loss = 1.23389
I0416 12:54:46.256223   977 solver.cpp:236]     Train net output #0: loss = 1.23675 (* 1 = 1.23675 loss)
I0416 12:54:46.256227   977 solver.cpp:542] Iteration 4820, lr = 0.1
I0416 12:54:59.729269   977 solver.cpp:221] Iteration 4840, loss = 1.2429
I0416 12:54:59.729295   977 solver.cpp:236]     Train net output #0: loss = 1.23688 (* 1 = 1.23688 loss)
I0416 12:54:59.729300   977 solver.cpp:542] Iteration 4840, lr = 0.1
I0416 12:55:13.167464   977 solver.cpp:221] Iteration 4860, loss = 1.21946
I0416 12:55:13.167490   977 solver.cpp:236]     Train net output #0: loss = 0.848411 (* 1 = 0.848411 loss)
I0416 12:55:13.167495   977 solver.cpp:542] Iteration 4860, lr = 0.1
I0416 12:55:26.616905   977 solver.cpp:221] Iteration 4880, loss = 1.28317
I0416 12:55:26.616930   977 solver.cpp:236]     Train net output #0: loss = 1.42737 (* 1 = 1.42737 loss)
I0416 12:55:26.616935   977 solver.cpp:542] Iteration 4880, lr = 0.1
I0416 12:55:40.109407   977 solver.cpp:221] Iteration 4900, loss = 1.29268
I0416 12:55:40.109433   977 solver.cpp:236]     Train net output #0: loss = 1.67811 (* 1 = 1.67811 loss)
I0416 12:55:40.109438   977 solver.cpp:542] Iteration 4900, lr = 0.1
I0416 12:55:53.595376   977 solver.cpp:221] Iteration 4920, loss = 1.31721
I0416 12:55:53.595402   977 solver.cpp:236]     Train net output #0: loss = 1.34544 (* 1 = 1.34544 loss)
I0416 12:55:53.595407   977 solver.cpp:542] Iteration 4920, lr = 0.1
I0416 12:56:07.061681   977 solver.cpp:221] Iteration 4940, loss = 1.23026
I0416 12:56:07.061707   977 solver.cpp:236]     Train net output #0: loss = 1.01314 (* 1 = 1.01314 loss)
I0416 12:56:07.061712   977 solver.cpp:542] Iteration 4940, lr = 0.1
I0416 12:56:20.524930   977 solver.cpp:221] Iteration 4960, loss = 1.24796
I0416 12:56:20.524956   977 solver.cpp:236]     Train net output #0: loss = 1.28462 (* 1 = 1.28462 loss)
I0416 12:56:20.524961   977 solver.cpp:542] Iteration 4960, lr = 0.1
I0416 12:56:33.990267   977 solver.cpp:221] Iteration 4980, loss = 1.18628
I0416 12:56:33.990293   977 solver.cpp:236]     Train net output #0: loss = 1.10781 (* 1 = 1.10781 loss)
I0416 12:56:33.990298   977 solver.cpp:542] Iteration 4980, lr = 0.1
I0416 12:56:46.785100   977 solver.cpp:316] Iteration 5000, Testing net (#0)
I0416 12:56:58.275859   977 solver.cpp:373]     Test net output #0: accuracy = 0.606844
I0416 12:56:58.275881   977 solver.cpp:373]     Test net output #1: loss = 1.54334 (* 1 = 1.54334 loss)
I0416 12:56:58.940138   977 solver.cpp:221] Iteration 5000, loss = 1.25059
I0416 12:56:58.940165   977 solver.cpp:236]     Train net output #0: loss = 1.4413 (* 1 = 1.4413 loss)
I0416 12:56:58.940171   977 solver.cpp:542] Iteration 5000, lr = 0.1
I0416 12:57:12.393257   977 solver.cpp:221] Iteration 5020, loss = 1.12668
I0416 12:57:12.393285   977 solver.cpp:236]     Train net output #0: loss = 1.04254 (* 1 = 1.04254 loss)
I0416 12:57:12.393288   977 solver.cpp:542] Iteration 5020, lr = 0.1
I0416 12:57:25.852037   977 solver.cpp:221] Iteration 5040, loss = 1.21397
I0416 12:57:25.852066   977 solver.cpp:236]     Train net output #0: loss = 0.998092 (* 1 = 0.998092 loss)
I0416 12:57:25.852071   977 solver.cpp:542] Iteration 5040, lr = 0.1
I0416 12:57:39.309312   977 solver.cpp:221] Iteration 5060, loss = 1.14095
I0416 12:57:39.309339   977 solver.cpp:236]     Train net output #0: loss = 1.12626 (* 1 = 1.12626 loss)
I0416 12:57:39.309343   977 solver.cpp:542] Iteration 5060, lr = 0.1
I0416 12:57:52.781060   977 solver.cpp:221] Iteration 5080, loss = 1.13385
I0416 12:57:52.781087   977 solver.cpp:236]     Train net output #0: loss = 1.12874 (* 1 = 1.12874 loss)
I0416 12:57:52.781091   977 solver.cpp:542] Iteration 5080, lr = 0.1
I0416 12:58:06.255270   977 solver.cpp:221] Iteration 5100, loss = 1.26188
I0416 12:58:06.255295   977 solver.cpp:236]     Train net output #0: loss = 0.722767 (* 1 = 0.722767 loss)
I0416 12:58:06.255300   977 solver.cpp:542] Iteration 5100, lr = 0.1
I0416 12:58:19.728440   977 solver.cpp:221] Iteration 5120, loss = 1.17619
I0416 12:58:19.728467   977 solver.cpp:236]     Train net output #0: loss = 1.03512 (* 1 = 1.03512 loss)
I0416 12:58:19.728471   977 solver.cpp:542] Iteration 5120, lr = 0.1
I0416 12:58:33.173250   977 solver.cpp:221] Iteration 5140, loss = 1.19634
I0416 12:58:33.173275   977 solver.cpp:236]     Train net output #0: loss = 1.17619 (* 1 = 1.17619 loss)
I0416 12:58:33.173280   977 solver.cpp:542] Iteration 5140, lr = 0.1
I0416 12:58:46.628983   977 solver.cpp:221] Iteration 5160, loss = 1.15216
I0416 12:58:46.629009   977 solver.cpp:236]     Train net output #0: loss = 0.986568 (* 1 = 0.986568 loss)
I0416 12:58:46.629014   977 solver.cpp:542] Iteration 5160, lr = 0.1
I0416 12:59:00.073344   977 solver.cpp:221] Iteration 5180, loss = 1.22293
I0416 12:59:00.073370   977 solver.cpp:236]     Train net output #0: loss = 1.3293 (* 1 = 1.3293 loss)
I0416 12:59:00.073374   977 solver.cpp:542] Iteration 5180, lr = 0.1
I0416 12:59:12.863216   977 solver.cpp:316] Iteration 5200, Testing net (#0)
I0416 12:59:24.362493   977 solver.cpp:373]     Test net output #0: accuracy = 0.658936
I0416 12:59:24.362514   977 solver.cpp:373]     Test net output #1: loss = 1.33793 (* 1 = 1.33793 loss)
I0416 12:59:25.029276   977 solver.cpp:221] Iteration 5200, loss = 1.18141
I0416 12:59:25.029302   977 solver.cpp:236]     Train net output #0: loss = 1.42822 (* 1 = 1.42822 loss)
I0416 12:59:25.029307   977 solver.cpp:542] Iteration 5200, lr = 0.1
I0416 12:59:38.483911   977 solver.cpp:221] Iteration 5220, loss = 1.1523
I0416 12:59:38.483937   977 solver.cpp:236]     Train net output #0: loss = 1.14944 (* 1 = 1.14944 loss)
I0416 12:59:38.483942   977 solver.cpp:542] Iteration 5220, lr = 0.1
I0416 12:59:51.934818   977 solver.cpp:221] Iteration 5240, loss = 1.1491
I0416 12:59:51.934844   977 solver.cpp:236]     Train net output #0: loss = 1.31472 (* 1 = 1.31472 loss)
I0416 12:59:51.934850   977 solver.cpp:542] Iteration 5240, lr = 0.1
I0416 13:00:05.384546   977 solver.cpp:221] Iteration 5260, loss = 1.17114
I0416 13:00:05.384572   977 solver.cpp:236]     Train net output #0: loss = 1.04351 (* 1 = 1.04351 loss)
I0416 13:00:05.384577   977 solver.cpp:542] Iteration 5260, lr = 0.1
I0416 13:00:18.860563   977 solver.cpp:221] Iteration 5280, loss = 1.18416
I0416 13:00:18.860589   977 solver.cpp:236]     Train net output #0: loss = 1.15231 (* 1 = 1.15231 loss)
I0416 13:00:18.860594   977 solver.cpp:542] Iteration 5280, lr = 0.1
I0416 13:00:32.313701   977 solver.cpp:221] Iteration 5300, loss = 1.24891
I0416 13:00:32.313729   977 solver.cpp:236]     Train net output #0: loss = 1.43271 (* 1 = 1.43271 loss)
I0416 13:00:32.313732   977 solver.cpp:542] Iteration 5300, lr = 0.1
I0416 13:00:45.789227   977 solver.cpp:221] Iteration 5320, loss = 1.2247
I0416 13:00:45.789252   977 solver.cpp:236]     Train net output #0: loss = 1.35261 (* 1 = 1.35261 loss)
I0416 13:00:45.789257   977 solver.cpp:542] Iteration 5320, lr = 0.1
I0416 13:00:59.248499   977 solver.cpp:221] Iteration 5340, loss = 1.24851
I0416 13:00:59.248527   977 solver.cpp:236]     Train net output #0: loss = 1.26782 (* 1 = 1.26782 loss)
I0416 13:00:59.248531   977 solver.cpp:542] Iteration 5340, lr = 0.1
I0416 13:01:12.703480   977 solver.cpp:221] Iteration 5360, loss = 1.20783
I0416 13:01:12.703506   977 solver.cpp:236]     Train net output #0: loss = 1.3086 (* 1 = 1.3086 loss)
I0416 13:01:12.703511   977 solver.cpp:542] Iteration 5360, lr = 0.1
I0416 13:01:26.181617   977 solver.cpp:221] Iteration 5380, loss = 1.12086
I0416 13:01:26.181643   977 solver.cpp:236]     Train net output #0: loss = 1.21278 (* 1 = 1.21278 loss)
I0416 13:01:26.181648   977 solver.cpp:542] Iteration 5380, lr = 0.1
I0416 13:01:39.005007   977 solver.cpp:316] Iteration 5400, Testing net (#0)
I0416 13:01:50.494230   977 solver.cpp:373]     Test net output #0: accuracy = 0.712928
I0416 13:01:50.494252   977 solver.cpp:373]     Test net output #1: loss = 1.09063 (* 1 = 1.09063 loss)
I0416 13:01:51.160282   977 solver.cpp:221] Iteration 5400, loss = 1.10975
I0416 13:01:51.160310   977 solver.cpp:236]     Train net output #0: loss = 1.24678 (* 1 = 1.24678 loss)
I0416 13:01:51.160315   977 solver.cpp:542] Iteration 5400, lr = 0.1
I0416 13:02:04.611044   977 solver.cpp:221] Iteration 5420, loss = 1.18217
I0416 13:02:04.611071   977 solver.cpp:236]     Train net output #0: loss = 0.74301 (* 1 = 0.74301 loss)
I0416 13:02:04.611076   977 solver.cpp:542] Iteration 5420, lr = 0.1
I0416 13:02:18.064327   977 solver.cpp:221] Iteration 5440, loss = 1.13959
I0416 13:02:18.064353   977 solver.cpp:236]     Train net output #0: loss = 0.92721 (* 1 = 0.92721 loss)
I0416 13:02:18.064357   977 solver.cpp:542] Iteration 5440, lr = 0.1
I0416 13:02:31.516230   977 solver.cpp:221] Iteration 5460, loss = 1.201
I0416 13:02:31.516257   977 solver.cpp:236]     Train net output #0: loss = 1.3158 (* 1 = 1.3158 loss)
I0416 13:02:31.516261   977 solver.cpp:542] Iteration 5460, lr = 0.1
I0416 13:02:44.985885   977 solver.cpp:221] Iteration 5480, loss = 1.0779
I0416 13:02:44.985913   977 solver.cpp:236]     Train net output #0: loss = 1.0832 (* 1 = 1.0832 loss)
I0416 13:02:44.985916   977 solver.cpp:542] Iteration 5480, lr = 0.1
I0416 13:02:58.435225   977 solver.cpp:221] Iteration 5500, loss = 1.11251
I0416 13:02:58.435251   977 solver.cpp:236]     Train net output #0: loss = 1.15914 (* 1 = 1.15914 loss)
I0416 13:02:58.435256   977 solver.cpp:542] Iteration 5500, lr = 0.1
I0416 13:03:11.901445   977 solver.cpp:221] Iteration 5520, loss = 1.13146
I0416 13:03:11.901473   977 solver.cpp:236]     Train net output #0: loss = 1.11352 (* 1 = 1.11352 loss)
I0416 13:03:11.901478   977 solver.cpp:542] Iteration 5520, lr = 0.1
I0416 13:03:25.359519   977 solver.cpp:221] Iteration 5540, loss = 1.11042
I0416 13:03:25.359545   977 solver.cpp:236]     Train net output #0: loss = 1.21156 (* 1 = 1.21156 loss)
I0416 13:03:25.359550   977 solver.cpp:542] Iteration 5540, lr = 0.1
I0416 13:03:38.806607   977 solver.cpp:221] Iteration 5560, loss = 1.18803
I0416 13:03:38.806634   977 solver.cpp:236]     Train net output #0: loss = 1.25756 (* 1 = 1.25756 loss)
I0416 13:03:38.806638   977 solver.cpp:542] Iteration 5560, lr = 0.1
I0416 13:03:52.249897   977 solver.cpp:221] Iteration 5580, loss = 1.14839
I0416 13:03:52.249922   977 solver.cpp:236]     Train net output #0: loss = 1.30008 (* 1 = 1.30008 loss)
I0416 13:03:52.249927   977 solver.cpp:542] Iteration 5580, lr = 0.1
I0416 13:04:05.051228   977 solver.cpp:316] Iteration 5600, Testing net (#0)
I0416 13:04:16.540825   977 solver.cpp:373]     Test net output #0: accuracy = 0.821673
I0416 13:04:16.540846   977 solver.cpp:373]     Test net output #1: loss = 0.639997 (* 1 = 0.639997 loss)
I0416 13:04:17.208529   977 solver.cpp:221] Iteration 5600, loss = 1.15636
I0416 13:04:17.208555   977 solver.cpp:236]     Train net output #0: loss = 1.10834 (* 1 = 1.10834 loss)
I0416 13:04:17.208560   977 solver.cpp:542] Iteration 5600, lr = 0.1
I0416 13:04:30.677966   977 solver.cpp:221] Iteration 5620, loss = 1.12949
I0416 13:04:30.677994   977 solver.cpp:236]     Train net output #0: loss = 1.10716 (* 1 = 1.10716 loss)
I0416 13:04:30.677999   977 solver.cpp:542] Iteration 5620, lr = 0.1
I0416 13:04:44.149699   977 solver.cpp:221] Iteration 5640, loss = 1.14817
I0416 13:04:44.149726   977 solver.cpp:236]     Train net output #0: loss = 0.998086 (* 1 = 0.998086 loss)
I0416 13:04:44.149731   977 solver.cpp:542] Iteration 5640, lr = 0.1
I0416 13:04:57.635185   977 solver.cpp:221] Iteration 5660, loss = 1.25745
I0416 13:04:57.635212   977 solver.cpp:236]     Train net output #0: loss = 1.20253 (* 1 = 1.20253 loss)
I0416 13:04:57.635217   977 solver.cpp:542] Iteration 5660, lr = 0.1
I0416 13:05:11.085988   977 solver.cpp:221] Iteration 5680, loss = 1.17262
I0416 13:05:11.086014   977 solver.cpp:236]     Train net output #0: loss = 0.91779 (* 1 = 0.91779 loss)
I0416 13:05:11.086019   977 solver.cpp:542] Iteration 5680, lr = 0.1
I0416 13:05:24.550873   977 solver.cpp:221] Iteration 5700, loss = 1.13078
I0416 13:05:24.550899   977 solver.cpp:236]     Train net output #0: loss = 0.987569 (* 1 = 0.987569 loss)
I0416 13:05:24.550904   977 solver.cpp:542] Iteration 5700, lr = 0.1
I0416 13:05:38.034281   977 solver.cpp:221] Iteration 5720, loss = 1.15853
I0416 13:05:38.034308   977 solver.cpp:236]     Train net output #0: loss = 0.781561 (* 1 = 0.781561 loss)
I0416 13:05:38.034313   977 solver.cpp:542] Iteration 5720, lr = 0.1
I0416 13:05:51.518527   977 solver.cpp:221] Iteration 5740, loss = 1.19353
I0416 13:05:51.518554   977 solver.cpp:236]     Train net output #0: loss = 1.06136 (* 1 = 1.06136 loss)
I0416 13:05:51.518558   977 solver.cpp:542] Iteration 5740, lr = 0.1
I0416 13:06:05.029597   977 solver.cpp:221] Iteration 5760, loss = 1.17558
I0416 13:06:05.029623   977 solver.cpp:236]     Train net output #0: loss = 0.669822 (* 1 = 0.669822 loss)
I0416 13:06:05.029628   977 solver.cpp:542] Iteration 5760, lr = 0.1
I0416 13:06:18.532294   977 solver.cpp:221] Iteration 5780, loss = 1.15865
I0416 13:06:18.532320   977 solver.cpp:236]     Train net output #0: loss = 1.1077 (* 1 = 1.1077 loss)
I0416 13:06:18.532325   977 solver.cpp:542] Iteration 5780, lr = 0.1
I0416 13:06:31.367311   977 solver.cpp:316] Iteration 5800, Testing net (#0)
I0416 13:06:42.861575   977 solver.cpp:373]     Test net output #0: accuracy = 0.818061
I0416 13:06:42.861596   977 solver.cpp:373]     Test net output #1: loss = 0.663776 (* 1 = 0.663776 loss)
I0416 13:06:43.526456   977 solver.cpp:221] Iteration 5800, loss = 1.15093
I0416 13:06:43.526482   977 solver.cpp:236]     Train net output #0: loss = 1.0545 (* 1 = 1.0545 loss)
I0416 13:06:43.526487   977 solver.cpp:542] Iteration 5800, lr = 0.1
I0416 13:06:57.009165   977 solver.cpp:221] Iteration 5820, loss = 1.08714
I0416 13:06:57.009191   977 solver.cpp:236]     Train net output #0: loss = 1.05882 (* 1 = 1.05882 loss)
I0416 13:06:57.009194   977 solver.cpp:542] Iteration 5820, lr = 0.1
I0416 13:07:10.488742   977 solver.cpp:221] Iteration 5840, loss = 1.14552
I0416 13:07:10.488770   977 solver.cpp:236]     Train net output #0: loss = 1.06469 (* 1 = 1.06469 loss)
I0416 13:07:10.488773   977 solver.cpp:542] Iteration 5840, lr = 0.1
I0416 13:07:23.990188   977 solver.cpp:221] Iteration 5860, loss = 1.14828
I0416 13:07:23.990216   977 solver.cpp:236]     Train net output #0: loss = 1.2 (* 1 = 1.2 loss)
I0416 13:07:23.990219   977 solver.cpp:542] Iteration 5860, lr = 0.1
I0416 13:07:37.490890   977 solver.cpp:221] Iteration 5880, loss = 1.19446
I0416 13:07:37.490917   977 solver.cpp:236]     Train net output #0: loss = 0.929061 (* 1 = 0.929061 loss)
I0416 13:07:37.490921   977 solver.cpp:542] Iteration 5880, lr = 0.1
I0416 13:07:50.981359   977 solver.cpp:221] Iteration 5900, loss = 1.15626
I0416 13:07:50.981384   977 solver.cpp:236]     Train net output #0: loss = 1.28513 (* 1 = 1.28513 loss)
I0416 13:07:50.981389   977 solver.cpp:542] Iteration 5900, lr = 0.1
I0416 13:08:04.459698   977 solver.cpp:221] Iteration 5920, loss = 1.13603
I0416 13:08:04.459724   977 solver.cpp:236]     Train net output #0: loss = 0.862703 (* 1 = 0.862703 loss)
I0416 13:08:04.459728   977 solver.cpp:542] Iteration 5920, lr = 0.1
I0416 13:08:17.924562   977 solver.cpp:221] Iteration 5940, loss = 1.13893
I0416 13:08:17.924589   977 solver.cpp:236]     Train net output #0: loss = 1.15302 (* 1 = 1.15302 loss)
I0416 13:08:17.924595   977 solver.cpp:542] Iteration 5940, lr = 0.1
I0416 13:08:31.378290   977 solver.cpp:221] Iteration 5960, loss = 1.12457
I0416 13:08:31.378317   977 solver.cpp:236]     Train net output #0: loss = 1.10231 (* 1 = 1.10231 loss)
I0416 13:08:31.378322   977 solver.cpp:542] Iteration 5960, lr = 0.1
I0416 13:08:44.875180   977 solver.cpp:221] Iteration 5980, loss = 1.09519
I0416 13:08:44.875206   977 solver.cpp:236]     Train net output #0: loss = 1.06687 (* 1 = 1.06687 loss)
I0416 13:08:44.875211   977 solver.cpp:542] Iteration 5980, lr = 0.1
I0416 13:08:57.705137   977 solver.cpp:316] Iteration 6000, Testing net (#0)
I0416 13:09:09.211225   977 solver.cpp:373]     Test net output #0: accuracy = 0.581939
I0416 13:09:09.211246   977 solver.cpp:373]     Test net output #1: loss = 1.86242 (* 1 = 1.86242 loss)
I0416 13:09:09.877683   977 solver.cpp:221] Iteration 6000, loss = 1.08995
I0416 13:09:09.877710   977 solver.cpp:236]     Train net output #0: loss = 1.01766 (* 1 = 1.01766 loss)
I0416 13:09:09.877715   977 solver.cpp:542] Iteration 6000, lr = 0.1
I0416 13:09:23.337206   977 solver.cpp:221] Iteration 6020, loss = 1.11297
I0416 13:09:23.337234   977 solver.cpp:236]     Train net output #0: loss = 1.30601 (* 1 = 1.30601 loss)
I0416 13:09:23.337237   977 solver.cpp:542] Iteration 6020, lr = 0.1
I0416 13:09:36.816486   977 solver.cpp:221] Iteration 6040, loss = 1.07068
I0416 13:09:36.816514   977 solver.cpp:236]     Train net output #0: loss = 1.07656 (* 1 = 1.07656 loss)
I0416 13:09:36.816517   977 solver.cpp:542] Iteration 6040, lr = 0.1
I0416 13:09:50.334091   977 solver.cpp:221] Iteration 6060, loss = 1.12678
I0416 13:09:50.334118   977 solver.cpp:236]     Train net output #0: loss = 1.16982 (* 1 = 1.16982 loss)
I0416 13:09:50.334122   977 solver.cpp:542] Iteration 6060, lr = 0.1
I0416 13:10:03.825587   977 solver.cpp:221] Iteration 6080, loss = 1.09896
I0416 13:10:03.825614   977 solver.cpp:236]     Train net output #0: loss = 1.28154 (* 1 = 1.28154 loss)
I0416 13:10:03.825619   977 solver.cpp:542] Iteration 6080, lr = 0.1
I0416 13:10:17.300938   977 solver.cpp:221] Iteration 6100, loss = 1.10534
I0416 13:10:17.300966   977 solver.cpp:236]     Train net output #0: loss = 1.13613 (* 1 = 1.13613 loss)
I0416 13:10:17.300969   977 solver.cpp:542] Iteration 6100, lr = 0.1
I0416 13:10:30.784145   977 solver.cpp:221] Iteration 6120, loss = 1.11134
I0416 13:10:30.784173   977 solver.cpp:236]     Train net output #0: loss = 1.15305 (* 1 = 1.15305 loss)
I0416 13:10:30.784176   977 solver.cpp:542] Iteration 6120, lr = 0.1
I0416 13:10:44.267774   977 solver.cpp:221] Iteration 6140, loss = 1.08004
I0416 13:10:44.267802   977 solver.cpp:236]     Train net output #0: loss = 1.12869 (* 1 = 1.12869 loss)
I0416 13:10:44.267807   977 solver.cpp:542] Iteration 6140, lr = 0.1
I0416 13:10:57.757740   977 solver.cpp:221] Iteration 6160, loss = 1.11728
I0416 13:10:57.757766   977 solver.cpp:236]     Train net output #0: loss = 1.54954 (* 1 = 1.54954 loss)
I0416 13:10:57.757771   977 solver.cpp:542] Iteration 6160, lr = 0.1
I0416 13:11:11.264189   977 solver.cpp:221] Iteration 6180, loss = 1.1353
I0416 13:11:11.264214   977 solver.cpp:236]     Train net output #0: loss = 1.0855 (* 1 = 1.0855 loss)
I0416 13:11:11.264219   977 solver.cpp:542] Iteration 6180, lr = 0.1
I0416 13:11:24.081857   977 solver.cpp:316] Iteration 6200, Testing net (#0)
I0416 13:11:35.577795   977 solver.cpp:373]     Test net output #0: accuracy = 0.473574
I0416 13:11:35.577816   977 solver.cpp:373]     Test net output #1: loss = 2.88569 (* 1 = 2.88569 loss)
I0416 13:11:36.243566   977 solver.cpp:221] Iteration 6200, loss = 1.21965
I0416 13:11:36.243593   977 solver.cpp:236]     Train net output #0: loss = 1.13986 (* 1 = 1.13986 loss)
I0416 13:11:36.243598   977 solver.cpp:542] Iteration 6200, lr = 0.1
I0416 13:11:49.743469   977 solver.cpp:221] Iteration 6220, loss = 1.12652
I0416 13:11:49.743496   977 solver.cpp:236]     Train net output #0: loss = 1.07011 (* 1 = 1.07011 loss)
I0416 13:11:49.743501   977 solver.cpp:542] Iteration 6220, lr = 0.1
I0416 13:12:03.208320   977 solver.cpp:221] Iteration 6240, loss = 1.1294
I0416 13:12:03.208348   977 solver.cpp:236]     Train net output #0: loss = 1.12982 (* 1 = 1.12982 loss)
I0416 13:12:03.208353   977 solver.cpp:542] Iteration 6240, lr = 0.1
I0416 13:12:16.669574   977 solver.cpp:221] Iteration 6260, loss = 1.12873
I0416 13:12:16.669600   977 solver.cpp:236]     Train net output #0: loss = 1.17893 (* 1 = 1.17893 loss)
I0416 13:12:16.669603   977 solver.cpp:542] Iteration 6260, lr = 0.1
I0416 13:12:30.129350   977 solver.cpp:221] Iteration 6280, loss = 1.0815
I0416 13:12:30.129377   977 solver.cpp:236]     Train net output #0: loss = 1.07697 (* 1 = 1.07697 loss)
I0416 13:12:30.129382   977 solver.cpp:542] Iteration 6280, lr = 0.1
I0416 13:12:43.601541   977 solver.cpp:221] Iteration 6300, loss = 1.11697
I0416 13:12:43.601568   977 solver.cpp:236]     Train net output #0: loss = 1.24516 (* 1 = 1.24516 loss)
I0416 13:12:43.601573   977 solver.cpp:542] Iteration 6300, lr = 0.1
I0416 13:12:57.053169   977 solver.cpp:221] Iteration 6320, loss = 1.10038
I0416 13:12:57.053195   977 solver.cpp:236]     Train net output #0: loss = 1.17639 (* 1 = 1.17639 loss)
I0416 13:12:57.053200   977 solver.cpp:542] Iteration 6320, lr = 0.1
I0416 13:13:10.506386   977 solver.cpp:221] Iteration 6340, loss = 1.09583
I0416 13:13:10.506413   977 solver.cpp:236]     Train net output #0: loss = 0.989187 (* 1 = 0.989187 loss)
I0416 13:13:10.506417   977 solver.cpp:542] Iteration 6340, lr = 0.1
I0416 13:13:23.955577   977 solver.cpp:221] Iteration 6360, loss = 1.14567
I0416 13:13:23.955603   977 solver.cpp:236]     Train net output #0: loss = 1.36693 (* 1 = 1.36693 loss)
I0416 13:13:23.955608   977 solver.cpp:542] Iteration 6360, lr = 0.1
I0416 13:13:37.412261   977 solver.cpp:221] Iteration 6380, loss = 1.12764
I0416 13:13:37.412288   977 solver.cpp:236]     Train net output #0: loss = 1.21734 (* 1 = 1.21734 loss)
I0416 13:13:37.412293   977 solver.cpp:542] Iteration 6380, lr = 0.1
I0416 13:13:50.229017   977 solver.cpp:316] Iteration 6400, Testing net (#0)
I0416 13:14:01.725368   977 solver.cpp:373]     Test net output #0: accuracy = 0.576046
I0416 13:14:01.725388   977 solver.cpp:373]     Test net output #1: loss = 2.04569 (* 1 = 2.04569 loss)
I0416 13:14:02.391371   977 solver.cpp:221] Iteration 6400, loss = 1.16439
I0416 13:14:02.391397   977 solver.cpp:236]     Train net output #0: loss = 1.29473 (* 1 = 1.29473 loss)
I0416 13:14:02.391402   977 solver.cpp:542] Iteration 6400, lr = 0.1
I0416 13:14:15.849953   977 solver.cpp:221] Iteration 6420, loss = 1.10822
I0416 13:14:15.849982   977 solver.cpp:236]     Train net output #0: loss = 1.16018 (* 1 = 1.16018 loss)
I0416 13:14:15.849985   977 solver.cpp:542] Iteration 6420, lr = 0.1
I0416 13:14:29.321934   977 solver.cpp:221] Iteration 6440, loss = 1.08301
I0416 13:14:29.321961   977 solver.cpp:236]     Train net output #0: loss = 1.08047 (* 1 = 1.08047 loss)
I0416 13:14:29.321965   977 solver.cpp:542] Iteration 6440, lr = 0.1
I0416 13:14:42.787732   977 solver.cpp:221] Iteration 6460, loss = 1.04636
I0416 13:14:42.787760   977 solver.cpp:236]     Train net output #0: loss = 1.06822 (* 1 = 1.06822 loss)
I0416 13:14:42.787765   977 solver.cpp:542] Iteration 6460, lr = 0.1
I0416 13:14:56.272125   977 solver.cpp:221] Iteration 6480, loss = 1.08803
I0416 13:14:56.272151   977 solver.cpp:236]     Train net output #0: loss = 1.01297 (* 1 = 1.01297 loss)
I0416 13:14:56.272156   977 solver.cpp:542] Iteration 6480, lr = 0.1
I0416 13:15:09.802975   977 solver.cpp:221] Iteration 6500, loss = 1.05439
I0416 13:15:09.803001   977 solver.cpp:236]     Train net output #0: loss = 0.844359 (* 1 = 0.844359 loss)
I0416 13:15:09.803006   977 solver.cpp:542] Iteration 6500, lr = 0.1
I0416 13:15:23.290771   977 solver.cpp:221] Iteration 6520, loss = 1.05362
I0416 13:15:23.290797   977 solver.cpp:236]     Train net output #0: loss = 1.17955 (* 1 = 1.17955 loss)
I0416 13:15:23.290803   977 solver.cpp:542] Iteration 6520, lr = 0.1
I0416 13:15:36.787792   977 solver.cpp:221] Iteration 6540, loss = 1.05641
I0416 13:15:36.787820   977 solver.cpp:236]     Train net output #0: loss = 1.08843 (* 1 = 1.08843 loss)
I0416 13:15:36.787827   977 solver.cpp:542] Iteration 6540, lr = 0.1
I0416 13:15:50.237275   977 solver.cpp:221] Iteration 6560, loss = 1.04464
I0416 13:15:50.237303   977 solver.cpp:236]     Train net output #0: loss = 1.17669 (* 1 = 1.17669 loss)
I0416 13:15:50.237308   977 solver.cpp:542] Iteration 6560, lr = 0.1
I0416 13:16:03.705446   977 solver.cpp:221] Iteration 6580, loss = 1.14828
I0416 13:16:03.705472   977 solver.cpp:236]     Train net output #0: loss = 1.5316 (* 1 = 1.5316 loss)
I0416 13:16:03.705477   977 solver.cpp:542] Iteration 6580, lr = 0.1
I0416 13:16:16.524726   977 solver.cpp:316] Iteration 6600, Testing net (#0)
I0416 13:16:28.021286   977 solver.cpp:373]     Test net output #0: accuracy = 0.842586
I0416 13:16:28.021307   977 solver.cpp:373]     Test net output #1: loss = 0.601934 (* 1 = 0.601934 loss)
I0416 13:16:28.686908   977 solver.cpp:221] Iteration 6600, loss = 1.12825
I0416 13:16:28.686934   977 solver.cpp:236]     Train net output #0: loss = 1.04982 (* 1 = 1.04982 loss)
I0416 13:16:28.686939   977 solver.cpp:542] Iteration 6600, lr = 0.1
I0416 13:16:42.174404   977 solver.cpp:221] Iteration 6620, loss = 1.14791
I0416 13:16:42.174432   977 solver.cpp:236]     Train net output #0: loss = 0.971274 (* 1 = 0.971274 loss)
I0416 13:16:42.174437   977 solver.cpp:542] Iteration 6620, lr = 0.1
I0416 13:16:55.642432   977 solver.cpp:221] Iteration 6640, loss = 1.11931
I0416 13:16:55.642459   977 solver.cpp:236]     Train net output #0: loss = 0.780157 (* 1 = 0.780157 loss)
I0416 13:16:55.642464   977 solver.cpp:542] Iteration 6640, lr = 0.1
I0416 13:17:09.123985   977 solver.cpp:221] Iteration 6660, loss = 1.09029
I0416 13:17:09.124011   977 solver.cpp:236]     Train net output #0: loss = 0.938695 (* 1 = 0.938695 loss)
I0416 13:17:09.124017   977 solver.cpp:542] Iteration 6660, lr = 0.1
I0416 13:17:22.601932   977 solver.cpp:221] Iteration 6680, loss = 1.1093
I0416 13:17:22.601959   977 solver.cpp:236]     Train net output #0: loss = 1.50378 (* 1 = 1.50378 loss)
I0416 13:17:22.601963   977 solver.cpp:542] Iteration 6680, lr = 0.1
I0416 13:17:36.076153   977 solver.cpp:221] Iteration 6700, loss = 0.983265
I0416 13:17:36.076180   977 solver.cpp:236]     Train net output #0: loss = 1.03951 (* 1 = 1.03951 loss)
I0416 13:17:36.076185   977 solver.cpp:542] Iteration 6700, lr = 0.1
I0416 13:17:49.542358   977 solver.cpp:221] Iteration 6720, loss = 1.11055
I0416 13:17:49.542384   977 solver.cpp:236]     Train net output #0: loss = 1.15787 (* 1 = 1.15787 loss)
I0416 13:17:49.542389   977 solver.cpp:542] Iteration 6720, lr = 0.1
I0416 13:18:02.998124   977 solver.cpp:221] Iteration 6740, loss = 1.06115
I0416 13:18:02.998152   977 solver.cpp:236]     Train net output #0: loss = 0.885508 (* 1 = 0.885508 loss)
I0416 13:18:02.998157   977 solver.cpp:542] Iteration 6740, lr = 0.1
I0416 13:18:16.471179   977 solver.cpp:221] Iteration 6760, loss = 1.06254
I0416 13:18:16.471205   977 solver.cpp:236]     Train net output #0: loss = 1.29187 (* 1 = 1.29187 loss)
I0416 13:18:16.471210   977 solver.cpp:542] Iteration 6760, lr = 0.1
I0416 13:18:29.980332   977 solver.cpp:221] Iteration 6780, loss = 1.1028
I0416 13:18:29.980358   977 solver.cpp:236]     Train net output #0: loss = 1.19222 (* 1 = 1.19222 loss)
I0416 13:18:29.980363   977 solver.cpp:542] Iteration 6780, lr = 0.1
I0416 13:18:42.817571   977 solver.cpp:316] Iteration 6800, Testing net (#0)
I0416 13:18:54.327522   977 solver.cpp:373]     Test net output #0: accuracy = 0.751521
I0416 13:18:54.327545   977 solver.cpp:373]     Test net output #1: loss = 0.973258 (* 1 = 0.973258 loss)
I0416 13:18:54.994062   977 solver.cpp:221] Iteration 6800, loss = 1.15082
I0416 13:18:54.994089   977 solver.cpp:236]     Train net output #0: loss = 1.14518 (* 1 = 1.14518 loss)
I0416 13:18:54.994094   977 solver.cpp:542] Iteration 6800, lr = 0.1
I0416 13:19:08.478343   977 solver.cpp:221] Iteration 6820, loss = 1.0829
I0416 13:19:08.478370   977 solver.cpp:236]     Train net output #0: loss = 1.2152 (* 1 = 1.2152 loss)
I0416 13:19:08.478374   977 solver.cpp:542] Iteration 6820, lr = 0.1
I0416 13:19:21.940668   977 solver.cpp:221] Iteration 6840, loss = 1.04926
I0416 13:19:21.940696   977 solver.cpp:236]     Train net output #0: loss = 1.01772 (* 1 = 1.01772 loss)
I0416 13:19:21.940701   977 solver.cpp:542] Iteration 6840, lr = 0.1
I0416 13:19:35.392848   977 solver.cpp:221] Iteration 6860, loss = 1.01405
I0416 13:19:35.392874   977 solver.cpp:236]     Train net output #0: loss = 1.3651 (* 1 = 1.3651 loss)
I0416 13:19:35.392879   977 solver.cpp:542] Iteration 6860, lr = 0.1
I0416 13:19:48.842180   977 solver.cpp:221] Iteration 6880, loss = 1.04884
I0416 13:19:48.842207   977 solver.cpp:236]     Train net output #0: loss = 0.9332 (* 1 = 0.9332 loss)
I0416 13:19:48.842212   977 solver.cpp:542] Iteration 6880, lr = 0.1
I0416 13:20:02.308230   977 solver.cpp:221] Iteration 6900, loss = 1.04183
I0416 13:20:02.308257   977 solver.cpp:236]     Train net output #0: loss = 1.18743 (* 1 = 1.18743 loss)
I0416 13:20:02.308262   977 solver.cpp:542] Iteration 6900, lr = 0.1
I0416 13:20:15.792058   977 solver.cpp:221] Iteration 6920, loss = 1.06032
I0416 13:20:15.792084   977 solver.cpp:236]     Train net output #0: loss = 1.12282 (* 1 = 1.12282 loss)
I0416 13:20:15.792089   977 solver.cpp:542] Iteration 6920, lr = 0.1
I0416 13:20:29.276895   977 solver.cpp:221] Iteration 6940, loss = 1.05549
I0416 13:20:29.276921   977 solver.cpp:236]     Train net output #0: loss = 1.13544 (* 1 = 1.13544 loss)
I0416 13:20:29.276926   977 solver.cpp:542] Iteration 6940, lr = 0.1
I0416 13:20:42.749982   977 solver.cpp:221] Iteration 6960, loss = 1.01904
I0416 13:20:42.750010   977 solver.cpp:236]     Train net output #0: loss = 0.800697 (* 1 = 0.800697 loss)
I0416 13:20:42.750016   977 solver.cpp:542] Iteration 6960, lr = 0.1
I0416 13:20:56.241818   977 solver.cpp:221] Iteration 6980, loss = 1.09532
I0416 13:20:56.241844   977 solver.cpp:236]     Train net output #0: loss = 1.02758 (* 1 = 1.02758 loss)
I0416 13:20:56.241849   977 solver.cpp:542] Iteration 6980, lr = 0.1
I0416 13:21:09.090620   977 solver.cpp:316] Iteration 7000, Testing net (#0)
I0416 13:21:20.591755   977 solver.cpp:373]     Test net output #0: accuracy = 0.779658
I0416 13:21:20.591776   977 solver.cpp:373]     Test net output #1: loss = 0.844215 (* 1 = 0.844215 loss)
I0416 13:21:21.258713   977 solver.cpp:221] Iteration 7000, loss = 1.05353
I0416 13:21:21.258739   977 solver.cpp:236]     Train net output #0: loss = 1.13383 (* 1 = 1.13383 loss)
I0416 13:21:21.258744   977 solver.cpp:542] Iteration 7000, lr = 0.1
I0416 13:21:34.729606   977 solver.cpp:221] Iteration 7020, loss = 1.1044
I0416 13:21:34.729635   977 solver.cpp:236]     Train net output #0: loss = 1.12061 (* 1 = 1.12061 loss)
I0416 13:21:34.729640   977 solver.cpp:542] Iteration 7020, lr = 0.1
I0416 13:21:48.199417   977 solver.cpp:221] Iteration 7040, loss = 1.06792
I0416 13:21:48.199445   977 solver.cpp:236]     Train net output #0: loss = 0.928008 (* 1 = 0.928008 loss)
I0416 13:21:48.199450   977 solver.cpp:542] Iteration 7040, lr = 0.1
I0416 13:22:01.663820   977 solver.cpp:221] Iteration 7060, loss = 0.975503
I0416 13:22:01.663847   977 solver.cpp:236]     Train net output #0: loss = 0.767356 (* 1 = 0.767356 loss)
I0416 13:22:01.663852   977 solver.cpp:542] Iteration 7060, lr = 0.1
I0416 13:22:15.138278   977 solver.cpp:221] Iteration 7080, loss = 1.05004
I0416 13:22:15.138304   977 solver.cpp:236]     Train net output #0: loss = 1.11598 (* 1 = 1.11598 loss)
I0416 13:22:15.138309   977 solver.cpp:542] Iteration 7080, lr = 0.1
I0416 13:22:28.643188   977 solver.cpp:221] Iteration 7100, loss = 1.00336
I0416 13:22:28.643215   977 solver.cpp:236]     Train net output #0: loss = 1.2007 (* 1 = 1.2007 loss)
I0416 13:22:28.643220   977 solver.cpp:542] Iteration 7100, lr = 0.1
I0416 13:22:42.144925   977 solver.cpp:221] Iteration 7120, loss = 1.0722
I0416 13:22:42.144951   977 solver.cpp:236]     Train net output #0: loss = 1.4422 (* 1 = 1.4422 loss)
I0416 13:22:42.144956   977 solver.cpp:542] Iteration 7120, lr = 0.1
I0416 13:22:55.630543   977 solver.cpp:221] Iteration 7140, loss = 1.0349
I0416 13:22:55.630570   977 solver.cpp:236]     Train net output #0: loss = 0.986472 (* 1 = 0.986472 loss)
I0416 13:22:55.630575   977 solver.cpp:542] Iteration 7140, lr = 0.1
I0416 13:23:09.126194   977 solver.cpp:221] Iteration 7160, loss = 1.00683
I0416 13:23:09.126221   977 solver.cpp:236]     Train net output #0: loss = 1.02382 (* 1 = 1.02382 loss)
I0416 13:23:09.126225   977 solver.cpp:542] Iteration 7160, lr = 0.1
I0416 13:23:22.594787   977 solver.cpp:221] Iteration 7180, loss = 0.973433
I0416 13:23:22.594816   977 solver.cpp:236]     Train net output #0: loss = 1.37398 (* 1 = 1.37398 loss)
I0416 13:23:22.594823   977 solver.cpp:542] Iteration 7180, lr = 0.1
I0416 13:23:35.402489   977 solver.cpp:316] Iteration 7200, Testing net (#0)
I0416 13:23:46.906327   977 solver.cpp:373]     Test net output #0: accuracy = 0.753802
I0416 13:23:46.906348   977 solver.cpp:373]     Test net output #1: loss = 0.945463 (* 1 = 0.945463 loss)
I0416 13:23:47.573278   977 solver.cpp:221] Iteration 7200, loss = 1.08697
I0416 13:23:47.573304   977 solver.cpp:236]     Train net output #0: loss = 1.29047 (* 1 = 1.29047 loss)
I0416 13:23:47.573309   977 solver.cpp:542] Iteration 7200, lr = 0.1
I0416 13:24:01.065316   977 solver.cpp:221] Iteration 7220, loss = 0.962072
I0416 13:24:01.065343   977 solver.cpp:236]     Train net output #0: loss = 1.04625 (* 1 = 1.04625 loss)
I0416 13:24:01.065348   977 solver.cpp:542] Iteration 7220, lr = 0.1
I0416 13:24:14.538362   977 solver.cpp:221] Iteration 7240, loss = 1.05205
I0416 13:24:14.538388   977 solver.cpp:236]     Train net output #0: loss = 1.22316 (* 1 = 1.22316 loss)
I0416 13:24:14.538393   977 solver.cpp:542] Iteration 7240, lr = 0.1
I0416 13:24:28.010036   977 solver.cpp:221] Iteration 7260, loss = 1.03771
I0416 13:24:28.010062   977 solver.cpp:236]     Train net output #0: loss = 1.30337 (* 1 = 1.30337 loss)
I0416 13:24:28.010067   977 solver.cpp:542] Iteration 7260, lr = 0.1
I0416 13:24:41.470654   977 solver.cpp:221] Iteration 7280, loss = 1.01151
I0416 13:24:41.470681   977 solver.cpp:236]     Train net output #0: loss = 0.905784 (* 1 = 0.905784 loss)
I0416 13:24:41.470685   977 solver.cpp:542] Iteration 7280, lr = 0.1
I0416 13:24:54.933226   977 solver.cpp:221] Iteration 7300, loss = 1.02855
I0416 13:24:54.933253   977 solver.cpp:236]     Train net output #0: loss = 1.04241 (* 1 = 1.04241 loss)
I0416 13:24:54.933257   977 solver.cpp:542] Iteration 7300, lr = 0.1
I0416 13:25:08.409950   977 solver.cpp:221] Iteration 7320, loss = 1.02687
I0416 13:25:08.409977   977 solver.cpp:236]     Train net output #0: loss = 1.0216 (* 1 = 1.0216 loss)
I0416 13:25:08.409982   977 solver.cpp:542] Iteration 7320, lr = 0.1
I0416 13:25:21.865172   977 solver.cpp:221] Iteration 7340, loss = 0.978059
I0416 13:25:21.865200   977 solver.cpp:236]     Train net output #0: loss = 1.32944 (* 1 = 1.32944 loss)
I0416 13:25:21.865205   977 solver.cpp:542] Iteration 7340, lr = 0.1
I0416 13:25:35.345232   977 solver.cpp:221] Iteration 7360, loss = 1.06458
I0416 13:25:35.345258   977 solver.cpp:236]     Train net output #0: loss = 1.05872 (* 1 = 1.05872 loss)
I0416 13:25:35.345263   977 solver.cpp:542] Iteration 7360, lr = 0.1
I0416 13:25:48.825448   977 solver.cpp:221] Iteration 7380, loss = 1.03583
I0416 13:25:48.825474   977 solver.cpp:236]     Train net output #0: loss = 0.933841 (* 1 = 0.933841 loss)
I0416 13:25:48.825479   977 solver.cpp:542] Iteration 7380, lr = 0.1
I0416 13:26:01.636687   977 solver.cpp:316] Iteration 7400, Testing net (#0)
I0416 13:26:13.142293   977 solver.cpp:373]     Test net output #0: accuracy = 0.64962
I0416 13:26:13.142315   977 solver.cpp:373]     Test net output #1: loss = 1.55941 (* 1 = 1.55941 loss)
I0416 13:26:13.807889   977 solver.cpp:221] Iteration 7400, loss = 1.03476
I0416 13:26:13.807916   977 solver.cpp:236]     Train net output #0: loss = 1.02836 (* 1 = 1.02836 loss)
I0416 13:26:13.807920   977 solver.cpp:542] Iteration 7400, lr = 0.1
I0416 13:26:27.263633   977 solver.cpp:221] Iteration 7420, loss = 0.995861
I0416 13:26:27.263659   977 solver.cpp:236]     Train net output #0: loss = 0.933502 (* 1 = 0.933502 loss)
I0416 13:26:27.263664   977 solver.cpp:542] Iteration 7420, lr = 0.1
I0416 13:26:40.731120   977 solver.cpp:221] Iteration 7440, loss = 1.02563
I0416 13:26:40.731148   977 solver.cpp:236]     Train net output #0: loss = 1.18273 (* 1 = 1.18273 loss)
I0416 13:26:40.731153   977 solver.cpp:542] Iteration 7440, lr = 0.1
I0416 13:26:54.187191   977 solver.cpp:221] Iteration 7460, loss = 1.05099
I0416 13:26:54.187218   977 solver.cpp:236]     Train net output #0: loss = 1.03317 (* 1 = 1.03317 loss)
I0416 13:26:54.187223   977 solver.cpp:542] Iteration 7460, lr = 0.1
I0416 13:27:07.654908   977 solver.cpp:221] Iteration 7480, loss = 1.00978
I0416 13:27:07.654935   977 solver.cpp:236]     Train net output #0: loss = 0.909027 (* 1 = 0.909027 loss)
I0416 13:27:07.654940   977 solver.cpp:542] Iteration 7480, lr = 0.1
I0416 13:27:21.130313   977 solver.cpp:221] Iteration 7500, loss = 0.977034
I0416 13:27:21.130341   977 solver.cpp:236]     Train net output #0: loss = 0.846779 (* 1 = 0.846779 loss)
I0416 13:27:21.130345   977 solver.cpp:542] Iteration 7500, lr = 0.1
I0416 13:27:34.607012   977 solver.cpp:221] Iteration 7520, loss = 1.05169
I0416 13:27:34.607038   977 solver.cpp:236]     Train net output #0: loss = 1.5029 (* 1 = 1.5029 loss)
I0416 13:27:34.607043   977 solver.cpp:542] Iteration 7520, lr = 0.1
I0416 13:27:48.100232   977 solver.cpp:221] Iteration 7540, loss = 0.979172
I0416 13:27:48.100258   977 solver.cpp:236]     Train net output #0: loss = 0.87109 (* 1 = 0.87109 loss)
I0416 13:27:48.100263   977 solver.cpp:542] Iteration 7540, lr = 0.1
I0416 13:28:01.563390   977 solver.cpp:221] Iteration 7560, loss = 1.05673
I0416 13:28:01.563416   977 solver.cpp:236]     Train net output #0: loss = 1.09944 (* 1 = 1.09944 loss)
I0416 13:28:01.563421   977 solver.cpp:542] Iteration 7560, lr = 0.1
I0416 13:28:15.033965   977 solver.cpp:221] Iteration 7580, loss = 1.01668
I0416 13:28:15.033993   977 solver.cpp:236]     Train net output #0: loss = 0.964476 (* 1 = 0.964476 loss)
I0416 13:28:15.033998   977 solver.cpp:542] Iteration 7580, lr = 0.1
I0416 13:28:27.839889   977 solver.cpp:316] Iteration 7600, Testing net (#0)
I0416 13:28:39.339812   977 solver.cpp:373]     Test net output #0: accuracy = 0.774525
I0416 13:28:39.339834   977 solver.cpp:373]     Test net output #1: loss = 0.862897 (* 1 = 0.862897 loss)
I0416 13:28:40.005107   977 solver.cpp:221] Iteration 7600, loss = 1.00503
I0416 13:28:40.005134   977 solver.cpp:236]     Train net output #0: loss = 1.12748 (* 1 = 1.12748 loss)
I0416 13:28:40.005139   977 solver.cpp:542] Iteration 7600, lr = 0.1
I0416 13:28:53.488845   977 solver.cpp:221] Iteration 7620, loss = 1.09265
I0416 13:28:53.488873   977 solver.cpp:236]     Train net output #0: loss = 0.922073 (* 1 = 0.922073 loss)
I0416 13:28:53.488878   977 solver.cpp:542] Iteration 7620, lr = 0.1
I0416 13:29:06.955502   977 solver.cpp:221] Iteration 7640, loss = 1.00401
I0416 13:29:06.955528   977 solver.cpp:236]     Train net output #0: loss = 1.28184 (* 1 = 1.28184 loss)
I0416 13:29:06.955533   977 solver.cpp:542] Iteration 7640, lr = 0.1
I0416 13:29:20.446099   977 solver.cpp:221] Iteration 7660, loss = 1.00471
I0416 13:29:20.446128   977 solver.cpp:236]     Train net output #0: loss = 1.0193 (* 1 = 1.0193 loss)
I0416 13:29:20.446133   977 solver.cpp:542] Iteration 7660, lr = 0.1
I0416 13:29:33.937930   977 solver.cpp:221] Iteration 7680, loss = 0.978552
I0416 13:29:33.937958   977 solver.cpp:236]     Train net output #0: loss = 1.26898 (* 1 = 1.26898 loss)
I0416 13:29:33.937963   977 solver.cpp:542] Iteration 7680, lr = 0.1
I0416 13:29:47.390103   977 solver.cpp:221] Iteration 7700, loss = 0.989322
I0416 13:29:47.390130   977 solver.cpp:236]     Train net output #0: loss = 1.04689 (* 1 = 1.04689 loss)
I0416 13:29:47.390136   977 solver.cpp:542] Iteration 7700, lr = 0.1
I0416 13:30:00.883582   977 solver.cpp:221] Iteration 7720, loss = 0.996462
I0416 13:30:00.883608   977 solver.cpp:236]     Train net output #0: loss = 0.772017 (* 1 = 0.772017 loss)
I0416 13:30:00.883612   977 solver.cpp:542] Iteration 7720, lr = 0.1
I0416 13:30:14.368862   977 solver.cpp:221] Iteration 7740, loss = 1.02667
I0416 13:30:14.368890   977 solver.cpp:236]     Train net output #0: loss = 1.04392 (* 1 = 1.04392 loss)
I0416 13:30:14.368893   977 solver.cpp:542] Iteration 7740, lr = 0.1
I0416 13:30:27.857383   977 solver.cpp:221] Iteration 7760, loss = 1.00708
I0416 13:30:27.857409   977 solver.cpp:236]     Train net output #0: loss = 1.26174 (* 1 = 1.26174 loss)
I0416 13:30:27.857414   977 solver.cpp:542] Iteration 7760, lr = 0.1
I0416 13:30:41.362824   977 solver.cpp:221] Iteration 7780, loss = 1.02887
I0416 13:30:41.362851   977 solver.cpp:236]     Train net output #0: loss = 1.20203 (* 1 = 1.20203 loss)
I0416 13:30:41.362856   977 solver.cpp:542] Iteration 7780, lr = 0.1
I0416 13:30:54.217684   977 solver.cpp:316] Iteration 7800, Testing net (#0)
I0416 13:31:05.732555   977 solver.cpp:373]     Test net output #0: accuracy = 0.853992
I0416 13:31:05.732576   977 solver.cpp:373]     Test net output #1: loss = 0.555513 (* 1 = 0.555513 loss)
I0416 13:31:06.401263   977 solver.cpp:221] Iteration 7800, loss = 1.00834
I0416 13:31:06.401289   977 solver.cpp:236]     Train net output #0: loss = 1.23174 (* 1 = 1.23174 loss)
I0416 13:31:06.401294   977 solver.cpp:542] Iteration 7800, lr = 0.1
I0416 13:31:19.905515   977 solver.cpp:221] Iteration 7820, loss = 1.07785
I0416 13:31:19.905541   977 solver.cpp:236]     Train net output #0: loss = 1.22244 (* 1 = 1.22244 loss)
I0416 13:31:19.905546   977 solver.cpp:542] Iteration 7820, lr = 0.1
I0416 13:31:33.362733   977 solver.cpp:221] Iteration 7840, loss = 1.02443
I0416 13:31:33.362761   977 solver.cpp:236]     Train net output #0: loss = 0.922904 (* 1 = 0.922904 loss)
I0416 13:31:33.362766   977 solver.cpp:542] Iteration 7840, lr = 0.1
I0416 13:31:46.828368   977 solver.cpp:221] Iteration 7860, loss = 1.03135
I0416 13:31:46.828395   977 solver.cpp:236]     Train net output #0: loss = 0.873464 (* 1 = 0.873464 loss)
I0416 13:31:46.828400   977 solver.cpp:542] Iteration 7860, lr = 0.1
I0416 13:32:00.311480   977 solver.cpp:221] Iteration 7880, loss = 1.0223
I0416 13:32:00.311507   977 solver.cpp:236]     Train net output #0: loss = 0.792372 (* 1 = 0.792372 loss)
I0416 13:32:00.311511   977 solver.cpp:542] Iteration 7880, lr = 0.1
I0416 13:32:13.768759   977 solver.cpp:221] Iteration 7900, loss = 1.0079
I0416 13:32:13.768785   977 solver.cpp:236]     Train net output #0: loss = 0.705033 (* 1 = 0.705033 loss)
I0416 13:32:13.768790   977 solver.cpp:542] Iteration 7900, lr = 0.1
I0416 13:32:27.225214   977 solver.cpp:221] Iteration 7920, loss = 1.00229
I0416 13:32:27.225239   977 solver.cpp:236]     Train net output #0: loss = 1.11832 (* 1 = 1.11832 loss)
I0416 13:32:27.225244   977 solver.cpp:542] Iteration 7920, lr = 0.1
I0416 13:32:40.681062   977 solver.cpp:221] Iteration 7940, loss = 0.989343
I0416 13:32:40.681087   977 solver.cpp:236]     Train net output #0: loss = 1.01601 (* 1 = 1.01601 loss)
I0416 13:32:40.681092   977 solver.cpp:542] Iteration 7940, lr = 0.1
I0416 13:32:54.143226   977 solver.cpp:221] Iteration 7960, loss = 1.01073
I0416 13:32:54.143252   977 solver.cpp:236]     Train net output #0: loss = 1.26894 (* 1 = 1.26894 loss)
I0416 13:32:54.143257   977 solver.cpp:542] Iteration 7960, lr = 0.1
I0416 13:33:07.618228   977 solver.cpp:221] Iteration 7980, loss = 1.0179
I0416 13:33:07.618255   977 solver.cpp:236]     Train net output #0: loss = 0.772535 (* 1 = 0.772535 loss)
I0416 13:33:07.618259   977 solver.cpp:542] Iteration 7980, lr = 0.1
I0416 13:33:20.426877   977 solver.cpp:316] Iteration 8000, Testing net (#0)
I0416 13:33:31.929770   977 solver.cpp:373]     Test net output #0: accuracy = 0.756654
I0416 13:33:31.929791   977 solver.cpp:373]     Test net output #1: loss = 0.927883 (* 1 = 0.927883 loss)
I0416 13:33:32.594359   977 solver.cpp:221] Iteration 8000, loss = 1.00353
I0416 13:33:32.594385   977 solver.cpp:236]     Train net output #0: loss = 1.03363 (* 1 = 1.03363 loss)
I0416 13:33:32.594390   977 solver.cpp:542] Iteration 8000, lr = 0.1
I0416 13:33:46.056921   977 solver.cpp:221] Iteration 8020, loss = 0.960216
I0416 13:33:46.056948   977 solver.cpp:236]     Train net output #0: loss = 0.779458 (* 1 = 0.779458 loss)
I0416 13:33:46.056953   977 solver.cpp:542] Iteration 8020, lr = 0.1
I0416 13:33:59.520025   977 solver.cpp:221] Iteration 8040, loss = 0.986335
I0416 13:33:59.520051   977 solver.cpp:236]     Train net output #0: loss = 0.78187 (* 1 = 0.78187 loss)
I0416 13:33:59.520056   977 solver.cpp:542] Iteration 8040, lr = 0.1
I0416 13:34:12.996704   977 solver.cpp:221] Iteration 8060, loss = 1.00668
I0416 13:34:12.996731   977 solver.cpp:236]     Train net output #0: loss = 0.847727 (* 1 = 0.847727 loss)
I0416 13:34:12.996737   977 solver.cpp:542] Iteration 8060, lr = 0.1
I0416 13:34:26.478024   977 solver.cpp:221] Iteration 8080, loss = 1.04841
I0416 13:34:26.478051   977 solver.cpp:236]     Train net output #0: loss = 1.02459 (* 1 = 1.02459 loss)
I0416 13:34:26.478056   977 solver.cpp:542] Iteration 8080, lr = 0.1
I0416 13:34:39.955510   977 solver.cpp:221] Iteration 8100, loss = 0.998961
I0416 13:34:39.955538   977 solver.cpp:236]     Train net output #0: loss = 0.977931 (* 1 = 0.977931 loss)
I0416 13:34:39.955543   977 solver.cpp:542] Iteration 8100, lr = 0.1
I0416 13:34:53.457626   977 solver.cpp:221] Iteration 8120, loss = 0.989596
I0416 13:34:53.457653   977 solver.cpp:236]     Train net output #0: loss = 0.784374 (* 1 = 0.784374 loss)
I0416 13:34:53.457659   977 solver.cpp:542] Iteration 8120, lr = 0.1
I0416 13:35:06.944345   977 solver.cpp:221] Iteration 8140, loss = 1.04667
I0416 13:35:06.944371   977 solver.cpp:236]     Train net output #0: loss = 1.21013 (* 1 = 1.21013 loss)
I0416 13:35:06.944376   977 solver.cpp:542] Iteration 8140, lr = 0.1
I0416 13:35:20.426048   977 solver.cpp:221] Iteration 8160, loss = 1.05489
I0416 13:35:20.426075   977 solver.cpp:236]     Train net output #0: loss = 1.10298 (* 1 = 1.10298 loss)
I0416 13:35:20.426080   977 solver.cpp:542] Iteration 8160, lr = 0.1
I0416 13:35:33.914952   977 solver.cpp:221] Iteration 8180, loss = 1.00038
I0416 13:35:33.914979   977 solver.cpp:236]     Train net output #0: loss = 0.752449 (* 1 = 0.752449 loss)
I0416 13:35:33.914983   977 solver.cpp:542] Iteration 8180, lr = 0.1
I0416 13:35:46.731477   977 solver.cpp:316] Iteration 8200, Testing net (#0)
I0416 13:35:58.247627   977 solver.cpp:373]     Test net output #0: accuracy = 0.621293
I0416 13:35:58.247649   977 solver.cpp:373]     Test net output #1: loss = 1.57329 (* 1 = 1.57329 loss)
I0416 13:35:58.915446   977 solver.cpp:221] Iteration 8200, loss = 0.993319
I0416 13:35:58.915473   977 solver.cpp:236]     Train net output #0: loss = 0.952177 (* 1 = 0.952177 loss)
I0416 13:35:58.915477   977 solver.cpp:542] Iteration 8200, lr = 0.1
I0416 13:36:12.395442   977 solver.cpp:221] Iteration 8220, loss = 0.993223
I0416 13:36:12.395468   977 solver.cpp:236]     Train net output #0: loss = 0.984397 (* 1 = 0.984397 loss)
I0416 13:36:12.395473   977 solver.cpp:542] Iteration 8220, lr = 0.1
I0416 13:36:25.866477   977 solver.cpp:221] Iteration 8240, loss = 1.0226
I0416 13:36:25.866504   977 solver.cpp:236]     Train net output #0: loss = 0.868611 (* 1 = 0.868611 loss)
I0416 13:36:25.866508   977 solver.cpp:542] Iteration 8240, lr = 0.1
I0416 13:36:39.329540   977 solver.cpp:221] Iteration 8260, loss = 1.03122
I0416 13:36:39.329566   977 solver.cpp:236]     Train net output #0: loss = 0.750459 (* 1 = 0.750459 loss)
I0416 13:36:39.329571   977 solver.cpp:542] Iteration 8260, lr = 0.1
I0416 13:36:52.810762   977 solver.cpp:221] Iteration 8280, loss = 1.0683
I0416 13:36:52.810789   977 solver.cpp:236]     Train net output #0: loss = 1.11041 (* 1 = 1.11041 loss)
I0416 13:36:52.810794   977 solver.cpp:542] Iteration 8280, lr = 0.1
I0416 13:37:06.282696   977 solver.cpp:221] Iteration 8300, loss = 0.996914
I0416 13:37:06.282723   977 solver.cpp:236]     Train net output #0: loss = 0.890948 (* 1 = 0.890948 loss)
I0416 13:37:06.282728   977 solver.cpp:542] Iteration 8300, lr = 0.1
I0416 13:37:19.750115   977 solver.cpp:221] Iteration 8320, loss = 0.998957
I0416 13:37:19.750143   977 solver.cpp:236]     Train net output #0: loss = 0.705668 (* 1 = 0.705668 loss)
I0416 13:37:19.750147   977 solver.cpp:542] Iteration 8320, lr = 0.1
I0416 13:37:33.216713   977 solver.cpp:221] Iteration 8340, loss = 0.955131
I0416 13:37:33.216740   977 solver.cpp:236]     Train net output #0: loss = 1.56935 (* 1 = 1.56935 loss)
I0416 13:37:33.216744   977 solver.cpp:542] Iteration 8340, lr = 0.1
I0416 13:37:46.691625   977 solver.cpp:221] Iteration 8360, loss = 0.993643
I0416 13:37:46.691653   977 solver.cpp:236]     Train net output #0: loss = 0.688596 (* 1 = 0.688596 loss)
I0416 13:37:46.691656   977 solver.cpp:542] Iteration 8360, lr = 0.1
I0416 13:38:00.168586   977 solver.cpp:221] Iteration 8380, loss = 0.974981
I0416 13:38:00.168614   977 solver.cpp:236]     Train net output #0: loss = 1.03108 (* 1 = 1.03108 loss)
I0416 13:38:00.168618   977 solver.cpp:542] Iteration 8380, lr = 0.1
I0416 13:38:12.976078   977 solver.cpp:316] Iteration 8400, Testing net (#0)
I0416 13:38:24.481243   977 solver.cpp:373]     Test net output #0: accuracy = 0.677947
I0416 13:38:24.481264   977 solver.cpp:373]     Test net output #1: loss = 1.37218 (* 1 = 1.37218 loss)
I0416 13:38:25.145442   977 solver.cpp:221] Iteration 8400, loss = 0.971632
I0416 13:38:25.145468   977 solver.cpp:236]     Train net output #0: loss = 1.17768 (* 1 = 1.17768 loss)
I0416 13:38:25.145473   977 solver.cpp:542] Iteration 8400, lr = 0.1
I0416 13:38:38.635960   977 solver.cpp:221] Iteration 8420, loss = 1.05934
I0416 13:38:38.635987   977 solver.cpp:236]     Train net output #0: loss = 1.41181 (* 1 = 1.41181 loss)
I0416 13:38:38.635992   977 solver.cpp:542] Iteration 8420, lr = 0.1
I0416 13:38:52.111690   977 solver.cpp:221] Iteration 8440, loss = 1.01886
I0416 13:38:52.111716   977 solver.cpp:236]     Train net output #0: loss = 1.00933 (* 1 = 1.00933 loss)
I0416 13:38:52.111721   977 solver.cpp:542] Iteration 8440, lr = 0.1
I0416 13:39:05.597757   977 solver.cpp:221] Iteration 8460, loss = 0.945551
I0416 13:39:05.597784   977 solver.cpp:236]     Train net output #0: loss = 0.862531 (* 1 = 0.862531 loss)
I0416 13:39:05.597789   977 solver.cpp:542] Iteration 8460, lr = 0.1
I0416 13:39:19.113515   977 solver.cpp:221] Iteration 8480, loss = 0.985175
I0416 13:39:19.113541   977 solver.cpp:236]     Train net output #0: loss = 1.35142 (* 1 = 1.35142 loss)
I0416 13:39:19.113546   977 solver.cpp:542] Iteration 8480, lr = 0.1
I0416 13:39:32.595343   977 solver.cpp:221] Iteration 8500, loss = 0.988577
I0416 13:39:32.595371   977 solver.cpp:236]     Train net output #0: loss = 1.28133 (* 1 = 1.28133 loss)
I0416 13:39:32.595376   977 solver.cpp:542] Iteration 8500, lr = 0.1
I0416 13:39:46.084328   977 solver.cpp:221] Iteration 8520, loss = 1.01425
I0416 13:39:46.084355   977 solver.cpp:236]     Train net output #0: loss = 0.925145 (* 1 = 0.925145 loss)
I0416 13:39:46.084362   977 solver.cpp:542] Iteration 8520, lr = 0.1
I0416 13:39:59.560070   977 solver.cpp:221] Iteration 8540, loss = 0.945098
I0416 13:39:59.560097   977 solver.cpp:236]     Train net output #0: loss = 1.00753 (* 1 = 1.00753 loss)
I0416 13:39:59.560102   977 solver.cpp:542] Iteration 8540, lr = 0.1
I0416 13:40:13.045053   977 solver.cpp:221] Iteration 8560, loss = 0.946189
I0416 13:40:13.045079   977 solver.cpp:236]     Train net output #0: loss = 1.0466 (* 1 = 1.0466 loss)
I0416 13:40:13.045084   977 solver.cpp:542] Iteration 8560, lr = 0.1
I0416 13:40:26.513469   977 solver.cpp:221] Iteration 8580, loss = 0.903585
I0416 13:40:26.513496   977 solver.cpp:236]     Train net output #0: loss = 0.928005 (* 1 = 0.928005 loss)
I0416 13:40:26.513501   977 solver.cpp:542] Iteration 8580, lr = 0.1
I0416 13:40:39.323004   977 solver.cpp:316] Iteration 8600, Testing net (#0)
I0416 13:40:50.829712   977 solver.cpp:373]     Test net output #0: accuracy = 0.851141
I0416 13:40:50.829735   977 solver.cpp:373]     Test net output #1: loss = 0.57411 (* 1 = 0.57411 loss)
I0416 13:40:51.495784   977 solver.cpp:221] Iteration 8600, loss = 0.913113
I0416 13:40:51.495810   977 solver.cpp:236]     Train net output #0: loss = 0.891558 (* 1 = 0.891558 loss)
I0416 13:40:51.495815   977 solver.cpp:542] Iteration 8600, lr = 0.1
I0416 13:41:05.016082   977 solver.cpp:221] Iteration 8620, loss = 0.979685
I0416 13:41:05.016108   977 solver.cpp:236]     Train net output #0: loss = 0.936611 (* 1 = 0.936611 loss)
I0416 13:41:05.016113   977 solver.cpp:542] Iteration 8620, lr = 0.1
I0416 13:41:18.522228   977 solver.cpp:221] Iteration 8640, loss = 0.941798
I0416 13:41:18.522255   977 solver.cpp:236]     Train net output #0: loss = 1.10521 (* 1 = 1.10521 loss)
I0416 13:41:18.522259   977 solver.cpp:542] Iteration 8640, lr = 0.1
I0416 13:41:32.008774   977 solver.cpp:221] Iteration 8660, loss = 0.958247
I0416 13:41:32.008800   977 solver.cpp:236]     Train net output #0: loss = 0.829672 (* 1 = 0.829672 loss)
I0416 13:41:32.008805   977 solver.cpp:542] Iteration 8660, lr = 0.1
I0416 13:41:45.483986   977 solver.cpp:221] Iteration 8680, loss = 0.997271
I0416 13:41:45.484014   977 solver.cpp:236]     Train net output #0: loss = 1.13799 (* 1 = 1.13799 loss)
I0416 13:41:45.484017   977 solver.cpp:542] Iteration 8680, lr = 0.1
I0416 13:41:58.949049   977 solver.cpp:221] Iteration 8700, loss = 0.958863
I0416 13:41:58.949077   977 solver.cpp:236]     Train net output #0: loss = 1.30899 (* 1 = 1.30899 loss)
I0416 13:41:58.949082   977 solver.cpp:542] Iteration 8700, lr = 0.1
I0416 13:42:12.437063   977 solver.cpp:221] Iteration 8720, loss = 1.04351
I0416 13:42:12.437091   977 solver.cpp:236]     Train net output #0: loss = 0.865503 (* 1 = 0.865503 loss)
I0416 13:42:12.437095   977 solver.cpp:542] Iteration 8720, lr = 0.1
I0416 13:42:25.903995   977 solver.cpp:221] Iteration 8740, loss = 0.913606
I0416 13:42:25.904022   977 solver.cpp:236]     Train net output #0: loss = 0.934844 (* 1 = 0.934844 loss)
I0416 13:42:25.904026   977 solver.cpp:542] Iteration 8740, lr = 0.1
I0416 13:42:39.381655   977 solver.cpp:221] Iteration 8760, loss = 0.918743
I0416 13:42:39.381683   977 solver.cpp:236]     Train net output #0: loss = 0.775642 (* 1 = 0.775642 loss)
I0416 13:42:39.381688   977 solver.cpp:542] Iteration 8760, lr = 0.1
I0416 13:42:52.880892   977 solver.cpp:221] Iteration 8780, loss = 0.977739
I0416 13:42:52.880918   977 solver.cpp:236]     Train net output #0: loss = 1.31974 (* 1 = 1.31974 loss)
I0416 13:42:52.880923   977 solver.cpp:542] Iteration 8780, lr = 0.1
I0416 13:43:05.709420   977 solver.cpp:316] Iteration 8800, Testing net (#0)
I0416 13:43:17.215395   977 solver.cpp:373]     Test net output #0: accuracy = 0.579658
I0416 13:43:17.215417   977 solver.cpp:373]     Test net output #1: loss = 1.89991 (* 1 = 1.89991 loss)
I0416 13:43:17.882686   977 solver.cpp:221] Iteration 8800, loss = 0.968729
I0416 13:43:17.882712   977 solver.cpp:236]     Train net output #0: loss = 1.15009 (* 1 = 1.15009 loss)
I0416 13:43:17.882717   977 solver.cpp:542] Iteration 8800, lr = 0.1
I0416 13:43:31.357689   977 solver.cpp:221] Iteration 8820, loss = 0.99839
I0416 13:43:31.357717   977 solver.cpp:236]     Train net output #0: loss = 1.10718 (* 1 = 1.10718 loss)
I0416 13:43:31.357722   977 solver.cpp:542] Iteration 8820, lr = 0.1
I0416 13:43:44.829298   977 solver.cpp:221] Iteration 8840, loss = 1.02028
I0416 13:43:44.829325   977 solver.cpp:236]     Train net output #0: loss = 1.31102 (* 1 = 1.31102 loss)
I0416 13:43:44.829329   977 solver.cpp:542] Iteration 8840, lr = 0.1
I0416 13:43:58.297116   977 solver.cpp:221] Iteration 8860, loss = 0.982125
I0416 13:43:58.297143   977 solver.cpp:236]     Train net output #0: loss = 1.12276 (* 1 = 1.12276 loss)
I0416 13:43:58.297148   977 solver.cpp:542] Iteration 8860, lr = 0.1
I0416 13:44:11.815901   977 solver.cpp:221] Iteration 8880, loss = 0.95724
I0416 13:44:11.815928   977 solver.cpp:236]     Train net output #0: loss = 0.876972 (* 1 = 0.876972 loss)
I0416 13:44:11.815933   977 solver.cpp:542] Iteration 8880, lr = 0.1
I0416 13:44:25.331462   977 solver.cpp:221] Iteration 8900, loss = 1.0524
I0416 13:44:25.331490   977 solver.cpp:236]     Train net output #0: loss = 0.894625 (* 1 = 0.894625 loss)
I0416 13:44:25.331493   977 solver.cpp:542] Iteration 8900, lr = 0.1
I0416 13:44:38.825454   977 solver.cpp:221] Iteration 8920, loss = 1.01583
I0416 13:44:38.825481   977 solver.cpp:236]     Train net output #0: loss = 0.980222 (* 1 = 0.980222 loss)
I0416 13:44:38.825486   977 solver.cpp:542] Iteration 8920, lr = 0.1
I0416 13:44:52.341960   977 solver.cpp:221] Iteration 8940, loss = 1.02624
I0416 13:44:52.341987   977 solver.cpp:236]     Train net output #0: loss = 0.928544 (* 1 = 0.928544 loss)
I0416 13:44:52.341992   977 solver.cpp:542] Iteration 8940, lr = 0.1
I0416 13:45:05.809238   977 solver.cpp:221] Iteration 8960, loss = 0.972852
I0416 13:45:05.809265   977 solver.cpp:236]     Train net output #0: loss = 1.0254 (* 1 = 1.0254 loss)
I0416 13:45:05.809269   977 solver.cpp:542] Iteration 8960, lr = 0.1
I0416 13:45:19.274947   977 solver.cpp:221] Iteration 8980, loss = 0.992055
I0416 13:45:19.274976   977 solver.cpp:236]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0416 13:45:19.274981   977 solver.cpp:542] Iteration 8980, lr = 0.1
I0416 13:45:32.124261   977 solver.cpp:316] Iteration 9000, Testing net (#0)
I0416 13:45:43.637250   977 solver.cpp:373]     Test net output #0: accuracy = 0.718631
I0416 13:45:43.637272   977 solver.cpp:373]     Test net output #1: loss = 1.09659 (* 1 = 1.09659 loss)
I0416 13:45:44.303357   977 solver.cpp:221] Iteration 9000, loss = 1.00193
I0416 13:45:44.303385   977 solver.cpp:236]     Train net output #0: loss = 0.981767 (* 1 = 0.981767 loss)
I0416 13:45:44.303390   977 solver.cpp:542] Iteration 9000, lr = 0.1
I0416 13:45:57.792059   977 solver.cpp:221] Iteration 9020, loss = 0.940486
I0416 13:45:57.792086   977 solver.cpp:236]     Train net output #0: loss = 1.12564 (* 1 = 1.12564 loss)
I0416 13:45:57.792090   977 solver.cpp:542] Iteration 9020, lr = 0.1
I0416 13:46:11.284083   977 solver.cpp:221] Iteration 9040, loss = 0.950516
I0416 13:46:11.284111   977 solver.cpp:236]     Train net output #0: loss = 1.07982 (* 1 = 1.07982 loss)
I0416 13:46:11.284116   977 solver.cpp:542] Iteration 9040, lr = 0.1
I0416 13:46:24.777390   977 solver.cpp:221] Iteration 9060, loss = 0.953873
I0416 13:46:24.777417   977 solver.cpp:236]     Train net output #0: loss = 0.76897 (* 1 = 0.76897 loss)
I0416 13:46:24.777422   977 solver.cpp:542] Iteration 9060, lr = 0.1
I0416 13:46:38.277632   977 solver.cpp:221] Iteration 9080, loss = 1.02759
I0416 13:46:38.277659   977 solver.cpp:236]     Train net output #0: loss = 0.777482 (* 1 = 0.777482 loss)
I0416 13:46:38.277664   977 solver.cpp:542] Iteration 9080, lr = 0.1
I0416 13:46:51.776731   977 solver.cpp:221] Iteration 9100, loss = 0.973557
I0416 13:46:51.776757   977 solver.cpp:236]     Train net output #0: loss = 1.21928 (* 1 = 1.21928 loss)
I0416 13:46:51.776762   977 solver.cpp:542] Iteration 9100, lr = 0.1
I0416 13:47:05.289669   977 solver.cpp:221] Iteration 9120, loss = 0.975567
I0416 13:47:05.289695   977 solver.cpp:236]     Train net output #0: loss = 0.462293 (* 1 = 0.462293 loss)
I0416 13:47:05.289700   977 solver.cpp:542] Iteration 9120, lr = 0.1
I0416 13:47:18.800539   977 solver.cpp:221] Iteration 9140, loss = 0.940868
I0416 13:47:18.800566   977 solver.cpp:236]     Train net output #0: loss = 0.847533 (* 1 = 0.847533 loss)
I0416 13:47:18.800571   977 solver.cpp:542] Iteration 9140, lr = 0.1
I0416 13:47:32.295914   977 solver.cpp:221] Iteration 9160, loss = 0.930058
I0416 13:47:32.295941   977 solver.cpp:236]     Train net output #0: loss = 0.978465 (* 1 = 0.978465 loss)
I0416 13:47:32.295945   977 solver.cpp:542] Iteration 9160, lr = 0.1
I0416 13:47:45.756840   977 solver.cpp:221] Iteration 9180, loss = 0.924351
I0416 13:47:45.756867   977 solver.cpp:236]     Train net output #0: loss = 0.719565 (* 1 = 0.719565 loss)
I0416 13:47:45.756872   977 solver.cpp:542] Iteration 9180, lr = 0.1
I0416 13:47:58.587944   977 solver.cpp:316] Iteration 9200, Testing net (#0)
I0416 13:48:10.095304   977 solver.cpp:373]     Test net output #0: accuracy = 0.856464
I0416 13:48:10.095325   977 solver.cpp:373]     Test net output #1: loss = 0.544578 (* 1 = 0.544578 loss)
I0416 13:48:10.760284   977 solver.cpp:221] Iteration 9200, loss = 1.00231
I0416 13:48:10.760311   977 solver.cpp:236]     Train net output #0: loss = 0.802528 (* 1 = 0.802528 loss)
I0416 13:48:10.760316   977 solver.cpp:542] Iteration 9200, lr = 0.1
I0416 13:48:24.223223   977 solver.cpp:221] Iteration 9220, loss = 0.964013
I0416 13:48:24.223249   977 solver.cpp:236]     Train net output #0: loss = 0.751284 (* 1 = 0.751284 loss)
I0416 13:48:24.223254   977 solver.cpp:542] Iteration 9220, lr = 0.1
I0416 13:48:37.719012   977 solver.cpp:221] Iteration 9240, loss = 0.92944
I0416 13:48:37.719038   977 solver.cpp:236]     Train net output #0: loss = 0.897659 (* 1 = 0.897659 loss)
I0416 13:48:37.719043   977 solver.cpp:542] Iteration 9240, lr = 0.1
I0416 13:48:51.203829   977 solver.cpp:221] Iteration 9260, loss = 0.95291
I0416 13:48:51.203856   977 solver.cpp:236]     Train net output #0: loss = 1.14341 (* 1 = 1.14341 loss)
I0416 13:48:51.203861   977 solver.cpp:542] Iteration 9260, lr = 0.1
I0416 13:49:04.697489   977 solver.cpp:221] Iteration 9280, loss = 0.964609
I0416 13:49:04.697516   977 solver.cpp:236]     Train net output #0: loss = 1.16001 (* 1 = 1.16001 loss)
I0416 13:49:04.697521   977 solver.cpp:542] Iteration 9280, lr = 0.1
I0416 13:49:18.205598   977 solver.cpp:221] Iteration 9300, loss = 0.929133
I0416 13:49:18.205626   977 solver.cpp:236]     Train net output #0: loss = 0.88977 (* 1 = 0.88977 loss)
I0416 13:49:18.205629   977 solver.cpp:542] Iteration 9300, lr = 0.1
I0416 13:49:31.697350   977 solver.cpp:221] Iteration 9320, loss = 0.942587
I0416 13:49:31.697376   977 solver.cpp:236]     Train net output #0: loss = 0.836085 (* 1 = 0.836085 loss)
I0416 13:49:31.697381   977 solver.cpp:542] Iteration 9320, lr = 0.1
I0416 13:49:45.178853   977 solver.cpp:221] Iteration 9340, loss = 0.944367
I0416 13:49:45.178880   977 solver.cpp:236]     Train net output #0: loss = 0.943904 (* 1 = 0.943904 loss)
I0416 13:49:45.178885   977 solver.cpp:542] Iteration 9340, lr = 0.1
I0416 13:49:58.663853   977 solver.cpp:221] Iteration 9360, loss = 0.997227
I0416 13:49:58.663880   977 solver.cpp:236]     Train net output #0: loss = 0.93151 (* 1 = 0.93151 loss)
I0416 13:49:58.663884   977 solver.cpp:542] Iteration 9360, lr = 0.1
I0416 13:50:12.132000   977 solver.cpp:221] Iteration 9380, loss = 0.992196
I0416 13:50:12.132027   977 solver.cpp:236]     Train net output #0: loss = 0.808923 (* 1 = 0.808923 loss)
I0416 13:50:12.132032   977 solver.cpp:542] Iteration 9380, lr = 0.1
I0416 13:50:24.956581   977 solver.cpp:316] Iteration 9400, Testing net (#0)
I0416 13:50:36.464218   977 solver.cpp:373]     Test net output #0: accuracy = 0.806084
I0416 13:50:36.464239   977 solver.cpp:373]     Test net output #1: loss = 0.743938 (* 1 = 0.743938 loss)
I0416 13:50:37.129524   977 solver.cpp:221] Iteration 9400, loss = 0.9413
I0416 13:50:37.129551   977 solver.cpp:236]     Train net output #0: loss = 0.807954 (* 1 = 0.807954 loss)
I0416 13:50:37.129556   977 solver.cpp:542] Iteration 9400, lr = 0.1
I0416 13:50:50.597441   977 solver.cpp:221] Iteration 9420, loss = 0.992144
I0416 13:50:50.597468   977 solver.cpp:236]     Train net output #0: loss = 0.810006 (* 1 = 0.810006 loss)
I0416 13:50:50.597473   977 solver.cpp:542] Iteration 9420, lr = 0.1
I0416 13:51:04.076369   977 solver.cpp:221] Iteration 9440, loss = 0.927058
I0416 13:51:04.076395   977 solver.cpp:236]     Train net output #0: loss = 0.835846 (* 1 = 0.835846 loss)
I0416 13:51:04.076400   977 solver.cpp:542] Iteration 9440, lr = 0.1
I0416 13:51:17.577673   977 solver.cpp:221] Iteration 9460, loss = 0.939896
I0416 13:51:17.577700   977 solver.cpp:236]     Train net output #0: loss = 0.8323 (* 1 = 0.8323 loss)
I0416 13:51:17.577705   977 solver.cpp:542] Iteration 9460, lr = 0.1
I0416 13:51:31.060163   977 solver.cpp:221] Iteration 9480, loss = 0.932561
I0416 13:51:31.060189   977 solver.cpp:236]     Train net output #0: loss = 0.879481 (* 1 = 0.879481 loss)
I0416 13:51:31.060192   977 solver.cpp:542] Iteration 9480, lr = 0.1
I0416 13:51:44.532136   977 solver.cpp:221] Iteration 9500, loss = 0.971565
I0416 13:51:44.532163   977 solver.cpp:236]     Train net output #0: loss = 0.968743 (* 1 = 0.968743 loss)
I0416 13:51:44.532168   977 solver.cpp:542] Iteration 9500, lr = 0.1
I0416 13:51:58.014241   977 solver.cpp:221] Iteration 9520, loss = 0.948602
I0416 13:51:58.014269   977 solver.cpp:236]     Train net output #0: loss = 1.13346 (* 1 = 1.13346 loss)
I0416 13:51:58.014273   977 solver.cpp:542] Iteration 9520, lr = 0.1
I0416 13:52:11.498827   977 solver.cpp:221] Iteration 9540, loss = 0.964231
I0416 13:52:11.498852   977 solver.cpp:236]     Train net output #0: loss = 1.26438 (* 1 = 1.26438 loss)
I0416 13:52:11.498857   977 solver.cpp:542] Iteration 9540, lr = 0.1
I0416 13:52:24.967521   977 solver.cpp:221] Iteration 9560, loss = 1.00527
I0416 13:52:24.967550   977 solver.cpp:236]     Train net output #0: loss = 1.25077 (* 1 = 1.25077 loss)
I0416 13:52:24.967553   977 solver.cpp:542] Iteration 9560, lr = 0.1
I0416 13:52:38.436554   977 solver.cpp:221] Iteration 9580, loss = 0.980432
I0416 13:52:38.436581   977 solver.cpp:236]     Train net output #0: loss = 0.948415 (* 1 = 0.948415 loss)
I0416 13:52:38.436586   977 solver.cpp:542] Iteration 9580, lr = 0.1
I0416 13:52:51.282869   977 solver.cpp:316] Iteration 9600, Testing net (#0)
I0416 13:53:02.800112   977 solver.cpp:373]     Test net output #0: accuracy = 0.761597
I0416 13:53:02.800133   977 solver.cpp:373]     Test net output #1: loss = 0.896884 (* 1 = 0.896884 loss)
I0416 13:53:03.467576   977 solver.cpp:221] Iteration 9600, loss = 0.926184
I0416 13:53:03.467604   977 solver.cpp:236]     Train net output #0: loss = 1.00058 (* 1 = 1.00058 loss)
I0416 13:53:03.467608   977 solver.cpp:542] Iteration 9600, lr = 0.1
I0416 13:53:16.962985   977 solver.cpp:221] Iteration 9620, loss = 0.936753
I0416 13:53:16.963011   977 solver.cpp:236]     Train net output #0: loss = 1.01025 (* 1 = 1.01025 loss)
I0416 13:53:16.963016   977 solver.cpp:542] Iteration 9620, lr = 0.1
I0416 13:53:30.449290   977 solver.cpp:221] Iteration 9640, loss = 0.902361
I0416 13:53:30.449316   977 solver.cpp:236]     Train net output #0: loss = 1.07898 (* 1 = 1.07898 loss)
I0416 13:53:30.449321   977 solver.cpp:542] Iteration 9640, lr = 0.1
I0416 13:53:43.943869   977 solver.cpp:221] Iteration 9660, loss = 0.943715
I0416 13:53:43.943895   977 solver.cpp:236]     Train net output #0: loss = 0.872264 (* 1 = 0.872264 loss)
I0416 13:53:43.943899   977 solver.cpp:542] Iteration 9660, lr = 0.1
I0416 13:53:57.449764   977 solver.cpp:221] Iteration 9680, loss = 0.930883
I0416 13:53:57.449791   977 solver.cpp:236]     Train net output #0: loss = 0.639166 (* 1 = 0.639166 loss)
I0416 13:53:57.449796   977 solver.cpp:542] Iteration 9680, lr = 0.1
I0416 13:54:10.941949   977 solver.cpp:221] Iteration 9700, loss = 0.900142
I0416 13:54:10.941977   977 solver.cpp:236]     Train net output #0: loss = 0.55541 (* 1 = 0.55541 loss)
I0416 13:54:10.941983   977 solver.cpp:542] Iteration 9700, lr = 0.1
I0416 13:54:24.427045   977 solver.cpp:221] Iteration 9720, loss = 0.947942
I0416 13:54:24.427073   977 solver.cpp:236]     Train net output #0: loss = 0.752407 (* 1 = 0.752407 loss)
I0416 13:54:24.427078   977 solver.cpp:542] Iteration 9720, lr = 0.1
I0416 13:54:37.929035   977 solver.cpp:221] Iteration 9740, loss = 0.988357
I0416 13:54:37.929062   977 solver.cpp:236]     Train net output #0: loss = 0.928578 (* 1 = 0.928578 loss)
I0416 13:54:37.929067   977 solver.cpp:542] Iteration 9740, lr = 0.1
I0416 13:54:51.408273   977 solver.cpp:221] Iteration 9760, loss = 0.976918
I0416 13:54:51.408300   977 solver.cpp:236]     Train net output #0: loss = 0.875994 (* 1 = 0.875994 loss)
I0416 13:54:51.408304   977 solver.cpp:542] Iteration 9760, lr = 0.1
I0416 13:55:04.905406   977 solver.cpp:221] Iteration 9780, loss = 0.907926
I0416 13:55:04.905432   977 solver.cpp:236]     Train net output #0: loss = 0.908628 (* 1 = 0.908628 loss)
I0416 13:55:04.905436   977 solver.cpp:542] Iteration 9780, lr = 0.1
I0416 13:55:17.750120   977 solver.cpp:316] Iteration 9800, Testing net (#0)
I0416 13:55:29.270670   977 solver.cpp:373]     Test net output #0: accuracy = 0.887642
I0416 13:55:29.270692   977 solver.cpp:373]     Test net output #1: loss = 0.415798 (* 1 = 0.415798 loss)
I0416 13:55:29.939287   977 solver.cpp:221] Iteration 9800, loss = 0.913934
I0416 13:55:29.939314   977 solver.cpp:236]     Train net output #0: loss = 0.793651 (* 1 = 0.793651 loss)
I0416 13:55:29.939318   977 solver.cpp:542] Iteration 9800, lr = 0.1
I0416 13:55:43.459679   977 solver.cpp:221] Iteration 9820, loss = 0.938036
I0416 13:55:43.459707   977 solver.cpp:236]     Train net output #0: loss = 1.0286 (* 1 = 1.0286 loss)
I0416 13:55:43.459712   977 solver.cpp:542] Iteration 9820, lr = 0.1
I0416 13:55:56.958869   977 solver.cpp:221] Iteration 9840, loss = 0.939887
I0416 13:55:56.958896   977 solver.cpp:236]     Train net output #0: loss = 0.877476 (* 1 = 0.877476 loss)
I0416 13:55:56.958900   977 solver.cpp:542] Iteration 9840, lr = 0.1
I0416 13:56:10.446557   977 solver.cpp:221] Iteration 9860, loss = 0.88826
I0416 13:56:10.446583   977 solver.cpp:236]     Train net output #0: loss = 0.877025 (* 1 = 0.877025 loss)
I0416 13:56:10.446588   977 solver.cpp:542] Iteration 9860, lr = 0.1
I0416 13:56:23.922428   977 solver.cpp:221] Iteration 9880, loss = 0.896892
I0416 13:56:23.922456   977 solver.cpp:236]     Train net output #0: loss = 0.868441 (* 1 = 0.868441 loss)
I0416 13:56:23.922461   977 solver.cpp:542] Iteration 9880, lr = 0.1
I0416 13:56:37.409744   977 solver.cpp:221] Iteration 9900, loss = 0.905201
I0416 13:56:37.409771   977 solver.cpp:236]     Train net output #0: loss = 0.529413 (* 1 = 0.529413 loss)
I0416 13:56:37.409775   977 solver.cpp:542] Iteration 9900, lr = 0.1
I0416 13:56:50.895766   977 solver.cpp:221] Iteration 9920, loss = 0.909957
I0416 13:56:50.895793   977 solver.cpp:236]     Train net output #0: loss = 0.736328 (* 1 = 0.736328 loss)
I0416 13:56:50.895797   977 solver.cpp:542] Iteration 9920, lr = 0.1
I0416 13:57:04.395620   977 solver.cpp:221] Iteration 9940, loss = 0.875175
I0416 13:57:04.395648   977 solver.cpp:236]     Train net output #0: loss = 0.938414 (* 1 = 0.938414 loss)
I0416 13:57:04.395653   977 solver.cpp:542] Iteration 9940, lr = 0.1
I0416 13:57:17.907658   977 solver.cpp:221] Iteration 9960, loss = 0.942799
I0416 13:57:17.907685   977 solver.cpp:236]     Train net output #0: loss = 1.0815 (* 1 = 1.0815 loss)
I0416 13:57:17.907690   977 solver.cpp:542] Iteration 9960, lr = 0.1
I0416 13:57:31.389495   977 solver.cpp:221] Iteration 9980, loss = 0.94643
I0416 13:57:31.389523   977 solver.cpp:236]     Train net output #0: loss = 0.870937 (* 1 = 0.870937 loss)
I0416 13:57:31.389526   977 solver.cpp:542] Iteration 9980, lr = 0.1
I0416 13:57:44.231617   977 solver.cpp:410] Snapshotting to binary proto file external/exp/snapshots/individually/cuhk03_iter_10000.caffemodel
I0416 13:57:44.308218   977 solver.cpp:705] Snapshotting solver state to binary proto fileexternal/exp/snapshots/individually/cuhk03_iter_10000.solverstate
I0416 13:57:44.336444   977 solver.cpp:316] Iteration 10000, Testing net (#0)
I0416 13:57:55.847483   977 solver.cpp:373]     Test net output #0: accuracy = 0.703612
I0416 13:57:55.847506   977 solver.cpp:373]     Test net output #1: loss = 1.24436 (* 1 = 1.24436 loss)
I0416 13:57:56.512665   977 solver.cpp:221] Iteration 10000, loss = 0.922617
I0416 13:57:56.512691   977 solver.cpp:236]     Train net output #0: loss = 0.991253 (* 1 = 0.991253 loss)
I0416 13:57:56.512696   977 solver.cpp:542] Iteration 10000, lr = 0.1
I0416 13:58:10.020442   977 solver.cpp:221] Iteration 10020, loss = 0.9192
I0416 13:58:10.020470   977 solver.cpp:236]     Train net output #0: loss = 0.899259 (* 1 = 0.899259 loss)
I0416 13:58:10.020474   977 solver.cpp:542] Iteration 10020, lr = 0.1
I0416 13:58:23.519265   977 solver.cpp:221] Iteration 10040, loss = 0.923375
I0416 13:58:23.519292   977 solver.cpp:236]     Train net output #0: loss = 1.19398 (* 1 = 1.19398 loss)
I0416 13:58:23.519299   977 solver.cpp:542] Iteration 10040, lr = 0.1
I0416 13:58:37.031844   977 solver.cpp:221] Iteration 10060, loss = 0.926223
I0416 13:58:37.031869   977 solver.cpp:236]     Train net output #0: loss = 0.786822 (* 1 = 0.786822 loss)
I0416 13:58:37.031873   977 solver.cpp:542] Iteration 10060, lr = 0.1
I0416 13:58:50.532500   977 solver.cpp:221] Iteration 10080, loss = 0.924815
I0416 13:58:50.532527   977 solver.cpp:236]     Train net output #0: loss = 1.07375 (* 1 = 1.07375 loss)
I0416 13:58:50.532531   977 solver.cpp:542] Iteration 10080, lr = 0.1
I0416 13:59:04.014513   977 solver.cpp:221] Iteration 10100, loss = 0.976905
I0416 13:59:04.014540   977 solver.cpp:236]     Train net output #0: loss = 0.75728 (* 1 = 0.75728 loss)
I0416 13:59:04.014544   977 solver.cpp:542] Iteration 10100, lr = 0.1
I0416 13:59:17.486263   977 solver.cpp:221] Iteration 10120, loss = 1.00693
I0416 13:59:17.486290   977 solver.cpp:236]     Train net output #0: loss = 0.699106 (* 1 = 0.699106 loss)
I0416 13:59:17.486295   977 solver.cpp:542] Iteration 10120, lr = 0.1
I0416 13:59:30.962085   977 solver.cpp:221] Iteration 10140, loss = 0.95222
I0416 13:59:30.962110   977 solver.cpp:236]     Train net output #0: loss = 0.763413 (* 1 = 0.763413 loss)
I0416 13:59:30.962116   977 solver.cpp:542] Iteration 10140, lr = 0.1
I0416 13:59:44.450498   977 solver.cpp:221] Iteration 10160, loss = 0.878299
I0416 13:59:44.450527   977 solver.cpp:236]     Train net output #0: loss = 0.861785 (* 1 = 0.861785 loss)
I0416 13:59:44.450532   977 solver.cpp:542] Iteration 10160, lr = 0.1
I0416 13:59:57.945441   977 solver.cpp:221] Iteration 10180, loss = 0.98418
I0416 13:59:57.945467   977 solver.cpp:236]     Train net output #0: loss = 1.09573 (* 1 = 1.09573 loss)
I0416 13:59:57.945472   977 solver.cpp:542] Iteration 10180, lr = 0.1
I0416 14:00:10.754799   977 solver.cpp:316] Iteration 10200, Testing net (#0)
I0416 14:00:22.267127   977 solver.cpp:373]     Test net output #0: accuracy = 0.771864
I0416 14:00:22.267148   977 solver.cpp:373]     Test net output #1: loss = 0.915079 (* 1 = 0.915079 loss)
I0416 14:00:22.932778   977 solver.cpp:221] Iteration 10200, loss = 0.940257
I0416 14:00:22.932806   977 solver.cpp:236]     Train net output #0: loss = 0.928672 (* 1 = 0.928672 loss)
I0416 14:00:22.932811   977 solver.cpp:542] Iteration 10200, lr = 0.1
I0416 14:00:36.415884   977 solver.cpp:221] Iteration 10220, loss = 0.987292
I0416 14:00:36.415911   977 solver.cpp:236]     Train net output #0: loss = 0.793106 (* 1 = 0.793106 loss)
I0416 14:00:36.415916   977 solver.cpp:542] Iteration 10220, lr = 0.1
I0416 14:00:49.892485   977 solver.cpp:221] Iteration 10240, loss = 0.974661
I0416 14:00:49.892513   977 solver.cpp:236]     Train net output #0: loss = 1.12765 (* 1 = 1.12765 loss)
I0416 14:00:49.892518   977 solver.cpp:542] Iteration 10240, lr = 0.1
I0416 14:01:03.392180   977 solver.cpp:221] Iteration 10260, loss = 0.954314
I0416 14:01:03.392209   977 solver.cpp:236]     Train net output #0: loss = 0.966439 (* 1 = 0.966439 loss)
I0416 14:01:03.392213   977 solver.cpp:542] Iteration 10260, lr = 0.1
I0416 14:01:16.887699   977 solver.cpp:221] Iteration 10280, loss = 0.957891
I0416 14:01:16.887728   977 solver.cpp:236]     Train net output #0: loss = 0.705199 (* 1 = 0.705199 loss)
I0416 14:01:16.887733   977 solver.cpp:542] Iteration 10280, lr = 0.1
I0416 14:01:30.390255   977 solver.cpp:221] Iteration 10300, loss = 0.889715
I0416 14:01:30.390283   977 solver.cpp:236]     Train net output #0: loss = 0.720019 (* 1 = 0.720019 loss)
I0416 14:01:30.390287   977 solver.cpp:542] Iteration 10300, lr = 0.1
I0416 14:01:43.864531   977 solver.cpp:221] Iteration 10320, loss = 0.88728
I0416 14:01:43.864559   977 solver.cpp:236]     Train net output #0: loss = 0.888139 (* 1 = 0.888139 loss)
I0416 14:01:43.864564   977 solver.cpp:542] Iteration 10320, lr = 0.1
I0416 14:01:57.352082   977 solver.cpp:221] Iteration 10340, loss = 0.902019
I0416 14:01:57.352110   977 solver.cpp:236]     Train net output #0: loss = 1.15371 (* 1 = 1.15371 loss)
I0416 14:01:57.352115   977 solver.cpp:542] Iteration 10340, lr = 0.1
I0416 14:02:10.869962   977 solver.cpp:221] Iteration 10360, loss = 0.96968
I0416 14:02:10.869989   977 solver.cpp:236]     Train net output #0: loss = 0.591181 (* 1 = 0.591181 loss)
I0416 14:02:10.869994   977 solver.cpp:542] Iteration 10360, lr = 0.1
I0416 14:02:24.381317   977 solver.cpp:221] Iteration 10380, loss = 0.948872
I0416 14:02:24.381345   977 solver.cpp:236]     Train net output #0: loss = 0.970476 (* 1 = 0.970476 loss)
I0416 14:02:24.381350   977 solver.cpp:542] Iteration 10380, lr = 0.1
I0416 14:02:37.213443   977 solver.cpp:316] Iteration 10400, Testing net (#0)
I0416 14:02:48.724140   977 solver.cpp:373]     Test net output #0: accuracy = 0.885361
I0416 14:02:48.724161   977 solver.cpp:373]     Test net output #1: loss = 0.417944 (* 1 = 0.417944 loss)
I0416 14:02:49.391206   977 solver.cpp:221] Iteration 10400, loss = 0.967726
I0416 14:02:49.391233   977 solver.cpp:236]     Train net output #0: loss = 1.17931 (* 1 = 1.17931 loss)
I0416 14:02:49.391238   977 solver.cpp:542] Iteration 10400, lr = 0.1
I0416 14:03:02.897361   977 solver.cpp:221] Iteration 10420, loss = 0.911133
I0416 14:03:02.897388   977 solver.cpp:236]     Train net output #0: loss = 1.25662 (* 1 = 1.25662 loss)
I0416 14:03:02.897392   977 solver.cpp:542] Iteration 10420, lr = 0.1
I0416 14:03:16.403650   977 solver.cpp:221] Iteration 10440, loss = 0.856183
I0416 14:03:16.403678   977 solver.cpp:236]     Train net output #0: loss = 0.701687 (* 1 = 0.701687 loss)
I0416 14:03:16.403682   977 solver.cpp:542] Iteration 10440, lr = 0.1
I0416 14:03:29.906949   977 solver.cpp:221] Iteration 10460, loss = 0.890812
I0416 14:03:29.906976   977 solver.cpp:236]     Train net output #0: loss = 0.870191 (* 1 = 0.870191 loss)
I0416 14:03:29.906980   977 solver.cpp:542] Iteration 10460, lr = 0.1
I0416 14:03:43.404191   977 solver.cpp:221] Iteration 10480, loss = 0.901661
I0416 14:03:43.404217   977 solver.cpp:236]     Train net output #0: loss = 0.588001 (* 1 = 0.588001 loss)
I0416 14:03:43.404222   977 solver.cpp:542] Iteration 10480, lr = 0.1
I0416 14:03:56.876878   977 solver.cpp:221] Iteration 10500, loss = 0.940898
I0416 14:03:56.876904   977 solver.cpp:236]     Train net output #0: loss = 1.04059 (* 1 = 1.04059 loss)
I0416 14:03:56.876909   977 solver.cpp:542] Iteration 10500, lr = 0.1
I0416 14:04:10.391216   977 solver.cpp:221] Iteration 10520, loss = 0.917522
I0416 14:04:10.391242   977 solver.cpp:236]     Train net output #0: loss = 0.655189 (* 1 = 0.655189 loss)
I0416 14:04:10.391247   977 solver.cpp:542] Iteration 10520, lr = 0.1
I0416 14:04:23.902570   977 solver.cpp:221] Iteration 10540, loss = 0.907433
I0416 14:04:23.902598   977 solver.cpp:236]     Train net output #0: loss = 1.03074 (* 1 = 1.03074 loss)
I0416 14:04:23.902602   977 solver.cpp:542] Iteration 10540, lr = 0.1
I0416 14:04:37.415648   977 solver.cpp:221] Iteration 10560, loss = 0.938169
I0416 14:04:37.415676   977 solver.cpp:236]     Train net output #0: loss = 1.24264 (* 1 = 1.24264 loss)
I0416 14:04:37.415680   977 solver.cpp:542] Iteration 10560, lr = 0.1
I0416 14:04:50.919968   977 solver.cpp:221] Iteration 10580, loss = 0.973753
I0416 14:04:50.919996   977 solver.cpp:236]     Train net output #0: loss = 1.3841 (* 1 = 1.3841 loss)
I0416 14:04:50.920001   977 solver.cpp:542] Iteration 10580, lr = 0.1
I0416 14:05:03.760437   977 solver.cpp:316] Iteration 10600, Testing net (#0)
I0416 14:05:15.274251   977 solver.cpp:373]     Test net output #0: accuracy = 0.85
I0416 14:05:15.274272   977 solver.cpp:373]     Test net output #1: loss = 0.557671 (* 1 = 0.557671 loss)
I0416 14:05:15.943610   977 solver.cpp:221] Iteration 10600, loss = 0.931377
I0416 14:05:15.943639   977 solver.cpp:236]     Train net output #0: loss = 1.12907 (* 1 = 1.12907 loss)
I0416 14:05:15.943644   977 solver.cpp:542] Iteration 10600, lr = 0.1
I0416 14:05:29.463626   977 solver.cpp:221] Iteration 10620, loss = 0.926094
I0416 14:05:29.463654   977 solver.cpp:236]     Train net output #0: loss = 0.954163 (* 1 = 0.954163 loss)
I0416 14:05:29.463659   977 solver.cpp:542] Iteration 10620, lr = 0.1
I0416 14:05:42.972611   977 solver.cpp:221] Iteration 10640, loss = 0.910354
I0416 14:05:42.972637   977 solver.cpp:236]     Train net output #0: loss = 0.954569 (* 1 = 0.954569 loss)
I0416 14:05:42.972642   977 solver.cpp:542] Iteration 10640, lr = 0.1
I0416 14:05:56.491884   977 solver.cpp:221] Iteration 10660, loss = 0.916319
I0416 14:05:56.491912   977 solver.cpp:236]     Train net output #0: loss = 0.784247 (* 1 = 0.784247 loss)
I0416 14:05:56.491917   977 solver.cpp:542] Iteration 10660, lr = 0.1
I0416 14:06:10.009018   977 solver.cpp:221] Iteration 10680, loss = 0.966276
I0416 14:06:10.009045   977 solver.cpp:236]     Train net output #0: loss = 0.943891 (* 1 = 0.943891 loss)
I0416 14:06:10.009050   977 solver.cpp:542] Iteration 10680, lr = 0.1
I0416 14:06:23.520344   977 solver.cpp:221] Iteration 10700, loss = 0.912803
I0416 14:06:23.520370   977 solver.cpp:236]     Train net output #0: loss = 0.646825 (* 1 = 0.646825 loss)
I0416 14:06:23.520375   977 solver.cpp:542] Iteration 10700, lr = 0.1
I0416 14:06:37.043268   977 solver.cpp:221] Iteration 10720, loss = 0.971126
I0416 14:06:37.043297   977 solver.cpp:236]     Train net output #0: loss = 0.848248 (* 1 = 0.848248 loss)
I0416 14:06:37.043301   977 solver.cpp:542] Iteration 10720, lr = 0.1
I0416 14:06:50.574040   977 solver.cpp:221] Iteration 10740, loss = 0.895652
I0416 14:06:50.574066   977 solver.cpp:236]     Train net output #0: loss = 0.903815 (* 1 = 0.903815 loss)
I0416 14:06:50.574071   977 solver.cpp:542] Iteration 10740, lr = 0.1
I0416 14:07:04.109045   977 solver.cpp:221] Iteration 10760, loss = 0.876661
I0416 14:07:04.109073   977 solver.cpp:236]     Train net output #0: loss = 1.16716 (* 1 = 1.16716 loss)
I0416 14:07:04.109078   977 solver.cpp:542] Iteration 10760, lr = 0.1
I0416 14:07:17.656249   977 solver.cpp:221] Iteration 10780, loss = 0.929818
I0416 14:07:17.656276   977 solver.cpp:236]     Train net output #0: loss = 1.01918 (* 1 = 1.01918 loss)
I0416 14:07:17.656281   977 solver.cpp:542] Iteration 10780, lr = 0.1
I0416 14:07:30.532727   977 solver.cpp:316] Iteration 10800, Testing net (#0)
I0416 14:07:42.047410   977 solver.cpp:373]     Test net output #0: accuracy = 0.840684
I0416 14:07:42.047431   977 solver.cpp:373]     Test net output #1: loss = 0.61791 (* 1 = 0.61791 loss)
I0416 14:07:42.713999   977 solver.cpp:221] Iteration 10800, loss = 0.93935
I0416 14:07:42.714027   977 solver.cpp:236]     Train net output #0: loss = 0.865754 (* 1 = 0.865754 loss)
I0416 14:07:42.714031   977 solver.cpp:542] Iteration 10800, lr = 0.1
I0416 14:07:56.215153   977 solver.cpp:221] Iteration 10820, loss = 0.935124
I0416 14:07:56.215181   977 solver.cpp:236]     Train net output #0: loss = 0.704675 (* 1 = 0.704675 loss)
I0416 14:07:56.215185   977 solver.cpp:542] Iteration 10820, lr = 0.1
I0416 14:08:09.736713   977 solver.cpp:221] Iteration 10840, loss = 0.894387
I0416 14:08:09.736742   977 solver.cpp:236]     Train net output #0: loss = 0.902787 (* 1 = 0.902787 loss)
I0416 14:08:09.736745   977 solver.cpp:542] Iteration 10840, lr = 0.1
I0416 14:08:23.246598   977 solver.cpp:221] Iteration 10860, loss = 0.91342
I0416 14:08:23.246625   977 solver.cpp:236]     Train net output #0: loss = 0.900711 (* 1 = 0.900711 loss)
I0416 14:08:23.246629   977 solver.cpp:542] Iteration 10860, lr = 0.1
I0416 14:08:36.735957   977 solver.cpp:221] Iteration 10880, loss = 0.926851
I0416 14:08:36.735985   977 solver.cpp:236]     Train net output #0: loss = 0.768026 (* 1 = 0.768026 loss)
I0416 14:08:36.735988   977 solver.cpp:542] Iteration 10880, lr = 0.1
I0416 14:08:50.236834   977 solver.cpp:221] Iteration 10900, loss = 0.883735
I0416 14:08:50.236861   977 solver.cpp:236]     Train net output #0: loss = 0.909545 (* 1 = 0.909545 loss)
I0416 14:08:50.236866   977 solver.cpp:542] Iteration 10900, lr = 0.1
I0416 14:09:03.739428   977 solver.cpp:221] Iteration 10920, loss = 0.890094
I0416 14:09:03.739455   977 solver.cpp:236]     Train net output #0: loss = 1.15674 (* 1 = 1.15674 loss)
I0416 14:09:03.739461   977 solver.cpp:542] Iteration 10920, lr = 0.1
I0416 14:09:17.246217   977 solver.cpp:221] Iteration 10940, loss = 0.898962
I0416 14:09:17.246245   977 solver.cpp:236]     Train net output #0: loss = 0.970418 (* 1 = 0.970418 loss)
I0416 14:09:17.246249   977 solver.cpp:542] Iteration 10940, lr = 0.1
I0416 14:09:30.756566   977 solver.cpp:221] Iteration 10960, loss = 0.858627
I0416 14:09:30.756592   977 solver.cpp:236]     Train net output #0: loss = 0.518163 (* 1 = 0.518163 loss)
I0416 14:09:30.756597   977 solver.cpp:542] Iteration 10960, lr = 0.1
I0416 14:09:44.279986   977 solver.cpp:221] Iteration 10980, loss = 0.832984
I0416 14:09:44.280015   977 solver.cpp:236]     Train net output #0: loss = 1.13376 (* 1 = 1.13376 loss)
I0416 14:09:44.280019   977 solver.cpp:542] Iteration 10980, lr = 0.1
I0416 14:09:57.144028   977 solver.cpp:316] Iteration 11000, Testing net (#0)
I0416 14:10:08.669350   977 solver.cpp:373]     Test net output #0: accuracy = 0.595437
I0416 14:10:08.669371   977 solver.cpp:373]     Test net output #1: loss = 1.95749 (* 1 = 1.95749 loss)
I0416 14:10:09.336926   977 solver.cpp:221] Iteration 11000, loss = 0.83904
I0416 14:10:09.336954   977 solver.cpp:236]     Train net output #0: loss = 0.784116 (* 1 = 0.784116 loss)
I0416 14:10:09.336961   977 solver.cpp:542] Iteration 11000, lr = 0.1
I0416 14:10:22.829789   977 solver.cpp:221] Iteration 11020, loss = 0.94061
I0416 14:10:22.829816   977 solver.cpp:236]     Train net output #0: loss = 0.76647 (* 1 = 0.76647 loss)
I0416 14:10:22.829821   977 solver.cpp:542] Iteration 11020, lr = 0.1
I0416 14:10:36.319294   977 solver.cpp:221] Iteration 11040, loss = 0.872459
I0416 14:10:36.319322   977 solver.cpp:236]     Train net output #0: loss = 1.01084 (* 1 = 1.01084 loss)
I0416 14:10:36.319327   977 solver.cpp:542] Iteration 11040, lr = 0.1
I0416 14:10:49.827126   977 solver.cpp:221] Iteration 11060, loss = 0.818627
I0416 14:10:49.827153   977 solver.cpp:236]     Train net output #0: loss = 0.864835 (* 1 = 0.864835 loss)
I0416 14:10:49.827158   977 solver.cpp:542] Iteration 11060, lr = 0.1
I0416 14:11:03.314510   977 solver.cpp:221] Iteration 11080, loss = 0.91578
I0416 14:11:03.314538   977 solver.cpp:236]     Train net output #0: loss = 0.723964 (* 1 = 0.723964 loss)
I0416 14:11:03.314543   977 solver.cpp:542] Iteration 11080, lr = 0.1
I0416 14:11:16.794572   977 solver.cpp:221] Iteration 11100, loss = 0.906575
I0416 14:11:16.794600   977 solver.cpp:236]     Train net output #0: loss = 1.1436 (* 1 = 1.1436 loss)
I0416 14:11:16.794605   977 solver.cpp:542] Iteration 11100, lr = 0.1
I0416 14:11:30.283329   977 solver.cpp:221] Iteration 11120, loss = 0.905266
I0416 14:11:30.283357   977 solver.cpp:236]     Train net output #0: loss = 0.856038 (* 1 = 0.856038 loss)
I0416 14:11:30.283362   977 solver.cpp:542] Iteration 11120, lr = 0.1
I0416 14:11:43.775367   977 solver.cpp:221] Iteration 11140, loss = 0.898937
I0416 14:11:43.775393   977 solver.cpp:236]     Train net output #0: loss = 0.928079 (* 1 = 0.928079 loss)
I0416 14:11:43.775398   977 solver.cpp:542] Iteration 11140, lr = 0.1
I0416 14:11:57.262776   977 solver.cpp:221] Iteration 11160, loss = 0.911824
I0416 14:11:57.262804   977 solver.cpp:236]     Train net output #0: loss = 0.874623 (* 1 = 0.874623 loss)
I0416 14:11:57.262809   977 solver.cpp:542] Iteration 11160, lr = 0.1
I0416 14:12:10.759624   977 solver.cpp:221] Iteration 11180, loss = 0.942333
I0416 14:12:10.759650   977 solver.cpp:236]     Train net output #0: loss = 0.839014 (* 1 = 0.839014 loss)
I0416 14:12:10.759655   977 solver.cpp:542] Iteration 11180, lr = 0.1
I0416 14:12:23.600152   977 solver.cpp:316] Iteration 11200, Testing net (#0)
I0416 14:12:35.124478   977 solver.cpp:373]     Test net output #0: accuracy = 0.778518
I0416 14:12:35.124500   977 solver.cpp:373]     Test net output #1: loss = 0.857037 (* 1 = 0.857037 loss)
I0416 14:12:35.790915   977 solver.cpp:221] Iteration 11200, loss = 0.944257
I0416 14:12:35.790941   977 solver.cpp:236]     Train net output #0: loss = 0.657223 (* 1 = 0.657223 loss)
I0416 14:12:35.790946   977 solver.cpp:542] Iteration 11200, lr = 0.1
I0416 14:12:49.289801   977 solver.cpp:221] Iteration 11220, loss = 0.953566
I0416 14:12:49.289829   977 solver.cpp:236]     Train net output #0: loss = 1.09721 (* 1 = 1.09721 loss)
I0416 14:12:49.289834   977 solver.cpp:542] Iteration 11220, lr = 0.1
I0416 14:13:02.800199   977 solver.cpp:221] Iteration 11240, loss = 0.980297
I0416 14:13:02.800225   977 solver.cpp:236]     Train net output #0: loss = 1.04181 (* 1 = 1.04181 loss)
I0416 14:13:02.800231   977 solver.cpp:542] Iteration 11240, lr = 0.1
I0416 14:13:16.322868   977 solver.cpp:221] Iteration 11260, loss = 0.857323
I0416 14:13:16.322896   977 solver.cpp:236]     Train net output #0: loss = 0.80073 (* 1 = 0.80073 loss)
I0416 14:13:16.322899   977 solver.cpp:542] Iteration 11260, lr = 0.1
I0416 14:13:29.851793   977 solver.cpp:221] Iteration 11280, loss = 0.835663
I0416 14:13:29.851819   977 solver.cpp:236]     Train net output #0: loss = 0.78221 (* 1 = 0.78221 loss)
I0416 14:13:29.851824   977 solver.cpp:542] Iteration 11280, lr = 0.1
I0416 14:13:43.374653   977 solver.cpp:221] Iteration 11300, loss = 0.943923
I0416 14:13:43.374680   977 solver.cpp:236]     Train net output #0: loss = 0.958866 (* 1 = 0.958866 loss)
I0416 14:13:43.374686   977 solver.cpp:542] Iteration 11300, lr = 0.1
I0416 14:13:56.873463   977 solver.cpp:221] Iteration 11320, loss = 0.961907
I0416 14:13:56.873489   977 solver.cpp:236]     Train net output #0: loss = 0.890057 (* 1 = 0.890057 loss)
I0416 14:13:56.873493   977 solver.cpp:542] Iteration 11320, lr = 0.1
I0416 14:14:10.372954   977 solver.cpp:221] Iteration 11340, loss = 0.951946
I0416 14:14:10.372980   977 solver.cpp:236]     Train net output #0: loss = 0.9833 (* 1 = 0.9833 loss)
I0416 14:14:10.372985   977 solver.cpp:542] Iteration 11340, lr = 0.1
I0416 14:14:23.892935   977 solver.cpp:221] Iteration 11360, loss = 0.9417
I0416 14:14:23.892962   977 solver.cpp:236]     Train net output #0: loss = 1.03497 (* 1 = 1.03497 loss)
I0416 14:14:23.892967   977 solver.cpp:542] Iteration 11360, lr = 0.1
I0416 14:14:37.400171   977 solver.cpp:221] Iteration 11380, loss = 0.929357
I0416 14:14:37.400197   977 solver.cpp:236]     Train net output #0: loss = 0.793638 (* 1 = 0.793638 loss)
I0416 14:14:37.400202   977 solver.cpp:542] Iteration 11380, lr = 0.1
I0416 14:14:50.257863   977 solver.cpp:316] Iteration 11400, Testing net (#0)
I0416 14:15:01.774327   977 solver.cpp:373]     Test net output #0: accuracy = 0.825285
I0416 14:15:01.774349   977 solver.cpp:373]     Test net output #1: loss = 0.646258 (* 1 = 0.646258 loss)
I0416 14:15:02.442286   977 solver.cpp:221] Iteration 11400, loss = 0.906822
I0416 14:15:02.442314   977 solver.cpp:236]     Train net output #0: loss = 1.03099 (* 1 = 1.03099 loss)
I0416 14:15:02.442320   977 solver.cpp:542] Iteration 11400, lr = 0.1
I0416 14:15:15.958449   977 solver.cpp:221] Iteration 11420, loss = 0.897971
I0416 14:15:15.958477   977 solver.cpp:236]     Train net output #0: loss = 0.855635 (* 1 = 0.855635 loss)
I0416 14:15:15.958482   977 solver.cpp:542] Iteration 11420, lr = 0.1
I0416 14:15:29.449028   977 solver.cpp:221] Iteration 11440, loss = 0.960645
I0416 14:15:29.449055   977 solver.cpp:236]     Train net output #0: loss = 1.14575 (* 1 = 1.14575 loss)
I0416 14:15:29.449060   977 solver.cpp:542] Iteration 11440, lr = 0.1
I0416 14:15:42.940321   977 solver.cpp:221] Iteration 11460, loss = 0.912342
I0416 14:15:42.940347   977 solver.cpp:236]     Train net output #0: loss = 0.774786 (* 1 = 0.774786 loss)
I0416 14:15:42.940351   977 solver.cpp:542] Iteration 11460, lr = 0.1
I0416 14:15:56.431310   977 solver.cpp:221] Iteration 11480, loss = 0.903518
I0416 14:15:56.431336   977 solver.cpp:236]     Train net output #0: loss = 1.2293 (* 1 = 1.2293 loss)
I0416 14:15:56.431341   977 solver.cpp:542] Iteration 11480, lr = 0.1
I0416 14:16:09.924497   977 solver.cpp:221] Iteration 11500, loss = 0.874751
I0416 14:16:09.924525   977 solver.cpp:236]     Train net output #0: loss = 0.856927 (* 1 = 0.856927 loss)
I0416 14:16:09.924530   977 solver.cpp:542] Iteration 11500, lr = 0.1
I0416 14:16:23.415015   977 solver.cpp:221] Iteration 11520, loss = 0.927746
I0416 14:16:23.415042   977 solver.cpp:236]     Train net output #0: loss = 0.901637 (* 1 = 0.901637 loss)
I0416 14:16:23.415047   977 solver.cpp:542] Iteration 11520, lr = 0.1
I0416 14:16:36.913801   977 solver.cpp:221] Iteration 11540, loss = 0.911555
I0416 14:16:36.913827   977 solver.cpp:236]     Train net output #0: loss = 0.881879 (* 1 = 0.881879 loss)
I0416 14:16:36.913832   977 solver.cpp:542] Iteration 11540, lr = 0.1
I0416 14:16:50.426669   977 solver.cpp:221] Iteration 11560, loss = 0.889595
I0416 14:16:50.426697   977 solver.cpp:236]     Train net output #0: loss = 0.818455 (* 1 = 0.818455 loss)
I0416 14:16:50.426702   977 solver.cpp:542] Iteration 11560, lr = 0.1
I0416 14:17:03.963206   977 solver.cpp:221] Iteration 11580, loss = 0.904175
I0416 14:17:03.963233   977 solver.cpp:236]     Train net output #0: loss = 0.859759 (* 1 = 0.859759 loss)
I0416 14:17:03.963238   977 solver.cpp:542] Iteration 11580, lr = 0.1
I0416 14:17:16.820552   977 solver.cpp:316] Iteration 11600, Testing net (#0)
I0416 14:17:28.337123   977 solver.cpp:373]     Test net output #0: accuracy = 0.455133
I0416 14:17:28.337146   977 solver.cpp:373]     Test net output #1: loss = 3.43816 (* 1 = 3.43816 loss)
I0416 14:17:29.003612   977 solver.cpp:221] Iteration 11600, loss = 0.940206
I0416 14:17:29.003640   977 solver.cpp:236]     Train net output #0: loss = 0.980891 (* 1 = 0.980891 loss)
I0416 14:17:29.003645   977 solver.cpp:542] Iteration 11600, lr = 0.1
I0416 14:17:42.534921   977 solver.cpp:221] Iteration 11620, loss = 0.877976
I0416 14:17:42.534948   977 solver.cpp:236]     Train net output #0: loss = 1.05527 (* 1 = 1.05527 loss)
I0416 14:17:42.534953   977 solver.cpp:542] Iteration 11620, lr = 0.1
I0416 14:17:56.066160   977 solver.cpp:221] Iteration 11640, loss = 0.899118
I0416 14:17:56.066187   977 solver.cpp:236]     Train net output #0: loss = 0.921263 (* 1 = 0.921263 loss)
I0416 14:17:56.066192   977 solver.cpp:542] Iteration 11640, lr = 0.1
I0416 14:18:09.593561   977 solver.cpp:221] Iteration 11660, loss = 0.922724
I0416 14:18:09.593588   977 solver.cpp:236]     Train net output #0: loss = 0.850945 (* 1 = 0.850945 loss)
I0416 14:18:09.593593   977 solver.cpp:542] Iteration 11660, lr = 0.1
I0416 14:18:23.093432   977 solver.cpp:221] Iteration 11680, loss = 0.899432
I0416 14:18:23.093459   977 solver.cpp:236]     Train net output #0: loss = 0.837711 (* 1 = 0.837711 loss)
I0416 14:18:23.093463   977 solver.cpp:542] Iteration 11680, lr = 0.1
I0416 14:18:36.611214   977 solver.cpp:221] Iteration 11700, loss = 0.883016
I0416 14:18:36.611241   977 solver.cpp:236]     Train net output #0: loss = 0.949481 (* 1 = 0.949481 loss)
I0416 14:18:36.611245   977 solver.cpp:542] Iteration 11700, lr = 0.1
I0416 14:18:50.127671   977 solver.cpp:221] Iteration 11720, loss = 0.898457
I0416 14:18:50.127692   977 solver.cpp:236]     Train net output #0: loss = 0.784404 (* 1 = 0.784404 loss)
I0416 14:18:50.127697   977 solver.cpp:542] Iteration 11720, lr = 0.1
I0416 14:19:03.637612   977 solver.cpp:221] Iteration 11740, loss = 0.87546
I0416 14:19:03.637639   977 solver.cpp:236]     Train net output #0: loss = 0.791888 (* 1 = 0.791888 loss)
I0416 14:19:03.637645   977 solver.cpp:542] Iteration 11740, lr = 0.1
I0416 14:19:17.127235   977 solver.cpp:221] Iteration 11760, loss = 0.88182
I0416 14:19:17.127262   977 solver.cpp:236]     Train net output #0: loss = 0.762965 (* 1 = 0.762965 loss)
I0416 14:19:17.127266   977 solver.cpp:542] Iteration 11760, lr = 0.1
I0416 14:19:30.609784   977 solver.cpp:221] Iteration 11780, loss = 0.892557
I0416 14:19:30.609812   977 solver.cpp:236]     Train net output #0: loss = 1.05406 (* 1 = 1.05406 loss)
I0416 14:19:30.609817   977 solver.cpp:542] Iteration 11780, lr = 0.1
I0416 14:19:43.454632   977 solver.cpp:316] Iteration 11800, Testing net (#0)
I0416 14:19:54.970687   977 solver.cpp:373]     Test net output #0: accuracy = 0.524144
I0416 14:19:54.970710   977 solver.cpp:373]     Test net output #1: loss = 2.41027 (* 1 = 2.41027 loss)
I0416 14:19:55.636674   977 solver.cpp:221] Iteration 11800, loss = 0.81335
I0416 14:19:55.636703   977 solver.cpp:236]     Train net output #0: loss = 0.742177 (* 1 = 0.742177 loss)
I0416 14:19:55.636708   977 solver.cpp:542] Iteration 11800, lr = 0.1
I0416 14:20:09.132648   977 solver.cpp:221] Iteration 11820, loss = 0.824412
I0416 14:20:09.132676   977 solver.cpp:236]     Train net output #0: loss = 0.660148 (* 1 = 0.660148 loss)
I0416 14:20:09.132681   977 solver.cpp:542] Iteration 11820, lr = 0.1
I0416 14:20:22.641962   977 solver.cpp:221] Iteration 11840, loss = 0.872253
I0416 14:20:22.641989   977 solver.cpp:236]     Train net output #0: loss = 0.85788 (* 1 = 0.85788 loss)
I0416 14:20:22.641993   977 solver.cpp:542] Iteration 11840, lr = 0.1
I0416 14:20:36.161703   977 solver.cpp:221] Iteration 11860, loss = 0.886212
I0416 14:20:36.161731   977 solver.cpp:236]     Train net output #0: loss = 0.878526 (* 1 = 0.878526 loss)
I0416 14:20:36.161736   977 solver.cpp:542] Iteration 11860, lr = 0.1
I0416 14:20:49.648393   977 solver.cpp:221] Iteration 11880, loss = 0.85522
I0416 14:20:49.648421   977 solver.cpp:236]     Train net output #0: loss = 0.493493 (* 1 = 0.493493 loss)
I0416 14:20:49.648425   977 solver.cpp:542] Iteration 11880, lr = 0.1
I0416 14:21:03.131072   977 solver.cpp:221] Iteration 11900, loss = 0.786232
I0416 14:21:03.131100   977 solver.cpp:236]     Train net output #0: loss = 1.23638 (* 1 = 1.23638 loss)
I0416 14:21:03.131104   977 solver.cpp:542] Iteration 11900, lr = 0.1
I0416 14:21:16.619506   977 solver.cpp:221] Iteration 11920, loss = 0.862589
I0416 14:21:16.619534   977 solver.cpp:236]     Train net output #0: loss = 0.575403 (* 1 = 0.575403 loss)
I0416 14:21:16.619537   977 solver.cpp:542] Iteration 11920, lr = 0.1
I0416 14:21:30.108486   977 solver.cpp:221] Iteration 11940, loss = 0.877152
I0416 14:21:30.108513   977 solver.cpp:236]     Train net output #0: loss = 0.894586 (* 1 = 0.894586 loss)
I0416 14:21:30.108518   977 solver.cpp:542] Iteration 11940, lr = 0.1
I0416 14:21:43.613075   977 solver.cpp:221] Iteration 11960, loss = 0.843851
I0416 14:21:43.613103   977 solver.cpp:236]     Train net output #0: loss = 0.942347 (* 1 = 0.942347 loss)
I0416 14:21:43.613107   977 solver.cpp:542] Iteration 11960, lr = 0.1
I0416 14:21:57.108360   977 solver.cpp:221] Iteration 11980, loss = 0.883531
I0416 14:21:57.108388   977 solver.cpp:236]     Train net output #0: loss = 0.806039 (* 1 = 0.806039 loss)
I0416 14:21:57.108393   977 solver.cpp:542] Iteration 11980, lr = 0.1
I0416 14:22:09.949204   977 solver.cpp:316] Iteration 12000, Testing net (#0)
I0416 14:22:21.462793   977 solver.cpp:373]     Test net output #0: accuracy = 0.849429
I0416 14:22:21.462815   977 solver.cpp:373]     Test net output #1: loss = 0.579261 (* 1 = 0.579261 loss)
I0416 14:22:22.130203   977 solver.cpp:221] Iteration 12000, loss = 0.836193
I0416 14:22:22.130230   977 solver.cpp:236]     Train net output #0: loss = 0.830365 (* 1 = 0.830365 loss)
I0416 14:22:22.130235   977 solver.cpp:542] Iteration 12000, lr = 0.1
I0416 14:22:35.645052   977 solver.cpp:221] Iteration 12020, loss = 0.862873
I0416 14:22:35.645079   977 solver.cpp:236]     Train net output #0: loss = 0.957361 (* 1 = 0.957361 loss)
I0416 14:22:35.645084   977 solver.cpp:542] Iteration 12020, lr = 0.1
I0416 14:22:49.156134   977 solver.cpp:221] Iteration 12040, loss = 0.912287
I0416 14:22:49.156162   977 solver.cpp:236]     Train net output #0: loss = 0.758974 (* 1 = 0.758974 loss)
I0416 14:22:49.156167   977 solver.cpp:542] Iteration 12040, lr = 0.1
I0416 14:23:02.653029   977 solver.cpp:221] Iteration 12060, loss = 0.926637
I0416 14:23:02.653056   977 solver.cpp:236]     Train net output #0: loss = 1.1503 (* 1 = 1.1503 loss)
I0416 14:23:02.653060   977 solver.cpp:542] Iteration 12060, lr = 0.1
I0416 14:23:16.157752   977 solver.cpp:221] Iteration 12080, loss = 0.888283
I0416 14:23:16.157778   977 solver.cpp:236]     Train net output #0: loss = 1.39703 (* 1 = 1.39703 loss)
I0416 14:23:16.157783   977 solver.cpp:542] Iteration 12080, lr = 0.1
I0416 14:23:29.663671   977 solver.cpp:221] Iteration 12100, loss = 0.84622
I0416 14:23:29.663698   977 solver.cpp:236]     Train net output #0: loss = 0.7825 (* 1 = 0.7825 loss)
I0416 14:23:29.663703   977 solver.cpp:542] Iteration 12100, lr = 0.1
I0416 14:23:43.189667   977 solver.cpp:221] Iteration 12120, loss = 0.875242
I0416 14:23:43.189697   977 solver.cpp:236]     Train net output #0: loss = 0.722573 (* 1 = 0.722573 loss)
I0416 14:23:43.189702   977 solver.cpp:542] Iteration 12120, lr = 0.1
I0416 14:23:56.672405   977 solver.cpp:221] Iteration 12140, loss = 0.908981
I0416 14:23:56.672430   977 solver.cpp:236]     Train net output #0: loss = 1.04054 (* 1 = 1.04054 loss)
I0416 14:23:56.672435   977 solver.cpp:542] Iteration 12140, lr = 0.1
I0416 14:24:10.165871   977 solver.cpp:221] Iteration 12160, loss = 0.96125
I0416 14:24:10.165899   977 solver.cpp:236]     Train net output #0: loss = 0.962291 (* 1 = 0.962291 loss)
I0416 14:24:10.165905   977 solver.cpp:542] Iteration 12160, lr = 0.1
I0416 14:24:23.680150   977 solver.cpp:221] Iteration 12180, loss = 0.900275
I0416 14:24:23.680178   977 solver.cpp:236]     Train net output #0: loss = 0.713993 (* 1 = 0.713993 loss)
I0416 14:24:23.680182   977 solver.cpp:542] Iteration 12180, lr = 0.1
I0416 14:24:36.545850   977 solver.cpp:316] Iteration 12200, Testing net (#0)
I0416 14:24:48.071219   977 solver.cpp:373]     Test net output #0: accuracy = 0.78365
I0416 14:24:48.071243   977 solver.cpp:373]     Test net output #1: loss = 0.837405 (* 1 = 0.837405 loss)
I0416 14:24:48.740425   977 solver.cpp:221] Iteration 12200, loss = 0.910268
I0416 14:24:48.740453   977 solver.cpp:236]     Train net output #0: loss = 1.03691 (* 1 = 1.03691 loss)
I0416 14:24:48.740458   977 solver.cpp:542] Iteration 12200, lr = 0.1
I0416 14:25:02.236150   977 solver.cpp:221] Iteration 12220, loss = 0.955895
I0416 14:25:02.236177   977 solver.cpp:236]     Train net output #0: loss = 0.914427 (* 1 = 0.914427 loss)
I0416 14:25:02.236182   977 solver.cpp:542] Iteration 12220, lr = 0.1
I0416 14:25:15.733526   977 solver.cpp:221] Iteration 12240, loss = 0.930193
I0416 14:25:15.733553   977 solver.cpp:236]     Train net output #0: loss = 1.39396 (* 1 = 1.39396 loss)
I0416 14:25:15.733558   977 solver.cpp:542] Iteration 12240, lr = 0.1
I0416 14:25:29.224706   977 solver.cpp:221] Iteration 12260, loss = 0.870304
I0416 14:25:29.224735   977 solver.cpp:236]     Train net output #0: loss = 0.928684 (* 1 = 0.928684 loss)
I0416 14:25:29.224740   977 solver.cpp:542] Iteration 12260, lr = 0.1
I0416 14:25:42.708791   977 solver.cpp:221] Iteration 12280, loss = 0.904724
I0416 14:25:42.708817   977 solver.cpp:236]     Train net output #0: loss = 0.78398 (* 1 = 0.78398 loss)
I0416 14:25:42.708822   977 solver.cpp:542] Iteration 12280, lr = 0.1
I0416 14:25:56.191200   977 solver.cpp:221] Iteration 12300, loss = 0.825342
I0416 14:25:56.191226   977 solver.cpp:236]     Train net output #0: loss = 0.847427 (* 1 = 0.847427 loss)
I0416 14:25:56.191231   977 solver.cpp:542] Iteration 12300, lr = 0.1
I0416 14:26:09.671624   977 solver.cpp:221] Iteration 12320, loss = 0.862319
I0416 14:26:09.671651   977 solver.cpp:236]     Train net output #0: loss = 0.880388 (* 1 = 0.880388 loss)
I0416 14:26:09.671656   977 solver.cpp:542] Iteration 12320, lr = 0.1
I0416 14:26:23.159183   977 solver.cpp:221] Iteration 12340, loss = 0.924895
I0416 14:26:23.159209   977 solver.cpp:236]     Train net output #0: loss = 1.14404 (* 1 = 1.14404 loss)
I0416 14:26:23.159214   977 solver.cpp:542] Iteration 12340, lr = 0.1
I0416 14:26:36.662904   977 solver.cpp:221] Iteration 12360, loss = 0.900999
I0416 14:26:36.662932   977 solver.cpp:236]     Train net output #0: loss = 0.983326 (* 1 = 0.983326 loss)
I0416 14:26:36.662936   977 solver.cpp:542] Iteration 12360, lr = 0.1
I0416 14:26:50.154743   977 solver.cpp:221] Iteration 12380, loss = 0.938346
I0416 14:26:50.154770   977 solver.cpp:236]     Train net output #0: loss = 0.99429 (* 1 = 0.99429 loss)
I0416 14:26:50.154775   977 solver.cpp:542] Iteration 12380, lr = 0.1
I0416 14:27:02.999181   977 solver.cpp:316] Iteration 12400, Testing net (#0)
I0416 14:27:14.514829   977 solver.cpp:373]     Test net output #0: accuracy = 0.559696
I0416 14:27:14.514850   977 solver.cpp:373]     Test net output #1: loss = 2.24701 (* 1 = 2.24701 loss)
I0416 14:27:15.181054   977 solver.cpp:221] Iteration 12400, loss = 0.909444
I0416 14:27:15.181080   977 solver.cpp:236]     Train net output #0: loss = 0.761187 (* 1 = 0.761187 loss)
I0416 14:27:15.181085   977 solver.cpp:542] Iteration 12400, lr = 0.1
I0416 14:27:28.669247   977 solver.cpp:221] Iteration 12420, loss = 0.891091
I0416 14:27:28.669273   977 solver.cpp:236]     Train net output #0: loss = 0.573831 (* 1 = 0.573831 loss)
I0416 14:27:28.669278   977 solver.cpp:542] Iteration 12420, lr = 0.1
I0416 14:27:42.159581   977 solver.cpp:221] Iteration 12440, loss = 0.991306
I0416 14:27:42.159608   977 solver.cpp:236]     Train net output #0: loss = 0.787667 (* 1 = 0.787667 loss)
I0416 14:27:42.159613   977 solver.cpp:542] Iteration 12440, lr = 0.1
I0416 14:27:55.671478   977 solver.cpp:221] Iteration 12460, loss = 0.909639
I0416 14:27:55.671505   977 solver.cpp:236]     Train net output #0: loss = 0.840942 (* 1 = 0.840942 loss)
I0416 14:27:55.671510   977 solver.cpp:542] Iteration 12460, lr = 0.1
I0416 14:28:09.175731   977 solver.cpp:221] Iteration 12480, loss = 0.895878
I0416 14:28:09.175758   977 solver.cpp:236]     Train net output #0: loss = 0.794636 (* 1 = 0.794636 loss)
I0416 14:28:09.175763   977 solver.cpp:542] Iteration 12480, lr = 0.1
I0416 14:28:22.684547   977 solver.cpp:221] Iteration 12500, loss = 0.891573
I0416 14:28:22.684574   977 solver.cpp:236]     Train net output #0: loss = 1.07028 (* 1 = 1.07028 loss)
I0416 14:28:22.684579   977 solver.cpp:542] Iteration 12500, lr = 0.1
I0416 14:28:36.201894   977 solver.cpp:221] Iteration 12520, loss = 0.94389
I0416 14:28:36.201921   977 solver.cpp:236]     Train net output #0: loss = 1.13657 (* 1 = 1.13657 loss)
I0416 14:28:36.201927   977 solver.cpp:542] Iteration 12520, lr = 0.1
I0416 14:28:49.702867   977 solver.cpp:221] Iteration 12540, loss = 0.92629
I0416 14:28:49.702893   977 solver.cpp:236]     Train net output #0: loss = 0.800196 (* 1 = 0.800196 loss)
I0416 14:28:49.702898   977 solver.cpp:542] Iteration 12540, lr = 0.1
I0416 14:29:03.186442   977 solver.cpp:221] Iteration 12560, loss = 0.918042
I0416 14:29:03.186470   977 solver.cpp:236]     Train net output #0: loss = 1.00138 (* 1 = 1.00138 loss)
I0416 14:29:03.186475   977 solver.cpp:542] Iteration 12560, lr = 0.1
I0416 14:29:16.682199   977 solver.cpp:221] Iteration 12580, loss = 0.923074
I0416 14:29:16.682226   977 solver.cpp:236]     Train net output #0: loss = 0.874635 (* 1 = 0.874635 loss)
I0416 14:29:16.682231   977 solver.cpp:542] Iteration 12580, lr = 0.1
I0416 14:29:29.538923   977 solver.cpp:316] Iteration 12600, Testing net (#0)
I0416 14:29:41.063531   977 solver.cpp:373]     Test net output #0: accuracy = 0.878136
I0416 14:29:41.063554   977 solver.cpp:373]     Test net output #1: loss = 0.446329 (* 1 = 0.446329 loss)
I0416 14:29:41.730818   977 solver.cpp:221] Iteration 12600, loss = 0.92482
I0416 14:29:41.730845   977 solver.cpp:236]     Train net output #0: loss = 0.534801 (* 1 = 0.534801 loss)
I0416 14:29:41.730850   977 solver.cpp:542] Iteration 12600, lr = 0.1
I0416 14:29:55.234983   977 solver.cpp:221] Iteration 12620, loss = 0.927192
I0416 14:29:55.235010   977 solver.cpp:236]     Train net output #0: loss = 0.888147 (* 1 = 0.888147 loss)
I0416 14:29:55.235015   977 solver.cpp:542] Iteration 12620, lr = 0.1
I0416 14:30:08.741025   977 solver.cpp:221] Iteration 12640, loss = 0.907009
I0416 14:30:08.741053   977 solver.cpp:236]     Train net output #0: loss = 0.86602 (* 1 = 0.86602 loss)
I0416 14:30:08.741057   977 solver.cpp:542] Iteration 12640, lr = 0.1
I0416 14:30:22.237422   977 solver.cpp:221] Iteration 12660, loss = 0.880593
I0416 14:30:22.237449   977 solver.cpp:236]     Train net output #0: loss = 0.55083 (* 1 = 0.55083 loss)
I0416 14:30:22.237454   977 solver.cpp:542] Iteration 12660, lr = 0.1
I0416 14:30:35.743340   977 solver.cpp:221] Iteration 12680, loss = 0.913998
I0416 14:30:35.743368   977 solver.cpp:236]     Train net output #0: loss = 1.14385 (* 1 = 1.14385 loss)
I0416 14:30:35.743373   977 solver.cpp:542] Iteration 12680, lr = 0.1
I0416 14:30:49.232095   977 solver.cpp:221] Iteration 12700, loss = 0.882707
I0416 14:30:49.232122   977 solver.cpp:236]     Train net output #0: loss = 0.883337 (* 1 = 0.883337 loss)
I0416 14:30:49.232126   977 solver.cpp:542] Iteration 12700, lr = 0.1
I0416 14:31:02.737928   977 solver.cpp:221] Iteration 12720, loss = 0.866574
I0416 14:31:02.737954   977 solver.cpp:236]     Train net output #0: loss = 0.595885 (* 1 = 0.595885 loss)
I0416 14:31:02.737959   977 solver.cpp:542] Iteration 12720, lr = 0.1
I0416 14:31:16.244859   977 solver.cpp:221] Iteration 12740, loss = 0.845829
I0416 14:31:16.244886   977 solver.cpp:236]     Train net output #0: loss = 0.640326 (* 1 = 0.640326 loss)
I0416 14:31:16.244891   977 solver.cpp:542] Iteration 12740, lr = 0.1
I0416 14:31:29.752431   977 solver.cpp:221] Iteration 12760, loss = 0.866151
I0416 14:31:29.752459   977 solver.cpp:236]     Train net output #0: loss = 0.864785 (* 1 = 0.864785 loss)
I0416 14:31:29.752463   977 solver.cpp:542] Iteration 12760, lr = 0.1
I0416 14:31:43.265736   977 solver.cpp:221] Iteration 12780, loss = 0.857923
I0416 14:31:43.265763   977 solver.cpp:236]     Train net output #0: loss = 0.87787 (* 1 = 0.87787 loss)
I0416 14:31:43.265769   977 solver.cpp:542] Iteration 12780, lr = 0.1
I0416 14:31:56.121140   977 solver.cpp:316] Iteration 12800, Testing net (#0)
I0416 14:32:07.636703   977 solver.cpp:373]     Test net output #0: accuracy = 0.852471
I0416 14:32:07.636724   977 solver.cpp:373]     Test net output #1: loss = 0.521528 (* 1 = 0.521528 loss)
I0416 14:32:08.303140   977 solver.cpp:221] Iteration 12800, loss = 0.864467
I0416 14:32:08.303167   977 solver.cpp:236]     Train net output #0: loss = 0.834505 (* 1 = 0.834505 loss)
I0416 14:32:08.303172   977 solver.cpp:542] Iteration 12800, lr = 0.1
I0416 14:32:21.832973   977 solver.cpp:221] Iteration 12820, loss = 0.86343
I0416 14:32:21.832999   977 solver.cpp:236]     Train net output #0: loss = 1.11254 (* 1 = 1.11254 loss)
I0416 14:32:21.833003   977 solver.cpp:542] Iteration 12820, lr = 0.1
I0416 14:32:35.355165   977 solver.cpp:221] Iteration 12840, loss = 0.833115
I0416 14:32:35.355192   977 solver.cpp:236]     Train net output #0: loss = 0.827409 (* 1 = 0.827409 loss)
I0416 14:32:35.355197   977 solver.cpp:542] Iteration 12840, lr = 0.1
I0416 14:32:48.883419   977 solver.cpp:221] Iteration 12860, loss = 0.866035
I0416 14:32:48.883445   977 solver.cpp:236]     Train net output #0: loss = 0.915186 (* 1 = 0.915186 loss)
I0416 14:32:48.883450   977 solver.cpp:542] Iteration 12860, lr = 0.1
I0416 14:33:02.389181   977 solver.cpp:221] Iteration 12880, loss = 0.91963
I0416 14:33:02.389209   977 solver.cpp:236]     Train net output #0: loss = 0.90147 (* 1 = 0.90147 loss)
I0416 14:33:02.389214   977 solver.cpp:542] Iteration 12880, lr = 0.1
I0416 14:33:15.892626   977 solver.cpp:221] Iteration 12900, loss = 0.89609
I0416 14:33:15.892652   977 solver.cpp:236]     Train net output #0: loss = 0.763481 (* 1 = 0.763481 loss)
I0416 14:33:15.892657   977 solver.cpp:542] Iteration 12900, lr = 0.1
I0416 14:33:29.403810   977 solver.cpp:221] Iteration 12920, loss = 0.897615
I0416 14:33:29.403836   977 solver.cpp:236]     Train net output #0: loss = 0.930968 (* 1 = 0.930968 loss)
I0416 14:33:29.403841   977 solver.cpp:542] Iteration 12920, lr = 0.1
I0416 14:33:42.915951   977 solver.cpp:221] Iteration 12940, loss = 0.921489
I0416 14:33:42.915976   977 solver.cpp:236]     Train net output #0: loss = 0.783217 (* 1 = 0.783217 loss)
I0416 14:33:42.915980   977 solver.cpp:542] Iteration 12940, lr = 0.1
I0416 14:33:56.435472   977 solver.cpp:221] Iteration 12960, loss = 0.906877
I0416 14:33:56.435498   977 solver.cpp:236]     Train net output #0: loss = 1.13519 (* 1 = 1.13519 loss)
I0416 14:33:56.435504   977 solver.cpp:542] Iteration 12960, lr = 0.1
I0416 14:34:09.957283   977 solver.cpp:221] Iteration 12980, loss = 0.927807
I0416 14:34:09.957309   977 solver.cpp:236]     Train net output #0: loss = 1.11287 (* 1 = 1.11287 loss)
I0416 14:34:09.957314   977 solver.cpp:542] Iteration 12980, lr = 0.1
I0416 14:34:22.828099   977 solver.cpp:316] Iteration 13000, Testing net (#0)
I0416 14:34:34.345702   977 solver.cpp:373]     Test net output #0: accuracy = 0.880418
I0416 14:34:34.345724   977 solver.cpp:373]     Test net output #1: loss = 0.459666 (* 1 = 0.459666 loss)
I0416 14:34:35.013351   977 solver.cpp:221] Iteration 13000, loss = 0.900283
I0416 14:34:35.013380   977 solver.cpp:236]     Train net output #0: loss = 0.966041 (* 1 = 0.966041 loss)
I0416 14:34:35.013383   977 solver.cpp:542] Iteration 13000, lr = 0.1
I0416 14:34:48.522727   977 solver.cpp:221] Iteration 13020, loss = 0.847954
I0416 14:34:48.522754   977 solver.cpp:236]     Train net output #0: loss = 0.716661 (* 1 = 0.716661 loss)
I0416 14:34:48.522759   977 solver.cpp:542] Iteration 13020, lr = 0.1
I0416 14:35:02.025365   977 solver.cpp:221] Iteration 13040, loss = 0.847464
I0416 14:35:02.025393   977 solver.cpp:236]     Train net output #0: loss = 0.930098 (* 1 = 0.930098 loss)
I0416 14:35:02.025398   977 solver.cpp:542] Iteration 13040, lr = 0.1
I0416 14:35:15.527653   977 solver.cpp:221] Iteration 13060, loss = 0.853453
I0416 14:35:15.527680   977 solver.cpp:236]     Train net output #0: loss = 0.94734 (* 1 = 0.94734 loss)
I0416 14:35:15.527685   977 solver.cpp:542] Iteration 13060, lr = 0.1
I0416 14:35:29.047241   977 solver.cpp:221] Iteration 13080, loss = 0.880309
I0416 14:35:29.047269   977 solver.cpp:236]     Train net output #0: loss = 0.901 (* 1 = 0.901 loss)
I0416 14:35:29.047273   977 solver.cpp:542] Iteration 13080, lr = 0.1
I0416 14:35:42.572760   977 solver.cpp:221] Iteration 13100, loss = 0.869947
I0416 14:35:42.572788   977 solver.cpp:236]     Train net output #0: loss = 0.904574 (* 1 = 0.904574 loss)
I0416 14:35:42.572791   977 solver.cpp:542] Iteration 13100, lr = 0.1
I0416 14:35:56.100672   977 solver.cpp:221] Iteration 13120, loss = 0.921409
I0416 14:35:56.100698   977 solver.cpp:236]     Train net output #0: loss = 0.933815 (* 1 = 0.933815 loss)
I0416 14:35:56.100703   977 solver.cpp:542] Iteration 13120, lr = 0.1
I0416 14:36:09.616128   977 solver.cpp:221] Iteration 13140, loss = 0.861641
I0416 14:36:09.616155   977 solver.cpp:236]     Train net output #0: loss = 1.28611 (* 1 = 1.28611 loss)
I0416 14:36:09.616159   977 solver.cpp:542] Iteration 13140, lr = 0.1
I0416 14:36:23.124192   977 solver.cpp:221] Iteration 13160, loss = 0.841513
I0416 14:36:23.124220   977 solver.cpp:236]     Train net output #0: loss = 0.681429 (* 1 = 0.681429 loss)
I0416 14:36:23.124224   977 solver.cpp:542] Iteration 13160, lr = 0.1
I0416 14:36:36.675868   977 solver.cpp:221] Iteration 13180, loss = 0.839131
I0416 14:36:36.675894   977 solver.cpp:236]     Train net output #0: loss = 1.32061 (* 1 = 1.32061 loss)
I0416 14:36:36.675899   977 solver.cpp:542] Iteration 13180, lr = 0.1
I0416 14:36:49.533565   977 solver.cpp:316] Iteration 13200, Testing net (#0)
I0416 14:37:01.062155   977 solver.cpp:373]     Test net output #0: accuracy = 0.889733
I0416 14:37:01.062175   977 solver.cpp:373]     Test net output #1: loss = 0.435496 (* 1 = 0.435496 loss)
I0416 14:37:01.731658   977 solver.cpp:221] Iteration 13200, loss = 0.83844
I0416 14:37:01.731686   977 solver.cpp:236]     Train net output #0: loss = 1.18086 (* 1 = 1.18086 loss)
I0416 14:37:01.731690   977 solver.cpp:542] Iteration 13200, lr = 0.1
I0416 14:37:15.271368   977 solver.cpp:221] Iteration 13220, loss = 0.85902
I0416 14:37:15.271395   977 solver.cpp:236]     Train net output #0: loss = 1.01237 (* 1 = 1.01237 loss)
I0416 14:37:15.271400   977 solver.cpp:542] Iteration 13220, lr = 0.1
I0416 14:37:28.801602   977 solver.cpp:221] Iteration 13240, loss = 0.883009
I0416 14:37:28.801630   977 solver.cpp:236]     Train net output #0: loss = 1.0289 (* 1 = 1.0289 loss)
I0416 14:37:28.801635   977 solver.cpp:542] Iteration 13240, lr = 0.1
I0416 14:37:42.305526   977 solver.cpp:221] Iteration 13260, loss = 0.845587
I0416 14:37:42.305555   977 solver.cpp:236]     Train net output #0: loss = 0.735497 (* 1 = 0.735497 loss)
I0416 14:37:42.305559   977 solver.cpp:542] Iteration 13260, lr = 0.1
I0416 14:37:55.817811   977 solver.cpp:221] Iteration 13280, loss = 0.861952
I0416 14:37:55.817838   977 solver.cpp:236]     Train net output #0: loss = 1.04146 (* 1 = 1.04146 loss)
I0416 14:37:55.817842   977 solver.cpp:542] Iteration 13280, lr = 0.1
I0416 14:38:09.319846   977 solver.cpp:221] Iteration 13300, loss = 0.909561
I0416 14:38:09.319875   977 solver.cpp:236]     Train net output #0: loss = 0.969988 (* 1 = 0.969988 loss)
I0416 14:38:09.319878   977 solver.cpp:542] Iteration 13300, lr = 0.1
I0416 14:38:22.805984   977 solver.cpp:221] Iteration 13320, loss = 0.90627
I0416 14:38:22.806010   977 solver.cpp:236]     Train net output #0: loss = 0.914309 (* 1 = 0.914309 loss)
I0416 14:38:22.806015   977 solver.cpp:542] Iteration 13320, lr = 0.1
I0416 14:38:36.315950   977 solver.cpp:221] Iteration 13340, loss = 0.894111
I0416 14:38:36.315978   977 solver.cpp:236]     Train net output #0: loss = 0.807567 (* 1 = 0.807567 loss)
I0416 14:38:36.315981   977 solver.cpp:542] Iteration 13340, lr = 0.1
I0416 14:38:49.846729   977 solver.cpp:221] Iteration 13360, loss = 0.855686
I0416 14:38:49.846755   977 solver.cpp:236]     Train net output #0: loss = 0.775685 (* 1 = 0.775685 loss)
I0416 14:38:49.846760   977 solver.cpp:542] Iteration 13360, lr = 0.1
I0416 14:39:03.373275   977 solver.cpp:221] Iteration 13380, loss = 0.813843
I0416 14:39:03.373302   977 solver.cpp:236]     Train net output #0: loss = 0.6924 (* 1 = 0.6924 loss)
I0416 14:39:03.373307   977 solver.cpp:542] Iteration 13380, lr = 0.1
I0416 14:39:16.214771   977 solver.cpp:316] Iteration 13400, Testing net (#0)
I0416 14:39:27.732796   977 solver.cpp:373]     Test net output #0: accuracy = 0.9019
I0416 14:39:27.732817   977 solver.cpp:373]     Test net output #1: loss = 0.377672 (* 1 = 0.377672 loss)
I0416 14:39:28.398856   977 solver.cpp:221] Iteration 13400, loss = 0.806255
I0416 14:39:28.398885   977 solver.cpp:236]     Train net output #0: loss = 0.722831 (* 1 = 0.722831 loss)
I0416 14:39:28.398890   977 solver.cpp:542] Iteration 13400, lr = 0.1
I0416 14:39:41.915148   977 solver.cpp:221] Iteration 13420, loss = 0.855071
I0416 14:39:41.915176   977 solver.cpp:236]     Train net output #0: loss = 1.11471 (* 1 = 1.11471 loss)
I0416 14:39:41.915181   977 solver.cpp:542] Iteration 13420, lr = 0.1
I0416 14:39:55.412158   977 solver.cpp:221] Iteration 13440, loss = 0.881551
I0416 14:39:55.412184   977 solver.cpp:236]     Train net output #0: loss = 0.915187 (* 1 = 0.915187 loss)
I0416 14:39:55.412190   977 solver.cpp:542] Iteration 13440, lr = 0.1
I0416 14:40:08.925501   977 solver.cpp:221] Iteration 13460, loss = 0.902065
I0416 14:40:08.925529   977 solver.cpp:236]     Train net output #0: loss = 1.12547 (* 1 = 1.12547 loss)
I0416 14:40:08.925534   977 solver.cpp:542] Iteration 13460, lr = 0.1
I0416 14:40:22.418315   977 solver.cpp:221] Iteration 13480, loss = 0.853248
I0416 14:40:22.418344   977 solver.cpp:236]     Train net output #0: loss = 0.83562 (* 1 = 0.83562 loss)
I0416 14:40:22.418347   977 solver.cpp:542] Iteration 13480, lr = 0.1
I0416 14:40:35.910763   977 solver.cpp:221] Iteration 13500, loss = 0.884503
I0416 14:40:35.910791   977 solver.cpp:236]     Train net output #0: loss = 0.94737 (* 1 = 0.94737 loss)
I0416 14:40:35.910797   977 solver.cpp:542] Iteration 13500, lr = 0.1
I0416 14:40:49.416491   977 solver.cpp:221] Iteration 13520, loss = 0.871839
I0416 14:40:49.416519   977 solver.cpp:236]     Train net output #0: loss = 0.835158 (* 1 = 0.835158 loss)
I0416 14:40:49.416524   977 solver.cpp:542] Iteration 13520, lr = 0.1
I0416 14:41:02.927924   977 solver.cpp:221] Iteration 13540, loss = 0.781403
I0416 14:41:02.927950   977 solver.cpp:236]     Train net output #0: loss = 0.916873 (* 1 = 0.916873 loss)
I0416 14:41:02.927954   977 solver.cpp:542] Iteration 13540, lr = 0.1
I0416 14:41:16.425310   977 solver.cpp:221] Iteration 13560, loss = 0.772779
I0416 14:41:16.425338   977 solver.cpp:236]     Train net output #0: loss = 0.815762 (* 1 = 0.815762 loss)
I0416 14:41:16.425341   977 solver.cpp:542] Iteration 13560, lr = 0.1
I0416 14:41:29.922765   977 solver.cpp:221] Iteration 13580, loss = 0.826145
I0416 14:41:29.922791   977 solver.cpp:236]     Train net output #0: loss = 0.913993 (* 1 = 0.913993 loss)
I0416 14:41:29.922796   977 solver.cpp:542] Iteration 13580, lr = 0.1
I0416 14:41:42.761255   977 solver.cpp:316] Iteration 13600, Testing net (#0)
I0416 14:41:54.281268   977 solver.cpp:373]     Test net output #0: accuracy = 0.890304
I0416 14:41:54.281291   977 solver.cpp:373]     Test net output #1: loss = 0.420469 (* 1 = 0.420469 loss)
I0416 14:41:54.947069   977 solver.cpp:221] Iteration 13600, loss = 0.8122
I0416 14:41:54.947096   977 solver.cpp:236]     Train net output #0: loss = 0.750785 (* 1 = 0.750785 loss)
I0416 14:41:54.947101   977 solver.cpp:542] Iteration 13600, lr = 0.1
I0416 14:42:08.448292   977 solver.cpp:221] Iteration 13620, loss = 0.851468
I0416 14:42:08.448319   977 solver.cpp:236]     Train net output #0: loss = 0.633456 (* 1 = 0.633456 loss)
I0416 14:42:08.448325   977 solver.cpp:542] Iteration 13620, lr = 0.1
I0416 14:42:21.982319   977 solver.cpp:221] Iteration 13640, loss = 0.827165
I0416 14:42:21.982349   977 solver.cpp:236]     Train net output #0: loss = 0.691334 (* 1 = 0.691334 loss)
I0416 14:42:21.982354   977 solver.cpp:542] Iteration 13640, lr = 0.1
I0416 14:42:35.530063   977 solver.cpp:221] Iteration 13660, loss = 0.834859
I0416 14:42:35.530091   977 solver.cpp:236]     Train net output #0: loss = 0.943271 (* 1 = 0.943271 loss)
I0416 14:42:35.530095   977 solver.cpp:542] Iteration 13660, lr = 0.1
I0416 14:42:49.076766   977 solver.cpp:221] Iteration 13680, loss = 0.91103
I0416 14:42:49.076793   977 solver.cpp:236]     Train net output #0: loss = 0.872538 (* 1 = 0.872538 loss)
I0416 14:42:49.076798   977 solver.cpp:542] Iteration 13680, lr = 0.1
I0416 14:43:02.585150   977 solver.cpp:221] Iteration 13700, loss = 0.889102
I0416 14:43:02.585176   977 solver.cpp:236]     Train net output #0: loss = 1.07451 (* 1 = 1.07451 loss)
I0416 14:43:02.585181   977 solver.cpp:542] Iteration 13700, lr = 0.1
I0416 14:43:16.098428   977 solver.cpp:221] Iteration 13720, loss = 0.863625
I0416 14:43:16.098454   977 solver.cpp:236]     Train net output #0: loss = 0.859685 (* 1 = 0.859685 loss)
I0416 14:43:16.098459   977 solver.cpp:542] Iteration 13720, lr = 0.1
I0416 14:43:29.601089   977 solver.cpp:221] Iteration 13740, loss = 0.886112
I0416 14:43:29.601116   977 solver.cpp:236]     Train net output #0: loss = 0.98685 (* 1 = 0.98685 loss)
I0416 14:43:29.601121   977 solver.cpp:542] Iteration 13740, lr = 0.1
I0416 14:43:43.105105   977 solver.cpp:221] Iteration 13760, loss = 0.907135
I0416 14:43:43.105132   977 solver.cpp:236]     Train net output #0: loss = 0.851739 (* 1 = 0.851739 loss)
I0416 14:43:43.105137   977 solver.cpp:542] Iteration 13760, lr = 0.1
I0416 14:43:56.619025   977 solver.cpp:221] Iteration 13780, loss = 0.804277
I0416 14:43:56.619052   977 solver.cpp:236]     Train net output #0: loss = 0.802391 (* 1 = 0.802391 loss)
I0416 14:43:56.619056   977 solver.cpp:542] Iteration 13780, lr = 0.1
I0416 14:44:09.465040   977 solver.cpp:316] Iteration 13800, Testing net (#0)
I0416 14:44:20.989434   977 solver.cpp:373]     Test net output #0: accuracy = 0.808365
I0416 14:44:20.989454   977 solver.cpp:373]     Test net output #1: loss = 0.727026 (* 1 = 0.727026 loss)
I0416 14:44:21.655225   977 solver.cpp:221] Iteration 13800, loss = 0.884922
I0416 14:44:21.655253   977 solver.cpp:236]     Train net output #0: loss = 1.24309 (* 1 = 1.24309 loss)
I0416 14:44:21.655258   977 solver.cpp:542] Iteration 13800, lr = 0.1
I0416 14:44:35.152405   977 solver.cpp:221] Iteration 13820, loss = 0.862188
I0416 14:44:35.152433   977 solver.cpp:236]     Train net output #0: loss = 0.875162 (* 1 = 0.875162 loss)
I0416 14:44:35.152438   977 solver.cpp:542] Iteration 13820, lr = 0.1
I0416 14:44:48.678699   977 solver.cpp:221] Iteration 13840, loss = 0.907154
I0416 14:44:48.678727   977 solver.cpp:236]     Train net output #0: loss = 1.19652 (* 1 = 1.19652 loss)
I0416 14:44:48.678731   977 solver.cpp:542] Iteration 13840, lr = 0.1
I0416 14:45:02.179924   977 solver.cpp:221] Iteration 13860, loss = 0.871997
I0416 14:45:02.179950   977 solver.cpp:236]     Train net output #0: loss = 1.11368 (* 1 = 1.11368 loss)
I0416 14:45:02.179955   977 solver.cpp:542] Iteration 13860, lr = 0.1
I0416 14:45:15.703920   977 solver.cpp:221] Iteration 13880, loss = 0.94148
I0416 14:45:15.703948   977 solver.cpp:236]     Train net output #0: loss = 1.0676 (* 1 = 1.0676 loss)
I0416 14:45:15.703953   977 solver.cpp:542] Iteration 13880, lr = 0.1
I0416 14:45:29.240059   977 solver.cpp:221] Iteration 13900, loss = 0.911305
I0416 14:45:29.240087   977 solver.cpp:236]     Train net output #0: loss = 1.07522 (* 1 = 1.07522 loss)
I0416 14:45:29.240092   977 solver.cpp:542] Iteration 13900, lr = 0.1
I0416 14:45:42.783632   977 solver.cpp:221] Iteration 13920, loss = 0.845852
I0416 14:45:42.783658   977 solver.cpp:236]     Train net output #0: loss = 0.763495 (* 1 = 0.763495 loss)
I0416 14:45:42.783663   977 solver.cpp:542] Iteration 13920, lr = 0.1
I0416 14:45:56.313740   977 solver.cpp:221] Iteration 13940, loss = 0.913897
I0416 14:45:56.313767   977 solver.cpp:236]     Train net output #0: loss = 0.725251 (* 1 = 0.725251 loss)
I0416 14:45:56.313772   977 solver.cpp:542] Iteration 13940, lr = 0.1
I0416 14:46:09.838994   977 solver.cpp:221] Iteration 13960, loss = 0.832498
I0416 14:46:09.839022   977 solver.cpp:236]     Train net output #0: loss = 0.936445 (* 1 = 0.936445 loss)
I0416 14:46:09.839027   977 solver.cpp:542] Iteration 13960, lr = 0.1
I0416 14:46:23.352967   977 solver.cpp:221] Iteration 13980, loss = 0.876908
I0416 14:46:23.352994   977 solver.cpp:236]     Train net output #0: loss = 0.81264 (* 1 = 0.81264 loss)
I0416 14:46:23.353000   977 solver.cpp:542] Iteration 13980, lr = 0.1
I0416 14:46:36.214974   977 solver.cpp:316] Iteration 14000, Testing net (#0)
I0416 14:46:47.747295   977 solver.cpp:373]     Test net output #0: accuracy = 0.85057
I0416 14:46:47.747316   977 solver.cpp:373]     Test net output #1: loss = 0.56593 (* 1 = 0.56593 loss)
I0416 14:46:48.413521   977 solver.cpp:221] Iteration 14000, loss = 0.837118
I0416 14:46:48.413548   977 solver.cpp:236]     Train net output #0: loss = 0.994725 (* 1 = 0.994725 loss)
I0416 14:46:48.413552   977 solver.cpp:542] Iteration 14000, lr = 0.1
I0416 14:47:01.944422   977 solver.cpp:221] Iteration 14020, loss = 0.858921
I0416 14:47:01.944448   977 solver.cpp:236]     Train net output #0: loss = 1.25011 (* 1 = 1.25011 loss)
I0416 14:47:01.944453   977 solver.cpp:542] Iteration 14020, lr = 0.1
I0416 14:47:15.487785   977 solver.cpp:221] Iteration 14040, loss = 0.86978
I0416 14:47:15.487809   977 solver.cpp:236]     Train net output #0: loss = 0.776513 (* 1 = 0.776513 loss)
I0416 14:47:15.487814   977 solver.cpp:542] Iteration 14040, lr = 0.1
I0416 14:47:29.019270   977 solver.cpp:221] Iteration 14060, loss = 0.851739
I0416 14:47:29.019299   977 solver.cpp:236]     Train net output #0: loss = 0.976312 (* 1 = 0.976312 loss)
I0416 14:47:29.019304   977 solver.cpp:542] Iteration 14060, lr = 0.1
I0416 14:47:42.589437   977 solver.cpp:221] Iteration 14080, loss = 0.854335
I0416 14:47:42.589464   977 solver.cpp:236]     Train net output #0: loss = 0.780149 (* 1 = 0.780149 loss)
I0416 14:47:42.589470   977 solver.cpp:542] Iteration 14080, lr = 0.1
I0416 14:47:56.123692   977 solver.cpp:221] Iteration 14100, loss = 0.876621
I0416 14:47:56.123719   977 solver.cpp:236]     Train net output #0: loss = 0.986313 (* 1 = 0.986313 loss)
I0416 14:47:56.123724   977 solver.cpp:542] Iteration 14100, lr = 0.1
I0416 14:48:09.693591   977 solver.cpp:221] Iteration 14120, loss = 0.828968
I0416 14:48:09.693617   977 solver.cpp:236]     Train net output #0: loss = 0.917307 (* 1 = 0.917307 loss)
I0416 14:48:09.693622   977 solver.cpp:542] Iteration 14120, lr = 0.1
I0416 14:48:23.245437   977 solver.cpp:221] Iteration 14140, loss = 0.844537
I0416 14:48:23.245465   977 solver.cpp:236]     Train net output #0: loss = 0.789752 (* 1 = 0.789752 loss)
I0416 14:48:23.245471   977 solver.cpp:542] Iteration 14140, lr = 0.1
I0416 14:48:36.767102   977 solver.cpp:221] Iteration 14160, loss = 0.831427
I0416 14:48:36.767128   977 solver.cpp:236]     Train net output #0: loss = 1.07893 (* 1 = 1.07893 loss)
I0416 14:48:36.767132   977 solver.cpp:542] Iteration 14160, lr = 0.1
I0416 14:48:50.280140   977 solver.cpp:221] Iteration 14180, loss = 0.818535
I0416 14:48:50.280167   977 solver.cpp:236]     Train net output #0: loss = 0.870827 (* 1 = 0.870827 loss)
I0416 14:48:50.280172   977 solver.cpp:542] Iteration 14180, lr = 0.1
I0416 14:49:03.130141   977 solver.cpp:316] Iteration 14200, Testing net (#0)
I0416 14:49:14.649001   977 solver.cpp:373]     Test net output #0: accuracy = 0.73251
I0416 14:49:14.649024   977 solver.cpp:373]     Test net output #1: loss = 1.06103 (* 1 = 1.06103 loss)
I0416 14:49:15.316265   977 solver.cpp:221] Iteration 14200, loss = 0.848197
I0416 14:49:15.316293   977 solver.cpp:236]     Train net output #0: loss = 0.67164 (* 1 = 0.67164 loss)
I0416 14:49:15.316298   977 solver.cpp:542] Iteration 14200, lr = 0.1
I0416 14:49:28.844503   977 solver.cpp:221] Iteration 14220, loss = 0.860542
I0416 14:49:28.844530   977 solver.cpp:236]     Train net output #0: loss = 0.689906 (* 1 = 0.689906 loss)
I0416 14:49:28.844534   977 solver.cpp:542] Iteration 14220, lr = 0.1
I0416 14:49:42.398561   977 solver.cpp:221] Iteration 14240, loss = 0.853488
I0416 14:49:42.398589   977 solver.cpp:236]     Train net output #0: loss = 1.16672 (* 1 = 1.16672 loss)
I0416 14:49:42.398593   977 solver.cpp:542] Iteration 14240, lr = 0.1
I0416 14:49:55.921777   977 solver.cpp:221] Iteration 14260, loss = 0.899772
I0416 14:49:55.921802   977 solver.cpp:236]     Train net output #0: loss = 1.2459 (* 1 = 1.2459 loss)
I0416 14:49:55.921808   977 solver.cpp:542] Iteration 14260, lr = 0.1
I0416 14:50:09.469094   977 solver.cpp:221] Iteration 14280, loss = 0.838969
I0416 14:50:09.469122   977 solver.cpp:236]     Train net output #0: loss = 0.962082 (* 1 = 0.962082 loss)
I0416 14:50:09.469127   977 solver.cpp:542] Iteration 14280, lr = 0.1
I0416 14:50:23.024839   977 solver.cpp:221] Iteration 14300, loss = 0.858679
I0416 14:50:23.024865   977 solver.cpp:236]     Train net output #0: loss = 0.8777 (* 1 = 0.8777 loss)
I0416 14:50:23.024870   977 solver.cpp:542] Iteration 14300, lr = 0.1
I0416 14:50:36.526382   977 solver.cpp:221] Iteration 14320, loss = 0.833757
I0416 14:50:36.526408   977 solver.cpp:236]     Train net output #0: loss = 0.958816 (* 1 = 0.958816 loss)
I0416 14:50:36.526413   977 solver.cpp:542] Iteration 14320, lr = 0.1
I0416 14:50:50.046545   977 solver.cpp:221] Iteration 14340, loss = 0.837149
I0416 14:50:50.046569   977 solver.cpp:236]     Train net output #0: loss = 0.771233 (* 1 = 0.771233 loss)
I0416 14:50:50.046574   977 solver.cpp:542] Iteration 14340, lr = 0.1
I0416 14:51:03.552006   977 solver.cpp:221] Iteration 14360, loss = 0.838295
I0416 14:51:03.552033   977 solver.cpp:236]     Train net output #0: loss = 1.11839 (* 1 = 1.11839 loss)
I0416 14:51:03.552038   977 solver.cpp:542] Iteration 14360, lr = 0.1
I0416 14:51:17.068470   977 solver.cpp:221] Iteration 14380, loss = 0.871554
I0416 14:51:17.068500   977 solver.cpp:236]     Train net output #0: loss = 0.893193 (* 1 = 0.893193 loss)
I0416 14:51:17.068505   977 solver.cpp:542] Iteration 14380, lr = 0.1
I0416 14:51:29.914409   977 solver.cpp:316] Iteration 14400, Testing net (#0)
I0416 14:51:41.436964   977 solver.cpp:373]     Test net output #0: accuracy = 0.734981
I0416 14:51:41.436988   977 solver.cpp:373]     Test net output #1: loss = 1.08999 (* 1 = 1.08999 loss)
I0416 14:51:42.103345   977 solver.cpp:221] Iteration 14400, loss = 0.856849
I0416 14:51:42.103373   977 solver.cpp:236]     Train net output #0: loss = 0.987842 (* 1 = 0.987842 loss)
I0416 14:51:42.103377   977 solver.cpp:542] Iteration 14400, lr = 0.1
I0416 14:51:55.646311   977 solver.cpp:221] Iteration 14420, loss = 0.894657
I0416 14:51:55.646338   977 solver.cpp:236]     Train net output #0: loss = 1.13269 (* 1 = 1.13269 loss)
I0416 14:51:55.646343   977 solver.cpp:542] Iteration 14420, lr = 0.1
I0416 14:52:09.155872   977 solver.cpp:221] Iteration 14440, loss = 0.817179
I0416 14:52:09.155900   977 solver.cpp:236]     Train net output #0: loss = 0.762992 (* 1 = 0.762992 loss)
I0416 14:52:09.155905   977 solver.cpp:542] Iteration 14440, lr = 0.1
I0416 14:52:22.666529   977 solver.cpp:221] Iteration 14460, loss = 0.865658
I0416 14:52:22.666556   977 solver.cpp:236]     Train net output #0: loss = 0.866716 (* 1 = 0.866716 loss)
I0416 14:52:22.666561   977 solver.cpp:542] Iteration 14460, lr = 0.1
I0416 14:52:36.179425   977 solver.cpp:221] Iteration 14480, loss = 0.901423
I0416 14:52:36.179451   977 solver.cpp:236]     Train net output #0: loss = 1.10201 (* 1 = 1.10201 loss)
I0416 14:52:36.179457   977 solver.cpp:542] Iteration 14480, lr = 0.1
I0416 14:52:49.731489   977 solver.cpp:221] Iteration 14500, loss = 0.840737
I0416 14:52:49.731516   977 solver.cpp:236]     Train net output #0: loss = 0.89996 (* 1 = 0.89996 loss)
I0416 14:52:49.731521   977 solver.cpp:542] Iteration 14500, lr = 0.1
I0416 14:53:03.288709   977 solver.cpp:221] Iteration 14520, loss = 0.855103
I0416 14:53:03.288736   977 solver.cpp:236]     Train net output #0: loss = 0.713266 (* 1 = 0.713266 loss)
I0416 14:53:03.288740   977 solver.cpp:542] Iteration 14520, lr = 0.1
I0416 14:53:16.838965   977 solver.cpp:221] Iteration 14540, loss = 0.892781
I0416 14:53:16.838994   977 solver.cpp:236]     Train net output #0: loss = 0.611109 (* 1 = 0.611109 loss)
I0416 14:53:16.838999   977 solver.cpp:542] Iteration 14540, lr = 0.1
I0416 14:53:30.403194   977 solver.cpp:221] Iteration 14560, loss = 0.88153
I0416 14:53:30.403221   977 solver.cpp:236]     Train net output #0: loss = 0.586929 (* 1 = 0.586929 loss)
I0416 14:53:30.403226   977 solver.cpp:542] Iteration 14560, lr = 0.1
I0416 14:53:43.950826   977 solver.cpp:221] Iteration 14580, loss = 0.849996
I0416 14:53:43.950853   977 solver.cpp:236]     Train net output #0: loss = 0.478383 (* 1 = 0.478383 loss)
I0416 14:53:43.950858   977 solver.cpp:542] Iteration 14580, lr = 0.1
I0416 14:53:56.862612   977 solver.cpp:316] Iteration 14600, Testing net (#0)
I0416 14:54:08.397617   977 solver.cpp:373]     Test net output #0: accuracy = 0.729278
I0416 14:54:08.397639   977 solver.cpp:373]     Test net output #1: loss = 1.07211 (* 1 = 1.07211 loss)
I0416 14:54:09.067461   977 solver.cpp:221] Iteration 14600, loss = 0.863094
I0416 14:54:09.067489   977 solver.cpp:236]     Train net output #0: loss = 0.968881 (* 1 = 0.968881 loss)
I0416 14:54:09.067493   977 solver.cpp:542] Iteration 14600, lr = 0.1
I0416 14:54:22.610878   977 solver.cpp:221] Iteration 14620, loss = 0.88168
I0416 14:54:22.610905   977 solver.cpp:236]     Train net output #0: loss = 0.777588 (* 1 = 0.777588 loss)
I0416 14:54:22.610910   977 solver.cpp:542] Iteration 14620, lr = 0.1
I0416 14:54:36.168931   977 solver.cpp:221] Iteration 14640, loss = 0.843483
I0416 14:54:36.168958   977 solver.cpp:236]     Train net output #0: loss = 0.961574 (* 1 = 0.961574 loss)
I0416 14:54:36.168963   977 solver.cpp:542] Iteration 14640, lr = 0.1
I0416 14:54:49.711841   977 solver.cpp:221] Iteration 14660, loss = 0.842203
I0416 14:54:49.711869   977 solver.cpp:236]     Train net output #0: loss = 0.742733 (* 1 = 0.742733 loss)
I0416 14:54:49.711874   977 solver.cpp:542] Iteration 14660, lr = 0.1
I0416 14:55:03.219493   977 solver.cpp:221] Iteration 14680, loss = 0.874084
I0416 14:55:03.219521   977 solver.cpp:236]     Train net output #0: loss = 0.806931 (* 1 = 0.806931 loss)
I0416 14:55:03.219526   977 solver.cpp:542] Iteration 14680, lr = 0.1
I0416 14:55:16.756685   977 solver.cpp:221] Iteration 14700, loss = 0.864958
I0416 14:55:16.756712   977 solver.cpp:236]     Train net output #0: loss = 1.02163 (* 1 = 1.02163 loss)
I0416 14:55:16.756717   977 solver.cpp:542] Iteration 14700, lr = 0.1
I0416 14:55:30.282686   977 solver.cpp:221] Iteration 14720, loss = 0.87118
I0416 14:55:30.282713   977 solver.cpp:236]     Train net output #0: loss = 0.67324 (* 1 = 0.67324 loss)
I0416 14:55:30.282717   977 solver.cpp:542] Iteration 14720, lr = 0.1
I0416 14:55:43.821096   977 solver.cpp:221] Iteration 14740, loss = 0.862554
I0416 14:55:43.821122   977 solver.cpp:236]     Train net output #0: loss = 0.981889 (* 1 = 0.981889 loss)
I0416 14:55:43.821127   977 solver.cpp:542] Iteration 14740, lr = 0.1
I0416 14:55:57.363682   977 solver.cpp:221] Iteration 14760, loss = 0.815626
I0416 14:55:57.363709   977 solver.cpp:236]     Train net output #0: loss = 0.681528 (* 1 = 0.681528 loss)
I0416 14:55:57.363713   977 solver.cpp:542] Iteration 14760, lr = 0.1
I0416 14:56:10.870900   977 solver.cpp:221] Iteration 14780, loss = 0.848585
I0416 14:56:10.870928   977 solver.cpp:236]     Train net output #0: loss = 0.78695 (* 1 = 0.78695 loss)
I0416 14:56:10.870932   977 solver.cpp:542] Iteration 14780, lr = 0.1
I0416 14:56:23.729845   977 solver.cpp:316] Iteration 14800, Testing net (#0)
I0416 14:56:35.251301   977 solver.cpp:373]     Test net output #0: accuracy = 0.887072
I0416 14:56:35.251322   977 solver.cpp:373]     Test net output #1: loss = 0.435748 (* 1 = 0.435748 loss)
I0416 14:56:35.917919   977 solver.cpp:221] Iteration 14800, loss = 0.870661
I0416 14:56:35.917946   977 solver.cpp:236]     Train net output #0: loss = 0.737892 (* 1 = 0.737892 loss)
I0416 14:56:35.917951   977 solver.cpp:542] Iteration 14800, lr = 0.1
I0416 14:56:49.432729   977 solver.cpp:221] Iteration 14820, loss = 0.874719
I0416 14:56:49.432755   977 solver.cpp:236]     Train net output #0: loss = 0.908883 (* 1 = 0.908883 loss)
I0416 14:56:49.432760   977 solver.cpp:542] Iteration 14820, lr = 0.1
I0416 14:57:02.955587   977 solver.cpp:221] Iteration 14840, loss = 0.791873
I0416 14:57:02.955615   977 solver.cpp:236]     Train net output #0: loss = 0.580687 (* 1 = 0.580687 loss)
I0416 14:57:02.955620   977 solver.cpp:542] Iteration 14840, lr = 0.1
I0416 14:57:16.468111   977 solver.cpp:221] Iteration 14860, loss = 0.818079
I0416 14:57:16.468139   977 solver.cpp:236]     Train net output #0: loss = 0.729712 (* 1 = 0.729712 loss)
I0416 14:57:16.468143   977 solver.cpp:542] Iteration 14860, lr = 0.1
I0416 14:57:29.986938   977 solver.cpp:221] Iteration 14880, loss = 0.832311
I0416 14:57:29.986966   977 solver.cpp:236]     Train net output #0: loss = 1.00101 (* 1 = 1.00101 loss)
I0416 14:57:29.986971   977 solver.cpp:542] Iteration 14880, lr = 0.1
I0416 14:57:43.533082   977 solver.cpp:221] Iteration 14900, loss = 0.833688
I0416 14:57:43.533108   977 solver.cpp:236]     Train net output #0: loss = 0.685979 (* 1 = 0.685979 loss)
I0416 14:57:43.533113   977 solver.cpp:542] Iteration 14900, lr = 0.1
I0416 14:57:57.070945   977 solver.cpp:221] Iteration 14920, loss = 0.802847
I0416 14:57:57.070972   977 solver.cpp:236]     Train net output #0: loss = 0.660524 (* 1 = 0.660524 loss)
I0416 14:57:57.070978   977 solver.cpp:542] Iteration 14920, lr = 0.1
I0416 14:58:10.589903   977 solver.cpp:221] Iteration 14940, loss = 0.84425
I0416 14:58:10.589931   977 solver.cpp:236]     Train net output #0: loss = 0.798675 (* 1 = 0.798675 loss)
I0416 14:58:10.589936   977 solver.cpp:542] Iteration 14940, lr = 0.1
I0416 14:58:24.115516   977 solver.cpp:221] Iteration 14960, loss = 0.809863
I0416 14:58:24.115543   977 solver.cpp:236]     Train net output #0: loss = 0.987878 (* 1 = 0.987878 loss)
I0416 14:58:24.115548   977 solver.cpp:542] Iteration 14960, lr = 0.1
I0416 14:58:37.653451   977 solver.cpp:221] Iteration 14980, loss = 0.843559
I0416 14:58:37.653478   977 solver.cpp:236]     Train net output #0: loss = 0.830645 (* 1 = 0.830645 loss)
I0416 14:58:37.653484   977 solver.cpp:542] Iteration 14980, lr = 0.1
I0416 14:58:50.521600   977 solver.cpp:316] Iteration 15000, Testing net (#0)
I0416 14:59:02.044916   977 solver.cpp:373]     Test net output #0: accuracy = 0.814068
I0416 14:59:02.044939   977 solver.cpp:373]     Test net output #1: loss = 0.751353 (* 1 = 0.751353 loss)
I0416 14:59:02.712625   977 solver.cpp:221] Iteration 15000, loss = 0.838041
I0416 14:59:02.712652   977 solver.cpp:236]     Train net output #0: loss = 1.11767 (* 1 = 1.11767 loss)
I0416 14:59:02.712657   977 solver.cpp:542] Iteration 15000, lr = 0.1
I0416 14:59:16.240033   977 solver.cpp:221] Iteration 15020, loss = 0.896617
I0416 14:59:16.240061   977 solver.cpp:236]     Train net output #0: loss = 0.872589 (* 1 = 0.872589 loss)
I0416 14:59:16.240066   977 solver.cpp:542] Iteration 15020, lr = 0.1
I0416 14:59:29.755707   977 solver.cpp:221] Iteration 15040, loss = 0.867933
I0416 14:59:29.755736   977 solver.cpp:236]     Train net output #0: loss = 0.979298 (* 1 = 0.979298 loss)
I0416 14:59:29.755740   977 solver.cpp:542] Iteration 15040, lr = 0.1
I0416 14:59:43.263852   977 solver.cpp:221] Iteration 15060, loss = 0.812214
I0416 14:59:43.263880   977 solver.cpp:236]     Train net output #0: loss = 1.01234 (* 1 = 1.01234 loss)
I0416 14:59:43.263885   977 solver.cpp:542] Iteration 15060, lr = 0.1
I0416 14:59:56.781381   977 solver.cpp:221] Iteration 15080, loss = 0.854133
I0416 14:59:56.781407   977 solver.cpp:236]     Train net output #0: loss = 0.792196 (* 1 = 0.792196 loss)
I0416 14:59:56.781412   977 solver.cpp:542] Iteration 15080, lr = 0.1
I0416 15:00:10.330425   977 solver.cpp:221] Iteration 15100, loss = 0.900011
I0416 15:00:10.330451   977 solver.cpp:236]     Train net output #0: loss = 0.562517 (* 1 = 0.562517 loss)
I0416 15:00:10.330456   977 solver.cpp:542] Iteration 15100, lr = 0.1
I0416 15:00:23.881158   977 solver.cpp:221] Iteration 15120, loss = 0.847516
I0416 15:00:23.881186   977 solver.cpp:236]     Train net output #0: loss = 1.05205 (* 1 = 1.05205 loss)
I0416 15:00:23.881191   977 solver.cpp:542] Iteration 15120, lr = 0.1
I0416 15:00:37.427377   977 solver.cpp:221] Iteration 15140, loss = 0.872228
I0416 15:00:37.427403   977 solver.cpp:236]     Train net output #0: loss = 0.830265 (* 1 = 0.830265 loss)
I0416 15:00:37.427408   977 solver.cpp:542] Iteration 15140, lr = 0.1
I0416 15:00:50.937032   977 solver.cpp:221] Iteration 15160, loss = 0.832043
I0416 15:00:50.937059   977 solver.cpp:236]     Train net output #0: loss = 0.860536 (* 1 = 0.860536 loss)
I0416 15:00:50.937064   977 solver.cpp:542] Iteration 15160, lr = 0.1
I0416 15:01:04.450867   977 solver.cpp:221] Iteration 15180, loss = 0.820365
I0416 15:01:04.450893   977 solver.cpp:236]     Train net output #0: loss = 0.809401 (* 1 = 0.809401 loss)
I0416 15:01:04.450898   977 solver.cpp:542] Iteration 15180, lr = 0.1
I0416 15:01:17.336066   977 solver.cpp:316] Iteration 15200, Testing net (#0)
I0416 15:01:28.870060   977 solver.cpp:373]     Test net output #0: accuracy = 0.835361
I0416 15:01:28.870082   977 solver.cpp:373]     Test net output #1: loss = 0.628216 (* 1 = 0.628216 loss)
I0416 15:01:29.539392   977 solver.cpp:221] Iteration 15200, loss = 0.900013
I0416 15:01:29.539419   977 solver.cpp:236]     Train net output #0: loss = 0.962993 (* 1 = 0.962993 loss)
I0416 15:01:29.539424   977 solver.cpp:542] Iteration 15200, lr = 0.1
I0416 15:01:43.108508   977 solver.cpp:221] Iteration 15220, loss = 0.9018
I0416 15:01:43.108536   977 solver.cpp:236]     Train net output #0: loss = 1.28033 (* 1 = 1.28033 loss)
I0416 15:01:43.108539   977 solver.cpp:542] Iteration 15220, lr = 0.1
I0416 15:01:56.638923   977 solver.cpp:221] Iteration 15240, loss = 0.891306
I0416 15:01:56.638950   977 solver.cpp:236]     Train net output #0: loss = 0.668751 (* 1 = 0.668751 loss)
I0416 15:01:56.638954   977 solver.cpp:542] Iteration 15240, lr = 0.1
I0416 15:02:10.146126   977 solver.cpp:221] Iteration 15260, loss = 0.848942
I0416 15:02:10.146152   977 solver.cpp:236]     Train net output #0: loss = 0.719776 (* 1 = 0.719776 loss)
I0416 15:02:10.146157   977 solver.cpp:542] Iteration 15260, lr = 0.1
I0416 15:02:23.652454   977 solver.cpp:221] Iteration 15280, loss = 0.871021
I0416 15:02:23.652482   977 solver.cpp:236]     Train net output #0: loss = 0.788861 (* 1 = 0.788861 loss)
I0416 15:02:23.652487   977 solver.cpp:542] Iteration 15280, lr = 0.1
I0416 15:02:37.153053   977 solver.cpp:221] Iteration 15300, loss = 0.862887
I0416 15:02:37.153079   977 solver.cpp:236]     Train net output #0: loss = 0.700563 (* 1 = 0.700563 loss)
I0416 15:02:37.153084   977 solver.cpp:542] Iteration 15300, lr = 0.1
I0416 15:02:50.683763   977 solver.cpp:221] Iteration 15320, loss = 0.930965
I0416 15:02:50.683789   977 solver.cpp:236]     Train net output #0: loss = 0.903122 (* 1 = 0.903122 loss)
I0416 15:02:50.683794   977 solver.cpp:542] Iteration 15320, lr = 0.1
I0416 15:03:04.220780   977 solver.cpp:221] Iteration 15340, loss = 0.873381
I0416 15:03:04.220808   977 solver.cpp:236]     Train net output #0: loss = 1.16348 (* 1 = 1.16348 loss)
I0416 15:03:04.220813   977 solver.cpp:542] Iteration 15340, lr = 0.1
I0416 15:03:17.756224   977 solver.cpp:221] Iteration 15360, loss = 0.869109
I0416 15:03:17.756252   977 solver.cpp:236]     Train net output #0: loss = 0.933699 (* 1 = 0.933699 loss)
I0416 15:03:17.756256   977 solver.cpp:542] Iteration 15360, lr = 0.1
I0416 15:03:31.271775   977 solver.cpp:221] Iteration 15380, loss = 0.881562
I0416 15:03:31.271803   977 solver.cpp:236]     Train net output #0: loss = 0.701667 (* 1 = 0.701667 loss)
I0416 15:03:31.271807   977 solver.cpp:542] Iteration 15380, lr = 0.1
I0416 15:03:44.121127   977 solver.cpp:316] Iteration 15400, Testing net (#0)
I0416 15:03:55.642935   977 solver.cpp:373]     Test net output #0: accuracy = 0.884981
I0416 15:03:55.642956   977 solver.cpp:373]     Test net output #1: loss = 0.423103 (* 1 = 0.423103 loss)
I0416 15:03:56.310765   977 solver.cpp:221] Iteration 15400, loss = 0.908657
I0416 15:03:56.310792   977 solver.cpp:236]     Train net output #0: loss = 0.814312 (* 1 = 0.814312 loss)
I0416 15:03:56.310798   977 solver.cpp:542] Iteration 15400, lr = 0.1
I0416 15:04:09.821811   977 solver.cpp:221] Iteration 15420, loss = 0.875017
I0416 15:04:09.821840   977 solver.cpp:236]     Train net output #0: loss = 0.848994 (* 1 = 0.848994 loss)
I0416 15:04:09.821844   977 solver.cpp:542] Iteration 15420, lr = 0.1
I0416 15:04:23.323313   977 solver.cpp:221] Iteration 15440, loss = 0.83014
I0416 15:04:23.323339   977 solver.cpp:236]     Train net output #0: loss = 0.887223 (* 1 = 0.887223 loss)
I0416 15:04:23.323344   977 solver.cpp:542] Iteration 15440, lr = 0.1
I0416 15:04:36.831378   977 solver.cpp:221] Iteration 15460, loss = 0.825144
I0416 15:04:36.831406   977 solver.cpp:236]     Train net output #0: loss = 0.454682 (* 1 = 0.454682 loss)
I0416 15:04:36.831413   977 solver.cpp:542] Iteration 15460, lr = 0.1
I0416 15:04:50.376286   977 solver.cpp:221] Iteration 15480, loss = 0.828838
I0416 15:04:50.376313   977 solver.cpp:236]     Train net output #0: loss = 0.555763 (* 1 = 0.555763 loss)
I0416 15:04:50.376318   977 solver.cpp:542] Iteration 15480, lr = 0.1
I0416 15:05:03.899483   977 solver.cpp:221] Iteration 15500, loss = 0.851577
I0416 15:05:03.899512   977 solver.cpp:236]     Train net output #0: loss = 0.710496 (* 1 = 0.710496 loss)
I0416 15:05:03.899516   977 solver.cpp:542] Iteration 15500, lr = 0.1
I0416 15:05:17.418267   977 solver.cpp:221] Iteration 15520, loss = 0.833757
I0416 15:05:17.418295   977 solver.cpp:236]     Train net output #0: loss = 0.840278 (* 1 = 0.840278 loss)
I0416 15:05:17.418300   977 solver.cpp:542] Iteration 15520, lr = 0.1
I0416 15:05:30.937755   977 solver.cpp:221] Iteration 15540, loss = 0.808329
I0416 15:05:30.937783   977 solver.cpp:236]     Train net output #0: loss = 0.956302 (* 1 = 0.956302 loss)
I0416 15:05:30.937788   977 solver.cpp:542] Iteration 15540, lr = 0.1
I0416 15:05:44.472232   977 solver.cpp:221] Iteration 15560, loss = 0.836639
I0416 15:05:44.472259   977 solver.cpp:236]     Train net output #0: loss = 0.967446 (* 1 = 0.967446 loss)
I0416 15:05:44.472265   977 solver.cpp:542] Iteration 15560, lr = 0.1
I0416 15:05:58.016201   977 solver.cpp:221] Iteration 15580, loss = 0.805456
I0416 15:05:58.016228   977 solver.cpp:236]     Train net output #0: loss = 0.896896 (* 1 = 0.896896 loss)
I0416 15:05:58.016233   977 solver.cpp:542] Iteration 15580, lr = 0.1
I0416 15:06:10.903306   977 solver.cpp:316] Iteration 15600, Testing net (#0)
I0416 15:06:22.437719   977 solver.cpp:373]     Test net output #0: accuracy = 0.546008
I0416 15:06:22.437741   977 solver.cpp:373]     Test net output #1: loss = 2.50942 (* 1 = 2.50942 loss)
I0416 15:06:23.108261   977 solver.cpp:221] Iteration 15600, loss = 0.805242
I0416 15:06:23.108289   977 solver.cpp:236]     Train net output #0: loss = 0.798934 (* 1 = 0.798934 loss)
I0416 15:06:23.108292   977 solver.cpp:542] Iteration 15600, lr = 0.1
I0416 15:06:36.601060   977 solver.cpp:221] Iteration 15620, loss = 0.864992
I0416 15:06:36.601089   977 solver.cpp:236]     Train net output #0: loss = 1.11782 (* 1 = 1.11782 loss)
I0416 15:06:36.601094   977 solver.cpp:542] Iteration 15620, lr = 0.1
I0416 15:06:50.104609   977 solver.cpp:221] Iteration 15640, loss = 0.887661
I0416 15:06:50.104635   977 solver.cpp:236]     Train net output #0: loss = 0.693561 (* 1 = 0.693561 loss)
I0416 15:06:50.104640   977 solver.cpp:542] Iteration 15640, lr = 0.1
I0416 15:07:03.623535   977 solver.cpp:221] Iteration 15660, loss = 0.869589
I0416 15:07:03.623569   977 solver.cpp:236]     Train net output #0: loss = 1.06309 (* 1 = 1.06309 loss)
I0416 15:07:03.623574   977 solver.cpp:542] Iteration 15660, lr = 0.1
I0416 15:07:17.132655   977 solver.cpp:221] Iteration 15680, loss = 0.87727
I0416 15:07:17.132683   977 solver.cpp:236]     Train net output #0: loss = 1.10678 (* 1 = 1.10678 loss)
I0416 15:07:17.132686   977 solver.cpp:542] Iteration 15680, lr = 0.1
I0416 15:07:30.634606   977 solver.cpp:221] Iteration 15700, loss = 0.802641
I0416 15:07:30.634634   977 solver.cpp:236]     Train net output #0: loss = 0.707882 (* 1 = 0.707882 loss)
I0416 15:07:30.634639   977 solver.cpp:542] Iteration 15700, lr = 0.1
I0416 15:07:44.169201   977 solver.cpp:221] Iteration 15720, loss = 0.830187
I0416 15:07:44.169229   977 solver.cpp:236]     Train net output #0: loss = 0.961434 (* 1 = 0.961434 loss)
I0416 15:07:44.169234   977 solver.cpp:542] Iteration 15720, lr = 0.1
I0416 15:07:57.681679   977 solver.cpp:221] Iteration 15740, loss = 0.805783
I0416 15:07:57.681702   977 solver.cpp:236]     Train net output #0: loss = 0.581788 (* 1 = 0.581788 loss)
I0416 15:07:57.681706   977 solver.cpp:542] Iteration 15740, lr = 0.1
I0416 15:08:11.217476   977 solver.cpp:221] Iteration 15760, loss = 0.796792
I0416 15:08:11.217504   977 solver.cpp:236]     Train net output #0: loss = 1.04141 (* 1 = 1.04141 loss)
I0416 15:08:11.217509   977 solver.cpp:542] Iteration 15760, lr = 0.1
I0416 15:08:24.781457   977 solver.cpp:221] Iteration 15780, loss = 0.775831
I0416 15:08:24.781484   977 solver.cpp:236]     Train net output #0: loss = 0.764095 (* 1 = 0.764095 loss)
I0416 15:08:24.781488   977 solver.cpp:542] Iteration 15780, lr = 0.1
I0416 15:08:37.653401   977 solver.cpp:316] Iteration 15800, Testing net (#0)
I0416 15:08:49.179164   977 solver.cpp:373]     Test net output #0: accuracy = 0.88308
I0416 15:08:49.179186   977 solver.cpp:373]     Test net output #1: loss = 0.454712 (* 1 = 0.454712 loss)
I0416 15:08:49.846122   977 solver.cpp:221] Iteration 15800, loss = 0.804962
I0416 15:08:49.846151   977 solver.cpp:236]     Train net output #0: loss = 0.821237 (* 1 = 0.821237 loss)
I0416 15:08:49.846156   977 solver.cpp:542] Iteration 15800, lr = 0.1
I0416 15:09:03.364099   977 solver.cpp:221] Iteration 15820, loss = 0.797316
I0416 15:09:03.364126   977 solver.cpp:236]     Train net output #0: loss = 0.745284 (* 1 = 0.745284 loss)
I0416 15:09:03.364131   977 solver.cpp:542] Iteration 15820, lr = 0.1
I0416 15:09:16.900632   977 solver.cpp:221] Iteration 15840, loss = 0.7565
I0416 15:09:16.900660   977 solver.cpp:236]     Train net output #0: loss = 0.991236 (* 1 = 0.991236 loss)
I0416 15:09:16.900665   977 solver.cpp:542] Iteration 15840, lr = 0.1
I0416 15:09:30.419762   977 solver.cpp:221] Iteration 15860, loss = 0.811735
I0416 15:09:30.419790   977 solver.cpp:236]     Train net output #0: loss = 0.948911 (* 1 = 0.948911 loss)
I0416 15:09:30.419795   977 solver.cpp:542] Iteration 15860, lr = 0.1
I0416 15:09:43.923967   977 solver.cpp:221] Iteration 15880, loss = 0.843418
I0416 15:09:43.923995   977 solver.cpp:236]     Train net output #0: loss = 0.766711 (* 1 = 0.766711 loss)
I0416 15:09:43.924000   977 solver.cpp:542] Iteration 15880, lr = 0.1
I0416 15:09:57.463413   977 solver.cpp:221] Iteration 15900, loss = 0.809469
I0416 15:09:57.463441   977 solver.cpp:236]     Train net output #0: loss = 0.994922 (* 1 = 0.994922 loss)
I0416 15:09:57.463446   977 solver.cpp:542] Iteration 15900, lr = 0.1
I0416 15:10:11.011641   977 solver.cpp:221] Iteration 15920, loss = 0.828046
I0416 15:10:11.011668   977 solver.cpp:236]     Train net output #0: loss = 0.927304 (* 1 = 0.927304 loss)
I0416 15:10:11.011673   977 solver.cpp:542] Iteration 15920, lr = 0.1
I0416 15:10:24.536326   977 solver.cpp:221] Iteration 15940, loss = 0.881638
I0416 15:10:24.536352   977 solver.cpp:236]     Train net output #0: loss = 1.1495 (* 1 = 1.1495 loss)
I0416 15:10:24.536357   977 solver.cpp:542] Iteration 15940, lr = 0.1
I0416 15:10:38.044687   977 solver.cpp:221] Iteration 15960, loss = 0.847924
I0416 15:10:38.044715   977 solver.cpp:236]     Train net output #0: loss = 0.610925 (* 1 = 0.610925 loss)
I0416 15:10:38.044719   977 solver.cpp:542] Iteration 15960, lr = 0.1
I0416 15:10:51.555743   977 solver.cpp:221] Iteration 15980, loss = 0.865757
I0416 15:10:51.555771   977 solver.cpp:236]     Train net output #0: loss = 1.01014 (* 1 = 1.01014 loss)
I0416 15:10:51.555776   977 solver.cpp:542] Iteration 15980, lr = 0.1
I0416 15:11:04.449389   977 solver.cpp:316] Iteration 16000, Testing net (#0)
I0416 15:11:15.971566   977 solver.cpp:373]     Test net output #0: accuracy = 0.916539
I0416 15:11:15.971587   977 solver.cpp:373]     Test net output #1: loss = 0.319863 (* 1 = 0.319863 loss)
I0416 15:11:16.639495   977 solver.cpp:221] Iteration 16000, loss = 0.862205
I0416 15:11:16.639521   977 solver.cpp:236]     Train net output #0: loss = 0.766089 (* 1 = 0.766089 loss)
I0416 15:11:16.639526   977 solver.cpp:542] Iteration 16000, lr = 0.1
I0416 15:11:30.190567   977 solver.cpp:221] Iteration 16020, loss = 0.818891
I0416 15:11:30.190593   977 solver.cpp:236]     Train net output #0: loss = 0.889213 (* 1 = 0.889213 loss)
I0416 15:11:30.190598   977 solver.cpp:542] Iteration 16020, lr = 0.1
I0416 15:11:43.720628   977 solver.cpp:221] Iteration 16040, loss = 0.838042
I0416 15:11:43.720656   977 solver.cpp:236]     Train net output #0: loss = 0.655276 (* 1 = 0.655276 loss)
I0416 15:11:43.720660   977 solver.cpp:542] Iteration 16040, lr = 0.1
I0416 15:11:57.266209   977 solver.cpp:221] Iteration 16060, loss = 0.855383
I0416 15:11:57.266237   977 solver.cpp:236]     Train net output #0: loss = 0.819002 (* 1 = 0.819002 loss)
I0416 15:11:57.266242   977 solver.cpp:542] Iteration 16060, lr = 0.1
I0416 15:12:10.781972   977 solver.cpp:221] Iteration 16080, loss = 0.927985
I0416 15:12:10.781999   977 solver.cpp:236]     Train net output #0: loss = 1.04822 (* 1 = 1.04822 loss)
I0416 15:12:10.782006   977 solver.cpp:542] Iteration 16080, lr = 0.1
I0416 15:12:24.317435   977 solver.cpp:221] Iteration 16100, loss = 0.860164
I0416 15:12:24.317461   977 solver.cpp:236]     Train net output #0: loss = 0.689201 (* 1 = 0.689201 loss)
I0416 15:12:24.317466   977 solver.cpp:542] Iteration 16100, lr = 0.1
I0416 15:12:37.856922   977 solver.cpp:221] Iteration 16120, loss = 0.833124
I0416 15:12:37.856950   977 solver.cpp:236]     Train net output #0: loss = 0.681818 (* 1 = 0.681818 loss)
I0416 15:12:37.856955   977 solver.cpp:542] Iteration 16120, lr = 0.1
I0416 15:12:51.385598   977 solver.cpp:221] Iteration 16140, loss = 0.808495
I0416 15:12:51.385627   977 solver.cpp:236]     Train net output #0: loss = 0.857309 (* 1 = 0.857309 loss)
I0416 15:12:51.385632   977 solver.cpp:542] Iteration 16140, lr = 0.1
I0416 15:13:04.949477   977 solver.cpp:221] Iteration 16160, loss = 0.862445
I0416 15:13:04.949504   977 solver.cpp:236]     Train net output #0: loss = 0.847459 (* 1 = 0.847459 loss)
I0416 15:13:04.949509   977 solver.cpp:542] Iteration 16160, lr = 0.1
I0416 15:13:18.478436   977 solver.cpp:221] Iteration 16180, loss = 0.816134
I0416 15:13:18.478462   977 solver.cpp:236]     Train net output #0: loss = 0.733428 (* 1 = 0.733428 loss)
I0416 15:13:18.478467   977 solver.cpp:542] Iteration 16180, lr = 0.1
I0416 15:13:31.330004   977 solver.cpp:316] Iteration 16200, Testing net (#0)
I0416 15:13:42.866574   977 solver.cpp:373]     Test net output #0: accuracy = 0.822244
I0416 15:13:42.866595   977 solver.cpp:373]     Test net output #1: loss = 0.674863 (* 1 = 0.674863 loss)
I0416 15:13:43.537123   977 solver.cpp:221] Iteration 16200, loss = 0.824561
I0416 15:13:43.537152   977 solver.cpp:236]     Train net output #0: loss = 0.919753 (* 1 = 0.919753 loss)
I0416 15:13:43.537156   977 solver.cpp:542] Iteration 16200, lr = 0.1
I0416 15:13:57.082253   977 solver.cpp:221] Iteration 16220, loss = 0.840857
I0416 15:13:57.082281   977 solver.cpp:236]     Train net output #0: loss = 0.963336 (* 1 = 0.963336 loss)
I0416 15:13:57.082286   977 solver.cpp:542] Iteration 16220, lr = 0.1
I0416 15:14:10.616070   977 solver.cpp:221] Iteration 16240, loss = 0.81544
I0416 15:14:10.616096   977 solver.cpp:236]     Train net output #0: loss = 0.900535 (* 1 = 0.900535 loss)
I0416 15:14:10.616101   977 solver.cpp:542] Iteration 16240, lr = 0.1
I0416 15:14:24.154716   977 solver.cpp:221] Iteration 16260, loss = 0.790285
I0416 15:14:24.154742   977 solver.cpp:236]     Train net output #0: loss = 0.775375 (* 1 = 0.775375 loss)
I0416 15:14:24.154747   977 solver.cpp:542] Iteration 16260, lr = 0.1
I0416 15:14:37.697448   977 solver.cpp:221] Iteration 16280, loss = 0.878556
I0416 15:14:37.697475   977 solver.cpp:236]     Train net output #0: loss = 0.730565 (* 1 = 0.730565 loss)
I0416 15:14:37.697479   977 solver.cpp:542] Iteration 16280, lr = 0.1
I0416 15:14:51.242421   977 solver.cpp:221] Iteration 16300, loss = 0.82802
I0416 15:14:51.242449   977 solver.cpp:236]     Train net output #0: loss = 0.70206 (* 1 = 0.70206 loss)
I0416 15:14:51.242454   977 solver.cpp:542] Iteration 16300, lr = 0.1
I0416 15:15:04.786916   977 solver.cpp:221] Iteration 16320, loss = 0.785152
I0416 15:15:04.786942   977 solver.cpp:236]     Train net output #0: loss = 0.69495 (* 1 = 0.69495 loss)
I0416 15:15:04.786947   977 solver.cpp:542] Iteration 16320, lr = 0.1
I0416 15:15:18.300760   977 solver.cpp:221] Iteration 16340, loss = 0.801864
I0416 15:15:18.300787   977 solver.cpp:236]     Train net output #0: loss = 0.935996 (* 1 = 0.935996 loss)
I0416 15:15:18.300792   977 solver.cpp:542] Iteration 16340, lr = 0.1
I0416 15:15:31.808060   977 solver.cpp:221] Iteration 16360, loss = 0.854757
I0416 15:15:31.808087   977 solver.cpp:236]     Train net output #0: loss = 0.82497 (* 1 = 0.82497 loss)
I0416 15:15:31.808091   977 solver.cpp:542] Iteration 16360, lr = 0.1
I0416 15:15:45.316256   977 solver.cpp:221] Iteration 16380, loss = 0.833091
I0416 15:15:45.316282   977 solver.cpp:236]     Train net output #0: loss = 0.707746 (* 1 = 0.707746 loss)
I0416 15:15:45.316287   977 solver.cpp:542] Iteration 16380, lr = 0.1
I0416 15:15:58.184723   977 solver.cpp:316] Iteration 16400, Testing net (#0)
I0416 15:16:09.708573   977 solver.cpp:373]     Test net output #0: accuracy = 0.9019
I0416 15:16:09.708595   977 solver.cpp:373]     Test net output #1: loss = 0.38865 (* 1 = 0.38865 loss)
I0416 15:16:10.376463   977 solver.cpp:221] Iteration 16400, loss = 0.879796
I0416 15:16:10.376490   977 solver.cpp:236]     Train net output #0: loss = 0.937623 (* 1 = 0.937623 loss)
I0416 15:16:10.376494   977 solver.cpp:542] Iteration 16400, lr = 0.1
I0416 15:16:23.885645   977 solver.cpp:221] Iteration 16420, loss = 0.806365
I0416 15:16:23.885673   977 solver.cpp:236]     Train net output #0: loss = 0.71653 (* 1 = 0.71653 loss)
I0416 15:16:23.885679   977 solver.cpp:542] Iteration 16420, lr = 0.1
I0416 15:16:37.395267   977 solver.cpp:221] Iteration 16440, loss = 0.760747
I0416 15:16:37.395295   977 solver.cpp:236]     Train net output #0: loss = 0.8275 (* 1 = 0.8275 loss)
I0416 15:16:37.395299   977 solver.cpp:542] Iteration 16440, lr = 0.1
I0416 15:16:50.907100   977 solver.cpp:221] Iteration 16460, loss = 0.817747
I0416 15:16:50.907129   977 solver.cpp:236]     Train net output #0: loss = 0.760603 (* 1 = 0.760603 loss)
I0416 15:16:50.907132   977 solver.cpp:542] Iteration 16460, lr = 0.1
I0416 15:17:04.429462   977 solver.cpp:221] Iteration 16480, loss = 0.800015
I0416 15:17:04.429489   977 solver.cpp:236]     Train net output #0: loss = 0.834223 (* 1 = 0.834223 loss)
I0416 15:17:04.429493   977 solver.cpp:542] Iteration 16480, lr = 0.1
I0416 15:17:17.953423   977 solver.cpp:221] Iteration 16500, loss = 0.840548
I0416 15:17:17.953451   977 solver.cpp:236]     Train net output #0: loss = 0.769239 (* 1 = 0.769239 loss)
I0416 15:17:17.953455   977 solver.cpp:542] Iteration 16500, lr = 0.1
I0416 15:17:31.487740   977 solver.cpp:221] Iteration 16520, loss = 0.824505
I0416 15:17:31.487767   977 solver.cpp:236]     Train net output #0: loss = 0.650112 (* 1 = 0.650112 loss)
I0416 15:17:31.487772   977 solver.cpp:542] Iteration 16520, lr = 0.1
I0416 15:17:45.011975   977 solver.cpp:221] Iteration 16540, loss = 0.777321
I0416 15:17:45.012001   977 solver.cpp:236]     Train net output #0: loss = 0.843748 (* 1 = 0.843748 loss)
I0416 15:17:45.012006   977 solver.cpp:542] Iteration 16540, lr = 0.1
I0416 15:17:58.542605   977 solver.cpp:221] Iteration 16560, loss = 0.869743
I0416 15:17:58.542634   977 solver.cpp:236]     Train net output #0: loss = 0.866748 (* 1 = 0.866748 loss)
I0416 15:17:58.542639   977 solver.cpp:542] Iteration 16560, lr = 0.1
I0416 15:18:12.078282   977 solver.cpp:221] Iteration 16580, loss = 0.789681
I0416 15:18:12.078311   977 solver.cpp:236]     Train net output #0: loss = 0.920434 (* 1 = 0.920434 loss)
I0416 15:18:12.078316   977 solver.cpp:542] Iteration 16580, lr = 0.1
I0416 15:18:24.981551   977 solver.cpp:316] Iteration 16600, Testing net (#0)
I0416 15:18:36.514147   977 solver.cpp:373]     Test net output #0: accuracy = 0.781939
I0416 15:18:36.514168   977 solver.cpp:373]     Test net output #1: loss = 0.860421 (* 1 = 0.860421 loss)
I0416 15:18:37.180064   977 solver.cpp:221] Iteration 16600, loss = 0.811455
I0416 15:18:37.180091   977 solver.cpp:236]     Train net output #0: loss = 0.74273 (* 1 = 0.74273 loss)
I0416 15:18:37.180096   977 solver.cpp:542] Iteration 16600, lr = 0.1
I0416 15:18:50.699985   977 solver.cpp:221] Iteration 16620, loss = 0.831634
I0416 15:18:50.700013   977 solver.cpp:236]     Train net output #0: loss = 0.756537 (* 1 = 0.756537 loss)
I0416 15:18:50.700017   977 solver.cpp:542] Iteration 16620, lr = 0.1
I0416 15:19:04.242106   977 solver.cpp:221] Iteration 16640, loss = 0.80037
I0416 15:19:04.242133   977 solver.cpp:236]     Train net output #0: loss = 0.786228 (* 1 = 0.786228 loss)
I0416 15:19:04.242138   977 solver.cpp:542] Iteration 16640, lr = 0.1
I0416 15:19:17.763592   977 solver.cpp:221] Iteration 16660, loss = 0.783995
I0416 15:19:17.763618   977 solver.cpp:236]     Train net output #0: loss = 0.788096 (* 1 = 0.788096 loss)
I0416 15:19:17.763623   977 solver.cpp:542] Iteration 16660, lr = 0.1
I0416 15:19:31.281276   977 solver.cpp:221] Iteration 16680, loss = 0.80226
I0416 15:19:31.281304   977 solver.cpp:236]     Train net output #0: loss = 0.612939 (* 1 = 0.612939 loss)
I0416 15:19:31.281308   977 solver.cpp:542] Iteration 16680, lr = 0.1
I0416 15:19:44.800849   977 solver.cpp:221] Iteration 16700, loss = 0.784367
I0416 15:19:44.800876   977 solver.cpp:236]     Train net output #0: loss = 0.944291 (* 1 = 0.944291 loss)
I0416 15:19:44.800880   977 solver.cpp:542] Iteration 16700, lr = 0.1
I0416 15:19:58.336277   977 solver.cpp:221] Iteration 16720, loss = 0.802987
I0416 15:19:58.336304   977 solver.cpp:236]     Train net output #0: loss = 0.665143 (* 1 = 0.665143 loss)
I0416 15:19:58.336309   977 solver.cpp:542] Iteration 16720, lr = 0.1
I0416 15:20:11.855561   977 solver.cpp:221] Iteration 16740, loss = 0.824931
I0416 15:20:11.855588   977 solver.cpp:236]     Train net output #0: loss = 0.633419 (* 1 = 0.633419 loss)
I0416 15:20:11.855593   977 solver.cpp:542] Iteration 16740, lr = 0.1
I0416 15:20:25.370481   977 solver.cpp:221] Iteration 16760, loss = 0.800243
I0416 15:20:25.370508   977 solver.cpp:236]     Train net output #0: loss = 0.837252 (* 1 = 0.837252 loss)
I0416 15:20:25.370513   977 solver.cpp:542] Iteration 16760, lr = 0.1
I0416 15:20:38.882236   977 solver.cpp:221] Iteration 16780, loss = 0.78614
I0416 15:20:38.882262   977 solver.cpp:236]     Train net output #0: loss = 0.850595 (* 1 = 0.850595 loss)
I0416 15:20:38.882267   977 solver.cpp:542] Iteration 16780, lr = 0.1
I0416 15:20:51.736156   977 solver.cpp:316] Iteration 16800, Testing net (#0)
I0416 15:21:03.262300   977 solver.cpp:373]     Test net output #0: accuracy = 0.838593
I0416 15:21:03.262321   977 solver.cpp:373]     Test net output #1: loss = 0.615374 (* 1 = 0.615374 loss)
I0416 15:21:03.929023   977 solver.cpp:221] Iteration 16800, loss = 0.787881
I0416 15:21:03.929049   977 solver.cpp:236]     Train net output #0: loss = 0.885402 (* 1 = 0.885402 loss)
I0416 15:21:03.929054   977 solver.cpp:542] Iteration 16800, lr = 0.1
I0416 15:21:17.447773   977 solver.cpp:221] Iteration 16820, loss = 0.879977
I0416 15:21:17.447801   977 solver.cpp:236]     Train net output #0: loss = 0.7823 (* 1 = 0.7823 loss)
I0416 15:21:17.447805   977 solver.cpp:542] Iteration 16820, lr = 0.1
I0416 15:21:30.996685   977 solver.cpp:221] Iteration 16840, loss = 0.845323
I0416 15:21:30.996711   977 solver.cpp:236]     Train net output #0: loss = 0.883028 (* 1 = 0.883028 loss)
I0416 15:21:30.996716   977 solver.cpp:542] Iteration 16840, lr = 0.1
I0416 15:21:44.526181   977 solver.cpp:221] Iteration 16860, loss = 0.83329
I0416 15:21:44.526209   977 solver.cpp:236]     Train net output #0: loss = 0.875788 (* 1 = 0.875788 loss)
I0416 15:21:44.526213   977 solver.cpp:542] Iteration 16860, lr = 0.1
I0416 15:21:58.046072   977 solver.cpp:221] Iteration 16880, loss = 0.828465
I0416 15:21:58.046099   977 solver.cpp:236]     Train net output #0: loss = 0.671313 (* 1 = 0.671313 loss)
I0416 15:21:58.046104   977 solver.cpp:542] Iteration 16880, lr = 0.1
I0416 15:22:11.571629   977 solver.cpp:221] Iteration 16900, loss = 0.826348
I0416 15:22:11.571655   977 solver.cpp:236]     Train net output #0: loss = 0.929046 (* 1 = 0.929046 loss)
I0416 15:22:11.571660   977 solver.cpp:542] Iteration 16900, lr = 0.1
I0416 15:22:25.090586   977 solver.cpp:221] Iteration 16920, loss = 0.836473
I0416 15:22:25.090612   977 solver.cpp:236]     Train net output #0: loss = 0.691831 (* 1 = 0.691831 loss)
I0416 15:22:25.090617   977 solver.cpp:542] Iteration 16920, lr = 0.1
I0416 15:22:38.613313   977 solver.cpp:221] Iteration 16940, loss = 0.75584
I0416 15:22:38.613342   977 solver.cpp:236]     Train net output #0: loss = 0.969819 (* 1 = 0.969819 loss)
I0416 15:22:38.613346   977 solver.cpp:542] Iteration 16940, lr = 0.1
I0416 15:22:52.126926   977 solver.cpp:221] Iteration 16960, loss = 0.856505
I0416 15:22:52.126953   977 solver.cpp:236]     Train net output #0: loss = 0.763664 (* 1 = 0.763664 loss)
I0416 15:22:52.126958   977 solver.cpp:542] Iteration 16960, lr = 0.1
I0416 15:23:05.660516   977 solver.cpp:221] Iteration 16980, loss = 0.856452
I0416 15:23:05.660543   977 solver.cpp:236]     Train net output #0: loss = 0.624685 (* 1 = 0.624685 loss)
I0416 15:23:05.660548   977 solver.cpp:542] Iteration 16980, lr = 0.1
I0416 15:23:18.520325   977 solver.cpp:316] Iteration 17000, Testing net (#0)
I0416 15:23:30.044953   977 solver.cpp:373]     Test net output #0: accuracy = 0.911596
I0416 15:23:30.044975   977 solver.cpp:373]     Test net output #1: loss = 0.347657 (* 1 = 0.347657 loss)
I0416 15:23:30.712149   977 solver.cpp:221] Iteration 17000, loss = 0.811311
I0416 15:23:30.712177   977 solver.cpp:236]     Train net output #0: loss = 0.630404 (* 1 = 0.630404 loss)
I0416 15:23:30.712183   977 solver.cpp:542] Iteration 17000, lr = 0.1
I0416 15:23:44.246153   977 solver.cpp:221] Iteration 17020, loss = 0.855106
I0416 15:23:44.246181   977 solver.cpp:236]     Train net output #0: loss = 0.677295 (* 1 = 0.677295 loss)
I0416 15:23:44.246186   977 solver.cpp:542] Iteration 17020, lr = 0.1
I0416 15:23:57.774583   977 solver.cpp:221] Iteration 17040, loss = 0.877226
I0416 15:23:57.774611   977 solver.cpp:236]     Train net output #0: loss = 0.68053 (* 1 = 0.68053 loss)
I0416 15:23:57.774616   977 solver.cpp:542] Iteration 17040, lr = 0.1
I0416 15:24:11.289597   977 solver.cpp:221] Iteration 17060, loss = 0.86602
I0416 15:24:11.289624   977 solver.cpp:236]     Train net output #0: loss = 0.953259 (* 1 = 0.953259 loss)
I0416 15:24:11.289628   977 solver.cpp:542] Iteration 17060, lr = 0.1
I0416 15:24:24.807478   977 solver.cpp:221] Iteration 17080, loss = 0.81623
I0416 15:24:24.807507   977 solver.cpp:236]     Train net output #0: loss = 0.956408 (* 1 = 0.956408 loss)
I0416 15:24:24.807512   977 solver.cpp:542] Iteration 17080, lr = 0.1
I0416 15:24:38.337980   977 solver.cpp:221] Iteration 17100, loss = 0.854515
I0416 15:24:38.338006   977 solver.cpp:236]     Train net output #0: loss = 0.534222 (* 1 = 0.534222 loss)
I0416 15:24:38.338011   977 solver.cpp:542] Iteration 17100, lr = 0.1
I0416 15:24:51.877117   977 solver.cpp:221] Iteration 17120, loss = 0.858421
I0416 15:24:51.877145   977 solver.cpp:236]     Train net output #0: loss = 0.822126 (* 1 = 0.822126 loss)
I0416 15:24:51.877148   977 solver.cpp:542] Iteration 17120, lr = 0.1
I0416 15:25:05.426676   977 solver.cpp:221] Iteration 17140, loss = 0.878482
I0416 15:25:05.426702   977 solver.cpp:236]     Train net output #0: loss = 0.685125 (* 1 = 0.685125 loss)
I0416 15:25:05.426707   977 solver.cpp:542] Iteration 17140, lr = 0.1
I0416 15:25:18.982511   977 solver.cpp:221] Iteration 17160, loss = 0.79638
I0416 15:25:18.982538   977 solver.cpp:236]     Train net output #0: loss = 0.802455 (* 1 = 0.802455 loss)
I0416 15:25:18.982542   977 solver.cpp:542] Iteration 17160, lr = 0.1
I0416 15:25:32.523473   977 solver.cpp:221] Iteration 17180, loss = 0.811668
I0416 15:25:32.523500   977 solver.cpp:236]     Train net output #0: loss = 0.73273 (* 1 = 0.73273 loss)
I0416 15:25:32.523505   977 solver.cpp:542] Iteration 17180, lr = 0.1
I0416 15:25:45.407403   977 solver.cpp:316] Iteration 17200, Testing net (#0)
I0416 15:25:56.933796   977 solver.cpp:373]     Test net output #0: accuracy = 0.877376
I0416 15:25:56.933817   977 solver.cpp:373]     Test net output #1: loss = 0.469952 (* 1 = 0.469952 loss)
I0416 15:25:57.601174   977 solver.cpp:221] Iteration 17200, loss = 0.829923
I0416 15:25:57.601202   977 solver.cpp:236]     Train net output #0: loss = 0.823863 (* 1 = 0.823863 loss)
I0416 15:25:57.601207   977 solver.cpp:542] Iteration 17200, lr = 0.1
I0416 15:26:11.138018   977 solver.cpp:221] Iteration 17220, loss = 0.803858
I0416 15:26:11.138046   977 solver.cpp:236]     Train net output #0: loss = 0.860866 (* 1 = 0.860866 loss)
I0416 15:26:11.138051   977 solver.cpp:542] Iteration 17220, lr = 0.1
I0416 15:26:24.675184   977 solver.cpp:221] Iteration 17240, loss = 0.847481
I0416 15:26:24.675211   977 solver.cpp:236]     Train net output #0: loss = 0.833682 (* 1 = 0.833682 loss)
I0416 15:26:24.675216   977 solver.cpp:542] Iteration 17240, lr = 0.1
I0416 15:26:38.202870   977 solver.cpp:221] Iteration 17260, loss = 0.816364
I0416 15:26:38.202898   977 solver.cpp:236]     Train net output #0: loss = 0.396665 (* 1 = 0.396665 loss)
I0416 15:26:38.202903   977 solver.cpp:542] Iteration 17260, lr = 0.1
I0416 15:26:51.702504   977 solver.cpp:221] Iteration 17280, loss = 0.821263
I0416 15:26:51.702532   977 solver.cpp:236]     Train net output #0: loss = 0.760849 (* 1 = 0.760849 loss)
I0416 15:26:51.702536   977 solver.cpp:542] Iteration 17280, lr = 0.1
I0416 15:27:05.211284   977 solver.cpp:221] Iteration 17300, loss = 0.797885
I0416 15:27:05.211311   977 solver.cpp:236]     Train net output #0: loss = 0.571398 (* 1 = 0.571398 loss)
I0416 15:27:05.211315   977 solver.cpp:542] Iteration 17300, lr = 0.1
I0416 15:27:18.731665   977 solver.cpp:221] Iteration 17320, loss = 0.817509
I0416 15:27:18.731693   977 solver.cpp:236]     Train net output #0: loss = 1.36072 (* 1 = 1.36072 loss)
I0416 15:27:18.731696   977 solver.cpp:542] Iteration 17320, lr = 0.1
I0416 15:27:32.283047   977 solver.cpp:221] Iteration 17340, loss = 0.830028
I0416 15:27:32.283076   977 solver.cpp:236]     Train net output #0: loss = 1.15007 (* 1 = 1.15007 loss)
I0416 15:27:32.283079   977 solver.cpp:542] Iteration 17340, lr = 0.1
I0416 15:27:45.832805   977 solver.cpp:221] Iteration 17360, loss = 0.819839
I0416 15:27:45.832834   977 solver.cpp:236]     Train net output #0: loss = 0.819983 (* 1 = 0.819983 loss)
I0416 15:27:45.832837   977 solver.cpp:542] Iteration 17360, lr = 0.1
I0416 15:27:59.355445   977 solver.cpp:221] Iteration 17380, loss = 0.834118
I0416 15:27:59.355473   977 solver.cpp:236]     Train net output #0: loss = 0.701681 (* 1 = 0.701681 loss)
I0416 15:27:59.355478   977 solver.cpp:542] Iteration 17380, lr = 0.1
I0416 15:28:12.237748   977 solver.cpp:316] Iteration 17400, Testing net (#0)
I0416 15:28:23.774271   977 solver.cpp:373]     Test net output #0: accuracy = 0.888213
I0416 15:28:23.774293   977 solver.cpp:373]     Test net output #1: loss = 0.419228 (* 1 = 0.419228 loss)
I0416 15:28:24.444203   977 solver.cpp:221] Iteration 17400, loss = 0.831948
I0416 15:28:24.444231   977 solver.cpp:236]     Train net output #0: loss = 0.970779 (* 1 = 0.970779 loss)
I0416 15:28:24.444236   977 solver.cpp:542] Iteration 17400, lr = 0.1
I0416 15:28:37.994738   977 solver.cpp:221] Iteration 17420, loss = 0.828474
I0416 15:28:37.994765   977 solver.cpp:236]     Train net output #0: loss = 1.3336 (* 1 = 1.3336 loss)
I0416 15:28:37.994770   977 solver.cpp:542] Iteration 17420, lr = 0.1
I0416 15:28:51.508774   977 solver.cpp:221] Iteration 17440, loss = 0.854718
I0416 15:28:51.508800   977 solver.cpp:236]     Train net output #0: loss = 0.79617 (* 1 = 0.79617 loss)
I0416 15:28:51.508805   977 solver.cpp:542] Iteration 17440, lr = 0.1
I0416 15:29:05.026345   977 solver.cpp:221] Iteration 17460, loss = 0.87349
I0416 15:29:05.026372   977 solver.cpp:236]     Train net output #0: loss = 0.737927 (* 1 = 0.737927 loss)
I0416 15:29:05.026378   977 solver.cpp:542] Iteration 17460, lr = 0.1
I0416 15:29:18.552747   977 solver.cpp:221] Iteration 17480, loss = 0.857778
I0416 15:29:18.552774   977 solver.cpp:236]     Train net output #0: loss = 0.79876 (* 1 = 0.79876 loss)
I0416 15:29:18.552779   977 solver.cpp:542] Iteration 17480, lr = 0.1
I0416 15:29:32.109033   977 solver.cpp:221] Iteration 17500, loss = 0.876138
I0416 15:29:32.109061   977 solver.cpp:236]     Train net output #0: loss = 0.873155 (* 1 = 0.873155 loss)
I0416 15:29:32.109066   977 solver.cpp:542] Iteration 17500, lr = 0.1
I0416 15:29:45.631824   977 solver.cpp:221] Iteration 17520, loss = 0.842956
I0416 15:29:45.631852   977 solver.cpp:236]     Train net output #0: loss = 0.850749 (* 1 = 0.850749 loss)
I0416 15:29:45.631857   977 solver.cpp:542] Iteration 17520, lr = 0.1
I0416 15:29:59.154100   977 solver.cpp:221] Iteration 17540, loss = 0.843237
I0416 15:29:59.154126   977 solver.cpp:236]     Train net output #0: loss = 0.826833 (* 1 = 0.826833 loss)
I0416 15:29:59.154131   977 solver.cpp:542] Iteration 17540, lr = 0.1
I0416 15:30:12.677166   977 solver.cpp:221] Iteration 17560, loss = 0.793593
I0416 15:30:12.677193   977 solver.cpp:236]     Train net output #0: loss = 0.930608 (* 1 = 0.930608 loss)
I0416 15:30:12.677197   977 solver.cpp:542] Iteration 17560, lr = 0.1
I0416 15:30:26.198161   977 solver.cpp:221] Iteration 17580, loss = 0.831369
I0416 15:30:26.198189   977 solver.cpp:236]     Train net output #0: loss = 0.650807 (* 1 = 0.650807 loss)
I0416 15:30:26.198194   977 solver.cpp:542] Iteration 17580, lr = 0.1
I0416 15:30:39.063215   977 solver.cpp:316] Iteration 17600, Testing net (#0)
I0416 15:30:50.586515   977 solver.cpp:373]     Test net output #0: accuracy = 0.903611
I0416 15:30:50.586535   977 solver.cpp:373]     Test net output #1: loss = 0.375435 (* 1 = 0.375435 loss)
I0416 15:30:51.254523   977 solver.cpp:221] Iteration 17600, loss = 0.794586
I0416 15:30:51.254551   977 solver.cpp:236]     Train net output #0: loss = 0.869818 (* 1 = 0.869818 loss)
I0416 15:30:51.254556   977 solver.cpp:542] Iteration 17600, lr = 0.1
I0416 15:31:04.792608   977 solver.cpp:221] Iteration 17620, loss = 0.838194
I0416 15:31:04.792636   977 solver.cpp:236]     Train net output #0: loss = 0.913278 (* 1 = 0.913278 loss)
I0416 15:31:04.792642   977 solver.cpp:542] Iteration 17620, lr = 0.1
I0416 15:31:18.345561   977 solver.cpp:221] Iteration 17640, loss = 0.802617
I0416 15:31:18.345588   977 solver.cpp:236]     Train net output #0: loss = 1.10776 (* 1 = 1.10776 loss)
I0416 15:31:18.345593   977 solver.cpp:542] Iteration 17640, lr = 0.1
I0416 15:31:31.885330   977 solver.cpp:221] Iteration 17660, loss = 0.87642
I0416 15:31:31.885357   977 solver.cpp:236]     Train net output #0: loss = 0.693803 (* 1 = 0.693803 loss)
I0416 15:31:31.885362   977 solver.cpp:542] Iteration 17660, lr = 0.1
I0416 15:31:45.424576   977 solver.cpp:221] Iteration 17680, loss = 0.834614
I0416 15:31:45.424603   977 solver.cpp:236]     Train net output #0: loss = 1.17498 (* 1 = 1.17498 loss)
I0416 15:31:45.424608   977 solver.cpp:542] Iteration 17680, lr = 0.1
I0416 15:31:58.995203   977 solver.cpp:221] Iteration 17700, loss = 0.791311
I0416 15:31:58.995230   977 solver.cpp:236]     Train net output #0: loss = 0.872428 (* 1 = 0.872428 loss)
I0416 15:31:58.995234   977 solver.cpp:542] Iteration 17700, lr = 0.1
I0416 15:32:12.545986   977 solver.cpp:221] Iteration 17720, loss = 0.826313
I0416 15:32:12.546015   977 solver.cpp:236]     Train net output #0: loss = 0.952653 (* 1 = 0.952653 loss)
I0416 15:32:12.546020   977 solver.cpp:542] Iteration 17720, lr = 0.1
I0416 15:32:26.060472   977 solver.cpp:221] Iteration 17740, loss = 0.833298
I0416 15:32:26.060499   977 solver.cpp:236]     Train net output #0: loss = 1.12252 (* 1 = 1.12252 loss)
I0416 15:32:26.060503   977 solver.cpp:542] Iteration 17740, lr = 0.1
I0416 15:32:39.584040   977 solver.cpp:221] Iteration 17760, loss = 0.897945
I0416 15:32:39.584067   977 solver.cpp:236]     Train net output #0: loss = 1.09523 (* 1 = 1.09523 loss)
I0416 15:32:39.584072   977 solver.cpp:542] Iteration 17760, lr = 0.1
I0416 15:32:53.118651   977 solver.cpp:221] Iteration 17780, loss = 0.820125
I0416 15:32:53.118680   977 solver.cpp:236]     Train net output #0: loss = 0.905312 (* 1 = 0.905312 loss)
I0416 15:32:53.118683   977 solver.cpp:542] Iteration 17780, lr = 0.1
I0416 15:33:05.992956   977 solver.cpp:316] Iteration 17800, Testing net (#0)
I0416 15:33:17.517174   977 solver.cpp:373]     Test net output #0: accuracy = 0.874144
I0416 15:33:17.517194   977 solver.cpp:373]     Test net output #1: loss = 0.470722 (* 1 = 0.470722 loss)
I0416 15:33:18.184864   977 solver.cpp:221] Iteration 17800, loss = 0.839967
I0416 15:33:18.184892   977 solver.cpp:236]     Train net output #0: loss = 0.755857 (* 1 = 0.755857 loss)
I0416 15:33:18.184897   977 solver.cpp:542] Iteration 17800, lr = 0.1
I0416 15:33:31.688464   977 solver.cpp:221] Iteration 17820, loss = 0.784097
I0416 15:33:31.688493   977 solver.cpp:236]     Train net output #0: loss = 0.950911 (* 1 = 0.950911 loss)
I0416 15:33:31.688498   977 solver.cpp:542] Iteration 17820, lr = 0.1
I0416 15:33:45.188613   977 solver.cpp:221] Iteration 17840, loss = 0.815515
I0416 15:33:45.188642   977 solver.cpp:236]     Train net output #0: loss = 0.43771 (* 1 = 0.43771 loss)
I0416 15:33:45.188645   977 solver.cpp:542] Iteration 17840, lr = 0.1
I0416 15:33:58.694226   977 solver.cpp:221] Iteration 17860, loss = 0.821608
I0416 15:33:58.694252   977 solver.cpp:236]     Train net output #0: loss = 1.04337 (* 1 = 1.04337 loss)
I0416 15:33:58.694257   977 solver.cpp:542] Iteration 17860, lr = 0.1
I0416 15:34:12.207034   977 solver.cpp:221] Iteration 17880, loss = 0.836322
I0416 15:34:12.207062   977 solver.cpp:236]     Train net output #0: loss = 0.528137 (* 1 = 0.528137 loss)
I0416 15:34:12.207067   977 solver.cpp:542] Iteration 17880, lr = 0.1
I0416 15:34:25.710711   977 solver.cpp:221] Iteration 17900, loss = 0.897774
I0416 15:34:25.710739   977 solver.cpp:236]     Train net output #0: loss = 0.75115 (* 1 = 0.75115 loss)
I0416 15:34:25.710744   977 solver.cpp:542] Iteration 17900, lr = 0.1
I0416 15:34:39.216267   977 solver.cpp:221] Iteration 17920, loss = 0.883015
I0416 15:34:39.216295   977 solver.cpp:236]     Train net output #0: loss = 1.23119 (* 1 = 1.23119 loss)
I0416 15:34:39.216300   977 solver.cpp:542] Iteration 17920, lr = 0.1
I0416 15:34:52.727527   977 solver.cpp:221] Iteration 17940, loss = 0.887793
I0416 15:34:52.727555   977 solver.cpp:236]     Train net output #0: loss = 0.796203 (* 1 = 0.796203 loss)
I0416 15:34:52.727558   977 solver.cpp:542] Iteration 17940, lr = 0.1
I0416 15:35:06.270779   977 solver.cpp:221] Iteration 17960, loss = 0.864824
I0416 15:35:06.270807   977 solver.cpp:236]     Train net output #0: loss = 0.908329 (* 1 = 0.908329 loss)
I0416 15:35:06.270812   977 solver.cpp:542] Iteration 17960, lr = 0.1
I0416 15:35:19.794796   977 solver.cpp:221] Iteration 17980, loss = 0.826466
I0416 15:35:19.794824   977 solver.cpp:236]     Train net output #0: loss = 0.859827 (* 1 = 0.859827 loss)
I0416 15:35:19.794829   977 solver.cpp:542] Iteration 17980, lr = 0.1
I0416 15:35:32.665771   977 solver.cpp:316] Iteration 18000, Testing net (#0)
I0416 15:35:44.189246   977 solver.cpp:373]     Test net output #0: accuracy = 0.890114
I0416 15:35:44.189267   977 solver.cpp:373]     Test net output #1: loss = 0.418706 (* 1 = 0.418706 loss)
I0416 15:35:44.857816   977 solver.cpp:221] Iteration 18000, loss = 0.826255
I0416 15:35:44.857844   977 solver.cpp:236]     Train net output #0: loss = 0.768471 (* 1 = 0.768471 loss)
I0416 15:35:44.857848   977 solver.cpp:542] Iteration 18000, lr = 0.1
I0416 15:35:58.363787   977 solver.cpp:221] Iteration 18020, loss = 0.826353
I0416 15:35:58.363816   977 solver.cpp:236]     Train net output #0: loss = 0.96168 (* 1 = 0.96168 loss)
I0416 15:35:58.363821   977 solver.cpp:542] Iteration 18020, lr = 0.1
I0416 15:36:11.897510   977 solver.cpp:221] Iteration 18040, loss = 0.857424
I0416 15:36:11.897537   977 solver.cpp:236]     Train net output #0: loss = 0.878062 (* 1 = 0.878062 loss)
I0416 15:36:11.897543   977 solver.cpp:542] Iteration 18040, lr = 0.1
I0416 15:36:25.447698   977 solver.cpp:221] Iteration 18060, loss = 0.791859
I0416 15:36:25.447726   977 solver.cpp:236]     Train net output #0: loss = 0.717546 (* 1 = 0.717546 loss)
I0416 15:36:25.447731   977 solver.cpp:542] Iteration 18060, lr = 0.1
I0416 15:36:38.997963   977 solver.cpp:221] Iteration 18080, loss = 0.809648
I0416 15:36:38.997989   977 solver.cpp:236]     Train net output #0: loss = 0.660642 (* 1 = 0.660642 loss)
I0416 15:36:38.997994   977 solver.cpp:542] Iteration 18080, lr = 0.1
I0416 15:36:52.520347   977 solver.cpp:221] Iteration 18100, loss = 0.816685
I0416 15:36:52.520375   977 solver.cpp:236]     Train net output #0: loss = 0.920653 (* 1 = 0.920653 loss)
I0416 15:36:52.520378   977 solver.cpp:542] Iteration 18100, lr = 0.1
I0416 15:37:06.047202   977 solver.cpp:221] Iteration 18120, loss = 0.80253
I0416 15:37:06.047230   977 solver.cpp:236]     Train net output #0: loss = 0.764349 (* 1 = 0.764349 loss)
I0416 15:37:06.047235   977 solver.cpp:542] Iteration 18120, lr = 0.1
I0416 15:37:19.595737   977 solver.cpp:221] Iteration 18140, loss = 0.824315
I0416 15:37:19.595764   977 solver.cpp:236]     Train net output #0: loss = 0.903418 (* 1 = 0.903418 loss)
I0416 15:37:19.595768   977 solver.cpp:542] Iteration 18140, lr = 0.1
I0416 15:37:33.139633   977 solver.cpp:221] Iteration 18160, loss = 0.870976
I0416 15:37:33.139660   977 solver.cpp:236]     Train net output #0: loss = 1.17341 (* 1 = 1.17341 loss)
I0416 15:37:33.139665   977 solver.cpp:542] Iteration 18160, lr = 0.1
I0416 15:37:46.681723   977 solver.cpp:221] Iteration 18180, loss = 0.834619
I0416 15:37:46.681751   977 solver.cpp:236]     Train net output #0: loss = 0.660038 (* 1 = 0.660038 loss)
I0416 15:37:46.681756   977 solver.cpp:542] Iteration 18180, lr = 0.1
I0416 15:37:59.552306   977 solver.cpp:316] Iteration 18200, Testing net (#0)
I0416 15:38:11.087060   977 solver.cpp:373]     Test net output #0: accuracy = 0.795627
I0416 15:38:11.087080   977 solver.cpp:373]     Test net output #1: loss = 0.771527 (* 1 = 0.771527 loss)
I0416 15:38:11.757825   977 solver.cpp:221] Iteration 18200, loss = 0.856065
I0416 15:38:11.757853   977 solver.cpp:236]     Train net output #0: loss = 1.05452 (* 1 = 1.05452 loss)
I0416 15:38:11.757858   977 solver.cpp:542] Iteration 18200, lr = 0.1
I0416 15:38:25.282304   977 solver.cpp:221] Iteration 18220, loss = 0.86756
I0416 15:38:25.282331   977 solver.cpp:236]     Train net output #0: loss = 0.884691 (* 1 = 0.884691 loss)
I0416 15:38:25.282336   977 solver.cpp:542] Iteration 18220, lr = 0.1
I0416 15:38:38.831290   977 solver.cpp:221] Iteration 18240, loss = 0.825262
I0416 15:38:38.831317   977 solver.cpp:236]     Train net output #0: loss = 0.724407 (* 1 = 0.724407 loss)
I0416 15:38:38.831322   977 solver.cpp:542] Iteration 18240, lr = 0.1
I0416 15:38:52.341548   977 solver.cpp:221] Iteration 18260, loss = 0.847871
I0416 15:38:52.341575   977 solver.cpp:236]     Train net output #0: loss = 1.15618 (* 1 = 1.15618 loss)
I0416 15:38:52.341579   977 solver.cpp:542] Iteration 18260, lr = 0.1
I0416 15:39:05.846905   977 solver.cpp:221] Iteration 18280, loss = 0.773681
I0416 15:39:05.846931   977 solver.cpp:236]     Train net output #0: loss = 0.98443 (* 1 = 0.98443 loss)
I0416 15:39:05.846936   977 solver.cpp:542] Iteration 18280, lr = 0.1
I0416 15:39:19.381364   977 solver.cpp:221] Iteration 18300, loss = 0.758555
I0416 15:39:19.381392   977 solver.cpp:236]     Train net output #0: loss = 0.456402 (* 1 = 0.456402 loss)
I0416 15:39:19.381397   977 solver.cpp:542] Iteration 18300, lr = 0.1
I0416 15:39:32.894700   977 solver.cpp:221] Iteration 18320, loss = 0.791895
I0416 15:39:32.894726   977 solver.cpp:236]     Train net output #0: loss = 0.816106 (* 1 = 0.816106 loss)
I0416 15:39:32.894731   977 solver.cpp:542] Iteration 18320, lr = 0.1
I0416 15:39:46.411510   977 solver.cpp:221] Iteration 18340, loss = 0.766779
I0416 15:39:46.411538   977 solver.cpp:236]     Train net output #0: loss = 1.026 (* 1 = 1.026 loss)
I0416 15:39:46.411545   977 solver.cpp:542] Iteration 18340, lr = 0.1
I0416 15:39:59.961204   977 solver.cpp:221] Iteration 18360, loss = 0.830302
I0416 15:39:59.961230   977 solver.cpp:236]     Train net output #0: loss = 0.824807 (* 1 = 0.824807 loss)
I0416 15:39:59.961236   977 solver.cpp:542] Iteration 18360, lr = 0.1
I0416 15:40:13.482138   977 solver.cpp:221] Iteration 18380, loss = 0.862564
I0416 15:40:13.482167   977 solver.cpp:236]     Train net output #0: loss = 1.15275 (* 1 = 1.15275 loss)
I0416 15:40:13.482170   977 solver.cpp:542] Iteration 18380, lr = 0.1
I0416 15:40:26.354818   977 solver.cpp:316] Iteration 18400, Testing net (#0)
I0416 15:40:37.879194   977 solver.cpp:373]     Test net output #0: accuracy = 0.86597
I0416 15:40:37.879215   977 solver.cpp:373]     Test net output #1: loss = 0.517547 (* 1 = 0.517547 loss)
I0416 15:40:38.547440   977 solver.cpp:221] Iteration 18400, loss = 0.829716
I0416 15:40:38.547466   977 solver.cpp:236]     Train net output #0: loss = 0.770408 (* 1 = 0.770408 loss)
I0416 15:40:38.547471   977 solver.cpp:542] Iteration 18400, lr = 0.1
I0416 15:40:52.059026   977 solver.cpp:221] Iteration 18420, loss = 0.815638
I0416 15:40:52.059053   977 solver.cpp:236]     Train net output #0: loss = 0.912506 (* 1 = 0.912506 loss)
I0416 15:40:52.059057   977 solver.cpp:542] Iteration 18420, lr = 0.1
I0416 15:41:05.557751   977 solver.cpp:221] Iteration 18440, loss = 0.812815
I0416 15:41:05.557778   977 solver.cpp:236]     Train net output #0: loss = 0.699314 (* 1 = 0.699314 loss)
I0416 15:41:05.557785   977 solver.cpp:542] Iteration 18440, lr = 0.1
I0416 15:41:19.074916   977 solver.cpp:221] Iteration 18460, loss = 0.807457
I0416 15:41:19.074944   977 solver.cpp:236]     Train net output #0: loss = 0.983067 (* 1 = 0.983067 loss)
I0416 15:41:19.074949   977 solver.cpp:542] Iteration 18460, lr = 0.1
I0416 15:41:32.615942   977 solver.cpp:221] Iteration 18480, loss = 0.806688
I0416 15:41:32.615969   977 solver.cpp:236]     Train net output #0: loss = 0.7146 (* 1 = 0.7146 loss)
I0416 15:41:32.615974   977 solver.cpp:542] Iteration 18480, lr = 0.1
I0416 15:41:46.172073   977 solver.cpp:221] Iteration 18500, loss = 0.780004
I0416 15:41:46.172101   977 solver.cpp:236]     Train net output #0: loss = 0.663806 (* 1 = 0.663806 loss)
I0416 15:41:46.172104   977 solver.cpp:542] Iteration 18500, lr = 0.1
I0416 15:41:59.722755   977 solver.cpp:221] Iteration 18520, loss = 0.774995
I0416 15:41:59.722782   977 solver.cpp:236]     Train net output #0: loss = 0.745741 (* 1 = 0.745741 loss)
I0416 15:41:59.722787   977 solver.cpp:542] Iteration 18520, lr = 0.1
I0416 15:42:13.292315   977 solver.cpp:221] Iteration 18540, loss = 0.754019
I0416 15:42:13.292341   977 solver.cpp:236]     Train net output #0: loss = 0.604723 (* 1 = 0.604723 loss)
I0416 15:42:13.292346   977 solver.cpp:542] Iteration 18540, lr = 0.1
I0416 15:42:26.855237   977 solver.cpp:221] Iteration 18560, loss = 0.719845
I0416 15:42:26.855264   977 solver.cpp:236]     Train net output #0: loss = 0.784573 (* 1 = 0.784573 loss)
I0416 15:42:26.855269   977 solver.cpp:542] Iteration 18560, lr = 0.1
I0416 15:42:40.361033   977 solver.cpp:221] Iteration 18580, loss = 0.741724
I0416 15:42:40.361059   977 solver.cpp:236]     Train net output #0: loss = 0.538769 (* 1 = 0.538769 loss)
I0416 15:42:40.361064   977 solver.cpp:542] Iteration 18580, lr = 0.1
I0416 15:42:53.214500   977 solver.cpp:316] Iteration 18600, Testing net (#0)
I0416 15:43:04.751399   977 solver.cpp:373]     Test net output #0: accuracy = 0.848859
I0416 15:43:04.751420   977 solver.cpp:373]     Test net output #1: loss = 0.558755 (* 1 = 0.558755 loss)
I0416 15:43:05.420918   977 solver.cpp:221] Iteration 18600, loss = 0.78066
I0416 15:43:05.420945   977 solver.cpp:236]     Train net output #0: loss = 0.705866 (* 1 = 0.705866 loss)
I0416 15:43:05.420950   977 solver.cpp:542] Iteration 18600, lr = 0.1
I0416 15:43:18.980855   977 solver.cpp:221] Iteration 18620, loss = 0.733172
I0416 15:43:18.980882   977 solver.cpp:236]     Train net output #0: loss = 0.560926 (* 1 = 0.560926 loss)
I0416 15:43:18.980887   977 solver.cpp:542] Iteration 18620, lr = 0.1
I0416 15:43:32.515111   977 solver.cpp:221] Iteration 18640, loss = 0.744598
I0416 15:43:32.515139   977 solver.cpp:236]     Train net output #0: loss = 0.695564 (* 1 = 0.695564 loss)
I0416 15:43:32.515144   977 solver.cpp:542] Iteration 18640, lr = 0.1
I0416 15:43:46.035893   977 solver.cpp:221] Iteration 18660, loss = 0.757843
I0416 15:43:46.035922   977 solver.cpp:236]     Train net output #0: loss = 0.94504 (* 1 = 0.94504 loss)
I0416 15:43:46.035925   977 solver.cpp:542] Iteration 18660, lr = 0.1
I0416 15:43:59.558522   977 solver.cpp:221] Iteration 18680, loss = 0.810027
I0416 15:43:59.558549   977 solver.cpp:236]     Train net output #0: loss = 0.584532 (* 1 = 0.584532 loss)
I0416 15:43:59.558553   977 solver.cpp:542] Iteration 18680, lr = 0.1
I0416 15:44:13.071147   977 solver.cpp:221] Iteration 18700, loss = 0.762322
I0416 15:44:13.071176   977 solver.cpp:236]     Train net output #0: loss = 0.898812 (* 1 = 0.898812 loss)
I0416 15:44:13.071180   977 solver.cpp:542] Iteration 18700, lr = 0.1
I0416 15:44:26.597323   977 solver.cpp:221] Iteration 18720, loss = 0.790227
I0416 15:44:26.597349   977 solver.cpp:236]     Train net output #0: loss = 0.782296 (* 1 = 0.782296 loss)
I0416 15:44:26.597354   977 solver.cpp:542] Iteration 18720, lr = 0.1
I0416 15:44:40.135602   977 solver.cpp:221] Iteration 18740, loss = 0.763731
I0416 15:44:40.135630   977 solver.cpp:236]     Train net output #0: loss = 0.787963 (* 1 = 0.787963 loss)
I0416 15:44:40.135634   977 solver.cpp:542] Iteration 18740, lr = 0.1
I0416 15:44:53.665560   977 solver.cpp:221] Iteration 18760, loss = 0.780252
I0416 15:44:53.665588   977 solver.cpp:236]     Train net output #0: loss = 0.796565 (* 1 = 0.796565 loss)
I0416 15:44:53.665594   977 solver.cpp:542] Iteration 18760, lr = 0.1
I0416 15:45:07.193367   977 solver.cpp:221] Iteration 18780, loss = 0.862061
I0416 15:45:07.193393   977 solver.cpp:236]     Train net output #0: loss = 0.9748 (* 1 = 0.9748 loss)
I0416 15:45:07.193398   977 solver.cpp:542] Iteration 18780, lr = 0.1
I0416 15:45:20.072876   977 solver.cpp:316] Iteration 18800, Testing net (#0)
I0416 15:45:31.612953   977 solver.cpp:373]     Test net output #0: accuracy = 0.860266
I0416 15:45:31.612975   977 solver.cpp:373]     Test net output #1: loss = 0.514192 (* 1 = 0.514192 loss)
I0416 15:45:32.282717   977 solver.cpp:221] Iteration 18800, loss = 0.779144
I0416 15:45:32.282745   977 solver.cpp:236]     Train net output #0: loss = 1.28215 (* 1 = 1.28215 loss)
I0416 15:45:32.282750   977 solver.cpp:542] Iteration 18800, lr = 0.1
I0416 15:45:45.828238   977 solver.cpp:221] Iteration 18820, loss = 0.796237
I0416 15:45:45.828265   977 solver.cpp:236]     Train net output #0: loss = 0.913623 (* 1 = 0.913623 loss)
I0416 15:45:45.828269   977 solver.cpp:542] Iteration 18820, lr = 0.1
I0416 15:45:59.359740   977 solver.cpp:221] Iteration 18840, loss = 0.802076
I0416 15:45:59.359766   977 solver.cpp:236]     Train net output #0: loss = 0.62925 (* 1 = 0.62925 loss)
I0416 15:45:59.359771   977 solver.cpp:542] Iteration 18840, lr = 0.1
I0416 15:46:12.906863   977 solver.cpp:221] Iteration 18860, loss = 0.786119
I0416 15:46:12.906890   977 solver.cpp:236]     Train net output #0: loss = 1.1403 (* 1 = 1.1403 loss)
I0416 15:46:12.906895   977 solver.cpp:542] Iteration 18860, lr = 0.1
I0416 15:46:26.447079   977 solver.cpp:221] Iteration 18880, loss = 0.857067
I0416 15:46:26.447105   977 solver.cpp:236]     Train net output #0: loss = 1.08853 (* 1 = 1.08853 loss)
I0416 15:46:26.447110   977 solver.cpp:542] Iteration 18880, lr = 0.1
I0416 15:46:40.001112   977 solver.cpp:221] Iteration 18900, loss = 0.781241
I0416 15:46:40.001139   977 solver.cpp:236]     Train net output #0: loss = 0.65281 (* 1 = 0.65281 loss)
I0416 15:46:40.001144   977 solver.cpp:542] Iteration 18900, lr = 0.1
I0416 15:46:53.544718   977 solver.cpp:221] Iteration 18920, loss = 0.812579
I0416 15:46:53.544744   977 solver.cpp:236]     Train net output #0: loss = 0.988198 (* 1 = 0.988198 loss)
I0416 15:46:53.544749   977 solver.cpp:542] Iteration 18920, lr = 0.1
I0416 15:47:07.082928   977 solver.cpp:221] Iteration 18940, loss = 0.860651
I0416 15:47:07.082957   977 solver.cpp:236]     Train net output #0: loss = 0.801495 (* 1 = 0.801495 loss)
I0416 15:47:07.082960   977 solver.cpp:542] Iteration 18940, lr = 0.1
I0416 15:47:20.664532   977 solver.cpp:221] Iteration 18960, loss = 0.855744
I0416 15:47:20.664561   977 solver.cpp:236]     Train net output #0: loss = 0.812975 (* 1 = 0.812975 loss)
I0416 15:47:20.664564   977 solver.cpp:542] Iteration 18960, lr = 0.1
I0416 15:47:34.199028   977 solver.cpp:221] Iteration 18980, loss = 0.890756
I0416 15:47:34.199056   977 solver.cpp:236]     Train net output #0: loss = 0.923882 (* 1 = 0.923882 loss)
I0416 15:47:34.199061   977 solver.cpp:542] Iteration 18980, lr = 0.1
I0416 15:47:47.079932   977 solver.cpp:316] Iteration 19000, Testing net (#0)
I0416 15:47:58.611047   977 solver.cpp:373]     Test net output #0: accuracy = 0.819962
I0416 15:47:58.611069   977 solver.cpp:373]     Test net output #1: loss = 0.707664 (* 1 = 0.707664 loss)
I0416 15:47:59.278854   977 solver.cpp:221] Iteration 19000, loss = 0.859198
I0416 15:47:59.278882   977 solver.cpp:236]     Train net output #0: loss = 1.11498 (* 1 = 1.11498 loss)
I0416 15:47:59.278885   977 solver.cpp:542] Iteration 19000, lr = 0.1
I0416 15:48:12.817216   977 solver.cpp:221] Iteration 19020, loss = 0.857703
I0416 15:48:12.817244   977 solver.cpp:236]     Train net output #0: loss = 0.859198 (* 1 = 0.859198 loss)
I0416 15:48:12.817248   977 solver.cpp:542] Iteration 19020, lr = 0.1
I0416 15:48:26.341686   977 solver.cpp:221] Iteration 19040, loss = 0.827977
I0416 15:48:26.341714   977 solver.cpp:236]     Train net output #0: loss = 0.629654 (* 1 = 0.629654 loss)
I0416 15:48:26.341718   977 solver.cpp:542] Iteration 19040, lr = 0.1
I0416 15:48:39.884356   977 solver.cpp:221] Iteration 19060, loss = 0.779871
I0416 15:48:39.884383   977 solver.cpp:236]     Train net output #0: loss = 0.973807 (* 1 = 0.973807 loss)
I0416 15:48:39.884388   977 solver.cpp:542] Iteration 19060, lr = 0.1
I0416 15:48:53.427790   977 solver.cpp:221] Iteration 19080, loss = 0.761284
I0416 15:48:53.427817   977 solver.cpp:236]     Train net output #0: loss = 0.595127 (* 1 = 0.595127 loss)
I0416 15:48:53.427821   977 solver.cpp:542] Iteration 19080, lr = 0.1
I0416 15:49:06.952152   977 solver.cpp:221] Iteration 19100, loss = 0.794792
I0416 15:49:06.952180   977 solver.cpp:236]     Train net output #0: loss = 0.595241 (* 1 = 0.595241 loss)
I0416 15:49:06.952185   977 solver.cpp:542] Iteration 19100, lr = 0.1
I0416 15:49:20.473698   977 solver.cpp:221] Iteration 19120, loss = 0.748264
I0416 15:49:20.473726   977 solver.cpp:236]     Train net output #0: loss = 0.843503 (* 1 = 0.843503 loss)
I0416 15:49:20.473731   977 solver.cpp:542] Iteration 19120, lr = 0.1
I0416 15:49:34.030833   977 solver.cpp:221] Iteration 19140, loss = 0.796734
I0416 15:49:34.030859   977 solver.cpp:236]     Train net output #0: loss = 0.832471 (* 1 = 0.832471 loss)
I0416 15:49:34.030864   977 solver.cpp:542] Iteration 19140, lr = 0.1
I0416 15:49:47.581202   977 solver.cpp:221] Iteration 19160, loss = 0.739045
I0416 15:49:47.581229   977 solver.cpp:236]     Train net output #0: loss = 0.636414 (* 1 = 0.636414 loss)
I0416 15:49:47.581233   977 solver.cpp:542] Iteration 19160, lr = 0.1
I0416 15:50:01.106665   977 solver.cpp:221] Iteration 19180, loss = 0.765771
I0416 15:50:01.106691   977 solver.cpp:236]     Train net output #0: loss = 0.778567 (* 1 = 0.778567 loss)
I0416 15:50:01.106696   977 solver.cpp:542] Iteration 19180, lr = 0.1
I0416 15:50:13.981585   977 solver.cpp:316] Iteration 19200, Testing net (#0)
I0416 15:50:25.509747   977 solver.cpp:373]     Test net output #0: accuracy = 0.818251
I0416 15:50:25.509768   977 solver.cpp:373]     Test net output #1: loss = 0.692415 (* 1 = 0.692415 loss)
I0416 15:50:26.177865   977 solver.cpp:221] Iteration 19200, loss = 0.81557
I0416 15:50:26.177892   977 solver.cpp:236]     Train net output #0: loss = 0.746049 (* 1 = 0.746049 loss)
I0416 15:50:26.177897   977 solver.cpp:542] Iteration 19200, lr = 0.1
I0416 15:50:39.732017   977 solver.cpp:221] Iteration 19220, loss = 0.810099
I0416 15:50:39.732044   977 solver.cpp:236]     Train net output #0: loss = 0.859938 (* 1 = 0.859938 loss)
I0416 15:50:39.732048   977 solver.cpp:542] Iteration 19220, lr = 0.1
I0416 15:50:53.285850   977 solver.cpp:221] Iteration 19240, loss = 0.782253
I0416 15:50:53.285876   977 solver.cpp:236]     Train net output #0: loss = 0.608842 (* 1 = 0.608842 loss)
I0416 15:50:53.285881   977 solver.cpp:542] Iteration 19240, lr = 0.1
I0416 15:51:06.817368   977 solver.cpp:221] Iteration 19260, loss = 0.780738
I0416 15:51:06.817395   977 solver.cpp:236]     Train net output #0: loss = 0.614953 (* 1 = 0.614953 loss)
I0416 15:51:06.817401   977 solver.cpp:542] Iteration 19260, lr = 0.1
I0416 15:51:20.356065   977 solver.cpp:221] Iteration 19280, loss = 0.812549
I0416 15:51:20.356091   977 solver.cpp:236]     Train net output #0: loss = 0.547203 (* 1 = 0.547203 loss)
I0416 15:51:20.356096   977 solver.cpp:542] Iteration 19280, lr = 0.1
I0416 15:51:33.900799   977 solver.cpp:221] Iteration 19300, loss = 0.777931
I0416 15:51:33.900825   977 solver.cpp:236]     Train net output #0: loss = 0.928466 (* 1 = 0.928466 loss)
I0416 15:51:33.900830   977 solver.cpp:542] Iteration 19300, lr = 0.1
I0416 15:51:47.422415   977 solver.cpp:221] Iteration 19320, loss = 0.814578
I0416 15:51:47.422443   977 solver.cpp:236]     Train net output #0: loss = 1.14799 (* 1 = 1.14799 loss)
I0416 15:51:47.422449   977 solver.cpp:542] Iteration 19320, lr = 0.1
I0416 15:52:00.975884   977 solver.cpp:221] Iteration 19340, loss = 0.822595
I0416 15:52:00.975911   977 solver.cpp:236]     Train net output #0: loss = 0.881459 (* 1 = 0.881459 loss)
I0416 15:52:00.975916   977 solver.cpp:542] Iteration 19340, lr = 0.1
I0416 15:52:14.525045   977 solver.cpp:221] Iteration 19360, loss = 0.770694
I0416 15:52:14.525073   977 solver.cpp:236]     Train net output #0: loss = 0.510985 (* 1 = 0.510985 loss)
I0416 15:52:14.525077   977 solver.cpp:542] Iteration 19360, lr = 0.1
I0416 15:52:28.044036   977 solver.cpp:221] Iteration 19380, loss = 0.826196
I0416 15:52:28.044064   977 solver.cpp:236]     Train net output #0: loss = 0.940396 (* 1 = 0.940396 loss)
I0416 15:52:28.044069   977 solver.cpp:542] Iteration 19380, lr = 0.1
I0416 15:52:40.916512   977 solver.cpp:316] Iteration 19400, Testing net (#0)
I0416 15:52:52.448369   977 solver.cpp:373]     Test net output #0: accuracy = 0.902471
I0416 15:52:52.448390   977 solver.cpp:373]     Test net output #1: loss = 0.376405 (* 1 = 0.376405 loss)
I0416 15:52:53.116276   977 solver.cpp:221] Iteration 19400, loss = 0.797414
I0416 15:52:53.116303   977 solver.cpp:236]     Train net output #0: loss = 0.752926 (* 1 = 0.752926 loss)
I0416 15:52:53.116309   977 solver.cpp:542] Iteration 19400, lr = 0.1
I0416 15:53:06.643425   977 solver.cpp:221] Iteration 19420, loss = 0.799839
I0416 15:53:06.643453   977 solver.cpp:236]     Train net output #0: loss = 0.599069 (* 1 = 0.599069 loss)
I0416 15:53:06.643458   977 solver.cpp:542] Iteration 19420, lr = 0.1
I0416 15:53:20.163619   977 solver.cpp:221] Iteration 19440, loss = 0.822991
I0416 15:53:20.163646   977 solver.cpp:236]     Train net output #0: loss = 1.05187 (* 1 = 1.05187 loss)
I0416 15:53:20.163650   977 solver.cpp:542] Iteration 19440, lr = 0.1
I0416 15:53:33.682525   977 solver.cpp:221] Iteration 19460, loss = 0.768364
I0416 15:53:33.682554   977 solver.cpp:236]     Train net output #0: loss = 0.746276 (* 1 = 0.746276 loss)
I0416 15:53:33.682559   977 solver.cpp:542] Iteration 19460, lr = 0.1
I0416 15:53:47.211802   977 solver.cpp:221] Iteration 19480, loss = 0.822872
I0416 15:53:47.211828   977 solver.cpp:236]     Train net output #0: loss = 0.917883 (* 1 = 0.917883 loss)
I0416 15:53:47.211833   977 solver.cpp:542] Iteration 19480, lr = 0.1
I0416 15:54:00.734889   977 solver.cpp:221] Iteration 19500, loss = 0.787274
I0416 15:54:00.734916   977 solver.cpp:236]     Train net output #0: loss = 0.843901 (* 1 = 0.843901 loss)
I0416 15:54:00.734921   977 solver.cpp:542] Iteration 19500, lr = 0.1
I0416 15:54:14.254688   977 solver.cpp:221] Iteration 19520, loss = 0.80881
I0416 15:54:14.254715   977 solver.cpp:236]     Train net output #0: loss = 1.13618 (* 1 = 1.13618 loss)
I0416 15:54:14.254720   977 solver.cpp:542] Iteration 19520, lr = 0.1
I0416 15:54:27.768664   977 solver.cpp:221] Iteration 19540, loss = 0.756339
I0416 15:54:27.768692   977 solver.cpp:236]     Train net output #0: loss = 0.774253 (* 1 = 0.774253 loss)
I0416 15:54:27.768697   977 solver.cpp:542] Iteration 19540, lr = 0.1
I0416 15:54:41.284924   977 solver.cpp:221] Iteration 19560, loss = 0.83098
I0416 15:54:41.284952   977 solver.cpp:236]     Train net output #0: loss = 0.7212 (* 1 = 0.7212 loss)
I0416 15:54:41.284957   977 solver.cpp:542] Iteration 19560, lr = 0.1
I0416 15:54:54.837864   977 solver.cpp:221] Iteration 19580, loss = 0.795349
I0416 15:54:54.837891   977 solver.cpp:236]     Train net output #0: loss = 0.751458 (* 1 = 0.751458 loss)
I0416 15:54:54.837896   977 solver.cpp:542] Iteration 19580, lr = 0.1
I0416 15:55:07.698241   977 solver.cpp:316] Iteration 19600, Testing net (#0)
I0416 15:55:19.229920   977 solver.cpp:373]     Test net output #0: accuracy = 0.90209
I0416 15:55:19.229943   977 solver.cpp:373]     Test net output #1: loss = 0.360798 (* 1 = 0.360798 loss)
I0416 15:55:19.899775   977 solver.cpp:221] Iteration 19600, loss = 0.798308
I0416 15:55:19.899802   977 solver.cpp:236]     Train net output #0: loss = 0.723449 (* 1 = 0.723449 loss)
I0416 15:55:19.899807   977 solver.cpp:542] Iteration 19600, lr = 0.1
I0416 15:55:33.427848   977 solver.cpp:221] Iteration 19620, loss = 0.844752
I0416 15:55:33.427876   977 solver.cpp:236]     Train net output #0: loss = 0.677369 (* 1 = 0.677369 loss)
I0416 15:55:33.427881   977 solver.cpp:542] Iteration 19620, lr = 0.1
I0416 15:55:46.961834   977 solver.cpp:221] Iteration 19640, loss = 0.835976
I0416 15:55:46.961861   977 solver.cpp:236]     Train net output #0: loss = 0.818739 (* 1 = 0.818739 loss)
I0416 15:55:46.961866   977 solver.cpp:542] Iteration 19640, lr = 0.1
I0416 15:56:00.516383   977 solver.cpp:221] Iteration 19660, loss = 0.90043
I0416 15:56:00.516410   977 solver.cpp:236]     Train net output #0: loss = 0.995131 (* 1 = 0.995131 loss)
I0416 15:56:00.516414   977 solver.cpp:542] Iteration 19660, lr = 0.1
I0416 15:56:14.079211   977 solver.cpp:221] Iteration 19680, loss = 0.78242
I0416 15:56:14.079239   977 solver.cpp:236]     Train net output #0: loss = 0.673775 (* 1 = 0.673775 loss)
I0416 15:56:14.079244   977 solver.cpp:542] Iteration 19680, lr = 0.1
I0416 15:56:27.660771   977 solver.cpp:221] Iteration 19700, loss = 0.853504
I0416 15:56:27.660799   977 solver.cpp:236]     Train net output #0: loss = 0.961269 (* 1 = 0.961269 loss)
I0416 15:56:27.660804   977 solver.cpp:542] Iteration 19700, lr = 0.1
I0416 15:56:41.226923   977 solver.cpp:221] Iteration 19720, loss = 0.86406
I0416 15:56:41.226950   977 solver.cpp:236]     Train net output #0: loss = 0.918582 (* 1 = 0.918582 loss)
I0416 15:56:41.226954   977 solver.cpp:542] Iteration 19720, lr = 0.1
I0416 15:56:54.766185   977 solver.cpp:221] Iteration 19740, loss = 0.85123
I0416 15:56:54.766211   977 solver.cpp:236]     Train net output #0: loss = 0.898034 (* 1 = 0.898034 loss)
I0416 15:56:54.766216   977 solver.cpp:542] Iteration 19740, lr = 0.1
I0416 15:57:08.333680   977 solver.cpp:221] Iteration 19760, loss = 0.805724
I0416 15:57:08.333709   977 solver.cpp:236]     Train net output #0: loss = 0.500879 (* 1 = 0.500879 loss)
I0416 15:57:08.333712   977 solver.cpp:542] Iteration 19760, lr = 0.1
I0416 15:57:21.886687   977 solver.cpp:221] Iteration 19780, loss = 0.842779
I0416 15:57:21.886713   977 solver.cpp:236]     Train net output #0: loss = 0.96981 (* 1 = 0.96981 loss)
I0416 15:57:21.886718   977 solver.cpp:542] Iteration 19780, lr = 0.1
I0416 15:57:34.770912   977 solver.cpp:316] Iteration 19800, Testing net (#0)
I0416 15:57:46.313395   977 solver.cpp:373]     Test net output #0: accuracy = 0.912927
I0416 15:57:46.313416   977 solver.cpp:373]     Test net output #1: loss = 0.320143 (* 1 = 0.320143 loss)
I0416 15:57:46.984766   977 solver.cpp:221] Iteration 19800, loss = 0.82321
I0416 15:57:46.984793   977 solver.cpp:236]     Train net output #0: loss = 0.701496 (* 1 = 0.701496 loss)
I0416 15:57:46.984799   977 solver.cpp:542] Iteration 19800, lr = 0.1
I0416 15:58:00.512209   977 solver.cpp:221] Iteration 19820, loss = 0.87927
I0416 15:58:00.512236   977 solver.cpp:236]     Train net output #0: loss = 0.874858 (* 1 = 0.874858 loss)
I0416 15:58:00.512240   977 solver.cpp:542] Iteration 19820, lr = 0.1
I0416 15:58:14.040546   977 solver.cpp:221] Iteration 19840, loss = 0.821863
I0416 15:58:14.040575   977 solver.cpp:236]     Train net output #0: loss = 0.852847 (* 1 = 0.852847 loss)
I0416 15:58:14.040581   977 solver.cpp:542] Iteration 19840, lr = 0.1
I0416 15:58:27.616582   977 solver.cpp:221] Iteration 19860, loss = 0.816637
I0416 15:58:27.616610   977 solver.cpp:236]     Train net output #0: loss = 0.832957 (* 1 = 0.832957 loss)
I0416 15:58:27.616614   977 solver.cpp:542] Iteration 19860, lr = 0.1
I0416 15:58:41.167443   977 solver.cpp:221] Iteration 19880, loss = 0.78723
I0416 15:58:41.167471   977 solver.cpp:236]     Train net output #0: loss = 0.834821 (* 1 = 0.834821 loss)
I0416 15:58:41.167476   977 solver.cpp:542] Iteration 19880, lr = 0.1
I0416 15:58:54.701347   977 solver.cpp:221] Iteration 19900, loss = 0.799797
I0416 15:58:54.701375   977 solver.cpp:236]     Train net output #0: loss = 1.01903 (* 1 = 1.01903 loss)
I0416 15:58:54.701380   977 solver.cpp:542] Iteration 19900, lr = 0.1
I0416 15:59:08.231868   977 solver.cpp:221] Iteration 19920, loss = 0.819267
I0416 15:59:08.231895   977 solver.cpp:236]     Train net output #0: loss = 0.746237 (* 1 = 0.746237 loss)
I0416 15:59:08.231900   977 solver.cpp:542] Iteration 19920, lr = 0.1
I0416 15:59:21.763433   977 solver.cpp:221] Iteration 19940, loss = 0.793924
I0416 15:59:21.763460   977 solver.cpp:236]     Train net output #0: loss = 0.852468 (* 1 = 0.852468 loss)
I0416 15:59:21.763464   977 solver.cpp:542] Iteration 19940, lr = 0.1
I0416 15:59:35.304536   977 solver.cpp:221] Iteration 19960, loss = 0.813123
I0416 15:59:35.304564   977 solver.cpp:236]     Train net output #0: loss = 0.792422 (* 1 = 0.792422 loss)
I0416 15:59:35.304569   977 solver.cpp:542] Iteration 19960, lr = 0.1
I0416 15:59:48.852252   977 solver.cpp:221] Iteration 19980, loss = 0.813974
I0416 15:59:48.852278   977 solver.cpp:236]     Train net output #0: loss = 0.658474 (* 1 = 0.658474 loss)
I0416 15:59:48.852283   977 solver.cpp:542] Iteration 19980, lr = 0.1
I0416 16:00:01.700994   977 solver.cpp:410] Snapshotting to binary proto file external/exp/snapshots/individually/cuhk03_iter_20000.caffemodel
I0416 16:00:01.766940   977 solver.cpp:705] Snapshotting solver state to binary proto fileexternal/exp/snapshots/individually/cuhk03_iter_20000.solverstate
I0416 16:00:01.794826   977 solver.cpp:316] Iteration 20000, Testing net (#0)
I0416 16:00:13.329027   977 solver.cpp:373]     Test net output #0: accuracy = 0.806655
I0416 16:00:13.329048   977 solver.cpp:373]     Test net output #1: loss = 0.747139 (* 1 = 0.747139 loss)
I0416 16:00:13.999151   977 solver.cpp:221] Iteration 20000, loss = 0.718738
I0416 16:00:13.999179   977 solver.cpp:236]     Train net output #0: loss = 0.809267 (* 1 = 0.809267 loss)
I0416 16:00:13.999183   977 solver.cpp:542] Iteration 20000, lr = 0.01
I0416 16:00:27.554395   977 solver.cpp:221] Iteration 20020, loss = 0.947444
I0416 16:00:27.554424   977 solver.cpp:236]     Train net output #0: loss = 0.682142 (* 1 = 0.682142 loss)
I0416 16:00:27.554427   977 solver.cpp:542] Iteration 20020, lr = 0.01
I0416 16:00:41.132473   977 solver.cpp:221] Iteration 20040, loss = 0.892373
I0416 16:00:41.132501   977 solver.cpp:236]     Train net output #0: loss = 0.924684 (* 1 = 0.924684 loss)
I0416 16:00:41.132506   977 solver.cpp:542] Iteration 20040, lr = 0.01
I0416 16:00:54.690623   977 solver.cpp:221] Iteration 20060, loss = 0.730033
I0416 16:00:54.690651   977 solver.cpp:236]     Train net output #0: loss = 0.453062 (* 1 = 0.453062 loss)
I0416 16:00:54.690655   977 solver.cpp:542] Iteration 20060, lr = 0.01
I0416 16:01:08.237911   977 solver.cpp:221] Iteration 20080, loss = 0.566094
I0416 16:01:08.237937   977 solver.cpp:236]     Train net output #0: loss = 0.497139 (* 1 = 0.497139 loss)
I0416 16:01:08.237942   977 solver.cpp:542] Iteration 20080, lr = 0.01
I0416 16:01:21.785893   977 solver.cpp:221] Iteration 20100, loss = 0.480144
I0416 16:01:21.785920   977 solver.cpp:236]     Train net output #0: loss = 0.648292 (* 1 = 0.648292 loss)
I0416 16:01:21.785925   977 solver.cpp:542] Iteration 20100, lr = 0.01
I0416 16:01:35.318429   977 solver.cpp:221] Iteration 20120, loss = 0.453809
I0416 16:01:35.318456   977 solver.cpp:236]     Train net output #0: loss = 0.496962 (* 1 = 0.496962 loss)
I0416 16:01:35.318461   977 solver.cpp:542] Iteration 20120, lr = 0.01
I0416 16:01:48.862787   977 solver.cpp:221] Iteration 20140, loss = 0.418921
I0416 16:01:48.862814   977 solver.cpp:236]     Train net output #0: loss = 0.333839 (* 1 = 0.333839 loss)
I0416 16:01:48.862819   977 solver.cpp:542] Iteration 20140, lr = 0.01
I0416 16:02:02.405571   977 solver.cpp:221] Iteration 20160, loss = 0.383554
I0416 16:02:02.405598   977 solver.cpp:236]     Train net output #0: loss = 0.337707 (* 1 = 0.337707 loss)
I0416 16:02:02.405603   977 solver.cpp:542] Iteration 20160, lr = 0.01
I0416 16:02:15.990442   977 solver.cpp:221] Iteration 20180, loss = 0.355271
I0416 16:02:15.990468   977 solver.cpp:236]     Train net output #0: loss = 0.230095 (* 1 = 0.230095 loss)
I0416 16:02:15.990473   977 solver.cpp:542] Iteration 20180, lr = 0.01
I0416 16:02:28.914572   977 solver.cpp:316] Iteration 20200, Testing net (#0)
I0416 16:02:40.447343   977 solver.cpp:373]     Test net output #0: accuracy = 0.976235
I0416 16:02:40.447365   977 solver.cpp:373]     Test net output #1: loss = 0.105957 (* 1 = 0.105957 loss)
I0416 16:02:41.115921   977 solver.cpp:221] Iteration 20200, loss = 0.298712
I0416 16:02:41.115949   977 solver.cpp:236]     Train net output #0: loss = 0.379397 (* 1 = 0.379397 loss)
I0416 16:02:41.115953   977 solver.cpp:542] Iteration 20200, lr = 0.01
I0416 16:02:54.656085   977 solver.cpp:221] Iteration 20220, loss = 0.283003
I0416 16:02:54.656111   977 solver.cpp:236]     Train net output #0: loss = 0.494011 (* 1 = 0.494011 loss)
I0416 16:02:54.656116   977 solver.cpp:542] Iteration 20220, lr = 0.01
I0416 16:03:08.212366   977 solver.cpp:221] Iteration 20240, loss = 0.336202
I0416 16:03:08.212393   977 solver.cpp:236]     Train net output #0: loss = 0.300736 (* 1 = 0.300736 loss)
I0416 16:03:08.212398   977 solver.cpp:542] Iteration 20240, lr = 0.01
I0416 16:03:21.780740   977 solver.cpp:221] Iteration 20260, loss = 0.359229
I0416 16:03:21.780767   977 solver.cpp:236]     Train net output #0: loss = 0.498638 (* 1 = 0.498638 loss)
I0416 16:03:21.780772   977 solver.cpp:542] Iteration 20260, lr = 0.01
I0416 16:03:35.332837   977 solver.cpp:221] Iteration 20280, loss = 0.31844
I0416 16:03:35.332865   977 solver.cpp:236]     Train net output #0: loss = 0.366301 (* 1 = 0.366301 loss)
I0416 16:03:35.332870   977 solver.cpp:542] Iteration 20280, lr = 0.01
I0416 16:03:48.865906   977 solver.cpp:221] Iteration 20300, loss = 0.311299
I0416 16:03:48.865932   977 solver.cpp:236]     Train net output #0: loss = 0.26508 (* 1 = 0.26508 loss)
I0416 16:03:48.865937   977 solver.cpp:542] Iteration 20300, lr = 0.01
I0416 16:04:02.403740   977 solver.cpp:221] Iteration 20320, loss = 0.297109
I0416 16:04:02.403767   977 solver.cpp:236]     Train net output #0: loss = 0.208519 (* 1 = 0.208519 loss)
I0416 16:04:02.403772   977 solver.cpp:542] Iteration 20320, lr = 0.01
I0416 16:04:15.978016   977 solver.cpp:221] Iteration 20340, loss = 0.280833
I0416 16:04:15.978044   977 solver.cpp:236]     Train net output #0: loss = 0.283059 (* 1 = 0.283059 loss)
I0416 16:04:15.978049   977 solver.cpp:542] Iteration 20340, lr = 0.01
I0416 16:04:29.560823   977 solver.cpp:221] Iteration 20360, loss = 0.300049
I0416 16:04:29.560853   977 solver.cpp:236]     Train net output #0: loss = 0.470286 (* 1 = 0.470286 loss)
I0416 16:04:29.560858   977 solver.cpp:542] Iteration 20360, lr = 0.01
I0416 16:04:43.115862   977 solver.cpp:221] Iteration 20380, loss = 0.238502
I0416 16:04:43.115888   977 solver.cpp:236]     Train net output #0: loss = 0.155211 (* 1 = 0.155211 loss)
I0416 16:04:43.115893   977 solver.cpp:542] Iteration 20380, lr = 0.01
I0416 16:04:55.999243   977 solver.cpp:316] Iteration 20400, Testing net (#0)
I0416 16:05:07.531971   977 solver.cpp:373]     Test net output #0: accuracy = 0.982319
I0416 16:05:07.531992   977 solver.cpp:373]     Test net output #1: loss = 0.0822837 (* 1 = 0.0822837 loss)
I0416 16:05:08.200970   977 solver.cpp:221] Iteration 20400, loss = 0.252415
I0416 16:05:08.200999   977 solver.cpp:236]     Train net output #0: loss = 0.331407 (* 1 = 0.331407 loss)
I0416 16:05:08.201004   977 solver.cpp:542] Iteration 20400, lr = 0.01
I0416 16:05:21.753839   977 solver.cpp:221] Iteration 20420, loss = 0.233583
I0416 16:05:21.753867   977 solver.cpp:236]     Train net output #0: loss = 0.192231 (* 1 = 0.192231 loss)
I0416 16:05:21.753872   977 solver.cpp:542] Iteration 20420, lr = 0.01
I0416 16:05:35.285480   977 solver.cpp:221] Iteration 20440, loss = 0.250859
I0416 16:05:35.285507   977 solver.cpp:236]     Train net output #0: loss = 0.18215 (* 1 = 0.18215 loss)
I0416 16:05:35.285512   977 solver.cpp:542] Iteration 20440, lr = 0.01
I0416 16:05:48.809036   977 solver.cpp:221] Iteration 20460, loss = 0.292078
I0416 16:05:48.809062   977 solver.cpp:236]     Train net output #0: loss = 0.27113 (* 1 = 0.27113 loss)
I0416 16:05:48.809067   977 solver.cpp:542] Iteration 20460, lr = 0.01
I0416 16:06:02.377400   977 solver.cpp:221] Iteration 20480, loss = 0.253904
I0416 16:06:02.377429   977 solver.cpp:236]     Train net output #0: loss = 0.364115 (* 1 = 0.364115 loss)
I0416 16:06:02.377434   977 solver.cpp:542] Iteration 20480, lr = 0.01
I0416 16:06:15.921190   977 solver.cpp:221] Iteration 20500, loss = 0.241604
I0416 16:06:15.921216   977 solver.cpp:236]     Train net output #0: loss = 0.199579 (* 1 = 0.199579 loss)
I0416 16:06:15.921221   977 solver.cpp:542] Iteration 20500, lr = 0.01
I0416 16:06:29.458449   977 solver.cpp:221] Iteration 20520, loss = 0.234052
I0416 16:06:29.458477   977 solver.cpp:236]     Train net output #0: loss = 0.265741 (* 1 = 0.265741 loss)
I0416 16:06:29.458482   977 solver.cpp:542] Iteration 20520, lr = 0.01
I0416 16:06:42.999902   977 solver.cpp:221] Iteration 20540, loss = 0.230664
I0416 16:06:42.999929   977 solver.cpp:236]     Train net output #0: loss = 0.235187 (* 1 = 0.235187 loss)
I0416 16:06:42.999934   977 solver.cpp:542] Iteration 20540, lr = 0.01
I0416 16:06:56.547353   977 solver.cpp:221] Iteration 20560, loss = 0.230491
I0416 16:06:56.547381   977 solver.cpp:236]     Train net output #0: loss = 0.312735 (* 1 = 0.312735 loss)
I0416 16:06:56.547386   977 solver.cpp:542] Iteration 20560, lr = 0.01
I0416 16:07:10.087674   977 solver.cpp:221] Iteration 20580, loss = 0.238641
I0416 16:07:10.087702   977 solver.cpp:236]     Train net output #0: loss = 0.19378 (* 1 = 0.19378 loss)
I0416 16:07:10.087707   977 solver.cpp:542] Iteration 20580, lr = 0.01
I0416 16:07:22.981623   977 solver.cpp:316] Iteration 20600, Testing net (#0)
I0416 16:07:34.515255   977 solver.cpp:373]     Test net output #0: accuracy = 0.984981
I0416 16:07:34.515277   977 solver.cpp:373]     Test net output #1: loss = 0.0713738 (* 1 = 0.0713738 loss)
I0416 16:07:35.185256   977 solver.cpp:221] Iteration 20600, loss = 0.224923
I0416 16:07:35.185283   977 solver.cpp:236]     Train net output #0: loss = 0.159633 (* 1 = 0.159633 loss)
I0416 16:07:35.185288   977 solver.cpp:542] Iteration 20600, lr = 0.01
I0416 16:07:48.725241   977 solver.cpp:221] Iteration 20620, loss = 0.217904
I0416 16:07:48.725270   977 solver.cpp:236]     Train net output #0: loss = 0.418167 (* 1 = 0.418167 loss)
I0416 16:07:48.725275   977 solver.cpp:542] Iteration 20620, lr = 0.01
I0416 16:08:02.264004   977 solver.cpp:221] Iteration 20640, loss = 0.209201
I0416 16:08:02.264031   977 solver.cpp:236]     Train net output #0: loss = 0.28815 (* 1 = 0.28815 loss)
I0416 16:08:02.264036   977 solver.cpp:542] Iteration 20640, lr = 0.01
I0416 16:08:15.806025   977 solver.cpp:221] Iteration 20660, loss = 0.245656
I0416 16:08:15.806052   977 solver.cpp:236]     Train net output #0: loss = 0.246357 (* 1 = 0.246357 loss)
I0416 16:08:15.806057   977 solver.cpp:542] Iteration 20660, lr = 0.01
I0416 16:08:29.349360   977 solver.cpp:221] Iteration 20680, loss = 0.240878
I0416 16:08:29.349387   977 solver.cpp:236]     Train net output #0: loss = 0.254999 (* 1 = 0.254999 loss)
I0416 16:08:29.349392   977 solver.cpp:542] Iteration 20680, lr = 0.01
I0416 16:08:42.900437   977 solver.cpp:221] Iteration 20700, loss = 0.214261
I0416 16:08:42.900465   977 solver.cpp:236]     Train net output #0: loss = 0.114291 (* 1 = 0.114291 loss)
I0416 16:08:42.900470   977 solver.cpp:542] Iteration 20700, lr = 0.01
I0416 16:08:56.465323   977 solver.cpp:221] Iteration 20720, loss = 0.222375
I0416 16:08:56.465350   977 solver.cpp:236]     Train net output #0: loss = 0.153951 (* 1 = 0.153951 loss)
I0416 16:08:56.465355   977 solver.cpp:542] Iteration 20720, lr = 0.01
I0416 16:09:10.010902   977 solver.cpp:221] Iteration 20740, loss = 0.218003
I0416 16:09:10.010931   977 solver.cpp:236]     Train net output #0: loss = 0.269251 (* 1 = 0.269251 loss)
I0416 16:09:10.010937   977 solver.cpp:542] Iteration 20740, lr = 0.01
I0416 16:09:23.548130   977 solver.cpp:221] Iteration 20760, loss = 0.208103
I0416 16:09:23.548157   977 solver.cpp:236]     Train net output #0: loss = 0.215424 (* 1 = 0.215424 loss)
I0416 16:09:23.548162   977 solver.cpp:542] Iteration 20760, lr = 0.01
I0416 16:09:37.069530   977 solver.cpp:221] Iteration 20780, loss = 0.187628
I0416 16:09:37.069556   977 solver.cpp:236]     Train net output #0: loss = 0.220853 (* 1 = 0.220853 loss)
I0416 16:09:37.069561   977 solver.cpp:542] Iteration 20780, lr = 0.01
I0416 16:09:49.961637   977 solver.cpp:316] Iteration 20800, Testing net (#0)
I0416 16:10:01.505982   977 solver.cpp:373]     Test net output #0: accuracy = 0.985551
I0416 16:10:01.506003   977 solver.cpp:373]     Test net output #1: loss = 0.0669679 (* 1 = 0.0669679 loss)
I0416 16:10:02.178436   977 solver.cpp:221] Iteration 20800, loss = 0.189891
I0416 16:10:02.178463   977 solver.cpp:236]     Train net output #0: loss = 0.202277 (* 1 = 0.202277 loss)
I0416 16:10:02.178467   977 solver.cpp:542] Iteration 20800, lr = 0.01
I0416 16:10:15.758997   977 solver.cpp:221] Iteration 20820, loss = 0.184205
I0416 16:10:15.759027   977 solver.cpp:236]     Train net output #0: loss = 0.147245 (* 1 = 0.147245 loss)
I0416 16:10:15.759030   977 solver.cpp:542] Iteration 20820, lr = 0.01
I0416 16:10:29.330719   977 solver.cpp:221] Iteration 20840, loss = 0.182525
I0416 16:10:29.330746   977 solver.cpp:236]     Train net output #0: loss = 0.216015 (* 1 = 0.216015 loss)
I0416 16:10:29.330751   977 solver.cpp:542] Iteration 20840, lr = 0.01
I0416 16:10:42.902209   977 solver.cpp:221] Iteration 20860, loss = 0.19467
I0416 16:10:42.902236   977 solver.cpp:236]     Train net output #0: loss = 0.19502 (* 1 = 0.19502 loss)
I0416 16:10:42.902241   977 solver.cpp:542] Iteration 20860, lr = 0.01
I0416 16:10:56.454231   977 solver.cpp:221] Iteration 20880, loss = 0.213991
I0416 16:10:56.454258   977 solver.cpp:236]     Train net output #0: loss = 0.113473 (* 1 = 0.113473 loss)
I0416 16:10:56.454263   977 solver.cpp:542] Iteration 20880, lr = 0.01
I0416 16:11:10.033512   977 solver.cpp:221] Iteration 20900, loss = 0.21632
I0416 16:11:10.033540   977 solver.cpp:236]     Train net output #0: loss = 0.198134 (* 1 = 0.198134 loss)
I0416 16:11:10.033543   977 solver.cpp:542] Iteration 20900, lr = 0.01
I0416 16:11:23.587705   977 solver.cpp:221] Iteration 20920, loss = 0.19212
I0416 16:11:23.587731   977 solver.cpp:236]     Train net output #0: loss = 0.134467 (* 1 = 0.134467 loss)
I0416 16:11:23.587736   977 solver.cpp:542] Iteration 20920, lr = 0.01
I0416 16:11:37.158542   977 solver.cpp:221] Iteration 20940, loss = 0.182855
I0416 16:11:37.158570   977 solver.cpp:236]     Train net output #0: loss = 0.181401 (* 1 = 0.181401 loss)
I0416 16:11:37.158574   977 solver.cpp:542] Iteration 20940, lr = 0.01
I0416 16:11:50.703445   977 solver.cpp:221] Iteration 20960, loss = 0.190844
I0416 16:11:50.703472   977 solver.cpp:236]     Train net output #0: loss = 0.17388 (* 1 = 0.17388 loss)
I0416 16:11:50.703476   977 solver.cpp:542] Iteration 20960, lr = 0.01
I0416 16:12:04.266566   977 solver.cpp:221] Iteration 20980, loss = 0.17419
I0416 16:12:04.266593   977 solver.cpp:236]     Train net output #0: loss = 0.158858 (* 1 = 0.158858 loss)
I0416 16:12:04.266598   977 solver.cpp:542] Iteration 20980, lr = 0.01
I0416 16:12:17.144033   977 solver.cpp:316] Iteration 21000, Testing net (#0)
I0416 16:12:28.681978   977 solver.cpp:373]     Test net output #0: accuracy = 0.987262
I0416 16:12:28.681999   977 solver.cpp:373]     Test net output #1: loss = 0.0644091 (* 1 = 0.0644091 loss)
I0416 16:12:29.350450   977 solver.cpp:221] Iteration 21000, loss = 0.188337
I0416 16:12:29.350477   977 solver.cpp:236]     Train net output #0: loss = 0.140583 (* 1 = 0.140583 loss)
I0416 16:12:29.350482   977 solver.cpp:542] Iteration 21000, lr = 0.01
I0416 16:12:42.873363   977 solver.cpp:221] Iteration 21020, loss = 0.166414
I0416 16:12:42.873390   977 solver.cpp:236]     Train net output #0: loss = 0.121124 (* 1 = 0.121124 loss)
I0416 16:12:42.873395   977 solver.cpp:542] Iteration 21020, lr = 0.01
I0416 16:12:56.458015   977 solver.cpp:221] Iteration 21040, loss = 0.170323
I0416 16:12:56.458041   977 solver.cpp:236]     Train net output #0: loss = 0.0890977 (* 1 = 0.0890977 loss)
I0416 16:12:56.458046   977 solver.cpp:542] Iteration 21040, lr = 0.01
I0416 16:13:10.002706   977 solver.cpp:221] Iteration 21060, loss = 0.169522
I0416 16:13:10.002733   977 solver.cpp:236]     Train net output #0: loss = 0.191645 (* 1 = 0.191645 loss)
I0416 16:13:10.002738   977 solver.cpp:542] Iteration 21060, lr = 0.01
I0416 16:13:23.562141   977 solver.cpp:221] Iteration 21080, loss = 0.205224
I0416 16:13:23.562168   977 solver.cpp:236]     Train net output #0: loss = 0.18543 (* 1 = 0.18543 loss)
I0416 16:13:23.562173   977 solver.cpp:542] Iteration 21080, lr = 0.01
I0416 16:13:37.120553   977 solver.cpp:221] Iteration 21100, loss = 0.191278
I0416 16:13:37.120580   977 solver.cpp:236]     Train net output #0: loss = 0.215289 (* 1 = 0.215289 loss)
I0416 16:13:37.120585   977 solver.cpp:542] Iteration 21100, lr = 0.01
I0416 16:13:50.675268   977 solver.cpp:221] Iteration 21120, loss = 0.187542
I0416 16:13:50.675298   977 solver.cpp:236]     Train net output #0: loss = 0.190419 (* 1 = 0.190419 loss)
I0416 16:13:50.675304   977 solver.cpp:542] Iteration 21120, lr = 0.01
I0416 16:14:04.209431   977 solver.cpp:221] Iteration 21140, loss = 0.17357
I0416 16:14:04.209458   977 solver.cpp:236]     Train net output #0: loss = 0.174845 (* 1 = 0.174845 loss)
I0416 16:14:04.209465   977 solver.cpp:542] Iteration 21140, lr = 0.01
I0416 16:14:17.747763   977 solver.cpp:221] Iteration 21160, loss = 0.176932
I0416 16:14:17.747791   977 solver.cpp:236]     Train net output #0: loss = 0.259888 (* 1 = 0.259888 loss)
I0416 16:14:17.747794   977 solver.cpp:542] Iteration 21160, lr = 0.01
I0416 16:14:31.271306   977 solver.cpp:221] Iteration 21180, loss = 0.175711
I0416 16:14:31.271333   977 solver.cpp:236]     Train net output #0: loss = 0.101765 (* 1 = 0.101765 loss)
I0416 16:14:31.271337   977 solver.cpp:542] Iteration 21180, lr = 0.01
I0416 16:14:44.140152   977 solver.cpp:316] Iteration 21200, Testing net (#0)
I0416 16:14:55.684029   977 solver.cpp:373]     Test net output #0: accuracy = 0.988973
I0416 16:14:55.684051   977 solver.cpp:373]     Test net output #1: loss = 0.0597075 (* 1 = 0.0597075 loss)
I0416 16:14:56.355234   977 solver.cpp:221] Iteration 21200, loss = 0.15806
I0416 16:14:56.355262   977 solver.cpp:236]     Train net output #0: loss = 0.16349 (* 1 = 0.16349 loss)
I0416 16:14:56.355267   977 solver.cpp:542] Iteration 21200, lr = 0.01
I0416 16:15:09.880312   977 solver.cpp:221] Iteration 21220, loss = 0.180098
I0416 16:15:09.880339   977 solver.cpp:236]     Train net output #0: loss = 0.209664 (* 1 = 0.209664 loss)
I0416 16:15:09.880344   977 solver.cpp:542] Iteration 21220, lr = 0.01
I0416 16:15:23.411293   977 solver.cpp:221] Iteration 21240, loss = 0.154694
I0416 16:15:23.411320   977 solver.cpp:236]     Train net output #0: loss = 0.132361 (* 1 = 0.132361 loss)
I0416 16:15:23.411324   977 solver.cpp:542] Iteration 21240, lr = 0.01
I0416 16:15:36.957051   977 solver.cpp:221] Iteration 21260, loss = 0.155453
I0416 16:15:36.957078   977 solver.cpp:236]     Train net output #0: loss = 0.266795 (* 1 = 0.266795 loss)
I0416 16:15:36.957082   977 solver.cpp:542] Iteration 21260, lr = 0.01
I0416 16:15:50.527066   977 solver.cpp:221] Iteration 21280, loss = 0.182154
I0416 16:15:50.527093   977 solver.cpp:236]     Train net output #0: loss = 0.11546 (* 1 = 0.11546 loss)
I0416 16:15:50.527099   977 solver.cpp:542] Iteration 21280, lr = 0.01
I0416 16:16:04.057185   977 solver.cpp:221] Iteration 21300, loss = 0.170785
I0416 16:16:04.057214   977 solver.cpp:236]     Train net output #0: loss = 0.133971 (* 1 = 0.133971 loss)
I0416 16:16:04.057217   977 solver.cpp:542] Iteration 21300, lr = 0.01
I0416 16:16:17.584331   977 solver.cpp:221] Iteration 21320, loss = 0.169211
I0416 16:16:17.584358   977 solver.cpp:236]     Train net output #0: loss = 0.143039 (* 1 = 0.143039 loss)
I0416 16:16:17.584363   977 solver.cpp:542] Iteration 21320, lr = 0.01
I0416 16:16:31.125427   977 solver.cpp:221] Iteration 21340, loss = 0.167237
I0416 16:16:31.125454   977 solver.cpp:236]     Train net output #0: loss = 0.186742 (* 1 = 0.186742 loss)
I0416 16:16:31.125458   977 solver.cpp:542] Iteration 21340, lr = 0.01
I0416 16:16:44.694983   977 solver.cpp:221] Iteration 21360, loss = 0.152017
I0416 16:16:44.695010   977 solver.cpp:236]     Train net output #0: loss = 0.147734 (* 1 = 0.147734 loss)
I0416 16:16:44.695015   977 solver.cpp:542] Iteration 21360, lr = 0.01
I0416 16:16:58.242918   977 solver.cpp:221] Iteration 21380, loss = 0.1715
I0416 16:16:58.242946   977 solver.cpp:236]     Train net output #0: loss = 0.192309 (* 1 = 0.192309 loss)
I0416 16:16:58.242950   977 solver.cpp:542] Iteration 21380, lr = 0.01
I0416 16:17:11.118235   977 solver.cpp:316] Iteration 21400, Testing net (#0)
I0416 16:17:22.655315   977 solver.cpp:373]     Test net output #0: accuracy = 0.987262
I0416 16:17:22.655336   977 solver.cpp:373]     Test net output #1: loss = 0.0616146 (* 1 = 0.0616146 loss)
I0416 16:17:23.323928   977 solver.cpp:221] Iteration 21400, loss = 0.151663
I0416 16:17:23.323956   977 solver.cpp:236]     Train net output #0: loss = 0.142947 (* 1 = 0.142947 loss)
I0416 16:17:23.323961   977 solver.cpp:542] Iteration 21400, lr = 0.01
I0416 16:17:36.871282   977 solver.cpp:221] Iteration 21420, loss = 0.149287
I0416 16:17:36.871310   977 solver.cpp:236]     Train net output #0: loss = 0.202562 (* 1 = 0.202562 loss)
I0416 16:17:36.871315   977 solver.cpp:542] Iteration 21420, lr = 0.01
I0416 16:17:50.435993   977 solver.cpp:221] Iteration 21440, loss = 0.1354
I0416 16:17:50.436020   977 solver.cpp:236]     Train net output #0: loss = 0.115124 (* 1 = 0.115124 loss)
I0416 16:17:50.436024   977 solver.cpp:542] Iteration 21440, lr = 0.01
I0416 16:18:04.014374   977 solver.cpp:221] Iteration 21460, loss = 0.157221
I0416 16:18:04.014401   977 solver.cpp:236]     Train net output #0: loss = 0.155283 (* 1 = 0.155283 loss)
I0416 16:18:04.014405   977 solver.cpp:542] Iteration 21460, lr = 0.01
I0416 16:18:17.551229   977 solver.cpp:221] Iteration 21480, loss = 0.148582
I0416 16:18:17.551255   977 solver.cpp:236]     Train net output #0: loss = 0.162813 (* 1 = 0.162813 loss)
I0416 16:18:17.551260   977 solver.cpp:542] Iteration 21480, lr = 0.01
I0416 16:18:31.093443   977 solver.cpp:221] Iteration 21500, loss = 0.161223
I0416 16:18:31.093471   977 solver.cpp:236]     Train net output #0: loss = 0.130514 (* 1 = 0.130514 loss)
I0416 16:18:31.093475   977 solver.cpp:542] Iteration 21500, lr = 0.01
I0416 16:18:44.659852   977 solver.cpp:221] Iteration 21520, loss = 0.167736
I0416 16:18:44.659879   977 solver.cpp:236]     Train net output #0: loss = 0.206014 (* 1 = 0.206014 loss)
I0416 16:18:44.659883   977 solver.cpp:542] Iteration 21520, lr = 0.01
I0416 16:18:58.220768   977 solver.cpp:221] Iteration 21540, loss = 0.173852
I0416 16:18:58.220795   977 solver.cpp:236]     Train net output #0: loss = 0.113778 (* 1 = 0.113778 loss)
I0416 16:18:58.220800   977 solver.cpp:542] Iteration 21540, lr = 0.01
I0416 16:19:11.766402   977 solver.cpp:221] Iteration 21560, loss = 0.148346
I0416 16:19:11.766430   977 solver.cpp:236]     Train net output #0: loss = 0.140259 (* 1 = 0.140259 loss)
I0416 16:19:11.766434   977 solver.cpp:542] Iteration 21560, lr = 0.01
I0416 16:19:25.312557   977 solver.cpp:221] Iteration 21580, loss = 0.150022
I0416 16:19:25.312585   977 solver.cpp:236]     Train net output #0: loss = 0.0875227 (* 1 = 0.0875227 loss)
I0416 16:19:25.312589   977 solver.cpp:542] Iteration 21580, lr = 0.01
I0416 16:19:38.186847   977 solver.cpp:316] Iteration 21600, Testing net (#0)
I0416 16:19:49.718119   977 solver.cpp:373]     Test net output #0: accuracy = 0.987642
I0416 16:19:49.718140   977 solver.cpp:373]     Test net output #1: loss = 0.0585251 (* 1 = 0.0585251 loss)
I0416 16:19:50.387879   977 solver.cpp:221] Iteration 21600, loss = 0.164875
I0416 16:19:50.387907   977 solver.cpp:236]     Train net output #0: loss = 0.187138 (* 1 = 0.187138 loss)
I0416 16:19:50.387912   977 solver.cpp:542] Iteration 21600, lr = 0.01
I0416 16:20:03.933265   977 solver.cpp:221] Iteration 21620, loss = 0.150037
I0416 16:20:03.933292   977 solver.cpp:236]     Train net output #0: loss = 0.165412 (* 1 = 0.165412 loss)
I0416 16:20:03.933296   977 solver.cpp:542] Iteration 21620, lr = 0.01
I0416 16:20:17.461525   977 solver.cpp:221] Iteration 21640, loss = 0.149745
I0416 16:20:17.461554   977 solver.cpp:236]     Train net output #0: loss = 0.158644 (* 1 = 0.158644 loss)
I0416 16:20:17.461558   977 solver.cpp:542] Iteration 21640, lr = 0.01
I0416 16:20:30.995764   977 solver.cpp:221] Iteration 21660, loss = 0.144743
I0416 16:20:30.995792   977 solver.cpp:236]     Train net output #0: loss = 0.122363 (* 1 = 0.122363 loss)
I0416 16:20:30.995796   977 solver.cpp:542] Iteration 21660, lr = 0.01
I0416 16:20:44.538254   977 solver.cpp:221] Iteration 21680, loss = 0.137143
I0416 16:20:44.538280   977 solver.cpp:236]     Train net output #0: loss = 0.0607403 (* 1 = 0.0607403 loss)
I0416 16:20:44.538285   977 solver.cpp:542] Iteration 21680, lr = 0.01
I0416 16:20:58.091161   977 solver.cpp:221] Iteration 21700, loss = 0.140833
I0416 16:20:58.091189   977 solver.cpp:236]     Train net output #0: loss = 0.0868447 (* 1 = 0.0868447 loss)
I0416 16:20:58.091194   977 solver.cpp:542] Iteration 21700, lr = 0.01
I0416 16:21:11.621665   977 solver.cpp:221] Iteration 21720, loss = 0.170644
I0416 16:21:11.621691   977 solver.cpp:236]     Train net output #0: loss = 0.193977 (* 1 = 0.193977 loss)
I0416 16:21:11.621696   977 solver.cpp:542] Iteration 21720, lr = 0.01
I0416 16:21:25.181895   977 solver.cpp:221] Iteration 21740, loss = 0.141818
I0416 16:21:25.181923   977 solver.cpp:236]     Train net output #0: loss = 0.270249 (* 1 = 0.270249 loss)
I0416 16:21:25.181927   977 solver.cpp:542] Iteration 21740, lr = 0.01
I0416 16:21:38.718646   977 solver.cpp:221] Iteration 21760, loss = 0.156212
I0416 16:21:38.718672   977 solver.cpp:236]     Train net output #0: loss = 0.105316 (* 1 = 0.105316 loss)
I0416 16:21:38.718677   977 solver.cpp:542] Iteration 21760, lr = 0.01
I0416 16:21:52.257652   977 solver.cpp:221] Iteration 21780, loss = 0.150006
I0416 16:21:52.257679   977 solver.cpp:236]     Train net output #0: loss = 0.0627306 (* 1 = 0.0627306 loss)
I0416 16:21:52.257684   977 solver.cpp:542] Iteration 21780, lr = 0.01
I0416 16:22:05.150419   977 solver.cpp:316] Iteration 21800, Testing net (#0)
I0416 16:22:16.694440   977 solver.cpp:373]     Test net output #0: accuracy = 0.987452
I0416 16:22:16.694461   977 solver.cpp:373]     Test net output #1: loss = 0.0566462 (* 1 = 0.0566462 loss)
I0416 16:22:17.366720   977 solver.cpp:221] Iteration 21800, loss = 0.153232
I0416 16:22:17.366747   977 solver.cpp:236]     Train net output #0: loss = 0.207156 (* 1 = 0.207156 loss)
I0416 16:22:17.366752   977 solver.cpp:542] Iteration 21800, lr = 0.01
I0416 16:22:30.903633   977 solver.cpp:221] Iteration 21820, loss = 0.137018
I0416 16:22:30.903661   977 solver.cpp:236]     Train net output #0: loss = 0.190328 (* 1 = 0.190328 loss)
I0416 16:22:30.903664   977 solver.cpp:542] Iteration 21820, lr = 0.01
I0416 16:22:44.431632   977 solver.cpp:221] Iteration 21840, loss = 0.131854
I0416 16:22:44.431658   977 solver.cpp:236]     Train net output #0: loss = 0.132388 (* 1 = 0.132388 loss)
I0416 16:22:44.431663   977 solver.cpp:542] Iteration 21840, lr = 0.01
I0416 16:22:57.958564   977 solver.cpp:221] Iteration 21860, loss = 0.131424
I0416 16:22:57.958591   977 solver.cpp:236]     Train net output #0: loss = 0.20522 (* 1 = 0.20522 loss)
I0416 16:22:57.958596   977 solver.cpp:542] Iteration 21860, lr = 0.01
I0416 16:23:11.497424   977 solver.cpp:221] Iteration 21880, loss = 0.131822
I0416 16:23:11.497452   977 solver.cpp:236]     Train net output #0: loss = 0.266199 (* 1 = 0.266199 loss)
I0416 16:23:11.497457   977 solver.cpp:542] Iteration 21880, lr = 0.01
I0416 16:23:25.027511   977 solver.cpp:221] Iteration 21900, loss = 0.13493
I0416 16:23:25.027539   977 solver.cpp:236]     Train net output #0: loss = 0.239039 (* 1 = 0.239039 loss)
I0416 16:23:25.027544   977 solver.cpp:542] Iteration 21900, lr = 0.01
I0416 16:23:38.556812   977 solver.cpp:221] Iteration 21920, loss = 0.146799
I0416 16:23:38.556839   977 solver.cpp:236]     Train net output #0: loss = 0.098429 (* 1 = 0.098429 loss)
I0416 16:23:38.556844   977 solver.cpp:542] Iteration 21920, lr = 0.01
I0416 16:23:52.098595   977 solver.cpp:221] Iteration 21940, loss = 0.144485
I0416 16:23:52.098621   977 solver.cpp:236]     Train net output #0: loss = 0.193139 (* 1 = 0.193139 loss)
I0416 16:23:52.098626   977 solver.cpp:542] Iteration 21940, lr = 0.01
I0416 16:24:05.656008   977 solver.cpp:221] Iteration 21960, loss = 0.148026
I0416 16:24:05.656035   977 solver.cpp:236]     Train net output #0: loss = 0.0909198 (* 1 = 0.0909198 loss)
I0416 16:24:05.656039   977 solver.cpp:542] Iteration 21960, lr = 0.01
I0416 16:24:19.201988   977 solver.cpp:221] Iteration 21980, loss = 0.131146
I0416 16:24:19.202016   977 solver.cpp:236]     Train net output #0: loss = 0.224457 (* 1 = 0.224457 loss)
I0416 16:24:19.202020   977 solver.cpp:542] Iteration 21980, lr = 0.01
I0416 16:24:32.092007   977 solver.cpp:316] Iteration 22000, Testing net (#0)
I0416 16:24:43.634008   977 solver.cpp:373]     Test net output #0: accuracy = 0.989353
I0416 16:24:43.634029   977 solver.cpp:373]     Test net output #1: loss = 0.0525505 (* 1 = 0.0525505 loss)
I0416 16:24:44.303823   977 solver.cpp:221] Iteration 22000, loss = 0.147442
I0416 16:24:44.303850   977 solver.cpp:236]     Train net output #0: loss = 0.247512 (* 1 = 0.247512 loss)
I0416 16:24:44.303854   977 solver.cpp:542] Iteration 22000, lr = 0.01
I0416 16:24:57.852334   977 solver.cpp:221] Iteration 22020, loss = 0.141102
I0416 16:24:57.852361   977 solver.cpp:236]     Train net output #0: loss = 0.16591 (* 1 = 0.16591 loss)
I0416 16:24:57.852365   977 solver.cpp:542] Iteration 22020, lr = 0.01
I0416 16:25:11.394765   977 solver.cpp:221] Iteration 22040, loss = 0.122645
I0416 16:25:11.394793   977 solver.cpp:236]     Train net output #0: loss = 0.134969 (* 1 = 0.134969 loss)
I0416 16:25:11.394798   977 solver.cpp:542] Iteration 22040, lr = 0.01
I0416 16:25:24.946981   977 solver.cpp:221] Iteration 22060, loss = 0.127301
I0416 16:25:24.947008   977 solver.cpp:236]     Train net output #0: loss = 0.108226 (* 1 = 0.108226 loss)
I0416 16:25:24.947013   977 solver.cpp:542] Iteration 22060, lr = 0.01
I0416 16:25:38.493238   977 solver.cpp:221] Iteration 22080, loss = 0.111207
I0416 16:25:38.493265   977 solver.cpp:236]     Train net output #0: loss = 0.20194 (* 1 = 0.20194 loss)
I0416 16:25:38.493270   977 solver.cpp:542] Iteration 22080, lr = 0.01
I0416 16:25:52.024231   977 solver.cpp:221] Iteration 22100, loss = 0.119257
I0416 16:25:52.024260   977 solver.cpp:236]     Train net output #0: loss = 0.10559 (* 1 = 0.10559 loss)
I0416 16:25:52.024265   977 solver.cpp:542] Iteration 22100, lr = 0.01
I0416 16:26:05.583645   977 solver.cpp:221] Iteration 22120, loss = 0.134268
I0416 16:26:05.583673   977 solver.cpp:236]     Train net output #0: loss = 0.0747944 (* 1 = 0.0747944 loss)
I0416 16:26:05.583678   977 solver.cpp:542] Iteration 22120, lr = 0.01
I0416 16:26:19.123085   977 solver.cpp:221] Iteration 22140, loss = 0.145931
I0416 16:26:19.123117   977 solver.cpp:236]     Train net output #0: loss = 0.217868 (* 1 = 0.217868 loss)
I0416 16:26:19.123122   977 solver.cpp:542] Iteration 22140, lr = 0.01
I0416 16:26:32.665364   977 solver.cpp:221] Iteration 22160, loss = 0.137613
I0416 16:26:32.665392   977 solver.cpp:236]     Train net output #0: loss = 0.174083 (* 1 = 0.174083 loss)
I0416 16:26:32.665397   977 solver.cpp:542] Iteration 22160, lr = 0.01
I0416 16:26:46.204527   977 solver.cpp:221] Iteration 22180, loss = 0.1304
I0416 16:26:46.204555   977 solver.cpp:236]     Train net output #0: loss = 0.101956 (* 1 = 0.101956 loss)
I0416 16:26:46.204558   977 solver.cpp:542] Iteration 22180, lr = 0.01
I0416 16:26:59.083608   977 solver.cpp:316] Iteration 22200, Testing net (#0)
I0416 16:27:10.627754   977 solver.cpp:373]     Test net output #0: accuracy = 0.988023
I0416 16:27:10.627775   977 solver.cpp:373]     Test net output #1: loss = 0.0549353 (* 1 = 0.0549353 loss)
I0416 16:27:11.297726   977 solver.cpp:221] Iteration 22200, loss = 0.122748
I0416 16:27:11.297754   977 solver.cpp:236]     Train net output #0: loss = 0.250075 (* 1 = 0.250075 loss)
I0416 16:27:11.297758   977 solver.cpp:542] Iteration 22200, lr = 0.01
I0416 16:27:24.854910   977 solver.cpp:221] Iteration 22220, loss = 0.118286
I0416 16:27:24.854938   977 solver.cpp:236]     Train net output #0: loss = 0.0729236 (* 1 = 0.0729236 loss)
I0416 16:27:24.854943   977 solver.cpp:542] Iteration 22220, lr = 0.01
I0416 16:27:38.403241   977 solver.cpp:221] Iteration 22240, loss = 0.126286
I0416 16:27:38.403270   977 solver.cpp:236]     Train net output #0: loss = 0.118843 (* 1 = 0.118843 loss)
I0416 16:27:38.403273   977 solver.cpp:542] Iteration 22240, lr = 0.01
I0416 16:27:51.951246   977 solver.cpp:221] Iteration 22260, loss = 0.112618
I0416 16:27:51.951272   977 solver.cpp:236]     Train net output #0: loss = 0.135215 (* 1 = 0.135215 loss)
I0416 16:27:51.951277   977 solver.cpp:542] Iteration 22260, lr = 0.01
I0416 16:28:05.499620   977 solver.cpp:221] Iteration 22280, loss = 0.124416
I0416 16:28:05.499646   977 solver.cpp:236]     Train net output #0: loss = 0.193966 (* 1 = 0.193966 loss)
I0416 16:28:05.499651   977 solver.cpp:542] Iteration 22280, lr = 0.01
I0416 16:28:19.059620   977 solver.cpp:221] Iteration 22300, loss = 0.116699
I0416 16:28:19.059648   977 solver.cpp:236]     Train net output #0: loss = 0.105913 (* 1 = 0.105913 loss)
I0416 16:28:19.059653   977 solver.cpp:542] Iteration 22300, lr = 0.01
I0416 16:28:32.645694   977 solver.cpp:221] Iteration 22320, loss = 0.110118
I0416 16:28:32.645722   977 solver.cpp:236]     Train net output #0: loss = 0.147097 (* 1 = 0.147097 loss)
I0416 16:28:32.645726   977 solver.cpp:542] Iteration 22320, lr = 0.01
I0416 16:28:46.187243   977 solver.cpp:221] Iteration 22340, loss = 0.128059
I0416 16:28:46.187270   977 solver.cpp:236]     Train net output #0: loss = 0.185189 (* 1 = 0.185189 loss)
I0416 16:28:46.187275   977 solver.cpp:542] Iteration 22340, lr = 0.01
I0416 16:28:59.740514   977 solver.cpp:221] Iteration 22360, loss = 0.11744
I0416 16:28:59.740542   977 solver.cpp:236]     Train net output #0: loss = 0.105955 (* 1 = 0.105955 loss)
I0416 16:28:59.740547   977 solver.cpp:542] Iteration 22360, lr = 0.01
I0416 16:29:13.304292   977 solver.cpp:221] Iteration 22380, loss = 0.131273
I0416 16:29:13.304319   977 solver.cpp:236]     Train net output #0: loss = 0.182602 (* 1 = 0.182602 loss)
I0416 16:29:13.304324   977 solver.cpp:542] Iteration 22380, lr = 0.01
I0416 16:29:26.193712   977 solver.cpp:316] Iteration 22400, Testing net (#0)
I0416 16:29:37.737746   977 solver.cpp:373]     Test net output #0: accuracy = 0.990114
I0416 16:29:37.737768   977 solver.cpp:373]     Test net output #1: loss = 0.0518704 (* 1 = 0.0518704 loss)
I0416 16:29:38.407137   977 solver.cpp:221] Iteration 22400, loss = 0.135353
I0416 16:29:38.407165   977 solver.cpp:236]     Train net output #0: loss = 0.109594 (* 1 = 0.109594 loss)
I0416 16:29:38.407169   977 solver.cpp:542] Iteration 22400, lr = 0.01
I0416 16:29:51.956842   977 solver.cpp:221] Iteration 22420, loss = 0.129971
I0416 16:29:51.956871   977 solver.cpp:236]     Train net output #0: loss = 0.0905911 (* 1 = 0.0905911 loss)
I0416 16:29:51.956876   977 solver.cpp:542] Iteration 22420, lr = 0.01
I0416 16:30:05.527254   977 solver.cpp:221] Iteration 22440, loss = 0.121381
I0416 16:30:05.527281   977 solver.cpp:236]     Train net output #0: loss = 0.136821 (* 1 = 0.136821 loss)
I0416 16:30:05.527286   977 solver.cpp:542] Iteration 22440, lr = 0.01
I0416 16:30:19.109371   977 solver.cpp:221] Iteration 22460, loss = 0.142542
I0416 16:30:19.109400   977 solver.cpp:236]     Train net output #0: loss = 0.0892005 (* 1 = 0.0892005 loss)
I0416 16:30:19.109405   977 solver.cpp:542] Iteration 22460, lr = 0.01
I0416 16:30:32.662683   977 solver.cpp:221] Iteration 22480, loss = 0.122835
I0416 16:30:32.662710   977 solver.cpp:236]     Train net output #0: loss = 0.0977911 (* 1 = 0.0977911 loss)
I0416 16:30:32.662715   977 solver.cpp:542] Iteration 22480, lr = 0.01
I0416 16:30:46.192760   977 solver.cpp:221] Iteration 22500, loss = 0.116116
I0416 16:30:46.192788   977 solver.cpp:236]     Train net output #0: loss = 0.0600361 (* 1 = 0.0600361 loss)
I0416 16:30:46.192792   977 solver.cpp:542] Iteration 22500, lr = 0.01
I0416 16:30:59.721429   977 solver.cpp:221] Iteration 22520, loss = 0.108421
I0416 16:30:59.721457   977 solver.cpp:236]     Train net output #0: loss = 0.0656777 (* 1 = 0.0656777 loss)
I0416 16:30:59.721462   977 solver.cpp:542] Iteration 22520, lr = 0.01
I0416 16:31:13.289517   977 solver.cpp:221] Iteration 22540, loss = 0.117731
I0416 16:31:13.289544   977 solver.cpp:236]     Train net output #0: loss = 0.0907342 (* 1 = 0.0907342 loss)
I0416 16:31:13.289549   977 solver.cpp:542] Iteration 22540, lr = 0.01
I0416 16:31:26.872417   977 solver.cpp:221] Iteration 22560, loss = 0.14065
I0416 16:31:26.872444   977 solver.cpp:236]     Train net output #0: loss = 0.119051 (* 1 = 0.119051 loss)
I0416 16:31:26.872448   977 solver.cpp:542] Iteration 22560, lr = 0.01
I0416 16:31:40.412485   977 solver.cpp:221] Iteration 22580, loss = 0.132973
I0416 16:31:40.412511   977 solver.cpp:236]     Train net output #0: loss = 0.146946 (* 1 = 0.146946 loss)
I0416 16:31:40.412516   977 solver.cpp:542] Iteration 22580, lr = 0.01
I0416 16:31:53.321740   977 solver.cpp:316] Iteration 22600, Testing net (#0)
I0416 16:32:04.868135   977 solver.cpp:373]     Test net output #0: accuracy = 0.989924
I0416 16:32:04.868156   977 solver.cpp:373]     Test net output #1: loss = 0.0506717 (* 1 = 0.0506717 loss)
I0416 16:32:05.539474   977 solver.cpp:221] Iteration 22600, loss = 0.115683
I0416 16:32:05.539502   977 solver.cpp:236]     Train net output #0: loss = 0.0929412 (* 1 = 0.0929412 loss)
I0416 16:32:05.539507   977 solver.cpp:542] Iteration 22600, lr = 0.01
I0416 16:32:19.095116   977 solver.cpp:221] Iteration 22620, loss = 0.110213
I0416 16:32:19.095144   977 solver.cpp:236]     Train net output #0: loss = 0.0994776 (* 1 = 0.0994776 loss)
I0416 16:32:19.095149   977 solver.cpp:542] Iteration 22620, lr = 0.01
I0416 16:32:32.636070   977 solver.cpp:221] Iteration 22640, loss = 0.115428
I0416 16:32:32.636098   977 solver.cpp:236]     Train net output #0: loss = 0.0894725 (* 1 = 0.0894725 loss)
I0416 16:32:32.636103   977 solver.cpp:542] Iteration 22640, lr = 0.01
I0416 16:32:46.192384   977 solver.cpp:221] Iteration 22660, loss = 0.107615
I0416 16:32:46.192410   977 solver.cpp:236]     Train net output #0: loss = 0.19005 (* 1 = 0.19005 loss)
I0416 16:32:46.192414   977 solver.cpp:542] Iteration 22660, lr = 0.01
I0416 16:32:59.734424   977 solver.cpp:221] Iteration 22680, loss = 0.109118
I0416 16:32:59.734452   977 solver.cpp:236]     Train net output #0: loss = 0.132872 (* 1 = 0.132872 loss)
I0416 16:32:59.734457   977 solver.cpp:542] Iteration 22680, lr = 0.01
I0416 16:33:13.287924   977 solver.cpp:221] Iteration 22700, loss = 0.107635
I0416 16:33:13.287950   977 solver.cpp:236]     Train net output #0: loss = 0.096393 (* 1 = 0.096393 loss)
I0416 16:33:13.287955   977 solver.cpp:542] Iteration 22700, lr = 0.01
I0416 16:33:26.839524   977 solver.cpp:221] Iteration 22720, loss = 0.102935
I0416 16:33:26.839551   977 solver.cpp:236]     Train net output #0: loss = 0.105574 (* 1 = 0.105574 loss)
I0416 16:33:26.839556   977 solver.cpp:542] Iteration 22720, lr = 0.01
I0416 16:33:40.384279   977 solver.cpp:221] Iteration 22740, loss = 0.119822
I0416 16:33:40.384305   977 solver.cpp:236]     Train net output #0: loss = 0.0980437 (* 1 = 0.0980437 loss)
I0416 16:33:40.384308   977 solver.cpp:542] Iteration 22740, lr = 0.01
I0416 16:33:53.960927   977 solver.cpp:221] Iteration 22760, loss = 0.127224
I0416 16:33:53.960954   977 solver.cpp:236]     Train net output #0: loss = 0.154173 (* 1 = 0.154173 loss)
I0416 16:33:53.960959   977 solver.cpp:542] Iteration 22760, lr = 0.01
I0416 16:34:07.557898   977 solver.cpp:221] Iteration 22780, loss = 0.119455
I0416 16:34:07.557925   977 solver.cpp:236]     Train net output #0: loss = 0.160816 (* 1 = 0.160816 loss)
I0416 16:34:07.557929   977 solver.cpp:542] Iteration 22780, lr = 0.01
I0416 16:34:20.468696   977 solver.cpp:316] Iteration 22800, Testing net (#0)
I0416 16:34:32.001868   977 solver.cpp:373]     Test net output #0: accuracy = 0.989734
I0416 16:34:32.001890   977 solver.cpp:373]     Test net output #1: loss = 0.0503328 (* 1 = 0.0503328 loss)
I0416 16:34:32.671030   977 solver.cpp:221] Iteration 22800, loss = 0.122544
I0416 16:34:32.671057   977 solver.cpp:236]     Train net output #0: loss = 0.0925847 (* 1 = 0.0925847 loss)
I0416 16:34:32.671062   977 solver.cpp:542] Iteration 22800, lr = 0.01
I0416 16:34:46.223249   977 solver.cpp:221] Iteration 22820, loss = 0.10809
I0416 16:34:46.223276   977 solver.cpp:236]     Train net output #0: loss = 0.0644742 (* 1 = 0.0644742 loss)
I0416 16:34:46.223281   977 solver.cpp:542] Iteration 22820, lr = 0.01
I0416 16:34:59.784917   977 solver.cpp:221] Iteration 22840, loss = 0.122444
I0416 16:34:59.784945   977 solver.cpp:236]     Train net output #0: loss = 0.163587 (* 1 = 0.163587 loss)
I0416 16:34:59.784950   977 solver.cpp:542] Iteration 22840, lr = 0.01
I0416 16:35:13.331089   977 solver.cpp:221] Iteration 22860, loss = 0.110926
I0416 16:35:13.331117   977 solver.cpp:236]     Train net output #0: loss = 0.0408089 (* 1 = 0.0408089 loss)
I0416 16:35:13.331122   977 solver.cpp:542] Iteration 22860, lr = 0.01
I0416 16:35:26.866955   977 solver.cpp:221] Iteration 22880, loss = 0.106926
I0416 16:35:26.866982   977 solver.cpp:236]     Train net output #0: loss = 0.137309 (* 1 = 0.137309 loss)
I0416 16:35:26.866987   977 solver.cpp:542] Iteration 22880, lr = 0.01
I0416 16:35:40.395299   977 solver.cpp:221] Iteration 22900, loss = 0.10693
I0416 16:35:40.395328   977 solver.cpp:236]     Train net output #0: loss = 0.0999227 (* 1 = 0.0999227 loss)
I0416 16:35:40.395331   977 solver.cpp:542] Iteration 22900, lr = 0.01
I0416 16:35:53.926913   977 solver.cpp:221] Iteration 22920, loss = 0.105626
I0416 16:35:53.926939   977 solver.cpp:236]     Train net output #0: loss = 0.123258 (* 1 = 0.123258 loss)
I0416 16:35:53.926944   977 solver.cpp:542] Iteration 22920, lr = 0.01
I0416 16:36:07.466894   977 solver.cpp:221] Iteration 22940, loss = 0.099949
I0416 16:36:07.466922   977 solver.cpp:236]     Train net output #0: loss = 0.142872 (* 1 = 0.142872 loss)
I0416 16:36:07.466927   977 solver.cpp:542] Iteration 22940, lr = 0.01
I0416 16:36:20.997325   977 solver.cpp:221] Iteration 22960, loss = 0.111868
I0416 16:36:20.997352   977 solver.cpp:236]     Train net output #0: loss = 0.125522 (* 1 = 0.125522 loss)
I0416 16:36:20.997357   977 solver.cpp:542] Iteration 22960, lr = 0.01
I0416 16:36:34.533366   977 solver.cpp:221] Iteration 22980, loss = 0.127556
I0416 16:36:34.533395   977 solver.cpp:236]     Train net output #0: loss = 0.102845 (* 1 = 0.102845 loss)
I0416 16:36:34.533399   977 solver.cpp:542] Iteration 22980, lr = 0.01
I0416 16:36:47.420677   977 solver.cpp:316] Iteration 23000, Testing net (#0)
I0416 16:36:58.954548   977 solver.cpp:373]     Test net output #0: accuracy = 0.988593
I0416 16:36:58.954568   977 solver.cpp:373]     Test net output #1: loss = 0.0510657 (* 1 = 0.0510657 loss)
I0416 16:36:59.623520   977 solver.cpp:221] Iteration 23000, loss = 0.0998036
I0416 16:36:59.623549   977 solver.cpp:236]     Train net output #0: loss = 0.0763252 (* 1 = 0.0763252 loss)
I0416 16:36:59.623553   977 solver.cpp:542] Iteration 23000, lr = 0.01
I0416 16:37:13.188158   977 solver.cpp:221] Iteration 23020, loss = 0.120523
I0416 16:37:13.188184   977 solver.cpp:236]     Train net output #0: loss = 0.112161 (* 1 = 0.112161 loss)
I0416 16:37:13.188189   977 solver.cpp:542] Iteration 23020, lr = 0.01
I0416 16:37:26.734683   977 solver.cpp:221] Iteration 23040, loss = 0.112083
I0416 16:37:26.734710   977 solver.cpp:236]     Train net output #0: loss = 0.0994687 (* 1 = 0.0994687 loss)
I0416 16:37:26.734715   977 solver.cpp:542] Iteration 23040, lr = 0.01
I0416 16:37:40.271433   977 solver.cpp:221] Iteration 23060, loss = 0.110149
I0416 16:37:40.271461   977 solver.cpp:236]     Train net output #0: loss = 0.133136 (* 1 = 0.133136 loss)
I0416 16:37:40.271466   977 solver.cpp:542] Iteration 23060, lr = 0.01
I0416 16:37:53.804071   977 solver.cpp:221] Iteration 23080, loss = 0.102954
I0416 16:37:53.804098   977 solver.cpp:236]     Train net output #0: loss = 0.0456601 (* 1 = 0.0456601 loss)
I0416 16:37:53.804102   977 solver.cpp:542] Iteration 23080, lr = 0.01
I0416 16:38:07.351366   977 solver.cpp:221] Iteration 23100, loss = 0.11009
I0416 16:38:07.351393   977 solver.cpp:236]     Train net output #0: loss = 0.142917 (* 1 = 0.142917 loss)
I0416 16:38:07.351398   977 solver.cpp:542] Iteration 23100, lr = 0.01
I0416 16:38:20.878960   977 solver.cpp:221] Iteration 23120, loss = 0.107081
I0416 16:38:20.878988   977 solver.cpp:236]     Train net output #0: loss = 0.154732 (* 1 = 0.154732 loss)
I0416 16:38:20.878993   977 solver.cpp:542] Iteration 23120, lr = 0.01
I0416 16:38:34.416036   977 solver.cpp:221] Iteration 23140, loss = 0.106178
I0416 16:38:34.416064   977 solver.cpp:236]     Train net output #0: loss = 0.203259 (* 1 = 0.203259 loss)
I0416 16:38:34.416069   977 solver.cpp:542] Iteration 23140, lr = 0.01
I0416 16:38:47.957932   977 solver.cpp:221] Iteration 23160, loss = 0.105161
I0416 16:38:47.957962   977 solver.cpp:236]     Train net output #0: loss = 0.0763968 (* 1 = 0.0763968 loss)
I0416 16:38:47.957965   977 solver.cpp:542] Iteration 23160, lr = 0.01
I0416 16:39:01.503860   977 solver.cpp:221] Iteration 23180, loss = 0.110987
I0416 16:39:01.503888   977 solver.cpp:236]     Train net output #0: loss = 0.0995048 (* 1 = 0.0995048 loss)
I0416 16:39:01.503893   977 solver.cpp:542] Iteration 23180, lr = 0.01
I0416 16:39:14.401510   977 solver.cpp:316] Iteration 23200, Testing net (#0)
I0416 16:39:25.944298   977 solver.cpp:373]     Test net output #0: accuracy = 0.989734
I0416 16:39:25.944319   977 solver.cpp:373]     Test net output #1: loss = 0.0501225 (* 1 = 0.0501225 loss)
I0416 16:39:26.616969   977 solver.cpp:221] Iteration 23200, loss = 0.115485
I0416 16:39:26.616997   977 solver.cpp:236]     Train net output #0: loss = 0.0566711 (* 1 = 0.0566711 loss)
I0416 16:39:26.617002   977 solver.cpp:542] Iteration 23200, lr = 0.01
I0416 16:39:40.204151   977 solver.cpp:221] Iteration 23220, loss = 0.11317
I0416 16:39:40.204179   977 solver.cpp:236]     Train net output #0: loss = 0.112421 (* 1 = 0.112421 loss)
I0416 16:39:40.204183   977 solver.cpp:542] Iteration 23220, lr = 0.01
I0416 16:39:53.778087   977 solver.cpp:221] Iteration 23240, loss = 0.121493
I0416 16:39:53.778113   977 solver.cpp:236]     Train net output #0: loss = 0.0908385 (* 1 = 0.0908385 loss)
I0416 16:39:53.778118   977 solver.cpp:542] Iteration 23240, lr = 0.01
I0416 16:40:07.352903   977 solver.cpp:221] Iteration 23260, loss = 0.108402
I0416 16:40:07.352931   977 solver.cpp:236]     Train net output #0: loss = 0.068036 (* 1 = 0.068036 loss)
I0416 16:40:07.352934   977 solver.cpp:542] Iteration 23260, lr = 0.01
I0416 16:40:20.919824   977 solver.cpp:221] Iteration 23280, loss = 0.116708
I0416 16:40:20.919852   977 solver.cpp:236]     Train net output #0: loss = 0.0615743 (* 1 = 0.0615743 loss)
I0416 16:40:20.919857   977 solver.cpp:542] Iteration 23280, lr = 0.01
I0416 16:40:34.468751   977 solver.cpp:221] Iteration 23300, loss = 0.107401
I0416 16:40:34.468780   977 solver.cpp:236]     Train net output #0: loss = 0.129085 (* 1 = 0.129085 loss)
I0416 16:40:34.468783   977 solver.cpp:542] Iteration 23300, lr = 0.01
I0416 16:40:48.033165   977 solver.cpp:221] Iteration 23320, loss = 0.100534
I0416 16:40:48.033192   977 solver.cpp:236]     Train net output #0: loss = 0.0530565 (* 1 = 0.0530565 loss)
I0416 16:40:48.033197   977 solver.cpp:542] Iteration 23320, lr = 0.01
I0416 16:41:01.568465   977 solver.cpp:221] Iteration 23340, loss = 0.0982227
I0416 16:41:01.568491   977 solver.cpp:236]     Train net output #0: loss = 0.120545 (* 1 = 0.120545 loss)
I0416 16:41:01.568496   977 solver.cpp:542] Iteration 23340, lr = 0.01
I0416 16:41:15.105698   977 solver.cpp:221] Iteration 23360, loss = 0.10427
I0416 16:41:15.105726   977 solver.cpp:236]     Train net output #0: loss = 0.0833147 (* 1 = 0.0833147 loss)
I0416 16:41:15.105731   977 solver.cpp:542] Iteration 23360, lr = 0.01
I0416 16:41:28.644345   977 solver.cpp:221] Iteration 23380, loss = 0.0951311
I0416 16:41:28.644372   977 solver.cpp:236]     Train net output #0: loss = 0.130659 (* 1 = 0.130659 loss)
I0416 16:41:28.644377   977 solver.cpp:542] Iteration 23380, lr = 0.01
I0416 16:41:41.540524   977 solver.cpp:316] Iteration 23400, Testing net (#0)
I0416 16:41:53.075330   977 solver.cpp:373]     Test net output #0: accuracy = 0.989924
I0416 16:41:53.075352   977 solver.cpp:373]     Test net output #1: loss = 0.0490652 (* 1 = 0.0490652 loss)
I0416 16:41:53.745704   977 solver.cpp:221] Iteration 23400, loss = 0.114578
I0416 16:41:53.745731   977 solver.cpp:236]     Train net output #0: loss = 0.0611901 (* 1 = 0.0611901 loss)
I0416 16:41:53.745736   977 solver.cpp:542] Iteration 23400, lr = 0.01
I0416 16:42:07.344377   977 solver.cpp:221] Iteration 23420, loss = 0.11066
I0416 16:42:07.344404   977 solver.cpp:236]     Train net output #0: loss = 0.108137 (* 1 = 0.108137 loss)
I0416 16:42:07.344408   977 solver.cpp:542] Iteration 23420, lr = 0.01
I0416 16:42:20.917621   977 solver.cpp:221] Iteration 23440, loss = 0.109062
I0416 16:42:20.917649   977 solver.cpp:236]     Train net output #0: loss = 0.162679 (* 1 = 0.162679 loss)
I0416 16:42:20.917654   977 solver.cpp:542] Iteration 23440, lr = 0.01
I0416 16:42:34.469931   977 solver.cpp:221] Iteration 23460, loss = 0.0997048
I0416 16:42:34.469959   977 solver.cpp:236]     Train net output #0: loss = 0.177071 (* 1 = 0.177071 loss)
I0416 16:42:34.469964   977 solver.cpp:542] Iteration 23460, lr = 0.01
I0416 16:42:48.012228   977 solver.cpp:221] Iteration 23480, loss = 0.100692
I0416 16:42:48.012255   977 solver.cpp:236]     Train net output #0: loss = 0.11663 (* 1 = 0.11663 loss)
I0416 16:42:48.012259   977 solver.cpp:542] Iteration 23480, lr = 0.01
I0416 16:43:01.535514   977 solver.cpp:221] Iteration 23500, loss = 0.0969229
I0416 16:43:01.535542   977 solver.cpp:236]     Train net output #0: loss = 0.12118 (* 1 = 0.12118 loss)
I0416 16:43:01.535545   977 solver.cpp:542] Iteration 23500, lr = 0.01
I0416 16:43:15.054474   977 solver.cpp:221] Iteration 23520, loss = 0.0932937
I0416 16:43:15.054502   977 solver.cpp:236]     Train net output #0: loss = 0.0470127 (* 1 = 0.0470127 loss)
I0416 16:43:15.054507   977 solver.cpp:542] Iteration 23520, lr = 0.01
I0416 16:43:28.579591   977 solver.cpp:221] Iteration 23540, loss = 0.0980859
I0416 16:43:28.579618   977 solver.cpp:236]     Train net output #0: loss = 0.17545 (* 1 = 0.17545 loss)
I0416 16:43:28.579622   977 solver.cpp:542] Iteration 23540, lr = 0.01
I0416 16:43:42.123378   977 solver.cpp:221] Iteration 23560, loss = 0.0968093
I0416 16:43:42.123404   977 solver.cpp:236]     Train net output #0: loss = 0.111172 (* 1 = 0.111172 loss)
I0416 16:43:42.123409   977 solver.cpp:542] Iteration 23560, lr = 0.01
I0416 16:43:55.715248   977 solver.cpp:221] Iteration 23580, loss = 0.0966039
I0416 16:43:55.715276   977 solver.cpp:236]     Train net output #0: loss = 0.086922 (* 1 = 0.086922 loss)
I0416 16:43:55.715281   977 solver.cpp:542] Iteration 23580, lr = 0.01
I0416 16:44:08.595432   977 solver.cpp:316] Iteration 23600, Testing net (#0)
I0416 16:44:20.129467   977 solver.cpp:373]     Test net output #0: accuracy = 0.989163
I0416 16:44:20.129488   977 solver.cpp:373]     Test net output #1: loss = 0.0491342 (* 1 = 0.0491342 loss)
I0416 16:44:20.798576   977 solver.cpp:221] Iteration 23600, loss = 0.0937878
I0416 16:44:20.798604   977 solver.cpp:236]     Train net output #0: loss = 0.0897058 (* 1 = 0.0897058 loss)
I0416 16:44:20.798609   977 solver.cpp:542] Iteration 23600, lr = 0.01
I0416 16:44:34.331763   977 solver.cpp:221] Iteration 23620, loss = 0.11126
I0416 16:44:34.331789   977 solver.cpp:236]     Train net output #0: loss = 0.135973 (* 1 = 0.135973 loss)
I0416 16:44:34.331794   977 solver.cpp:542] Iteration 23620, lr = 0.01
I0416 16:44:47.866271   977 solver.cpp:221] Iteration 23640, loss = 0.100746
I0416 16:44:47.866307   977 solver.cpp:236]     Train net output #0: loss = 0.0748471 (* 1 = 0.0748471 loss)
I0416 16:44:47.866312   977 solver.cpp:542] Iteration 23640, lr = 0.01
I0416 16:45:01.406148   977 solver.cpp:221] Iteration 23660, loss = 0.0988759
I0416 16:45:01.406177   977 solver.cpp:236]     Train net output #0: loss = 0.0753033 (* 1 = 0.0753033 loss)
I0416 16:45:01.406180   977 solver.cpp:542] Iteration 23660, lr = 0.01
I0416 16:45:14.941261   977 solver.cpp:221] Iteration 23680, loss = 0.110222
I0416 16:45:14.941287   977 solver.cpp:236]     Train net output #0: loss = 0.130585 (* 1 = 0.130585 loss)
I0416 16:45:14.941292   977 solver.cpp:542] Iteration 23680, lr = 0.01
I0416 16:45:28.482019   977 solver.cpp:221] Iteration 23700, loss = 0.0985502
I0416 16:45:28.482046   977 solver.cpp:236]     Train net output #0: loss = 0.029467 (* 1 = 0.029467 loss)
I0416 16:45:28.482051   977 solver.cpp:542] Iteration 23700, lr = 0.01
I0416 16:45:42.020290   977 solver.cpp:221] Iteration 23720, loss = 0.101541
I0416 16:45:42.020318   977 solver.cpp:236]     Train net output #0: loss = 0.108353 (* 1 = 0.108353 loss)
I0416 16:45:42.020323   977 solver.cpp:542] Iteration 23720, lr = 0.01
I0416 16:45:55.549001   977 solver.cpp:221] Iteration 23740, loss = 0.100423
I0416 16:45:55.549028   977 solver.cpp:236]     Train net output #0: loss = 0.120291 (* 1 = 0.120291 loss)
I0416 16:45:55.549033   977 solver.cpp:542] Iteration 23740, lr = 0.01
I0416 16:46:09.086585   977 solver.cpp:221] Iteration 23760, loss = 0.0931895
I0416 16:46:09.086611   977 solver.cpp:236]     Train net output #0: loss = 0.0927027 (* 1 = 0.0927027 loss)
I0416 16:46:09.086617   977 solver.cpp:542] Iteration 23760, lr = 0.01
I0416 16:46:22.630514   977 solver.cpp:221] Iteration 23780, loss = 0.0864196
I0416 16:46:22.630542   977 solver.cpp:236]     Train net output #0: loss = 0.0701647 (* 1 = 0.0701647 loss)
I0416 16:46:22.630548   977 solver.cpp:542] Iteration 23780, lr = 0.01
I0416 16:46:35.509903   977 solver.cpp:316] Iteration 23800, Testing net (#0)
I0416 16:46:47.045116   977 solver.cpp:373]     Test net output #0: accuracy = 0.990874
I0416 16:46:47.045137   977 solver.cpp:373]     Test net output #1: loss = 0.0467175 (* 1 = 0.0467175 loss)
I0416 16:46:47.713019   977 solver.cpp:221] Iteration 23800, loss = 0.0974837
I0416 16:46:47.713047   977 solver.cpp:236]     Train net output #0: loss = 0.0513602 (* 1 = 0.0513602 loss)
I0416 16:46:47.713052   977 solver.cpp:542] Iteration 23800, lr = 0.01
I0416 16:47:01.263276   977 solver.cpp:221] Iteration 23820, loss = 0.112088
I0416 16:47:01.263303   977 solver.cpp:236]     Train net output #0: loss = 0.124412 (* 1 = 0.124412 loss)
I0416 16:47:01.263309   977 solver.cpp:542] Iteration 23820, lr = 0.01
I0416 16:47:14.817009   977 solver.cpp:221] Iteration 23840, loss = 0.114022
I0416 16:47:14.817035   977 solver.cpp:236]     Train net output #0: loss = 0.12436 (* 1 = 0.12436 loss)
I0416 16:47:14.817040   977 solver.cpp:542] Iteration 23840, lr = 0.01
I0416 16:47:28.387495   977 solver.cpp:221] Iteration 23860, loss = 0.10164
I0416 16:47:28.387522   977 solver.cpp:236]     Train net output #0: loss = 0.0490366 (* 1 = 0.0490366 loss)
I0416 16:47:28.387527   977 solver.cpp:542] Iteration 23860, lr = 0.01
I0416 16:47:41.926620   977 solver.cpp:221] Iteration 23880, loss = 0.100484
I0416 16:47:41.926648   977 solver.cpp:236]     Train net output #0: loss = 0.105947 (* 1 = 0.105947 loss)
I0416 16:47:41.926653   977 solver.cpp:542] Iteration 23880, lr = 0.01
I0416 16:47:55.465200   977 solver.cpp:221] Iteration 23900, loss = 0.0948496
I0416 16:47:55.465227   977 solver.cpp:236]     Train net output #0: loss = 0.0907231 (* 1 = 0.0907231 loss)
I0416 16:47:55.465232   977 solver.cpp:542] Iteration 23900, lr = 0.01
I0416 16:48:08.999689   977 solver.cpp:221] Iteration 23920, loss = 0.0873595
I0416 16:48:08.999716   977 solver.cpp:236]     Train net output #0: loss = 0.077545 (* 1 = 0.077545 loss)
I0416 16:48:08.999721   977 solver.cpp:542] Iteration 23920, lr = 0.01
I0416 16:48:22.549265   977 solver.cpp:221] Iteration 23940, loss = 0.104485
I0416 16:48:22.549293   977 solver.cpp:236]     Train net output #0: loss = 0.171673 (* 1 = 0.171673 loss)
I0416 16:48:22.549299   977 solver.cpp:542] Iteration 23940, lr = 0.01
I0416 16:48:36.114617   977 solver.cpp:221] Iteration 23960, loss = 0.0881825
I0416 16:48:36.114645   977 solver.cpp:236]     Train net output #0: loss = 0.14746 (* 1 = 0.14746 loss)
I0416 16:48:36.114650   977 solver.cpp:542] Iteration 23960, lr = 0.01
I0416 16:48:49.664768   977 solver.cpp:221] Iteration 23980, loss = 0.0892247
I0416 16:48:49.664795   977 solver.cpp:236]     Train net output #0: loss = 0.063713 (* 1 = 0.063713 loss)
I0416 16:48:49.664800   977 solver.cpp:542] Iteration 23980, lr = 0.01
I0416 16:49:02.546284   977 solver.cpp:316] Iteration 24000, Testing net (#0)
I0416 16:49:14.080230   977 solver.cpp:373]     Test net output #0: accuracy = 0.990684
I0416 16:49:14.080253   977 solver.cpp:373]     Test net output #1: loss = 0.0485316 (* 1 = 0.0485316 loss)
I0416 16:49:14.749802   977 solver.cpp:221] Iteration 24000, loss = 0.0884615
I0416 16:49:14.749830   977 solver.cpp:236]     Train net output #0: loss = 0.0788228 (* 1 = 0.0788228 loss)
I0416 16:49:14.749835   977 solver.cpp:542] Iteration 24000, lr = 0.01
I0416 16:49:28.300030   977 solver.cpp:221] Iteration 24020, loss = 0.0973104
I0416 16:49:28.300057   977 solver.cpp:236]     Train net output #0: loss = 0.0839773 (* 1 = 0.0839773 loss)
I0416 16:49:28.300061   977 solver.cpp:542] Iteration 24020, lr = 0.01
I0416 16:49:41.841435   977 solver.cpp:221] Iteration 24040, loss = 0.0964999
I0416 16:49:41.841464   977 solver.cpp:236]     Train net output #0: loss = 0.0476488 (* 1 = 0.0476488 loss)
I0416 16:49:41.841467   977 solver.cpp:542] Iteration 24040, lr = 0.01
I0416 16:49:55.382342   977 solver.cpp:221] Iteration 24060, loss = 0.0985847
I0416 16:49:55.382369   977 solver.cpp:236]     Train net output #0: loss = 0.106833 (* 1 = 0.106833 loss)
I0416 16:49:55.382375   977 solver.cpp:542] Iteration 24060, lr = 0.01
I0416 16:50:08.938984   977 solver.cpp:221] Iteration 24080, loss = 0.100325
I0416 16:50:08.939012   977 solver.cpp:236]     Train net output #0: loss = 0.065023 (* 1 = 0.065023 loss)
I0416 16:50:08.939015   977 solver.cpp:542] Iteration 24080, lr = 0.01
I0416 16:50:22.484158   977 solver.cpp:221] Iteration 24100, loss = 0.0986788
I0416 16:50:22.484185   977 solver.cpp:236]     Train net output #0: loss = 0.0769557 (* 1 = 0.0769557 loss)
I0416 16:50:22.484189   977 solver.cpp:542] Iteration 24100, lr = 0.01
I0416 16:50:36.022318   977 solver.cpp:221] Iteration 24120, loss = 0.0952994
I0416 16:50:36.022346   977 solver.cpp:236]     Train net output #0: loss = 0.0395955 (* 1 = 0.0395955 loss)
I0416 16:50:36.022351   977 solver.cpp:542] Iteration 24120, lr = 0.01
I0416 16:50:49.567813   977 solver.cpp:221] Iteration 24140, loss = 0.0933681
I0416 16:50:49.567838   977 solver.cpp:236]     Train net output #0: loss = 0.108425 (* 1 = 0.108425 loss)
I0416 16:50:49.567842   977 solver.cpp:542] Iteration 24140, lr = 0.01
I0416 16:51:03.101384   977 solver.cpp:221] Iteration 24160, loss = 0.0926048
I0416 16:51:03.101413   977 solver.cpp:236]     Train net output #0: loss = 0.178077 (* 1 = 0.178077 loss)
I0416 16:51:03.101418   977 solver.cpp:542] Iteration 24160, lr = 0.01
I0416 16:51:16.645203   977 solver.cpp:221] Iteration 24180, loss = 0.0865612
I0416 16:51:16.645232   977 solver.cpp:236]     Train net output #0: loss = 0.109829 (* 1 = 0.109829 loss)
I0416 16:51:16.645236   977 solver.cpp:542] Iteration 24180, lr = 0.01
I0416 16:51:29.555732   977 solver.cpp:316] Iteration 24200, Testing net (#0)
I0416 16:51:41.103688   977 solver.cpp:373]     Test net output #0: accuracy = 0.989543
I0416 16:51:41.103709   977 solver.cpp:373]     Test net output #1: loss = 0.0450862 (* 1 = 0.0450862 loss)
I0416 16:51:41.775372   977 solver.cpp:221] Iteration 24200, loss = 0.0828591
I0416 16:51:41.775398   977 solver.cpp:236]     Train net output #0: loss = 0.0724767 (* 1 = 0.0724767 loss)
I0416 16:51:41.775403   977 solver.cpp:542] Iteration 24200, lr = 0.01
I0416 16:51:55.342062   977 solver.cpp:221] Iteration 24220, loss = 0.0891326
I0416 16:51:55.342089   977 solver.cpp:236]     Train net output #0: loss = 0.114032 (* 1 = 0.114032 loss)
I0416 16:51:55.342093   977 solver.cpp:542] Iteration 24220, lr = 0.01
I0416 16:52:08.896050   977 solver.cpp:221] Iteration 24240, loss = 0.104109
I0416 16:52:08.896077   977 solver.cpp:236]     Train net output #0: loss = 0.106569 (* 1 = 0.106569 loss)
I0416 16:52:08.896082   977 solver.cpp:542] Iteration 24240, lr = 0.01
I0416 16:52:22.443254   977 solver.cpp:221] Iteration 24260, loss = 0.0962082
I0416 16:52:22.443282   977 solver.cpp:236]     Train net output #0: loss = 0.0863582 (* 1 = 0.0863582 loss)
I0416 16:52:22.443287   977 solver.cpp:542] Iteration 24260, lr = 0.01
I0416 16:52:35.968564   977 solver.cpp:221] Iteration 24280, loss = 0.0933991
I0416 16:52:35.968591   977 solver.cpp:236]     Train net output #0: loss = 0.0696708 (* 1 = 0.0696708 loss)
I0416 16:52:35.968598   977 solver.cpp:542] Iteration 24280, lr = 0.01
I0416 16:52:49.489912   977 solver.cpp:221] Iteration 24300, loss = 0.094979
I0416 16:52:49.489939   977 solver.cpp:236]     Train net output #0: loss = 0.100457 (* 1 = 0.100457 loss)
I0416 16:52:49.489944   977 solver.cpp:542] Iteration 24300, lr = 0.01
I0416 16:53:03.023118   977 solver.cpp:221] Iteration 24320, loss = 0.084404
I0416 16:53:03.023145   977 solver.cpp:236]     Train net output #0: loss = 0.139769 (* 1 = 0.139769 loss)
I0416 16:53:03.023150   977 solver.cpp:542] Iteration 24320, lr = 0.01
I0416 16:53:16.563833   977 solver.cpp:221] Iteration 24340, loss = 0.0930838
I0416 16:53:16.563861   977 solver.cpp:236]     Train net output #0: loss = 0.053916 (* 1 = 0.053916 loss)
I0416 16:53:16.563866   977 solver.cpp:542] Iteration 24340, lr = 0.01
I0416 16:53:30.108247   977 solver.cpp:221] Iteration 24360, loss = 0.0826098
I0416 16:53:30.108275   977 solver.cpp:236]     Train net output #0: loss = 0.0592294 (* 1 = 0.0592294 loss)
I0416 16:53:30.108280   977 solver.cpp:542] Iteration 24360, lr = 0.01
I0416 16:53:43.637229   977 solver.cpp:221] Iteration 24380, loss = 0.0865603
I0416 16:53:43.637254   977 solver.cpp:236]     Train net output #0: loss = 0.079345 (* 1 = 0.079345 loss)
I0416 16:53:43.637259   977 solver.cpp:542] Iteration 24380, lr = 0.01
I0416 16:53:56.521692   977 solver.cpp:316] Iteration 24400, Testing net (#0)
I0416 16:54:08.055614   977 solver.cpp:373]     Test net output #0: accuracy = 0.990114
I0416 16:54:08.055635   977 solver.cpp:373]     Test net output #1: loss = 0.0454262 (* 1 = 0.0454262 loss)
I0416 16:54:08.725040   977 solver.cpp:221] Iteration 24400, loss = 0.0903498
I0416 16:54:08.725067   977 solver.cpp:236]     Train net output #0: loss = 0.0726016 (* 1 = 0.0726016 loss)
I0416 16:54:08.725072   977 solver.cpp:542] Iteration 24400, lr = 0.01
I0416 16:54:22.259016   977 solver.cpp:221] Iteration 24420, loss = 0.0843346
I0416 16:54:22.259043   977 solver.cpp:236]     Train net output #0: loss = 0.111054 (* 1 = 0.111054 loss)
I0416 16:54:22.259048   977 solver.cpp:542] Iteration 24420, lr = 0.01
I0416 16:54:35.842356   977 solver.cpp:221] Iteration 24440, loss = 0.0900481
I0416 16:54:35.842384   977 solver.cpp:236]     Train net output #0: loss = 0.086028 (* 1 = 0.086028 loss)
I0416 16:54:35.842391   977 solver.cpp:542] Iteration 24440, lr = 0.01
I0416 16:54:49.397434   977 solver.cpp:221] Iteration 24460, loss = 0.0969377
I0416 16:54:49.397462   977 solver.cpp:236]     Train net output #0: loss = 0.108868 (* 1 = 0.108868 loss)
I0416 16:54:49.397466   977 solver.cpp:542] Iteration 24460, lr = 0.01
I0416 16:55:02.936497   977 solver.cpp:221] Iteration 24480, loss = 0.0988234
I0416 16:55:02.936525   977 solver.cpp:236]     Train net output #0: loss = 0.133344 (* 1 = 0.133344 loss)
I0416 16:55:02.936529   977 solver.cpp:542] Iteration 24480, lr = 0.01
I0416 16:55:16.473922   977 solver.cpp:221] Iteration 24500, loss = 0.0899365
I0416 16:55:16.473949   977 solver.cpp:236]     Train net output #0: loss = 0.109714 (* 1 = 0.109714 loss)
I0416 16:55:16.473954   977 solver.cpp:542] Iteration 24500, lr = 0.01
I0416 16:55:30.008378   977 solver.cpp:221] Iteration 24520, loss = 0.0946799
I0416 16:55:30.008405   977 solver.cpp:236]     Train net output #0: loss = 0.0762025 (* 1 = 0.0762025 loss)
I0416 16:55:30.008410   977 solver.cpp:542] Iteration 24520, lr = 0.01
I0416 16:55:43.543592   977 solver.cpp:221] Iteration 24540, loss = 0.0927209
I0416 16:55:43.543620   977 solver.cpp:236]     Train net output #0: loss = 0.0736268 (* 1 = 0.0736268 loss)
I0416 16:55:43.543624   977 solver.cpp:542] Iteration 24540, lr = 0.01
I0416 16:55:57.078192   977 solver.cpp:221] Iteration 24560, loss = 0.0824696
I0416 16:55:57.078220   977 solver.cpp:236]     Train net output #0: loss = 0.0853321 (* 1 = 0.0853321 loss)
I0416 16:55:57.078225   977 solver.cpp:542] Iteration 24560, lr = 0.01
I0416 16:56:10.629678   977 solver.cpp:221] Iteration 24580, loss = 0.0885903
I0416 16:56:10.629706   977 solver.cpp:236]     Train net output #0: loss = 0.116932 (* 1 = 0.116932 loss)
I0416 16:56:10.629712   977 solver.cpp:542] Iteration 24580, lr = 0.01
I0416 16:56:23.524301   977 solver.cpp:316] Iteration 24600, Testing net (#0)
I0416 16:56:35.059960   977 solver.cpp:373]     Test net output #0: accuracy = 0.991064
I0416 16:56:35.059981   977 solver.cpp:373]     Test net output #1: loss = 0.044786 (* 1 = 0.044786 loss)
I0416 16:56:35.728381   977 solver.cpp:221] Iteration 24600, loss = 0.0808215
I0416 16:56:35.728410   977 solver.cpp:236]     Train net output #0: loss = 0.0726188 (* 1 = 0.0726188 loss)
I0416 16:56:35.728413   977 solver.cpp:542] Iteration 24600, lr = 0.01
I0416 16:56:49.269759   977 solver.cpp:221] Iteration 24620, loss = 0.079401
I0416 16:56:49.269788   977 solver.cpp:236]     Train net output #0: loss = 0.103052 (* 1 = 0.103052 loss)
I0416 16:56:49.269793   977 solver.cpp:542] Iteration 24620, lr = 0.01
I0416 16:57:02.807919   977 solver.cpp:221] Iteration 24640, loss = 0.0914129
I0416 16:57:02.807945   977 solver.cpp:236]     Train net output #0: loss = 0.16128 (* 1 = 0.16128 loss)
I0416 16:57:02.807950   977 solver.cpp:542] Iteration 24640, lr = 0.01
I0416 16:57:16.339390   977 solver.cpp:221] Iteration 24660, loss = 0.0948618
I0416 16:57:16.339418   977 solver.cpp:236]     Train net output #0: loss = 0.142035 (* 1 = 0.142035 loss)
I0416 16:57:16.339422   977 solver.cpp:542] Iteration 24660, lr = 0.01
I0416 16:57:29.866600   977 solver.cpp:221] Iteration 24680, loss = 0.0906503
I0416 16:57:29.866627   977 solver.cpp:236]     Train net output #0: loss = 0.0447485 (* 1 = 0.0447485 loss)
I0416 16:57:29.866631   977 solver.cpp:542] Iteration 24680, lr = 0.01
I0416 16:57:43.412485   977 solver.cpp:221] Iteration 24700, loss = 0.0891864
I0416 16:57:43.412513   977 solver.cpp:236]     Train net output #0: loss = 0.124293 (* 1 = 0.124293 loss)
I0416 16:57:43.412518   977 solver.cpp:542] Iteration 24700, lr = 0.01
I0416 16:57:56.959720   977 solver.cpp:221] Iteration 24720, loss = 0.0867882
I0416 16:57:56.959748   977 solver.cpp:236]     Train net output #0: loss = 0.0482372 (* 1 = 0.0482372 loss)
I0416 16:57:56.959753   977 solver.cpp:542] Iteration 24720, lr = 0.01
I0416 16:58:10.500066   977 solver.cpp:221] Iteration 24740, loss = 0.092903
I0416 16:58:10.500092   977 solver.cpp:236]     Train net output #0: loss = 0.106172 (* 1 = 0.106172 loss)
I0416 16:58:10.500097   977 solver.cpp:542] Iteration 24740, lr = 0.01
I0416 16:58:24.034850   977 solver.cpp:221] Iteration 24760, loss = 0.0822743
I0416 16:58:24.034878   977 solver.cpp:236]     Train net output #0: loss = 0.0844359 (* 1 = 0.0844359 loss)
I0416 16:58:24.034883   977 solver.cpp:542] Iteration 24760, lr = 0.01
I0416 16:58:37.579939   977 solver.cpp:221] Iteration 24780, loss = 0.0876554
I0416 16:58:37.579967   977 solver.cpp:236]     Train net output #0: loss = 0.155071 (* 1 = 0.155071 loss)
I0416 16:58:37.579972   977 solver.cpp:542] Iteration 24780, lr = 0.01
I0416 16:58:50.467615   977 solver.cpp:316] Iteration 24800, Testing net (#0)
I0416 16:59:02.000155   977 solver.cpp:373]     Test net output #0: accuracy = 0.990684
I0416 16:59:02.000176   977 solver.cpp:373]     Test net output #1: loss = 0.0461487 (* 1 = 0.0461487 loss)
I0416 16:59:02.670203   977 solver.cpp:221] Iteration 24800, loss = 0.0863818
I0416 16:59:02.670231   977 solver.cpp:236]     Train net output #0: loss = 0.0748334 (* 1 = 0.0748334 loss)
I0416 16:59:02.670235   977 solver.cpp:542] Iteration 24800, lr = 0.01
I0416 16:59:16.246157   977 solver.cpp:221] Iteration 24820, loss = 0.0841007
I0416 16:59:16.246186   977 solver.cpp:236]     Train net output #0: loss = 0.0546651 (* 1 = 0.0546651 loss)
I0416 16:59:16.246189   977 solver.cpp:542] Iteration 24820, lr = 0.01
I0416 16:59:29.793210   977 solver.cpp:221] Iteration 24840, loss = 0.0861324
I0416 16:59:29.793237   977 solver.cpp:236]     Train net output #0: loss = 0.0812139 (* 1 = 0.0812139 loss)
I0416 16:59:29.793243   977 solver.cpp:542] Iteration 24840, lr = 0.01
I0416 16:59:43.342203   977 solver.cpp:221] Iteration 24860, loss = 0.0868906
I0416 16:59:43.342231   977 solver.cpp:236]     Train net output #0: loss = 0.0423044 (* 1 = 0.0423044 loss)
I0416 16:59:43.342236   977 solver.cpp:542] Iteration 24860, lr = 0.01
I0416 16:59:56.890136   977 solver.cpp:221] Iteration 24880, loss = 0.0876361
I0416 16:59:56.890163   977 solver.cpp:236]     Train net output #0: loss = 0.090931 (* 1 = 0.090931 loss)
I0416 16:59:56.890168   977 solver.cpp:542] Iteration 24880, lr = 0.01
I0416 17:00:10.458411   977 solver.cpp:221] Iteration 24900, loss = 0.0918566
I0416 17:00:10.458438   977 solver.cpp:236]     Train net output #0: loss = 0.0821979 (* 1 = 0.0821979 loss)
I0416 17:00:10.458443   977 solver.cpp:542] Iteration 24900, lr = 0.01
I0416 17:00:23.981784   977 solver.cpp:221] Iteration 24920, loss = 0.0820791
I0416 17:00:23.981812   977 solver.cpp:236]     Train net output #0: loss = 0.0364836 (* 1 = 0.0364836 loss)
I0416 17:00:23.981817   977 solver.cpp:542] Iteration 24920, lr = 0.01
I0416 17:00:37.507760   977 solver.cpp:221] Iteration 24940, loss = 0.0802077
I0416 17:00:37.507787   977 solver.cpp:236]     Train net output #0: loss = 0.120514 (* 1 = 0.120514 loss)
I0416 17:00:37.507791   977 solver.cpp:542] Iteration 24940, lr = 0.01
I0416 17:00:51.037225   977 solver.cpp:221] Iteration 24960, loss = 0.0836489
I0416 17:00:51.037252   977 solver.cpp:236]     Train net output #0: loss = 0.0714491 (* 1 = 0.0714491 loss)
I0416 17:00:51.037257   977 solver.cpp:542] Iteration 24960, lr = 0.01
I0416 17:01:04.568358   977 solver.cpp:221] Iteration 24980, loss = 0.0911447
I0416 17:01:04.568387   977 solver.cpp:236]     Train net output #0: loss = 0.102018 (* 1 = 0.102018 loss)
I0416 17:01:04.568390   977 solver.cpp:542] Iteration 24980, lr = 0.01
I0416 17:01:17.437502   977 solver.cpp:316] Iteration 25000, Testing net (#0)
I0416 17:01:28.971137   977 solver.cpp:373]     Test net output #0: accuracy = 0.990874
I0416 17:01:28.971158   977 solver.cpp:373]     Test net output #1: loss = 0.0460118 (* 1 = 0.0460118 loss)
I0416 17:01:29.641295   977 solver.cpp:221] Iteration 25000, loss = 0.0914555
I0416 17:01:29.641324   977 solver.cpp:236]     Train net output #0: loss = 0.0341286 (* 1 = 0.0341286 loss)
I0416 17:01:29.641330   977 solver.cpp:542] Iteration 25000, lr = 0.01
I0416 17:01:43.165503   977 solver.cpp:221] Iteration 25020, loss = 0.0776631
I0416 17:01:43.165529   977 solver.cpp:236]     Train net output #0: loss = 0.0472581 (* 1 = 0.0472581 loss)
I0416 17:01:43.165534   977 solver.cpp:542] Iteration 25020, lr = 0.01
I0416 17:01:56.697305   977 solver.cpp:221] Iteration 25040, loss = 0.0841812
I0416 17:01:56.697332   977 solver.cpp:236]     Train net output #0: loss = 0.0564799 (* 1 = 0.0564799 loss)
I0416 17:01:56.697337   977 solver.cpp:542] Iteration 25040, lr = 0.01
I0416 17:02:10.236506   977 solver.cpp:221] Iteration 25060, loss = 0.0833438
I0416 17:02:10.236536   977 solver.cpp:236]     Train net output #0: loss = 0.0632238 (* 1 = 0.0632238 loss)
I0416 17:02:10.236542   977 solver.cpp:542] Iteration 25060, lr = 0.01
I0416 17:02:23.796010   977 solver.cpp:221] Iteration 25080, loss = 0.0894177
I0416 17:02:23.796037   977 solver.cpp:236]     Train net output #0: loss = 0.115481 (* 1 = 0.115481 loss)
I0416 17:02:23.796042   977 solver.cpp:542] Iteration 25080, lr = 0.01
I0416 17:02:37.354814   977 solver.cpp:221] Iteration 25100, loss = 0.0944858
I0416 17:02:37.354840   977 solver.cpp:236]     Train net output #0: loss = 0.08062 (* 1 = 0.08062 loss)
I0416 17:02:37.354846   977 solver.cpp:542] Iteration 25100, lr = 0.01
I0416 17:02:50.890939   977 solver.cpp:221] Iteration 25120, loss = 0.0860301
I0416 17:02:50.890966   977 solver.cpp:236]     Train net output #0: loss = 0.121599 (* 1 = 0.121599 loss)
I0416 17:02:50.890971   977 solver.cpp:542] Iteration 25120, lr = 0.01
I0416 17:03:04.443980   977 solver.cpp:221] Iteration 25140, loss = 0.0910068
I0416 17:03:04.444007   977 solver.cpp:236]     Train net output #0: loss = 0.0434694 (* 1 = 0.0434694 loss)
I0416 17:03:04.444012   977 solver.cpp:542] Iteration 25140, lr = 0.01
I0416 17:03:17.986731   977 solver.cpp:221] Iteration 25160, loss = 0.0882637
I0416 17:03:17.986757   977 solver.cpp:236]     Train net output #0: loss = 0.0687377 (* 1 = 0.0687377 loss)
I0416 17:03:17.986763   977 solver.cpp:542] Iteration 25160, lr = 0.01
I0416 17:03:31.534472   977 solver.cpp:221] Iteration 25180, loss = 0.0894222
I0416 17:03:31.534500   977 solver.cpp:236]     Train net output #0: loss = 0.0843359 (* 1 = 0.0843359 loss)
I0416 17:03:31.534505   977 solver.cpp:542] Iteration 25180, lr = 0.01
I0416 17:03:44.422385   977 solver.cpp:316] Iteration 25200, Testing net (#0)
I0416 17:03:55.955071   977 solver.cpp:373]     Test net output #0: accuracy = 0.990494
I0416 17:03:55.955093   977 solver.cpp:373]     Test net output #1: loss = 0.0450764 (* 1 = 0.0450764 loss)
I0416 17:03:56.623440   977 solver.cpp:221] Iteration 25200, loss = 0.0806157
I0416 17:03:56.623467   977 solver.cpp:236]     Train net output #0: loss = 0.079876 (* 1 = 0.079876 loss)
I0416 17:03:56.623471   977 solver.cpp:542] Iteration 25200, lr = 0.01
I0416 17:04:10.175143   977 solver.cpp:221] Iteration 25220, loss = 0.0829807
I0416 17:04:10.175169   977 solver.cpp:236]     Train net output #0: loss = 0.0863492 (* 1 = 0.0863492 loss)
I0416 17:04:10.175174   977 solver.cpp:542] Iteration 25220, lr = 0.01
I0416 17:04:23.725258   977 solver.cpp:221] Iteration 25240, loss = 0.0791904
I0416 17:04:23.725283   977 solver.cpp:236]     Train net output #0: loss = 0.0398915 (* 1 = 0.0398915 loss)
I0416 17:04:23.725288   977 solver.cpp:542] Iteration 25240, lr = 0.01
I0416 17:04:37.262897   977 solver.cpp:221] Iteration 25260, loss = 0.08223
I0416 17:04:37.262923   977 solver.cpp:236]     Train net output #0: loss = 0.122169 (* 1 = 0.122169 loss)
I0416 17:04:37.262928   977 solver.cpp:542] Iteration 25260, lr = 0.01
I0416 17:04:50.824596   977 solver.cpp:221] Iteration 25280, loss = 0.0843047
I0416 17:04:50.824623   977 solver.cpp:236]     Train net output #0: loss = 0.0394797 (* 1 = 0.0394797 loss)
I0416 17:04:50.824630   977 solver.cpp:542] Iteration 25280, lr = 0.01
I0416 17:05:04.359797   977 solver.cpp:221] Iteration 25300, loss = 0.0884536
I0416 17:05:04.359825   977 solver.cpp:236]     Train net output #0: loss = 0.0788504 (* 1 = 0.0788504 loss)
I0416 17:05:04.359830   977 solver.cpp:542] Iteration 25300, lr = 0.01
I0416 17:05:17.882879   977 solver.cpp:221] Iteration 25320, loss = 0.0907901
I0416 17:05:17.882906   977 solver.cpp:236]     Train net output #0: loss = 0.0895656 (* 1 = 0.0895656 loss)
I0416 17:05:17.882911   977 solver.cpp:542] Iteration 25320, lr = 0.01
I0416 17:05:31.426604   977 solver.cpp:221] Iteration 25340, loss = 0.0905351
I0416 17:05:31.426631   977 solver.cpp:236]     Train net output #0: loss = 0.148064 (* 1 = 0.148064 loss)
I0416 17:05:31.426636   977 solver.cpp:542] Iteration 25340, lr = 0.01
I0416 17:05:44.987399   977 solver.cpp:221] Iteration 25360, loss = 0.0842964
I0416 17:05:44.987426   977 solver.cpp:236]     Train net output #0: loss = 0.0811068 (* 1 = 0.0811068 loss)
I0416 17:05:44.987431   977 solver.cpp:542] Iteration 25360, lr = 0.01
I0416 17:05:58.539003   977 solver.cpp:221] Iteration 25380, loss = 0.0784267
I0416 17:05:58.539031   977 solver.cpp:236]     Train net output #0: loss = 0.0518436 (* 1 = 0.0518436 loss)
I0416 17:05:58.539036   977 solver.cpp:542] Iteration 25380, lr = 0.01
I0416 17:06:11.456578   977 solver.cpp:316] Iteration 25400, Testing net (#0)
I0416 17:06:23.001514   977 solver.cpp:373]     Test net output #0: accuracy = 0.990304
I0416 17:06:23.001535   977 solver.cpp:373]     Test net output #1: loss = 0.0445081 (* 1 = 0.0445081 loss)
I0416 17:06:23.672335   977 solver.cpp:221] Iteration 25400, loss = 0.0852245
I0416 17:06:23.672363   977 solver.cpp:236]     Train net output #0: loss = 0.0787555 (* 1 = 0.0787555 loss)
I0416 17:06:23.672368   977 solver.cpp:542] Iteration 25400, lr = 0.01
I0416 17:06:37.240878   977 solver.cpp:221] Iteration 25420, loss = 0.0760045
I0416 17:06:37.240906   977 solver.cpp:236]     Train net output #0: loss = 0.0706991 (* 1 = 0.0706991 loss)
I0416 17:06:37.240911   977 solver.cpp:542] Iteration 25420, lr = 0.01
I0416 17:06:50.796234   977 solver.cpp:221] Iteration 25440, loss = 0.0803297
I0416 17:06:50.796262   977 solver.cpp:236]     Train net output #0: loss = 0.10947 (* 1 = 0.10947 loss)
I0416 17:06:50.796267   977 solver.cpp:542] Iteration 25440, lr = 0.01
I0416 17:07:04.330966   977 solver.cpp:221] Iteration 25460, loss = 0.0768184
I0416 17:07:04.330993   977 solver.cpp:236]     Train net output #0: loss = 0.0680716 (* 1 = 0.0680716 loss)
I0416 17:07:04.330997   977 solver.cpp:542] Iteration 25460, lr = 0.01
I0416 17:07:17.854251   977 solver.cpp:221] Iteration 25480, loss = 0.076107
I0416 17:07:17.854279   977 solver.cpp:236]     Train net output #0: loss = 0.0689421 (* 1 = 0.0689421 loss)
I0416 17:07:17.854284   977 solver.cpp:542] Iteration 25480, lr = 0.01
I0416 17:07:31.391809   977 solver.cpp:221] Iteration 25500, loss = 0.0905741
I0416 17:07:31.391836   977 solver.cpp:236]     Train net output #0: loss = 0.0535115 (* 1 = 0.0535115 loss)
I0416 17:07:31.391841   977 solver.cpp:542] Iteration 25500, lr = 0.01
I0416 17:07:44.922024   977 solver.cpp:221] Iteration 25520, loss = 0.0793597
I0416 17:07:44.922051   977 solver.cpp:236]     Train net output #0: loss = 0.0867671 (* 1 = 0.0867671 loss)
I0416 17:07:44.922056   977 solver.cpp:542] Iteration 25520, lr = 0.01
I0416 17:07:58.502836   977 solver.cpp:221] Iteration 25540, loss = 0.0864181
I0416 17:07:58.502862   977 solver.cpp:236]     Train net output #0: loss = 0.117562 (* 1 = 0.117562 loss)
I0416 17:07:58.502867   977 solver.cpp:542] Iteration 25540, lr = 0.01
I0416 17:08:12.071965   977 solver.cpp:221] Iteration 25560, loss = 0.0802711
I0416 17:08:12.071992   977 solver.cpp:236]     Train net output #0: loss = 0.0917782 (* 1 = 0.0917782 loss)
I0416 17:08:12.071997   977 solver.cpp:542] Iteration 25560, lr = 0.01
I0416 17:08:25.619319   977 solver.cpp:221] Iteration 25580, loss = 0.0778595
I0416 17:08:25.619348   977 solver.cpp:236]     Train net output #0: loss = 0.0523697 (* 1 = 0.0523697 loss)
I0416 17:08:25.619351   977 solver.cpp:542] Iteration 25580, lr = 0.01
I0416 17:08:38.511438   977 solver.cpp:316] Iteration 25600, Testing net (#0)
I0416 17:08:50.044651   977 solver.cpp:373]     Test net output #0: accuracy = 0.991064
I0416 17:08:50.044672   977 solver.cpp:373]     Test net output #1: loss = 0.044407 (* 1 = 0.044407 loss)
I0416 17:08:50.713332   977 solver.cpp:221] Iteration 25600, loss = 0.0779209
I0416 17:08:50.713361   977 solver.cpp:236]     Train net output #0: loss = 0.108988 (* 1 = 0.108988 loss)
I0416 17:08:50.713364   977 solver.cpp:542] Iteration 25600, lr = 0.01
I0416 17:09:04.250953   977 solver.cpp:221] Iteration 25620, loss = 0.0864303
I0416 17:09:04.250980   977 solver.cpp:236]     Train net output #0: loss = 0.0802195 (* 1 = 0.0802195 loss)
I0416 17:09:04.250985   977 solver.cpp:542] Iteration 25620, lr = 0.01
I0416 17:09:17.809391   977 solver.cpp:221] Iteration 25640, loss = 0.0799964
I0416 17:09:17.809418   977 solver.cpp:236]     Train net output #0: loss = 0.029921 (* 1 = 0.029921 loss)
I0416 17:09:17.809423   977 solver.cpp:542] Iteration 25640, lr = 0.01
I0416 17:09:31.358150   977 solver.cpp:221] Iteration 25660, loss = 0.0742732
I0416 17:09:31.358176   977 solver.cpp:236]     Train net output #0: loss = 0.11066 (* 1 = 0.11066 loss)
I0416 17:09:31.358181   977 solver.cpp:542] Iteration 25660, lr = 0.01
I0416 17:09:44.892441   977 solver.cpp:221] Iteration 25680, loss = 0.074256
I0416 17:09:44.892469   977 solver.cpp:236]     Train net output #0: loss = 0.0740086 (* 1 = 0.0740086 loss)
I0416 17:09:44.892475   977 solver.cpp:542] Iteration 25680, lr = 0.01
I0416 17:09:58.453824   977 solver.cpp:221] Iteration 25700, loss = 0.0844862
I0416 17:09:58.453852   977 solver.cpp:236]     Train net output #0: loss = 0.0598411 (* 1 = 0.0598411 loss)
I0416 17:09:58.453857   977 solver.cpp:542] Iteration 25700, lr = 0.01
I0416 17:10:12.014760   977 solver.cpp:221] Iteration 25720, loss = 0.0795805
I0416 17:10:12.014787   977 solver.cpp:236]     Train net output #0: loss = 0.103535 (* 1 = 0.103535 loss)
I0416 17:10:12.014792   977 solver.cpp:542] Iteration 25720, lr = 0.01
I0416 17:10:25.553084   977 solver.cpp:221] Iteration 25740, loss = 0.0908924
I0416 17:10:25.553112   977 solver.cpp:236]     Train net output #0: loss = 0.201684 (* 1 = 0.201684 loss)
I0416 17:10:25.553117   977 solver.cpp:542] Iteration 25740, lr = 0.01
I0416 17:10:39.135427   977 solver.cpp:221] Iteration 25760, loss = 0.0900277
I0416 17:10:39.135455   977 solver.cpp:236]     Train net output #0: loss = 0.106149 (* 1 = 0.106149 loss)
I0416 17:10:39.135459   977 solver.cpp:542] Iteration 25760, lr = 0.01
I0416 17:10:52.729369   977 solver.cpp:221] Iteration 25780, loss = 0.0842876
I0416 17:10:52.729398   977 solver.cpp:236]     Train net output #0: loss = 0.0403185 (* 1 = 0.0403185 loss)
I0416 17:10:52.729401   977 solver.cpp:542] Iteration 25780, lr = 0.01
I0416 17:11:05.620935   977 solver.cpp:316] Iteration 25800, Testing net (#0)
I0416 17:11:17.154255   977 solver.cpp:373]     Test net output #0: accuracy = 0.990304
I0416 17:11:17.154276   977 solver.cpp:373]     Test net output #1: loss = 0.044698 (* 1 = 0.044698 loss)
I0416 17:11:17.821964   977 solver.cpp:221] Iteration 25800, loss = 0.0818151
I0416 17:11:17.821992   977 solver.cpp:236]     Train net output #0: loss = 0.0589653 (* 1 = 0.0589653 loss)
I0416 17:11:17.821998   977 solver.cpp:542] Iteration 25800, lr = 0.01
I0416 17:11:31.390012   977 solver.cpp:221] Iteration 25820, loss = 0.0726466
I0416 17:11:31.390038   977 solver.cpp:236]     Train net output #0: loss = 0.0814838 (* 1 = 0.0814838 loss)
I0416 17:11:31.390043   977 solver.cpp:542] Iteration 25820, lr = 0.01
I0416 17:11:44.925622   977 solver.cpp:221] Iteration 25840, loss = 0.0798558
I0416 17:11:44.925650   977 solver.cpp:236]     Train net output #0: loss = 0.10013 (* 1 = 0.10013 loss)
I0416 17:11:44.925654   977 solver.cpp:542] Iteration 25840, lr = 0.01
I0416 17:11:58.457715   977 solver.cpp:221] Iteration 25860, loss = 0.0707883
I0416 17:11:58.457742   977 solver.cpp:236]     Train net output #0: loss = 0.0888261 (* 1 = 0.0888261 loss)
I0416 17:11:58.457747   977 solver.cpp:542] Iteration 25860, lr = 0.01
I0416 17:12:11.991467   977 solver.cpp:221] Iteration 25880, loss = 0.0762733
I0416 17:12:11.991495   977 solver.cpp:236]     Train net output #0: loss = 0.0241334 (* 1 = 0.0241334 loss)
I0416 17:12:11.991500   977 solver.cpp:542] Iteration 25880, lr = 0.01
I0416 17:12:25.534025   977 solver.cpp:221] Iteration 25900, loss = 0.0787052
I0416 17:12:25.534054   977 solver.cpp:236]     Train net output #0: loss = 0.100502 (* 1 = 0.100502 loss)
I0416 17:12:25.534059   977 solver.cpp:542] Iteration 25900, lr = 0.01
I0416 17:12:39.074532   977 solver.cpp:221] Iteration 25920, loss = 0.0892008
I0416 17:12:39.074560   977 solver.cpp:236]     Train net output #0: loss = 0.0891491 (* 1 = 0.0891491 loss)
I0416 17:12:39.074564   977 solver.cpp:542] Iteration 25920, lr = 0.01
I0416 17:12:52.603147   977 solver.cpp:221] Iteration 25940, loss = 0.0883482
I0416 17:12:52.603174   977 solver.cpp:236]     Train net output #0: loss = 0.0624519 (* 1 = 0.0624519 loss)
I0416 17:12:52.603179   977 solver.cpp:542] Iteration 25940, lr = 0.01
I0416 17:13:06.144697   977 solver.cpp:221] Iteration 25960, loss = 0.084734
I0416 17:13:06.144726   977 solver.cpp:236]     Train net output #0: loss = 0.128685 (* 1 = 0.128685 loss)
I0416 17:13:06.144729   977 solver.cpp:542] Iteration 25960, lr = 0.01
I0416 17:13:19.693856   977 solver.cpp:221] Iteration 25980, loss = 0.076036
I0416 17:13:19.693883   977 solver.cpp:236]     Train net output #0: loss = 0.090151 (* 1 = 0.090151 loss)
I0416 17:13:19.693887   977 solver.cpp:542] Iteration 25980, lr = 0.01
I0416 17:13:32.585938   977 solver.cpp:316] Iteration 26000, Testing net (#0)
I0416 17:13:44.123119   977 solver.cpp:373]     Test net output #0: accuracy = 0.991064
I0416 17:13:44.123141   977 solver.cpp:373]     Test net output #1: loss = 0.0434257 (* 1 = 0.0434257 loss)
I0416 17:13:44.791671   977 solver.cpp:221] Iteration 26000, loss = 0.0728156
I0416 17:13:44.791698   977 solver.cpp:236]     Train net output #0: loss = 0.0755929 (* 1 = 0.0755929 loss)
I0416 17:13:44.791702   977 solver.cpp:542] Iteration 26000, lr = 0.01
I0416 17:13:58.360834   977 solver.cpp:221] Iteration 26020, loss = 0.07373
I0416 17:13:58.360862   977 solver.cpp:236]     Train net output #0: loss = 0.0557599 (* 1 = 0.0557599 loss)
I0416 17:13:58.360867   977 solver.cpp:542] Iteration 26020, lr = 0.01
I0416 17:14:11.905973   977 solver.cpp:221] Iteration 26040, loss = 0.0832916
I0416 17:14:11.906000   977 solver.cpp:236]     Train net output #0: loss = 0.0649236 (* 1 = 0.0649236 loss)
I0416 17:14:11.906004   977 solver.cpp:542] Iteration 26040, lr = 0.01
I0416 17:14:25.463850   977 solver.cpp:221] Iteration 26060, loss = 0.0800913
I0416 17:14:25.463877   977 solver.cpp:236]     Train net output #0: loss = 0.103212 (* 1 = 0.103212 loss)
I0416 17:14:25.463883   977 solver.cpp:542] Iteration 26060, lr = 0.01
I0416 17:14:39.059253   977 solver.cpp:221] Iteration 26080, loss = 0.0749814
I0416 17:14:39.059281   977 solver.cpp:236]     Train net output #0: loss = 0.0810335 (* 1 = 0.0810335 loss)
I0416 17:14:39.059286   977 solver.cpp:542] Iteration 26080, lr = 0.01
I0416 17:14:52.636606   977 solver.cpp:221] Iteration 26100, loss = 0.0771783
I0416 17:14:52.636633   977 solver.cpp:236]     Train net output #0: loss = 0.063966 (* 1 = 0.063966 loss)
I0416 17:14:52.636638   977 solver.cpp:542] Iteration 26100, lr = 0.01
I0416 17:15:06.212554   977 solver.cpp:221] Iteration 26120, loss = 0.0752481
I0416 17:15:06.212584   977 solver.cpp:236]     Train net output #0: loss = 0.110785 (* 1 = 0.110785 loss)
I0416 17:15:06.212587   977 solver.cpp:542] Iteration 26120, lr = 0.01
I0416 17:15:19.781445   977 solver.cpp:221] Iteration 26140, loss = 0.0792655
I0416 17:15:19.781471   977 solver.cpp:236]     Train net output #0: loss = 0.141357 (* 1 = 0.141357 loss)
I0416 17:15:19.781476   977 solver.cpp:542] Iteration 26140, lr = 0.01
I0416 17:15:33.348253   977 solver.cpp:221] Iteration 26160, loss = 0.0770138
I0416 17:15:33.348281   977 solver.cpp:236]     Train net output #0: loss = 0.0766111 (* 1 = 0.0766111 loss)
I0416 17:15:33.348286   977 solver.cpp:542] Iteration 26160, lr = 0.01
I0416 17:15:46.934623   977 solver.cpp:221] Iteration 26180, loss = 0.0819391
I0416 17:15:46.934651   977 solver.cpp:236]     Train net output #0: loss = 0.0777102 (* 1 = 0.0777102 loss)
I0416 17:15:46.934656   977 solver.cpp:542] Iteration 26180, lr = 0.01
I0416 17:15:59.867858   977 solver.cpp:316] Iteration 26200, Testing net (#0)
I0416 17:16:11.414635   977 solver.cpp:373]     Test net output #0: accuracy = 0.991254
I0416 17:16:11.414656   977 solver.cpp:373]     Test net output #1: loss = 0.042994 (* 1 = 0.042994 loss)
I0416 17:16:12.086849   977 solver.cpp:221] Iteration 26200, loss = 0.0697111
I0416 17:16:12.086877   977 solver.cpp:236]     Train net output #0: loss = 0.111163 (* 1 = 0.111163 loss)
I0416 17:16:12.086882   977 solver.cpp:542] Iteration 26200, lr = 0.01
I0416 17:16:25.652609   977 solver.cpp:221] Iteration 26220, loss = 0.0786108
I0416 17:16:25.652638   977 solver.cpp:236]     Train net output #0: loss = 0.0656807 (* 1 = 0.0656807 loss)
I0416 17:16:25.652642   977 solver.cpp:542] Iteration 26220, lr = 0.01
I0416 17:16:39.201822   977 solver.cpp:221] Iteration 26240, loss = 0.0789859
I0416 17:16:39.201850   977 solver.cpp:236]     Train net output #0: loss = 0.063971 (* 1 = 0.063971 loss)
I0416 17:16:39.201856   977 solver.cpp:542] Iteration 26240, lr = 0.01
I0416 17:16:52.742331   977 solver.cpp:221] Iteration 26260, loss = 0.0845026
I0416 17:16:52.742357   977 solver.cpp:236]     Train net output #0: loss = 0.058051 (* 1 = 0.058051 loss)
I0416 17:16:52.742362   977 solver.cpp:542] Iteration 26260, lr = 0.01
I0416 17:17:06.280743   977 solver.cpp:221] Iteration 26280, loss = 0.0729086
I0416 17:17:06.280771   977 solver.cpp:236]     Train net output #0: loss = 0.0755437 (* 1 = 0.0755437 loss)
I0416 17:17:06.280776   977 solver.cpp:542] Iteration 26280, lr = 0.01
I0416 17:17:19.816339   977 solver.cpp:221] Iteration 26300, loss = 0.0779423
I0416 17:17:19.816365   977 solver.cpp:236]     Train net output #0: loss = 0.0601001 (* 1 = 0.0601001 loss)
I0416 17:17:19.816370   977 solver.cpp:542] Iteration 26300, lr = 0.01
I0416 17:17:33.369382   977 solver.cpp:221] Iteration 26320, loss = 0.0799459
I0416 17:17:33.369410   977 solver.cpp:236]     Train net output #0: loss = 0.100663 (* 1 = 0.100663 loss)
I0416 17:17:33.369415   977 solver.cpp:542] Iteration 26320, lr = 0.01
I0416 17:17:46.903712   977 solver.cpp:221] Iteration 26340, loss = 0.0817163
I0416 17:17:46.903738   977 solver.cpp:236]     Train net output #0: loss = 0.0667762 (* 1 = 0.0667762 loss)
I0416 17:17:46.903743   977 solver.cpp:542] Iteration 26340, lr = 0.01
I0416 17:18:00.472373   977 solver.cpp:221] Iteration 26360, loss = 0.0811713
I0416 17:18:00.472400   977 solver.cpp:236]     Train net output #0: loss = 0.0760594 (* 1 = 0.0760594 loss)
I0416 17:18:00.472405   977 solver.cpp:542] Iteration 26360, lr = 0.01
I0416 17:18:14.037696   977 solver.cpp:221] Iteration 26380, loss = 0.0869261
I0416 17:18:14.037724   977 solver.cpp:236]     Train net output #0: loss = 0.0620741 (* 1 = 0.0620741 loss)
I0416 17:18:14.037729   977 solver.cpp:542] Iteration 26380, lr = 0.01
I0416 17:18:26.910205   977 solver.cpp:316] Iteration 26400, Testing net (#0)
I0416 17:18:38.443572   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 17:18:38.443593   977 solver.cpp:373]     Test net output #1: loss = 0.0434719 (* 1 = 0.0434719 loss)
I0416 17:18:39.113436   977 solver.cpp:221] Iteration 26400, loss = 0.0814687
I0416 17:18:39.113464   977 solver.cpp:236]     Train net output #0: loss = 0.0874895 (* 1 = 0.0874895 loss)
I0416 17:18:39.113468   977 solver.cpp:542] Iteration 26400, lr = 0.01
I0416 17:18:52.665825   977 solver.cpp:221] Iteration 26420, loss = 0.0797712
I0416 17:18:52.665853   977 solver.cpp:236]     Train net output #0: loss = 0.133141 (* 1 = 0.133141 loss)
I0416 17:18:52.665856   977 solver.cpp:542] Iteration 26420, lr = 0.01
I0416 17:19:06.203618   977 solver.cpp:221] Iteration 26440, loss = 0.0744453
I0416 17:19:06.203644   977 solver.cpp:236]     Train net output #0: loss = 0.074316 (* 1 = 0.074316 loss)
I0416 17:19:06.203649   977 solver.cpp:542] Iteration 26440, lr = 0.01
I0416 17:19:19.751464   977 solver.cpp:221] Iteration 26460, loss = 0.0774316
I0416 17:19:19.751492   977 solver.cpp:236]     Train net output #0: loss = 0.108709 (* 1 = 0.108709 loss)
I0416 17:19:19.751497   977 solver.cpp:542] Iteration 26460, lr = 0.01
I0416 17:19:33.329763   977 solver.cpp:221] Iteration 26480, loss = 0.0699717
I0416 17:19:33.329792   977 solver.cpp:236]     Train net output #0: loss = 0.0867427 (* 1 = 0.0867427 loss)
I0416 17:19:33.329797   977 solver.cpp:542] Iteration 26480, lr = 0.01
I0416 17:19:46.895501   977 solver.cpp:221] Iteration 26500, loss = 0.0776465
I0416 17:19:46.895529   977 solver.cpp:236]     Train net output #0: loss = 0.0588922 (* 1 = 0.0588922 loss)
I0416 17:19:46.895534   977 solver.cpp:542] Iteration 26500, lr = 0.01
I0416 17:20:00.468168   977 solver.cpp:221] Iteration 26520, loss = 0.0700862
I0416 17:20:00.468196   977 solver.cpp:236]     Train net output #0: loss = 0.0752755 (* 1 = 0.0752755 loss)
I0416 17:20:00.468201   977 solver.cpp:542] Iteration 26520, lr = 0.01
I0416 17:20:14.046514   977 solver.cpp:221] Iteration 26540, loss = 0.0715808
I0416 17:20:14.046541   977 solver.cpp:236]     Train net output #0: loss = 0.0675879 (* 1 = 0.0675879 loss)
I0416 17:20:14.046547   977 solver.cpp:542] Iteration 26540, lr = 0.01
I0416 17:20:27.649294   977 solver.cpp:221] Iteration 26560, loss = 0.0766496
I0416 17:20:27.649322   977 solver.cpp:236]     Train net output #0: loss = 0.0375168 (* 1 = 0.0375168 loss)
I0416 17:20:27.649327   977 solver.cpp:542] Iteration 26560, lr = 0.01
I0416 17:20:41.242285   977 solver.cpp:221] Iteration 26580, loss = 0.0767487
I0416 17:20:41.242312   977 solver.cpp:236]     Train net output #0: loss = 0.0697277 (* 1 = 0.0697277 loss)
I0416 17:20:41.242316   977 solver.cpp:542] Iteration 26580, lr = 0.01
I0416 17:20:54.135846   977 solver.cpp:316] Iteration 26600, Testing net (#0)
I0416 17:21:05.671746   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 17:21:05.671769   977 solver.cpp:373]     Test net output #1: loss = 0.0415242 (* 1 = 0.0415242 loss)
I0416 17:21:06.341866   977 solver.cpp:221] Iteration 26600, loss = 0.0806312
I0416 17:21:06.341894   977 solver.cpp:236]     Train net output #0: loss = 0.0361214 (* 1 = 0.0361214 loss)
I0416 17:21:06.341898   977 solver.cpp:542] Iteration 26600, lr = 0.01
I0416 17:21:19.880960   977 solver.cpp:221] Iteration 26620, loss = 0.0736541
I0416 17:21:19.880988   977 solver.cpp:236]     Train net output #0: loss = 0.104529 (* 1 = 0.104529 loss)
I0416 17:21:19.880993   977 solver.cpp:542] Iteration 26620, lr = 0.01
I0416 17:21:33.416517   977 solver.cpp:221] Iteration 26640, loss = 0.0746374
I0416 17:21:33.416544   977 solver.cpp:236]     Train net output #0: loss = 0.107893 (* 1 = 0.107893 loss)
I0416 17:21:33.416548   977 solver.cpp:542] Iteration 26640, lr = 0.01
I0416 17:21:46.977346   977 solver.cpp:221] Iteration 26660, loss = 0.0710663
I0416 17:21:46.977375   977 solver.cpp:236]     Train net output #0: loss = 0.0602072 (* 1 = 0.0602072 loss)
I0416 17:21:46.977378   977 solver.cpp:542] Iteration 26660, lr = 0.01
I0416 17:22:00.513558   977 solver.cpp:221] Iteration 26680, loss = 0.0761746
I0416 17:22:00.513586   977 solver.cpp:236]     Train net output #0: loss = 0.0661786 (* 1 = 0.0661786 loss)
I0416 17:22:00.513589   977 solver.cpp:542] Iteration 26680, lr = 0.01
I0416 17:22:14.061985   977 solver.cpp:221] Iteration 26700, loss = 0.074938
I0416 17:22:14.062012   977 solver.cpp:236]     Train net output #0: loss = 0.0461012 (* 1 = 0.0461012 loss)
I0416 17:22:14.062017   977 solver.cpp:542] Iteration 26700, lr = 0.01
I0416 17:22:27.596535   977 solver.cpp:221] Iteration 26720, loss = 0.0741157
I0416 17:22:27.596561   977 solver.cpp:236]     Train net output #0: loss = 0.0412089 (* 1 = 0.0412089 loss)
I0416 17:22:27.596566   977 solver.cpp:542] Iteration 26720, lr = 0.01
I0416 17:22:41.125540   977 solver.cpp:221] Iteration 26740, loss = 0.0736407
I0416 17:22:41.125567   977 solver.cpp:236]     Train net output #0: loss = 0.0742301 (* 1 = 0.0742301 loss)
I0416 17:22:41.125572   977 solver.cpp:542] Iteration 26740, lr = 0.01
I0416 17:22:54.656821   977 solver.cpp:221] Iteration 26760, loss = 0.0800394
I0416 17:22:54.656847   977 solver.cpp:236]     Train net output #0: loss = 0.086117 (* 1 = 0.086117 loss)
I0416 17:22:54.656853   977 solver.cpp:542] Iteration 26760, lr = 0.01
I0416 17:23:08.219823   977 solver.cpp:221] Iteration 26780, loss = 0.0838109
I0416 17:23:08.219851   977 solver.cpp:236]     Train net output #0: loss = 0.0654902 (* 1 = 0.0654902 loss)
I0416 17:23:08.219856   977 solver.cpp:542] Iteration 26780, lr = 0.01
I0416 17:23:21.129473   977 solver.cpp:316] Iteration 26800, Testing net (#0)
I0416 17:23:32.663406   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 17:23:32.663429   977 solver.cpp:373]     Test net output #1: loss = 0.0426666 (* 1 = 0.0426666 loss)
I0416 17:23:33.332993   977 solver.cpp:221] Iteration 26800, loss = 0.0825183
I0416 17:23:33.333020   977 solver.cpp:236]     Train net output #0: loss = 0.100501 (* 1 = 0.100501 loss)
I0416 17:23:33.333025   977 solver.cpp:542] Iteration 26800, lr = 0.01
I0416 17:23:46.901978   977 solver.cpp:221] Iteration 26820, loss = 0.0766352
I0416 17:23:46.902005   977 solver.cpp:236]     Train net output #0: loss = 0.0845753 (* 1 = 0.0845753 loss)
I0416 17:23:46.902010   977 solver.cpp:542] Iteration 26820, lr = 0.01
I0416 17:24:00.477352   977 solver.cpp:221] Iteration 26840, loss = 0.0720616
I0416 17:24:00.477380   977 solver.cpp:236]     Train net output #0: loss = 0.0317995 (* 1 = 0.0317995 loss)
I0416 17:24:00.477385   977 solver.cpp:542] Iteration 26840, lr = 0.01
I0416 17:24:14.050366   977 solver.cpp:221] Iteration 26860, loss = 0.0733507
I0416 17:24:14.050393   977 solver.cpp:236]     Train net output #0: loss = 0.06522 (* 1 = 0.06522 loss)
I0416 17:24:14.050398   977 solver.cpp:542] Iteration 26860, lr = 0.01
I0416 17:24:27.617979   977 solver.cpp:221] Iteration 26880, loss = 0.0751862
I0416 17:24:27.618006   977 solver.cpp:236]     Train net output #0: loss = 0.0843326 (* 1 = 0.0843326 loss)
I0416 17:24:27.618011   977 solver.cpp:542] Iteration 26880, lr = 0.01
I0416 17:24:41.165848   977 solver.cpp:221] Iteration 26900, loss = 0.0778033
I0416 17:24:41.165874   977 solver.cpp:236]     Train net output #0: loss = 0.061421 (* 1 = 0.061421 loss)
I0416 17:24:41.165879   977 solver.cpp:542] Iteration 26900, lr = 0.01
I0416 17:24:54.710479   977 solver.cpp:221] Iteration 26920, loss = 0.0738123
I0416 17:24:54.710507   977 solver.cpp:236]     Train net output #0: loss = 0.102139 (* 1 = 0.102139 loss)
I0416 17:24:54.710512   977 solver.cpp:542] Iteration 26920, lr = 0.01
I0416 17:25:08.274247   977 solver.cpp:221] Iteration 26940, loss = 0.0709503
I0416 17:25:08.274273   977 solver.cpp:236]     Train net output #0: loss = 0.0444378 (* 1 = 0.0444378 loss)
I0416 17:25:08.274277   977 solver.cpp:542] Iteration 26940, lr = 0.01
I0416 17:25:21.843608   977 solver.cpp:221] Iteration 26960, loss = 0.0747083
I0416 17:25:21.843636   977 solver.cpp:236]     Train net output #0: loss = 0.0902594 (* 1 = 0.0902594 loss)
I0416 17:25:21.843641   977 solver.cpp:542] Iteration 26960, lr = 0.01
I0416 17:25:35.417543   977 solver.cpp:221] Iteration 26980, loss = 0.0713515
I0416 17:25:35.417572   977 solver.cpp:236]     Train net output #0: loss = 0.0739023 (* 1 = 0.0739023 loss)
I0416 17:25:35.417575   977 solver.cpp:542] Iteration 26980, lr = 0.01
I0416 17:25:48.332397   977 solver.cpp:316] Iteration 27000, Testing net (#0)
I0416 17:25:59.881912   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 17:25:59.881934   977 solver.cpp:373]     Test net output #1: loss = 0.0422041 (* 1 = 0.0422041 loss)
I0416 17:26:00.551964   977 solver.cpp:221] Iteration 27000, loss = 0.0843235
I0416 17:26:00.551991   977 solver.cpp:236]     Train net output #0: loss = 0.060629 (* 1 = 0.060629 loss)
I0416 17:26:00.551996   977 solver.cpp:542] Iteration 27000, lr = 0.01
I0416 17:26:14.118288   977 solver.cpp:221] Iteration 27020, loss = 0.0789944
I0416 17:26:14.118315   977 solver.cpp:236]     Train net output #0: loss = 0.0706297 (* 1 = 0.0706297 loss)
I0416 17:26:14.118320   977 solver.cpp:542] Iteration 27020, lr = 0.01
I0416 17:26:27.686255   977 solver.cpp:221] Iteration 27040, loss = 0.0771592
I0416 17:26:27.686283   977 solver.cpp:236]     Train net output #0: loss = 0.120574 (* 1 = 0.120574 loss)
I0416 17:26:27.686287   977 solver.cpp:542] Iteration 27040, lr = 0.01
I0416 17:26:41.240777   977 solver.cpp:221] Iteration 27060, loss = 0.0738437
I0416 17:26:41.240805   977 solver.cpp:236]     Train net output #0: loss = 0.105146 (* 1 = 0.105146 loss)
I0416 17:26:41.240810   977 solver.cpp:542] Iteration 27060, lr = 0.01
I0416 17:26:54.779598   977 solver.cpp:221] Iteration 27080, loss = 0.0777282
I0416 17:26:54.779624   977 solver.cpp:236]     Train net output #0: loss = 0.104478 (* 1 = 0.104478 loss)
I0416 17:26:54.779629   977 solver.cpp:542] Iteration 27080, lr = 0.01
I0416 17:27:08.338348   977 solver.cpp:221] Iteration 27100, loss = 0.0715104
I0416 17:27:08.338377   977 solver.cpp:236]     Train net output #0: loss = 0.0729593 (* 1 = 0.0729593 loss)
I0416 17:27:08.338382   977 solver.cpp:542] Iteration 27100, lr = 0.01
I0416 17:27:21.936897   977 solver.cpp:221] Iteration 27120, loss = 0.0801734
I0416 17:27:21.936924   977 solver.cpp:236]     Train net output #0: loss = 0.0458452 (* 1 = 0.0458452 loss)
I0416 17:27:21.936929   977 solver.cpp:542] Iteration 27120, lr = 0.01
I0416 17:27:35.494998   977 solver.cpp:221] Iteration 27140, loss = 0.0728207
I0416 17:27:35.495026   977 solver.cpp:236]     Train net output #0: loss = 0.0550243 (* 1 = 0.0550243 loss)
I0416 17:27:35.495031   977 solver.cpp:542] Iteration 27140, lr = 0.01
I0416 17:27:49.021080   977 solver.cpp:221] Iteration 27160, loss = 0.0679469
I0416 17:27:49.021107   977 solver.cpp:236]     Train net output #0: loss = 0.0675694 (* 1 = 0.0675694 loss)
I0416 17:27:49.021112   977 solver.cpp:542] Iteration 27160, lr = 0.01
I0416 17:28:02.561774   977 solver.cpp:221] Iteration 27180, loss = 0.0729129
I0416 17:28:02.561802   977 solver.cpp:236]     Train net output #0: loss = 0.0510116 (* 1 = 0.0510116 loss)
I0416 17:28:02.561806   977 solver.cpp:542] Iteration 27180, lr = 0.01
I0416 17:28:15.464226   977 solver.cpp:316] Iteration 27200, Testing net (#0)
I0416 17:28:27.011898   977 solver.cpp:373]     Test net output #0: accuracy = 0.991255
I0416 17:28:27.011920   977 solver.cpp:373]     Test net output #1: loss = 0.0416212 (* 1 = 0.0416212 loss)
I0416 17:28:27.682703   977 solver.cpp:221] Iteration 27200, loss = 0.0821957
I0416 17:28:27.682731   977 solver.cpp:236]     Train net output #0: loss = 0.0351495 (* 1 = 0.0351495 loss)
I0416 17:28:27.682736   977 solver.cpp:542] Iteration 27200, lr = 0.01
I0416 17:28:41.232982   977 solver.cpp:221] Iteration 27220, loss = 0.0812188
I0416 17:28:41.233011   977 solver.cpp:236]     Train net output #0: loss = 0.0770036 (* 1 = 0.0770036 loss)
I0416 17:28:41.233014   977 solver.cpp:542] Iteration 27220, lr = 0.01
I0416 17:28:54.825469   977 solver.cpp:221] Iteration 27240, loss = 0.0708227
I0416 17:28:54.825496   977 solver.cpp:236]     Train net output #0: loss = 0.0307438 (* 1 = 0.0307438 loss)
I0416 17:28:54.825501   977 solver.cpp:542] Iteration 27240, lr = 0.01
I0416 17:29:08.426057   977 solver.cpp:221] Iteration 27260, loss = 0.0706173
I0416 17:29:08.426084   977 solver.cpp:236]     Train net output #0: loss = 0.0681423 (* 1 = 0.0681423 loss)
I0416 17:29:08.426090   977 solver.cpp:542] Iteration 27260, lr = 0.01
I0416 17:29:21.989965   977 solver.cpp:221] Iteration 27280, loss = 0.073321
I0416 17:29:21.989994   977 solver.cpp:236]     Train net output #0: loss = 0.100229 (* 1 = 0.100229 loss)
I0416 17:29:21.989998   977 solver.cpp:542] Iteration 27280, lr = 0.01
I0416 17:29:35.555564   977 solver.cpp:221] Iteration 27300, loss = 0.0748877
I0416 17:29:35.555590   977 solver.cpp:236]     Train net output #0: loss = 0.0587014 (* 1 = 0.0587014 loss)
I0416 17:29:35.555595   977 solver.cpp:542] Iteration 27300, lr = 0.01
I0416 17:29:49.095309   977 solver.cpp:221] Iteration 27320, loss = 0.0718683
I0416 17:29:49.095335   977 solver.cpp:236]     Train net output #0: loss = 0.0734734 (* 1 = 0.0734734 loss)
I0416 17:29:49.095340   977 solver.cpp:542] Iteration 27320, lr = 0.01
I0416 17:30:02.644475   977 solver.cpp:221] Iteration 27340, loss = 0.0697521
I0416 17:30:02.644502   977 solver.cpp:236]     Train net output #0: loss = 0.0660354 (* 1 = 0.0660354 loss)
I0416 17:30:02.644506   977 solver.cpp:542] Iteration 27340, lr = 0.01
I0416 17:30:16.196722   977 solver.cpp:221] Iteration 27360, loss = 0.0674476
I0416 17:30:16.196749   977 solver.cpp:236]     Train net output #0: loss = 0.0424131 (* 1 = 0.0424131 loss)
I0416 17:30:16.196754   977 solver.cpp:542] Iteration 27360, lr = 0.01
I0416 17:30:29.739609   977 solver.cpp:221] Iteration 27380, loss = 0.0752077
I0416 17:30:29.739636   977 solver.cpp:236]     Train net output #0: loss = 0.0427972 (* 1 = 0.0427972 loss)
I0416 17:30:29.739641   977 solver.cpp:542] Iteration 27380, lr = 0.01
I0416 17:30:42.629295   977 solver.cpp:316] Iteration 27400, Testing net (#0)
I0416 17:30:54.166733   977 solver.cpp:373]     Test net output #0: accuracy = 0.991064
I0416 17:30:54.166754   977 solver.cpp:373]     Test net output #1: loss = 0.0412803 (* 1 = 0.0412803 loss)
I0416 17:30:54.835242   977 solver.cpp:221] Iteration 27400, loss = 0.0670536
I0416 17:30:54.835269   977 solver.cpp:236]     Train net output #0: loss = 0.0613259 (* 1 = 0.0613259 loss)
I0416 17:30:54.835275   977 solver.cpp:542] Iteration 27400, lr = 0.01
I0416 17:31:08.371345   977 solver.cpp:221] Iteration 27420, loss = 0.0713585
I0416 17:31:08.371372   977 solver.cpp:236]     Train net output #0: loss = 0.0608441 (* 1 = 0.0608441 loss)
I0416 17:31:08.371377   977 solver.cpp:542] Iteration 27420, lr = 0.01
I0416 17:31:21.922472   977 solver.cpp:221] Iteration 27440, loss = 0.0786841
I0416 17:31:21.922499   977 solver.cpp:236]     Train net output #0: loss = 0.053895 (* 1 = 0.053895 loss)
I0416 17:31:21.922503   977 solver.cpp:542] Iteration 27440, lr = 0.01
I0416 17:31:35.470759   977 solver.cpp:221] Iteration 27460, loss = 0.0699403
I0416 17:31:35.470787   977 solver.cpp:236]     Train net output #0: loss = 0.0272382 (* 1 = 0.0272382 loss)
I0416 17:31:35.470791   977 solver.cpp:542] Iteration 27460, lr = 0.01
I0416 17:31:49.015746   977 solver.cpp:221] Iteration 27480, loss = 0.0781845
I0416 17:31:49.015774   977 solver.cpp:236]     Train net output #0: loss = 0.147779 (* 1 = 0.147779 loss)
I0416 17:31:49.015779   977 solver.cpp:542] Iteration 27480, lr = 0.01
I0416 17:32:02.544117   977 solver.cpp:221] Iteration 27500, loss = 0.0693872
I0416 17:32:02.544145   977 solver.cpp:236]     Train net output #0: loss = 0.0561349 (* 1 = 0.0561349 loss)
I0416 17:32:02.544150   977 solver.cpp:542] Iteration 27500, lr = 0.01
I0416 17:32:16.079159   977 solver.cpp:221] Iteration 27520, loss = 0.0701902
I0416 17:32:16.079187   977 solver.cpp:236]     Train net output #0: loss = 0.0525418 (* 1 = 0.0525418 loss)
I0416 17:32:16.079193   977 solver.cpp:542] Iteration 27520, lr = 0.01
I0416 17:32:29.638559   977 solver.cpp:221] Iteration 27540, loss = 0.0641786
I0416 17:32:29.638586   977 solver.cpp:236]     Train net output #0: loss = 0.0638946 (* 1 = 0.0638946 loss)
I0416 17:32:29.638592   977 solver.cpp:542] Iteration 27540, lr = 0.01
I0416 17:32:43.179605   977 solver.cpp:221] Iteration 27560, loss = 0.0708882
I0416 17:32:43.179632   977 solver.cpp:236]     Train net output #0: loss = 0.0710281 (* 1 = 0.0710281 loss)
I0416 17:32:43.179637   977 solver.cpp:542] Iteration 27560, lr = 0.01
I0416 17:32:56.729048   977 solver.cpp:221] Iteration 27580, loss = 0.0649474
I0416 17:32:56.729076   977 solver.cpp:236]     Train net output #0: loss = 0.121179 (* 1 = 0.121179 loss)
I0416 17:32:56.729080   977 solver.cpp:542] Iteration 27580, lr = 0.01
I0416 17:33:09.656388   977 solver.cpp:316] Iteration 27600, Testing net (#0)
I0416 17:33:21.200124   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 17:33:21.200146   977 solver.cpp:373]     Test net output #1: loss = 0.0400709 (* 1 = 0.0400709 loss)
I0416 17:33:21.869702   977 solver.cpp:221] Iteration 27600, loss = 0.0683724
I0416 17:33:21.869729   977 solver.cpp:236]     Train net output #0: loss = 0.0403534 (* 1 = 0.0403534 loss)
I0416 17:33:21.869735   977 solver.cpp:542] Iteration 27600, lr = 0.01
I0416 17:33:35.429381   977 solver.cpp:221] Iteration 27620, loss = 0.0776429
I0416 17:33:35.429409   977 solver.cpp:236]     Train net output #0: loss = 0.0515797 (* 1 = 0.0515797 loss)
I0416 17:33:35.429414   977 solver.cpp:542] Iteration 27620, lr = 0.01
I0416 17:33:48.987304   977 solver.cpp:221] Iteration 27640, loss = 0.0689229
I0416 17:33:48.987331   977 solver.cpp:236]     Train net output #0: loss = 0.0460916 (* 1 = 0.0460916 loss)
I0416 17:33:48.987336   977 solver.cpp:542] Iteration 27640, lr = 0.01
I0416 17:34:02.513722   977 solver.cpp:221] Iteration 27660, loss = 0.0747865
I0416 17:34:02.513751   977 solver.cpp:236]     Train net output #0: loss = 0.11386 (* 1 = 0.11386 loss)
I0416 17:34:02.513756   977 solver.cpp:542] Iteration 27660, lr = 0.01
I0416 17:34:16.067958   977 solver.cpp:221] Iteration 27680, loss = 0.0673205
I0416 17:34:16.067986   977 solver.cpp:236]     Train net output #0: loss = 0.0379833 (* 1 = 0.0379833 loss)
I0416 17:34:16.067991   977 solver.cpp:542] Iteration 27680, lr = 0.01
I0416 17:34:29.609911   977 solver.cpp:221] Iteration 27700, loss = 0.0823309
I0416 17:34:29.609940   977 solver.cpp:236]     Train net output #0: loss = 0.0698611 (* 1 = 0.0698611 loss)
I0416 17:34:29.609943   977 solver.cpp:542] Iteration 27700, lr = 0.01
I0416 17:34:43.161002   977 solver.cpp:221] Iteration 27720, loss = 0.0699525
I0416 17:34:43.161029   977 solver.cpp:236]     Train net output #0: loss = 0.07508 (* 1 = 0.07508 loss)
I0416 17:34:43.161033   977 solver.cpp:542] Iteration 27720, lr = 0.01
I0416 17:34:56.739135   977 solver.cpp:221] Iteration 27740, loss = 0.0673702
I0416 17:34:56.739162   977 solver.cpp:236]     Train net output #0: loss = 0.0772014 (* 1 = 0.0772014 loss)
I0416 17:34:56.739168   977 solver.cpp:542] Iteration 27740, lr = 0.01
I0416 17:35:10.294504   977 solver.cpp:221] Iteration 27760, loss = 0.079296
I0416 17:35:10.294531   977 solver.cpp:236]     Train net output #0: loss = 0.11501 (* 1 = 0.11501 loss)
I0416 17:35:10.294536   977 solver.cpp:542] Iteration 27760, lr = 0.01
I0416 17:35:23.824213   977 solver.cpp:221] Iteration 27780, loss = 0.0656136
I0416 17:35:23.824240   977 solver.cpp:236]     Train net output #0: loss = 0.0652949 (* 1 = 0.0652949 loss)
I0416 17:35:23.824245   977 solver.cpp:542] Iteration 27780, lr = 0.01
I0416 17:35:36.706157   977 solver.cpp:316] Iteration 27800, Testing net (#0)
I0416 17:35:48.241711   977 solver.cpp:373]     Test net output #0: accuracy = 0.990874
I0416 17:35:48.241732   977 solver.cpp:373]     Test net output #1: loss = 0.0420406 (* 1 = 0.0420406 loss)
I0416 17:35:48.912515   977 solver.cpp:221] Iteration 27800, loss = 0.0697913
I0416 17:35:48.912544   977 solver.cpp:236]     Train net output #0: loss = 0.0665929 (* 1 = 0.0665929 loss)
I0416 17:35:48.912550   977 solver.cpp:542] Iteration 27800, lr = 0.01
I0416 17:36:02.508846   977 solver.cpp:221] Iteration 27820, loss = 0.0723702
I0416 17:36:02.508873   977 solver.cpp:236]     Train net output #0: loss = 0.0651814 (* 1 = 0.0651814 loss)
I0416 17:36:02.508878   977 solver.cpp:542] Iteration 27820, lr = 0.01
I0416 17:36:16.069121   977 solver.cpp:221] Iteration 27840, loss = 0.0730677
I0416 17:36:16.069149   977 solver.cpp:236]     Train net output #0: loss = 0.0805297 (* 1 = 0.0805297 loss)
I0416 17:36:16.069154   977 solver.cpp:542] Iteration 27840, lr = 0.01
I0416 17:36:29.615901   977 solver.cpp:221] Iteration 27860, loss = 0.0746876
I0416 17:36:29.615929   977 solver.cpp:236]     Train net output #0: loss = 0.0576964 (* 1 = 0.0576964 loss)
I0416 17:36:29.615934   977 solver.cpp:542] Iteration 27860, lr = 0.01
I0416 17:36:43.183835   977 solver.cpp:221] Iteration 27880, loss = 0.0698847
I0416 17:36:43.183862   977 solver.cpp:236]     Train net output #0: loss = 0.0573817 (* 1 = 0.0573817 loss)
I0416 17:36:43.183866   977 solver.cpp:542] Iteration 27880, lr = 0.01
I0416 17:36:56.739594   977 solver.cpp:221] Iteration 27900, loss = 0.0708563
I0416 17:36:56.739622   977 solver.cpp:236]     Train net output #0: loss = 0.0938843 (* 1 = 0.0938843 loss)
I0416 17:36:56.739627   977 solver.cpp:542] Iteration 27900, lr = 0.01
I0416 17:37:10.289415   977 solver.cpp:221] Iteration 27920, loss = 0.0670937
I0416 17:37:10.289443   977 solver.cpp:236]     Train net output #0: loss = 0.0420882 (* 1 = 0.0420882 loss)
I0416 17:37:10.289448   977 solver.cpp:542] Iteration 27920, lr = 0.01
I0416 17:37:23.841701   977 solver.cpp:221] Iteration 27940, loss = 0.0684839
I0416 17:37:23.841727   977 solver.cpp:236]     Train net output #0: loss = 0.0599842 (* 1 = 0.0599842 loss)
I0416 17:37:23.841732   977 solver.cpp:542] Iteration 27940, lr = 0.01
I0416 17:37:37.385705   977 solver.cpp:221] Iteration 27960, loss = 0.0640135
I0416 17:37:37.385733   977 solver.cpp:236]     Train net output #0: loss = 0.0691378 (* 1 = 0.0691378 loss)
I0416 17:37:37.385737   977 solver.cpp:542] Iteration 27960, lr = 0.01
I0416 17:37:50.923856   977 solver.cpp:221] Iteration 27980, loss = 0.0681692
I0416 17:37:50.923882   977 solver.cpp:236]     Train net output #0: loss = 0.030194 (* 1 = 0.030194 loss)
I0416 17:37:50.923887   977 solver.cpp:542] Iteration 27980, lr = 0.01
I0416 17:38:03.802587   977 solver.cpp:316] Iteration 28000, Testing net (#0)
I0416 17:38:15.337632   977 solver.cpp:373]     Test net output #0: accuracy = 0.990304
I0416 17:38:15.337654   977 solver.cpp:373]     Test net output #1: loss = 0.0414519 (* 1 = 0.0414519 loss)
I0416 17:38:16.006697   977 solver.cpp:221] Iteration 28000, loss = 0.0658218
I0416 17:38:16.006724   977 solver.cpp:236]     Train net output #0: loss = 0.0506247 (* 1 = 0.0506247 loss)
I0416 17:38:16.006729   977 solver.cpp:542] Iteration 28000, lr = 0.01
I0416 17:38:29.562366   977 solver.cpp:221] Iteration 28020, loss = 0.0723967
I0416 17:38:29.562394   977 solver.cpp:236]     Train net output #0: loss = 0.0946751 (* 1 = 0.0946751 loss)
I0416 17:38:29.562399   977 solver.cpp:542] Iteration 28020, lr = 0.01
I0416 17:38:43.109388   977 solver.cpp:221] Iteration 28040, loss = 0.079094
I0416 17:38:43.109414   977 solver.cpp:236]     Train net output #0: loss = 0.0544931 (* 1 = 0.0544931 loss)
I0416 17:38:43.109419   977 solver.cpp:542] Iteration 28040, lr = 0.01
I0416 17:38:56.677008   977 solver.cpp:221] Iteration 28060, loss = 0.0752189
I0416 17:38:56.677036   977 solver.cpp:236]     Train net output #0: loss = 0.0566814 (* 1 = 0.0566814 loss)
I0416 17:38:56.677040   977 solver.cpp:542] Iteration 28060, lr = 0.01
I0416 17:39:10.243537   977 solver.cpp:221] Iteration 28080, loss = 0.0722993
I0416 17:39:10.243566   977 solver.cpp:236]     Train net output #0: loss = 0.0756677 (* 1 = 0.0756677 loss)
I0416 17:39:10.243569   977 solver.cpp:542] Iteration 28080, lr = 0.01
I0416 17:39:23.781819   977 solver.cpp:221] Iteration 28100, loss = 0.0673027
I0416 17:39:23.781848   977 solver.cpp:236]     Train net output #0: loss = 0.0742419 (* 1 = 0.0742419 loss)
I0416 17:39:23.781852   977 solver.cpp:542] Iteration 28100, lr = 0.01
I0416 17:39:37.331203   977 solver.cpp:221] Iteration 28120, loss = 0.0660568
I0416 17:39:37.331230   977 solver.cpp:236]     Train net output #0: loss = 0.109352 (* 1 = 0.109352 loss)
I0416 17:39:37.331236   977 solver.cpp:542] Iteration 28120, lr = 0.01
I0416 17:39:50.920367   977 solver.cpp:221] Iteration 28140, loss = 0.068964
I0416 17:39:50.920395   977 solver.cpp:236]     Train net output #0: loss = 0.0618295 (* 1 = 0.0618295 loss)
I0416 17:39:50.920400   977 solver.cpp:542] Iteration 28140, lr = 0.01
I0416 17:40:04.493927   977 solver.cpp:221] Iteration 28160, loss = 0.0701706
I0416 17:40:04.493954   977 solver.cpp:236]     Train net output #0: loss = 0.0602271 (* 1 = 0.0602271 loss)
I0416 17:40:04.493959   977 solver.cpp:542] Iteration 28160, lr = 0.01
I0416 17:40:18.073570   977 solver.cpp:221] Iteration 28180, loss = 0.0680487
I0416 17:40:18.073598   977 solver.cpp:236]     Train net output #0: loss = 0.0561771 (* 1 = 0.0561771 loss)
I0416 17:40:18.073603   977 solver.cpp:542] Iteration 28180, lr = 0.01
I0416 17:40:30.954177   977 solver.cpp:316] Iteration 28200, Testing net (#0)
I0416 17:40:42.491976   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 17:40:42.491997   977 solver.cpp:373]     Test net output #1: loss = 0.0421437 (* 1 = 0.0421437 loss)
I0416 17:40:43.161779   977 solver.cpp:221] Iteration 28200, loss = 0.0714418
I0416 17:40:43.161808   977 solver.cpp:236]     Train net output #0: loss = 0.0554402 (* 1 = 0.0554402 loss)
I0416 17:40:43.161811   977 solver.cpp:542] Iteration 28200, lr = 0.01
I0416 17:40:56.715873   977 solver.cpp:221] Iteration 28220, loss = 0.0687294
I0416 17:40:56.715900   977 solver.cpp:236]     Train net output #0: loss = 0.0532188 (* 1 = 0.0532188 loss)
I0416 17:40:56.715905   977 solver.cpp:542] Iteration 28220, lr = 0.01
I0416 17:41:10.277237   977 solver.cpp:221] Iteration 28240, loss = 0.0734955
I0416 17:41:10.277266   977 solver.cpp:236]     Train net output #0: loss = 0.0296103 (* 1 = 0.0296103 loss)
I0416 17:41:10.277271   977 solver.cpp:542] Iteration 28240, lr = 0.01
I0416 17:41:23.822965   977 solver.cpp:221] Iteration 28260, loss = 0.0705171
I0416 17:41:23.822991   977 solver.cpp:236]     Train net output #0: loss = 0.0972557 (* 1 = 0.0972557 loss)
I0416 17:41:23.822996   977 solver.cpp:542] Iteration 28260, lr = 0.01
I0416 17:41:37.384420   977 solver.cpp:221] Iteration 28280, loss = 0.0736634
I0416 17:41:37.384449   977 solver.cpp:236]     Train net output #0: loss = 0.0504686 (* 1 = 0.0504686 loss)
I0416 17:41:37.384452   977 solver.cpp:542] Iteration 28280, lr = 0.01
I0416 17:41:50.958567   977 solver.cpp:221] Iteration 28300, loss = 0.070283
I0416 17:41:50.958593   977 solver.cpp:236]     Train net output #0: loss = 0.067431 (* 1 = 0.067431 loss)
I0416 17:41:50.958598   977 solver.cpp:542] Iteration 28300, lr = 0.01
I0416 17:42:04.527092   977 solver.cpp:221] Iteration 28320, loss = 0.0755408
I0416 17:42:04.527120   977 solver.cpp:236]     Train net output #0: loss = 0.072468 (* 1 = 0.072468 loss)
I0416 17:42:04.527127   977 solver.cpp:542] Iteration 28320, lr = 0.01
I0416 17:42:18.109905   977 solver.cpp:221] Iteration 28340, loss = 0.0691007
I0416 17:42:18.109932   977 solver.cpp:236]     Train net output #0: loss = 0.0859052 (* 1 = 0.0859052 loss)
I0416 17:42:18.109937   977 solver.cpp:542] Iteration 28340, lr = 0.01
I0416 17:42:31.688305   977 solver.cpp:221] Iteration 28360, loss = 0.0647656
I0416 17:42:31.688333   977 solver.cpp:236]     Train net output #0: loss = 0.0609393 (* 1 = 0.0609393 loss)
I0416 17:42:31.688338   977 solver.cpp:542] Iteration 28360, lr = 0.01
I0416 17:42:45.269551   977 solver.cpp:221] Iteration 28380, loss = 0.070307
I0416 17:42:45.269578   977 solver.cpp:236]     Train net output #0: loss = 0.0870675 (* 1 = 0.0870675 loss)
I0416 17:42:45.269582   977 solver.cpp:542] Iteration 28380, lr = 0.01
I0416 17:42:58.179015   977 solver.cpp:316] Iteration 28400, Testing net (#0)
I0416 17:43:09.714643   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 17:43:09.714663   977 solver.cpp:373]     Test net output #1: loss = 0.0416633 (* 1 = 0.0416633 loss)
I0416 17:43:10.383447   977 solver.cpp:221] Iteration 28400, loss = 0.0689163
I0416 17:43:10.383474   977 solver.cpp:236]     Train net output #0: loss = 0.0871331 (* 1 = 0.0871331 loss)
I0416 17:43:10.383479   977 solver.cpp:542] Iteration 28400, lr = 0.01
I0416 17:43:23.935905   977 solver.cpp:221] Iteration 28420, loss = 0.0703938
I0416 17:43:23.935933   977 solver.cpp:236]     Train net output #0: loss = 0.0823827 (* 1 = 0.0823827 loss)
I0416 17:43:23.935945   977 solver.cpp:542] Iteration 28420, lr = 0.01
I0416 17:43:37.486672   977 solver.cpp:221] Iteration 28440, loss = 0.0718971
I0416 17:43:37.486699   977 solver.cpp:236]     Train net output #0: loss = 0.0892688 (* 1 = 0.0892688 loss)
I0416 17:43:37.486704   977 solver.cpp:542] Iteration 28440, lr = 0.01
I0416 17:43:51.009729   977 solver.cpp:221] Iteration 28460, loss = 0.0660012
I0416 17:43:51.009757   977 solver.cpp:236]     Train net output #0: loss = 0.0986187 (* 1 = 0.0986187 loss)
I0416 17:43:51.009762   977 solver.cpp:542] Iteration 28460, lr = 0.01
I0416 17:44:04.544530   977 solver.cpp:221] Iteration 28480, loss = 0.0642971
I0416 17:44:04.544558   977 solver.cpp:236]     Train net output #0: loss = 0.0616 (* 1 = 0.0616 loss)
I0416 17:44:04.544562   977 solver.cpp:542] Iteration 28480, lr = 0.01
I0416 17:44:18.079341   977 solver.cpp:221] Iteration 28500, loss = 0.0707594
I0416 17:44:18.079368   977 solver.cpp:236]     Train net output #0: loss = 0.100582 (* 1 = 0.100582 loss)
I0416 17:44:18.079373   977 solver.cpp:542] Iteration 28500, lr = 0.01
I0416 17:44:31.632490   977 solver.cpp:221] Iteration 28520, loss = 0.0710681
I0416 17:44:31.632519   977 solver.cpp:236]     Train net output #0: loss = 0.0728393 (* 1 = 0.0728393 loss)
I0416 17:44:31.632524   977 solver.cpp:542] Iteration 28520, lr = 0.01
I0416 17:44:45.212043   977 solver.cpp:221] Iteration 28540, loss = 0.0705463
I0416 17:44:45.212070   977 solver.cpp:236]     Train net output #0: loss = 0.0566497 (* 1 = 0.0566497 loss)
I0416 17:44:45.212075   977 solver.cpp:542] Iteration 28540, lr = 0.01
I0416 17:44:58.779625   977 solver.cpp:221] Iteration 28560, loss = 0.0677149
I0416 17:44:58.779652   977 solver.cpp:236]     Train net output #0: loss = 0.0607196 (* 1 = 0.0607196 loss)
I0416 17:44:58.779657   977 solver.cpp:542] Iteration 28560, lr = 0.01
I0416 17:45:12.311002   977 solver.cpp:221] Iteration 28580, loss = 0.0678157
I0416 17:45:12.311028   977 solver.cpp:236]     Train net output #0: loss = 0.0440141 (* 1 = 0.0440141 loss)
I0416 17:45:12.311033   977 solver.cpp:542] Iteration 28580, lr = 0.01
I0416 17:45:25.185602   977 solver.cpp:316] Iteration 28600, Testing net (#0)
I0416 17:45:36.725673   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 17:45:36.725695   977 solver.cpp:373]     Test net output #1: loss = 0.0403405 (* 1 = 0.0403405 loss)
I0416 17:45:37.393983   977 solver.cpp:221] Iteration 28600, loss = 0.0637704
I0416 17:45:37.394011   977 solver.cpp:236]     Train net output #0: loss = 0.0462515 (* 1 = 0.0462515 loss)
I0416 17:45:37.394017   977 solver.cpp:542] Iteration 28600, lr = 0.01
I0416 17:45:50.930454   977 solver.cpp:221] Iteration 28620, loss = 0.0663306
I0416 17:45:50.930481   977 solver.cpp:236]     Train net output #0: loss = 0.0849088 (* 1 = 0.0849088 loss)
I0416 17:45:50.930486   977 solver.cpp:542] Iteration 28620, lr = 0.01
I0416 17:46:04.485827   977 solver.cpp:221] Iteration 28640, loss = 0.0737192
I0416 17:46:04.485854   977 solver.cpp:236]     Train net output #0: loss = 0.100052 (* 1 = 0.100052 loss)
I0416 17:46:04.485859   977 solver.cpp:542] Iteration 28640, lr = 0.01
I0416 17:46:18.024288   977 solver.cpp:221] Iteration 28660, loss = 0.0700644
I0416 17:46:18.024317   977 solver.cpp:236]     Train net output #0: loss = 0.0633822 (* 1 = 0.0633822 loss)
I0416 17:46:18.024322   977 solver.cpp:542] Iteration 28660, lr = 0.01
I0416 17:46:31.598348   977 solver.cpp:221] Iteration 28680, loss = 0.0751862
I0416 17:46:31.598377   977 solver.cpp:236]     Train net output #0: loss = 0.0796426 (* 1 = 0.0796426 loss)
I0416 17:46:31.598382   977 solver.cpp:542] Iteration 28680, lr = 0.01
I0416 17:46:45.190419   977 solver.cpp:221] Iteration 28700, loss = 0.0788574
I0416 17:46:45.190446   977 solver.cpp:236]     Train net output #0: loss = 0.0927649 (* 1 = 0.0927649 loss)
I0416 17:46:45.190451   977 solver.cpp:542] Iteration 28700, lr = 0.01
I0416 17:46:58.778669   977 solver.cpp:221] Iteration 28720, loss = 0.0713678
I0416 17:46:58.778697   977 solver.cpp:236]     Train net output #0: loss = 0.0566292 (* 1 = 0.0566292 loss)
I0416 17:46:58.778700   977 solver.cpp:542] Iteration 28720, lr = 0.01
I0416 17:47:12.372639   977 solver.cpp:221] Iteration 28740, loss = 0.0763506
I0416 17:47:12.372668   977 solver.cpp:236]     Train net output #0: loss = 0.0366343 (* 1 = 0.0366343 loss)
I0416 17:47:12.372673   977 solver.cpp:542] Iteration 28740, lr = 0.01
I0416 17:47:25.956279   977 solver.cpp:221] Iteration 28760, loss = 0.0618953
I0416 17:47:25.956306   977 solver.cpp:236]     Train net output #0: loss = 0.0312585 (* 1 = 0.0312585 loss)
I0416 17:47:25.956311   977 solver.cpp:542] Iteration 28760, lr = 0.01
I0416 17:47:39.496584   977 solver.cpp:221] Iteration 28780, loss = 0.0765956
I0416 17:47:39.496613   977 solver.cpp:236]     Train net output #0: loss = 0.112555 (* 1 = 0.112555 loss)
I0416 17:47:39.496618   977 solver.cpp:542] Iteration 28780, lr = 0.01
I0416 17:47:52.409728   977 solver.cpp:316] Iteration 28800, Testing net (#0)
I0416 17:48:03.952026   977 solver.cpp:373]     Test net output #0: accuracy = 0.991635
I0416 17:48:03.952049   977 solver.cpp:373]     Test net output #1: loss = 0.0409382 (* 1 = 0.0409382 loss)
I0416 17:48:04.620851   977 solver.cpp:221] Iteration 28800, loss = 0.0649729
I0416 17:48:04.620877   977 solver.cpp:236]     Train net output #0: loss = 0.066733 (* 1 = 0.066733 loss)
I0416 17:48:04.620882   977 solver.cpp:542] Iteration 28800, lr = 0.01
I0416 17:48:18.155019   977 solver.cpp:221] Iteration 28820, loss = 0.0658375
I0416 17:48:18.155046   977 solver.cpp:236]     Train net output #0: loss = 0.0621935 (* 1 = 0.0621935 loss)
I0416 17:48:18.155050   977 solver.cpp:542] Iteration 28820, lr = 0.01
I0416 17:48:31.703318   977 solver.cpp:221] Iteration 28840, loss = 0.0699955
I0416 17:48:31.703346   977 solver.cpp:236]     Train net output #0: loss = 0.131987 (* 1 = 0.131987 loss)
I0416 17:48:31.703351   977 solver.cpp:542] Iteration 28840, lr = 0.01
I0416 17:48:45.262805   977 solver.cpp:221] Iteration 28860, loss = 0.0695859
I0416 17:48:45.262832   977 solver.cpp:236]     Train net output #0: loss = 0.124139 (* 1 = 0.124139 loss)
I0416 17:48:45.262837   977 solver.cpp:542] Iteration 28860, lr = 0.01
I0416 17:48:58.835883   977 solver.cpp:221] Iteration 28880, loss = 0.0703003
I0416 17:48:58.835918   977 solver.cpp:236]     Train net output #0: loss = 0.0520193 (* 1 = 0.0520193 loss)
I0416 17:48:58.835923   977 solver.cpp:542] Iteration 28880, lr = 0.01
I0416 17:49:12.380328   977 solver.cpp:221] Iteration 28900, loss = 0.0726174
I0416 17:49:12.380355   977 solver.cpp:236]     Train net output #0: loss = 0.0445584 (* 1 = 0.0445584 loss)
I0416 17:49:12.380360   977 solver.cpp:542] Iteration 28900, lr = 0.01
I0416 17:49:25.941905   977 solver.cpp:221] Iteration 28920, loss = 0.0706297
I0416 17:49:25.941931   977 solver.cpp:236]     Train net output #0: loss = 0.0710262 (* 1 = 0.0710262 loss)
I0416 17:49:25.941936   977 solver.cpp:542] Iteration 28920, lr = 0.01
I0416 17:49:39.514619   977 solver.cpp:221] Iteration 28940, loss = 0.0648537
I0416 17:49:39.514647   977 solver.cpp:236]     Train net output #0: loss = 0.0794711 (* 1 = 0.0794711 loss)
I0416 17:49:39.514650   977 solver.cpp:542] Iteration 28940, lr = 0.01
I0416 17:49:53.080811   977 solver.cpp:221] Iteration 28960, loss = 0.0721004
I0416 17:49:53.080839   977 solver.cpp:236]     Train net output #0: loss = 0.0884559 (* 1 = 0.0884559 loss)
I0416 17:49:53.080844   977 solver.cpp:542] Iteration 28960, lr = 0.01
I0416 17:50:06.659780   977 solver.cpp:221] Iteration 28980, loss = 0.0663878
I0416 17:50:06.659807   977 solver.cpp:236]     Train net output #0: loss = 0.0564675 (* 1 = 0.0564675 loss)
I0416 17:50:06.659813   977 solver.cpp:542] Iteration 28980, lr = 0.01
I0416 17:50:19.556066   977 solver.cpp:316] Iteration 29000, Testing net (#0)
I0416 17:50:31.099563   977 solver.cpp:373]     Test net output #0: accuracy = 0.989734
I0416 17:50:31.099586   977 solver.cpp:373]     Test net output #1: loss = 0.0423272 (* 1 = 0.0423272 loss)
I0416 17:50:31.767031   977 solver.cpp:221] Iteration 29000, loss = 0.0647874
I0416 17:50:31.767060   977 solver.cpp:236]     Train net output #0: loss = 0.0487628 (* 1 = 0.0487628 loss)
I0416 17:50:31.767065   977 solver.cpp:542] Iteration 29000, lr = 0.01
I0416 17:50:45.311456   977 solver.cpp:221] Iteration 29020, loss = 0.0653432
I0416 17:50:45.311483   977 solver.cpp:236]     Train net output #0: loss = 0.0788042 (* 1 = 0.0788042 loss)
I0416 17:50:45.311487   977 solver.cpp:542] Iteration 29020, lr = 0.01
I0416 17:50:58.889168   977 solver.cpp:221] Iteration 29040, loss = 0.0663824
I0416 17:50:58.889195   977 solver.cpp:236]     Train net output #0: loss = 0.0679641 (* 1 = 0.0679641 loss)
I0416 17:50:58.889200   977 solver.cpp:542] Iteration 29040, lr = 0.01
I0416 17:51:12.465144   977 solver.cpp:221] Iteration 29060, loss = 0.0675967
I0416 17:51:12.465173   977 solver.cpp:236]     Train net output #0: loss = 0.0670236 (* 1 = 0.0670236 loss)
I0416 17:51:12.465178   977 solver.cpp:542] Iteration 29060, lr = 0.01
I0416 17:51:26.032163   977 solver.cpp:221] Iteration 29080, loss = 0.0746377
I0416 17:51:26.032191   977 solver.cpp:236]     Train net output #0: loss = 0.0599691 (* 1 = 0.0599691 loss)
I0416 17:51:26.032197   977 solver.cpp:542] Iteration 29080, lr = 0.01
I0416 17:51:39.581382   977 solver.cpp:221] Iteration 29100, loss = 0.0709735
I0416 17:51:39.581410   977 solver.cpp:236]     Train net output #0: loss = 0.0911329 (* 1 = 0.0911329 loss)
I0416 17:51:39.581415   977 solver.cpp:542] Iteration 29100, lr = 0.01
I0416 17:51:53.127152   977 solver.cpp:221] Iteration 29120, loss = 0.0668269
I0416 17:51:53.127179   977 solver.cpp:236]     Train net output #0: loss = 0.0731002 (* 1 = 0.0731002 loss)
I0416 17:51:53.127184   977 solver.cpp:542] Iteration 29120, lr = 0.01
I0416 17:52:06.665577   977 solver.cpp:221] Iteration 29140, loss = 0.0725869
I0416 17:52:06.665606   977 solver.cpp:236]     Train net output #0: loss = 0.0612374 (* 1 = 0.0612374 loss)
I0416 17:52:06.665611   977 solver.cpp:542] Iteration 29140, lr = 0.01
I0416 17:52:20.214406   977 solver.cpp:221] Iteration 29160, loss = 0.0669471
I0416 17:52:20.214434   977 solver.cpp:236]     Train net output #0: loss = 0.0696419 (* 1 = 0.0696419 loss)
I0416 17:52:20.214439   977 solver.cpp:542] Iteration 29160, lr = 0.01
I0416 17:52:33.768987   977 solver.cpp:221] Iteration 29180, loss = 0.0683465
I0416 17:52:33.769016   977 solver.cpp:236]     Train net output #0: loss = 0.0495133 (* 1 = 0.0495133 loss)
I0416 17:52:33.769019   977 solver.cpp:542] Iteration 29180, lr = 0.01
I0416 17:52:46.653990   977 solver.cpp:316] Iteration 29200, Testing net (#0)
I0416 17:52:58.187608   977 solver.cpp:373]     Test net output #0: accuracy = 0.991255
I0416 17:52:58.187629   977 solver.cpp:373]     Test net output #1: loss = 0.0423563 (* 1 = 0.0423563 loss)
I0416 17:52:58.857496   977 solver.cpp:221] Iteration 29200, loss = 0.0693418
I0416 17:52:58.857522   977 solver.cpp:236]     Train net output #0: loss = 0.0618029 (* 1 = 0.0618029 loss)
I0416 17:52:58.857527   977 solver.cpp:542] Iteration 29200, lr = 0.01
I0416 17:53:12.419560   977 solver.cpp:221] Iteration 29220, loss = 0.062412
I0416 17:53:12.419589   977 solver.cpp:236]     Train net output #0: loss = 0.093021 (* 1 = 0.093021 loss)
I0416 17:53:12.419594   977 solver.cpp:542] Iteration 29220, lr = 0.01
I0416 17:53:25.988134   977 solver.cpp:221] Iteration 29240, loss = 0.0693423
I0416 17:53:25.988162   977 solver.cpp:236]     Train net output #0: loss = 0.0358458 (* 1 = 0.0358458 loss)
I0416 17:53:25.988168   977 solver.cpp:542] Iteration 29240, lr = 0.01
I0416 17:53:39.553762   977 solver.cpp:221] Iteration 29260, loss = 0.0650218
I0416 17:53:39.553791   977 solver.cpp:236]     Train net output #0: loss = 0.0589008 (* 1 = 0.0589008 loss)
I0416 17:53:39.553794   977 solver.cpp:542] Iteration 29260, lr = 0.01
I0416 17:53:53.114960   977 solver.cpp:221] Iteration 29280, loss = 0.0718281
I0416 17:53:53.114989   977 solver.cpp:236]     Train net output #0: loss = 0.06633 (* 1 = 0.06633 loss)
I0416 17:53:53.114995   977 solver.cpp:542] Iteration 29280, lr = 0.01
I0416 17:54:06.656574   977 solver.cpp:221] Iteration 29300, loss = 0.0729219
I0416 17:54:06.656601   977 solver.cpp:236]     Train net output #0: loss = 0.0628842 (* 1 = 0.0628842 loss)
I0416 17:54:06.656606   977 solver.cpp:542] Iteration 29300, lr = 0.01
I0416 17:54:20.201354   977 solver.cpp:221] Iteration 29320, loss = 0.0705393
I0416 17:54:20.201382   977 solver.cpp:236]     Train net output #0: loss = 0.0518555 (* 1 = 0.0518555 loss)
I0416 17:54:20.201387   977 solver.cpp:542] Iteration 29320, lr = 0.01
I0416 17:54:33.750987   977 solver.cpp:221] Iteration 29340, loss = 0.0707547
I0416 17:54:33.751015   977 solver.cpp:236]     Train net output #0: loss = 0.0802656 (* 1 = 0.0802656 loss)
I0416 17:54:33.751019   977 solver.cpp:542] Iteration 29340, lr = 0.01
I0416 17:54:47.296020   977 solver.cpp:221] Iteration 29360, loss = 0.0693716
I0416 17:54:47.296047   977 solver.cpp:236]     Train net output #0: loss = 0.0625863 (* 1 = 0.0625863 loss)
I0416 17:54:47.296052   977 solver.cpp:542] Iteration 29360, lr = 0.01
I0416 17:55:00.842499   977 solver.cpp:221] Iteration 29380, loss = 0.0639363
I0416 17:55:00.842526   977 solver.cpp:236]     Train net output #0: loss = 0.0595871 (* 1 = 0.0595871 loss)
I0416 17:55:00.842531   977 solver.cpp:542] Iteration 29380, lr = 0.01
I0416 17:55:13.738891   977 solver.cpp:316] Iteration 29400, Testing net (#0)
I0416 17:55:25.273773   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 17:55:25.273794   977 solver.cpp:373]     Test net output #1: loss = 0.042313 (* 1 = 0.042313 loss)
I0416 17:55:25.944128   977 solver.cpp:221] Iteration 29400, loss = 0.0643763
I0416 17:55:25.944155   977 solver.cpp:236]     Train net output #0: loss = 0.0554336 (* 1 = 0.0554336 loss)
I0416 17:55:25.944160   977 solver.cpp:542] Iteration 29400, lr = 0.01
I0416 17:55:39.508703   977 solver.cpp:221] Iteration 29420, loss = 0.0736183
I0416 17:55:39.508731   977 solver.cpp:236]     Train net output #0: loss = 0.0420337 (* 1 = 0.0420337 loss)
I0416 17:55:39.508736   977 solver.cpp:542] Iteration 29420, lr = 0.01
I0416 17:55:53.085969   977 solver.cpp:221] Iteration 29440, loss = 0.0658967
I0416 17:55:53.085996   977 solver.cpp:236]     Train net output #0: loss = 0.062707 (* 1 = 0.062707 loss)
I0416 17:55:53.086001   977 solver.cpp:542] Iteration 29440, lr = 0.01
I0416 17:56:06.609781   977 solver.cpp:221] Iteration 29460, loss = 0.065298
I0416 17:56:06.609808   977 solver.cpp:236]     Train net output #0: loss = 0.0804017 (* 1 = 0.0804017 loss)
I0416 17:56:06.609813   977 solver.cpp:542] Iteration 29460, lr = 0.01
I0416 17:56:20.172216   977 solver.cpp:221] Iteration 29480, loss = 0.0716353
I0416 17:56:20.172245   977 solver.cpp:236]     Train net output #0: loss = 0.029371 (* 1 = 0.029371 loss)
I0416 17:56:20.172248   977 solver.cpp:542] Iteration 29480, lr = 0.01
I0416 17:56:33.754539   977 solver.cpp:221] Iteration 29500, loss = 0.0751951
I0416 17:56:33.754565   977 solver.cpp:236]     Train net output #0: loss = 0.0905494 (* 1 = 0.0905494 loss)
I0416 17:56:33.754570   977 solver.cpp:542] Iteration 29500, lr = 0.01
I0416 17:56:47.326061   977 solver.cpp:221] Iteration 29520, loss = 0.0688782
I0416 17:56:47.326086   977 solver.cpp:236]     Train net output #0: loss = 0.0741594 (* 1 = 0.0741594 loss)
I0416 17:56:47.326092   977 solver.cpp:542] Iteration 29520, lr = 0.01
I0416 17:57:00.879185   977 solver.cpp:221] Iteration 29540, loss = 0.0693198
I0416 17:57:00.879220   977 solver.cpp:236]     Train net output #0: loss = 0.0525206 (* 1 = 0.0525206 loss)
I0416 17:57:00.879225   977 solver.cpp:542] Iteration 29540, lr = 0.01
I0416 17:57:14.459506   977 solver.cpp:221] Iteration 29560, loss = 0.0651347
I0416 17:57:14.459533   977 solver.cpp:236]     Train net output #0: loss = 0.0802697 (* 1 = 0.0802697 loss)
I0416 17:57:14.459538   977 solver.cpp:542] Iteration 29560, lr = 0.01
I0416 17:57:28.022979   977 solver.cpp:221] Iteration 29580, loss = 0.0678456
I0416 17:57:28.023007   977 solver.cpp:236]     Train net output #0: loss = 0.0620049 (* 1 = 0.0620049 loss)
I0416 17:57:28.023012   977 solver.cpp:542] Iteration 29580, lr = 0.01
I0416 17:57:40.907675   977 solver.cpp:316] Iteration 29600, Testing net (#0)
I0416 17:57:52.440621   977 solver.cpp:373]     Test net output #0: accuracy = 0.991635
I0416 17:57:52.440644   977 solver.cpp:373]     Test net output #1: loss = 0.0435265 (* 1 = 0.0435265 loss)
I0416 17:57:53.109083   977 solver.cpp:221] Iteration 29600, loss = 0.0693217
I0416 17:57:53.109109   977 solver.cpp:236]     Train net output #0: loss = 0.100395 (* 1 = 0.100395 loss)
I0416 17:57:53.109114   977 solver.cpp:542] Iteration 29600, lr = 0.01
I0416 17:58:06.678726   977 solver.cpp:221] Iteration 29620, loss = 0.0634515
I0416 17:58:06.678755   977 solver.cpp:236]     Train net output #0: loss = 0.0562014 (* 1 = 0.0562014 loss)
I0416 17:58:06.678761   977 solver.cpp:542] Iteration 29620, lr = 0.01
I0416 17:58:20.266392   977 solver.cpp:221] Iteration 29640, loss = 0.0625719
I0416 17:58:20.266419   977 solver.cpp:236]     Train net output #0: loss = 0.0645724 (* 1 = 0.0645724 loss)
I0416 17:58:20.266424   977 solver.cpp:542] Iteration 29640, lr = 0.01
I0416 17:58:33.835878   977 solver.cpp:221] Iteration 29660, loss = 0.0586053
I0416 17:58:33.835904   977 solver.cpp:236]     Train net output #0: loss = 0.033868 (* 1 = 0.033868 loss)
I0416 17:58:33.835908   977 solver.cpp:542] Iteration 29660, lr = 0.01
I0416 17:58:47.382165   977 solver.cpp:221] Iteration 29680, loss = 0.0660243
I0416 17:58:47.382194   977 solver.cpp:236]     Train net output #0: loss = 0.0769518 (* 1 = 0.0769518 loss)
I0416 17:58:47.382199   977 solver.cpp:542] Iteration 29680, lr = 0.01
I0416 17:59:00.930513   977 solver.cpp:221] Iteration 29700, loss = 0.0694776
I0416 17:59:00.930541   977 solver.cpp:236]     Train net output #0: loss = 0.0393835 (* 1 = 0.0393835 loss)
I0416 17:59:00.930546   977 solver.cpp:542] Iteration 29700, lr = 0.01
I0416 17:59:14.466470   977 solver.cpp:221] Iteration 29720, loss = 0.0694574
I0416 17:59:14.466497   977 solver.cpp:236]     Train net output #0: loss = 0.0700263 (* 1 = 0.0700263 loss)
I0416 17:59:14.466503   977 solver.cpp:542] Iteration 29720, lr = 0.01
I0416 17:59:28.047201   977 solver.cpp:221] Iteration 29740, loss = 0.0651901
I0416 17:59:28.047227   977 solver.cpp:236]     Train net output #0: loss = 0.0371681 (* 1 = 0.0371681 loss)
I0416 17:59:28.047232   977 solver.cpp:542] Iteration 29740, lr = 0.01
I0416 17:59:41.609752   977 solver.cpp:221] Iteration 29760, loss = 0.0626077
I0416 17:59:41.609781   977 solver.cpp:236]     Train net output #0: loss = 0.0545917 (* 1 = 0.0545917 loss)
I0416 17:59:41.609784   977 solver.cpp:542] Iteration 29760, lr = 0.01
I0416 17:59:55.167568   977 solver.cpp:221] Iteration 29780, loss = 0.0633088
I0416 17:59:55.167596   977 solver.cpp:236]     Train net output #0: loss = 0.0756453 (* 1 = 0.0756453 loss)
I0416 17:59:55.167600   977 solver.cpp:542] Iteration 29780, lr = 0.01
I0416 18:00:08.094166   977 solver.cpp:316] Iteration 29800, Testing net (#0)
I0416 18:00:19.640607   977 solver.cpp:373]     Test net output #0: accuracy = 0.990304
I0416 18:00:19.640630   977 solver.cpp:373]     Test net output #1: loss = 0.0435415 (* 1 = 0.0435415 loss)
I0416 18:00:20.311743   977 solver.cpp:221] Iteration 29800, loss = 0.0672862
I0416 18:00:20.311770   977 solver.cpp:236]     Train net output #0: loss = 0.0550244 (* 1 = 0.0550244 loss)
I0416 18:00:20.311776   977 solver.cpp:542] Iteration 29800, lr = 0.01
I0416 18:00:33.884179   977 solver.cpp:221] Iteration 29820, loss = 0.0665667
I0416 18:00:33.884207   977 solver.cpp:236]     Train net output #0: loss = 0.0699039 (* 1 = 0.0699039 loss)
I0416 18:00:33.884212   977 solver.cpp:542] Iteration 29820, lr = 0.01
I0416 18:00:47.446102   977 solver.cpp:221] Iteration 29840, loss = 0.0642699
I0416 18:00:47.446130   977 solver.cpp:236]     Train net output #0: loss = 0.0611031 (* 1 = 0.0611031 loss)
I0416 18:00:47.446135   977 solver.cpp:542] Iteration 29840, lr = 0.01
I0416 18:01:01.008992   977 solver.cpp:221] Iteration 29860, loss = 0.0616091
I0416 18:01:01.009021   977 solver.cpp:236]     Train net output #0: loss = 0.0349298 (* 1 = 0.0349298 loss)
I0416 18:01:01.009026   977 solver.cpp:542] Iteration 29860, lr = 0.01
I0416 18:01:14.534518   977 solver.cpp:221] Iteration 29880, loss = 0.0659001
I0416 18:01:14.534545   977 solver.cpp:236]     Train net output #0: loss = 0.0749051 (* 1 = 0.0749051 loss)
I0416 18:01:14.534550   977 solver.cpp:542] Iteration 29880, lr = 0.01
I0416 18:01:28.053676   977 solver.cpp:221] Iteration 29900, loss = 0.0623727
I0416 18:01:28.053704   977 solver.cpp:236]     Train net output #0: loss = 0.0456027 (* 1 = 0.0456027 loss)
I0416 18:01:28.053709   977 solver.cpp:542] Iteration 29900, lr = 0.01
I0416 18:01:41.579502   977 solver.cpp:221] Iteration 29920, loss = 0.060846
I0416 18:01:41.579530   977 solver.cpp:236]     Train net output #0: loss = 0.065904 (* 1 = 0.065904 loss)
I0416 18:01:41.579535   977 solver.cpp:542] Iteration 29920, lr = 0.01
I0416 18:01:55.107894   977 solver.cpp:221] Iteration 29940, loss = 0.0696304
I0416 18:01:55.107976   977 solver.cpp:236]     Train net output #0: loss = 0.0417399 (* 1 = 0.0417399 loss)
I0416 18:01:55.107982   977 solver.cpp:542] Iteration 29940, lr = 0.01
I0416 18:02:08.639674   977 solver.cpp:221] Iteration 29960, loss = 0.0748892
I0416 18:02:08.639703   977 solver.cpp:236]     Train net output #0: loss = 0.123897 (* 1 = 0.123897 loss)
I0416 18:02:08.639708   977 solver.cpp:542] Iteration 29960, lr = 0.01
I0416 18:02:22.165985   977 solver.cpp:221] Iteration 29980, loss = 0.0679116
I0416 18:02:22.166013   977 solver.cpp:236]     Train net output #0: loss = 0.0591084 (* 1 = 0.0591084 loss)
I0416 18:02:22.166018   977 solver.cpp:542] Iteration 29980, lr = 0.01
I0416 18:02:35.045181   977 solver.cpp:410] Snapshotting to binary proto file external/exp/snapshots/individually/cuhk03_iter_30000.caffemodel
I0416 18:02:35.110438   977 solver.cpp:705] Snapshotting solver state to binary proto fileexternal/exp/snapshots/individually/cuhk03_iter_30000.solverstate
I0416 18:02:35.138389   977 solver.cpp:316] Iteration 30000, Testing net (#0)
I0416 18:02:46.683061   977 solver.cpp:373]     Test net output #0: accuracy = 0.991255
I0416 18:02:46.683082   977 solver.cpp:373]     Test net output #1: loss = 0.0419599 (* 1 = 0.0419599 loss)
I0416 18:02:47.352645   977 solver.cpp:221] Iteration 30000, loss = 0.0647365
I0416 18:02:47.352672   977 solver.cpp:236]     Train net output #0: loss = 0.0933126 (* 1 = 0.0933126 loss)
I0416 18:02:47.352677   977 solver.cpp:542] Iteration 30000, lr = 0.01
I0416 18:03:00.912253   977 solver.cpp:221] Iteration 30020, loss = 0.0606067
I0416 18:03:00.912279   977 solver.cpp:236]     Train net output #0: loss = 0.0316703 (* 1 = 0.0316703 loss)
I0416 18:03:00.912284   977 solver.cpp:542] Iteration 30020, lr = 0.01
I0416 18:03:14.451496   977 solver.cpp:221] Iteration 30040, loss = 0.0717178
I0416 18:03:14.451524   977 solver.cpp:236]     Train net output #0: loss = 0.0833697 (* 1 = 0.0833697 loss)
I0416 18:03:14.451529   977 solver.cpp:542] Iteration 30040, lr = 0.01
I0416 18:03:27.985671   977 solver.cpp:221] Iteration 30060, loss = 0.0606578
I0416 18:03:27.985699   977 solver.cpp:236]     Train net output #0: loss = 0.0834765 (* 1 = 0.0834765 loss)
I0416 18:03:27.985704   977 solver.cpp:542] Iteration 30060, lr = 0.01
I0416 18:03:41.545516   977 solver.cpp:221] Iteration 30080, loss = 0.062515
I0416 18:03:41.545543   977 solver.cpp:236]     Train net output #0: loss = 0.0388708 (* 1 = 0.0388708 loss)
I0416 18:03:41.545548   977 solver.cpp:542] Iteration 30080, lr = 0.01
I0416 18:03:55.084961   977 solver.cpp:221] Iteration 30100, loss = 0.0649658
I0416 18:03:55.084988   977 solver.cpp:236]     Train net output #0: loss = 0.0796377 (* 1 = 0.0796377 loss)
I0416 18:03:55.084993   977 solver.cpp:542] Iteration 30100, lr = 0.01
I0416 18:04:08.650367   977 solver.cpp:221] Iteration 30120, loss = 0.0691941
I0416 18:04:08.650394   977 solver.cpp:236]     Train net output #0: loss = 0.0554147 (* 1 = 0.0554147 loss)
I0416 18:04:08.650399   977 solver.cpp:542] Iteration 30120, lr = 0.01
I0416 18:04:22.208693   977 solver.cpp:221] Iteration 30140, loss = 0.068845
I0416 18:04:22.208720   977 solver.cpp:236]     Train net output #0: loss = 0.0826699 (* 1 = 0.0826699 loss)
I0416 18:04:22.208725   977 solver.cpp:542] Iteration 30140, lr = 0.01
I0416 18:04:35.742218   977 solver.cpp:221] Iteration 30160, loss = 0.0634106
I0416 18:04:35.742244   977 solver.cpp:236]     Train net output #0: loss = 0.0681845 (* 1 = 0.0681845 loss)
I0416 18:04:35.742249   977 solver.cpp:542] Iteration 30160, lr = 0.01
I0416 18:04:49.318032   977 solver.cpp:221] Iteration 30180, loss = 0.0670581
I0416 18:04:49.318063   977 solver.cpp:236]     Train net output #0: loss = 0.0874334 (* 1 = 0.0874334 loss)
I0416 18:04:49.318069   977 solver.cpp:542] Iteration 30180, lr = 0.01
I0416 18:05:02.231362   977 solver.cpp:316] Iteration 30200, Testing net (#0)
I0416 18:05:13.779191   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:05:13.779213   977 solver.cpp:373]     Test net output #1: loss = 0.0405571 (* 1 = 0.0405571 loss)
I0416 18:05:14.451200   977 solver.cpp:221] Iteration 30200, loss = 0.0616601
I0416 18:05:14.451226   977 solver.cpp:236]     Train net output #0: loss = 0.0590105 (* 1 = 0.0590105 loss)
I0416 18:05:14.451232   977 solver.cpp:542] Iteration 30200, lr = 0.01
I0416 18:05:27.991495   977 solver.cpp:221] Iteration 30220, loss = 0.0677586
I0416 18:05:27.991523   977 solver.cpp:236]     Train net output #0: loss = 0.0434287 (* 1 = 0.0434287 loss)
I0416 18:05:27.991526   977 solver.cpp:542] Iteration 30220, lr = 0.01
I0416 18:05:41.536026   977 solver.cpp:221] Iteration 30240, loss = 0.064947
I0416 18:05:41.536053   977 solver.cpp:236]     Train net output #0: loss = 0.0889642 (* 1 = 0.0889642 loss)
I0416 18:05:41.536057   977 solver.cpp:542] Iteration 30240, lr = 0.01
I0416 18:05:55.089090   977 solver.cpp:221] Iteration 30260, loss = 0.0634116
I0416 18:05:55.089118   977 solver.cpp:236]     Train net output #0: loss = 0.0574863 (* 1 = 0.0574863 loss)
I0416 18:05:55.089123   977 solver.cpp:542] Iteration 30260, lr = 0.01
I0416 18:06:08.656757   977 solver.cpp:221] Iteration 30280, loss = 0.0630245
I0416 18:06:08.656785   977 solver.cpp:236]     Train net output #0: loss = 0.0761117 (* 1 = 0.0761117 loss)
I0416 18:06:08.656790   977 solver.cpp:542] Iteration 30280, lr = 0.01
I0416 18:06:22.195415   977 solver.cpp:221] Iteration 30300, loss = 0.0713076
I0416 18:06:22.195442   977 solver.cpp:236]     Train net output #0: loss = 0.0307454 (* 1 = 0.0307454 loss)
I0416 18:06:22.195447   977 solver.cpp:542] Iteration 30300, lr = 0.01
I0416 18:06:35.722823   977 solver.cpp:221] Iteration 30320, loss = 0.0644143
I0416 18:06:35.722851   977 solver.cpp:236]     Train net output #0: loss = 0.0559659 (* 1 = 0.0559659 loss)
I0416 18:06:35.722856   977 solver.cpp:542] Iteration 30320, lr = 0.01
I0416 18:06:49.254809   977 solver.cpp:221] Iteration 30340, loss = 0.0664172
I0416 18:06:49.254835   977 solver.cpp:236]     Train net output #0: loss = 0.0938297 (* 1 = 0.0938297 loss)
I0416 18:06:49.254839   977 solver.cpp:542] Iteration 30340, lr = 0.01
I0416 18:07:02.820997   977 solver.cpp:221] Iteration 30360, loss = 0.068943
I0416 18:07:02.821025   977 solver.cpp:236]     Train net output #0: loss = 0.100385 (* 1 = 0.100385 loss)
I0416 18:07:02.821029   977 solver.cpp:542] Iteration 30360, lr = 0.01
I0416 18:07:16.405993   977 solver.cpp:221] Iteration 30380, loss = 0.0633196
I0416 18:07:16.406020   977 solver.cpp:236]     Train net output #0: loss = 0.0887862 (* 1 = 0.0887862 loss)
I0416 18:07:16.406025   977 solver.cpp:542] Iteration 30380, lr = 0.01
I0416 18:07:29.345209   977 solver.cpp:316] Iteration 30400, Testing net (#0)
I0416 18:07:40.894141   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 18:07:40.894165   977 solver.cpp:373]     Test net output #1: loss = 0.0410066 (* 1 = 0.0410066 loss)
I0416 18:07:41.565523   977 solver.cpp:221] Iteration 30400, loss = 0.0638301
I0416 18:07:41.565551   977 solver.cpp:236]     Train net output #0: loss = 0.0352126 (* 1 = 0.0352126 loss)
I0416 18:07:41.565556   977 solver.cpp:542] Iteration 30400, lr = 0.01
I0416 18:07:55.118638   977 solver.cpp:221] Iteration 30420, loss = 0.0645513
I0416 18:07:55.118665   977 solver.cpp:236]     Train net output #0: loss = 0.0441434 (* 1 = 0.0441434 loss)
I0416 18:07:55.118670   977 solver.cpp:542] Iteration 30420, lr = 0.01
I0416 18:08:08.657177   977 solver.cpp:221] Iteration 30440, loss = 0.0644201
I0416 18:08:08.657204   977 solver.cpp:236]     Train net output #0: loss = 0.035272 (* 1 = 0.035272 loss)
I0416 18:08:08.657208   977 solver.cpp:542] Iteration 30440, lr = 0.01
I0416 18:08:22.225904   977 solver.cpp:221] Iteration 30460, loss = 0.0664611
I0416 18:08:22.225931   977 solver.cpp:236]     Train net output #0: loss = 0.054577 (* 1 = 0.054577 loss)
I0416 18:08:22.225935   977 solver.cpp:542] Iteration 30460, lr = 0.01
I0416 18:08:35.763411   977 solver.cpp:221] Iteration 30480, loss = 0.0639814
I0416 18:08:35.763438   977 solver.cpp:236]     Train net output #0: loss = 0.0593237 (* 1 = 0.0593237 loss)
I0416 18:08:35.763443   977 solver.cpp:542] Iteration 30480, lr = 0.01
I0416 18:08:49.303061   977 solver.cpp:221] Iteration 30500, loss = 0.0619854
I0416 18:08:49.303087   977 solver.cpp:236]     Train net output #0: loss = 0.0595878 (* 1 = 0.0595878 loss)
I0416 18:08:49.303092   977 solver.cpp:542] Iteration 30500, lr = 0.01
I0416 18:09:02.859288   977 solver.cpp:221] Iteration 30520, loss = 0.0603463
I0416 18:09:02.859315   977 solver.cpp:236]     Train net output #0: loss = 0.0361332 (* 1 = 0.0361332 loss)
I0416 18:09:02.859320   977 solver.cpp:542] Iteration 30520, lr = 0.01
I0416 18:09:16.414072   977 solver.cpp:221] Iteration 30540, loss = 0.0606962
I0416 18:09:16.414100   977 solver.cpp:236]     Train net output #0: loss = 0.0329335 (* 1 = 0.0329335 loss)
I0416 18:09:16.414106   977 solver.cpp:542] Iteration 30540, lr = 0.01
I0416 18:09:29.968623   977 solver.cpp:221] Iteration 30560, loss = 0.0684329
I0416 18:09:29.968652   977 solver.cpp:236]     Train net output #0: loss = 0.0564592 (* 1 = 0.0564592 loss)
I0416 18:09:29.968657   977 solver.cpp:542] Iteration 30560, lr = 0.01
I0416 18:09:43.509109   977 solver.cpp:221] Iteration 30580, loss = 0.0648105
I0416 18:09:43.509143   977 solver.cpp:236]     Train net output #0: loss = 0.0499414 (* 1 = 0.0499414 loss)
I0416 18:09:43.509147   977 solver.cpp:542] Iteration 30580, lr = 0.01
I0416 18:09:56.382925   977 solver.cpp:316] Iteration 30600, Testing net (#0)
I0416 18:10:07.926825   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:10:07.926846   977 solver.cpp:373]     Test net output #1: loss = 0.040301 (* 1 = 0.040301 loss)
I0416 18:10:08.594827   977 solver.cpp:221] Iteration 30600, loss = 0.0697778
I0416 18:10:08.594856   977 solver.cpp:236]     Train net output #0: loss = 0.113712 (* 1 = 0.113712 loss)
I0416 18:10:08.594859   977 solver.cpp:542] Iteration 30600, lr = 0.01
I0416 18:10:22.131495   977 solver.cpp:221] Iteration 30620, loss = 0.0639452
I0416 18:10:22.131523   977 solver.cpp:236]     Train net output #0: loss = 0.0794982 (* 1 = 0.0794982 loss)
I0416 18:10:22.131530   977 solver.cpp:542] Iteration 30620, lr = 0.01
I0416 18:10:35.675274   977 solver.cpp:221] Iteration 30640, loss = 0.0600641
I0416 18:10:35.675302   977 solver.cpp:236]     Train net output #0: loss = 0.0629274 (* 1 = 0.0629274 loss)
I0416 18:10:35.675307   977 solver.cpp:542] Iteration 30640, lr = 0.01
I0416 18:10:49.217798   977 solver.cpp:221] Iteration 30660, loss = 0.0571354
I0416 18:10:49.217826   977 solver.cpp:236]     Train net output #0: loss = 0.0959377 (* 1 = 0.0959377 loss)
I0416 18:10:49.217831   977 solver.cpp:542] Iteration 30660, lr = 0.01
I0416 18:11:02.793246   977 solver.cpp:221] Iteration 30680, loss = 0.0682275
I0416 18:11:02.793274   977 solver.cpp:236]     Train net output #0: loss = 0.111213 (* 1 = 0.111213 loss)
I0416 18:11:02.793279   977 solver.cpp:542] Iteration 30680, lr = 0.01
I0416 18:11:16.357939   977 solver.cpp:221] Iteration 30700, loss = 0.0635728
I0416 18:11:16.357969   977 solver.cpp:236]     Train net output #0: loss = 0.0496985 (* 1 = 0.0496985 loss)
I0416 18:11:16.357974   977 solver.cpp:542] Iteration 30700, lr = 0.01
I0416 18:11:29.915858   977 solver.cpp:221] Iteration 30720, loss = 0.0662214
I0416 18:11:29.915886   977 solver.cpp:236]     Train net output #0: loss = 0.0794286 (* 1 = 0.0794286 loss)
I0416 18:11:29.915891   977 solver.cpp:542] Iteration 30720, lr = 0.01
I0416 18:11:43.446003   977 solver.cpp:221] Iteration 30740, loss = 0.0613269
I0416 18:11:43.446030   977 solver.cpp:236]     Train net output #0: loss = 0.0550074 (* 1 = 0.0550074 loss)
I0416 18:11:43.446035   977 solver.cpp:542] Iteration 30740, lr = 0.01
I0416 18:11:56.974251   977 solver.cpp:221] Iteration 30760, loss = 0.0664914
I0416 18:11:56.974279   977 solver.cpp:236]     Train net output #0: loss = 0.0435914 (* 1 = 0.0435914 loss)
I0416 18:11:56.974284   977 solver.cpp:542] Iteration 30760, lr = 0.01
I0416 18:12:10.503803   977 solver.cpp:221] Iteration 30780, loss = 0.0655338
I0416 18:12:10.503830   977 solver.cpp:236]     Train net output #0: loss = 0.127986 (* 1 = 0.127986 loss)
I0416 18:12:10.503835   977 solver.cpp:542] Iteration 30780, lr = 0.01
I0416 18:12:23.373800   977 solver.cpp:316] Iteration 30800, Testing net (#0)
I0416 18:12:34.908512   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 18:12:34.908535   977 solver.cpp:373]     Test net output #1: loss = 0.0397685 (* 1 = 0.0397685 loss)
I0416 18:12:35.577517   977 solver.cpp:221] Iteration 30800, loss = 0.061871
I0416 18:12:35.577544   977 solver.cpp:236]     Train net output #0: loss = 0.0487719 (* 1 = 0.0487719 loss)
I0416 18:12:35.577549   977 solver.cpp:542] Iteration 30800, lr = 0.01
I0416 18:12:49.136641   977 solver.cpp:221] Iteration 30820, loss = 0.0594588
I0416 18:12:49.136669   977 solver.cpp:236]     Train net output #0: loss = 0.0435064 (* 1 = 0.0435064 loss)
I0416 18:12:49.136674   977 solver.cpp:542] Iteration 30820, lr = 0.01
I0416 18:13:02.666936   977 solver.cpp:221] Iteration 30840, loss = 0.0624474
I0416 18:13:02.666963   977 solver.cpp:236]     Train net output #0: loss = 0.0936614 (* 1 = 0.0936614 loss)
I0416 18:13:02.666967   977 solver.cpp:542] Iteration 30840, lr = 0.01
I0416 18:13:16.221529   977 solver.cpp:221] Iteration 30860, loss = 0.0604558
I0416 18:13:16.221556   977 solver.cpp:236]     Train net output #0: loss = 0.0462532 (* 1 = 0.0462532 loss)
I0416 18:13:16.221560   977 solver.cpp:542] Iteration 30860, lr = 0.01
I0416 18:13:29.781605   977 solver.cpp:221] Iteration 30880, loss = 0.0651084
I0416 18:13:29.781632   977 solver.cpp:236]     Train net output #0: loss = 0.0492342 (* 1 = 0.0492342 loss)
I0416 18:13:29.781637   977 solver.cpp:542] Iteration 30880, lr = 0.01
I0416 18:13:43.330425   977 solver.cpp:221] Iteration 30900, loss = 0.064444
I0416 18:13:43.330452   977 solver.cpp:236]     Train net output #0: loss = 0.0516312 (* 1 = 0.0516312 loss)
I0416 18:13:43.330457   977 solver.cpp:542] Iteration 30900, lr = 0.01
I0416 18:13:56.884649   977 solver.cpp:221] Iteration 30920, loss = 0.0615338
I0416 18:13:56.884675   977 solver.cpp:236]     Train net output #0: loss = 0.049339 (* 1 = 0.049339 loss)
I0416 18:13:56.884680   977 solver.cpp:542] Iteration 30920, lr = 0.01
I0416 18:14:10.424554   977 solver.cpp:221] Iteration 30940, loss = 0.0535975
I0416 18:14:10.424582   977 solver.cpp:236]     Train net output #0: loss = 0.0851672 (* 1 = 0.0851672 loss)
I0416 18:14:10.424587   977 solver.cpp:542] Iteration 30940, lr = 0.01
I0416 18:14:23.956101   977 solver.cpp:221] Iteration 30960, loss = 0.0591615
I0416 18:14:23.956128   977 solver.cpp:236]     Train net output #0: loss = 0.0683149 (* 1 = 0.0683149 loss)
I0416 18:14:23.956132   977 solver.cpp:542] Iteration 30960, lr = 0.01
I0416 18:14:37.514196   977 solver.cpp:221] Iteration 30980, loss = 0.0630856
I0416 18:14:37.514225   977 solver.cpp:236]     Train net output #0: loss = 0.0683567 (* 1 = 0.0683567 loss)
I0416 18:14:37.514230   977 solver.cpp:542] Iteration 30980, lr = 0.01
I0416 18:14:50.404961   977 solver.cpp:316] Iteration 31000, Testing net (#0)
I0416 18:15:01.947325   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 18:15:01.947347   977 solver.cpp:373]     Test net output #1: loss = 0.0406751 (* 1 = 0.0406751 loss)
I0416 18:15:02.616650   977 solver.cpp:221] Iteration 31000, loss = 0.064308
I0416 18:15:02.616679   977 solver.cpp:236]     Train net output #0: loss = 0.0715798 (* 1 = 0.0715798 loss)
I0416 18:15:02.616684   977 solver.cpp:542] Iteration 31000, lr = 0.01
I0416 18:15:16.203261   977 solver.cpp:221] Iteration 31020, loss = 0.0646667
I0416 18:15:16.203289   977 solver.cpp:236]     Train net output #0: loss = 0.0429561 (* 1 = 0.0429561 loss)
I0416 18:15:16.203294   977 solver.cpp:542] Iteration 31020, lr = 0.01
I0416 18:15:29.793030   977 solver.cpp:221] Iteration 31040, loss = 0.0670825
I0416 18:15:29.793058   977 solver.cpp:236]     Train net output #0: loss = 0.0788787 (* 1 = 0.0788787 loss)
I0416 18:15:29.793063   977 solver.cpp:542] Iteration 31040, lr = 0.01
I0416 18:15:43.353281   977 solver.cpp:221] Iteration 31060, loss = 0.0585886
I0416 18:15:43.353307   977 solver.cpp:236]     Train net output #0: loss = 0.0465782 (* 1 = 0.0465782 loss)
I0416 18:15:43.353312   977 solver.cpp:542] Iteration 31060, lr = 0.01
I0416 18:15:56.891950   977 solver.cpp:221] Iteration 31080, loss = 0.064418
I0416 18:15:56.891978   977 solver.cpp:236]     Train net output #0: loss = 0.0489087 (* 1 = 0.0489087 loss)
I0416 18:15:56.891983   977 solver.cpp:542] Iteration 31080, lr = 0.01
I0416 18:16:10.422749   977 solver.cpp:221] Iteration 31100, loss = 0.0643494
I0416 18:16:10.422776   977 solver.cpp:236]     Train net output #0: loss = 0.0739821 (* 1 = 0.0739821 loss)
I0416 18:16:10.422780   977 solver.cpp:542] Iteration 31100, lr = 0.01
I0416 18:16:23.967767   977 solver.cpp:221] Iteration 31120, loss = 0.0548134
I0416 18:16:23.967795   977 solver.cpp:236]     Train net output #0: loss = 0.0822227 (* 1 = 0.0822227 loss)
I0416 18:16:23.967800   977 solver.cpp:542] Iteration 31120, lr = 0.01
I0416 18:16:37.518571   977 solver.cpp:221] Iteration 31140, loss = 0.0644194
I0416 18:16:37.518596   977 solver.cpp:236]     Train net output #0: loss = 0.0860458 (* 1 = 0.0860458 loss)
I0416 18:16:37.518601   977 solver.cpp:542] Iteration 31140, lr = 0.01
I0416 18:16:51.058472   977 solver.cpp:221] Iteration 31160, loss = 0.061987
I0416 18:16:51.058501   977 solver.cpp:236]     Train net output #0: loss = 0.0540146 (* 1 = 0.0540146 loss)
I0416 18:16:51.058506   977 solver.cpp:542] Iteration 31160, lr = 0.01
I0416 18:17:04.589390   977 solver.cpp:221] Iteration 31180, loss = 0.0705962
I0416 18:17:04.589417   977 solver.cpp:236]     Train net output #0: loss = 0.104166 (* 1 = 0.104166 loss)
I0416 18:17:04.589422   977 solver.cpp:542] Iteration 31180, lr = 0.01
I0416 18:17:17.473909   977 solver.cpp:316] Iteration 31200, Testing net (#0)
I0416 18:17:29.015221   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:17:29.015244   977 solver.cpp:373]     Test net output #1: loss = 0.0401146 (* 1 = 0.0401146 loss)
I0416 18:17:29.686141   977 solver.cpp:221] Iteration 31200, loss = 0.068786
I0416 18:17:29.686167   977 solver.cpp:236]     Train net output #0: loss = 0.0565719 (* 1 = 0.0565719 loss)
I0416 18:17:29.686172   977 solver.cpp:542] Iteration 31200, lr = 0.01
I0416 18:17:43.253154   977 solver.cpp:221] Iteration 31220, loss = 0.0692225
I0416 18:17:43.253183   977 solver.cpp:236]     Train net output #0: loss = 0.0791986 (* 1 = 0.0791986 loss)
I0416 18:17:43.253188   977 solver.cpp:542] Iteration 31220, lr = 0.01
I0416 18:17:56.810833   977 solver.cpp:221] Iteration 31240, loss = 0.0659919
I0416 18:17:56.810861   977 solver.cpp:236]     Train net output #0: loss = 0.0866588 (* 1 = 0.0866588 loss)
I0416 18:17:56.810865   977 solver.cpp:542] Iteration 31240, lr = 0.01
I0416 18:18:10.370862   977 solver.cpp:221] Iteration 31260, loss = 0.0577778
I0416 18:18:10.370889   977 solver.cpp:236]     Train net output #0: loss = 0.0408517 (* 1 = 0.0408517 loss)
I0416 18:18:10.370894   977 solver.cpp:542] Iteration 31260, lr = 0.01
I0416 18:18:23.923615   977 solver.cpp:221] Iteration 31280, loss = 0.0629026
I0416 18:18:23.923643   977 solver.cpp:236]     Train net output #0: loss = 0.0704497 (* 1 = 0.0704497 loss)
I0416 18:18:23.923648   977 solver.cpp:542] Iteration 31280, lr = 0.01
I0416 18:18:37.490043   977 solver.cpp:221] Iteration 31300, loss = 0.0660827
I0416 18:18:37.490072   977 solver.cpp:236]     Train net output #0: loss = 0.105352 (* 1 = 0.105352 loss)
I0416 18:18:37.490077   977 solver.cpp:542] Iteration 31300, lr = 0.01
I0416 18:18:51.047507   977 solver.cpp:221] Iteration 31320, loss = 0.0615015
I0416 18:18:51.047534   977 solver.cpp:236]     Train net output #0: loss = 0.0401572 (* 1 = 0.0401572 loss)
I0416 18:18:51.047539   977 solver.cpp:542] Iteration 31320, lr = 0.01
I0416 18:19:04.602951   977 solver.cpp:221] Iteration 31340, loss = 0.0698841
I0416 18:19:04.602977   977 solver.cpp:236]     Train net output #0: loss = 0.0533675 (* 1 = 0.0533675 loss)
I0416 18:19:04.602982   977 solver.cpp:542] Iteration 31340, lr = 0.01
I0416 18:19:18.150269   977 solver.cpp:221] Iteration 31360, loss = 0.0612101
I0416 18:19:18.150296   977 solver.cpp:236]     Train net output #0: loss = 0.0780237 (* 1 = 0.0780237 loss)
I0416 18:19:18.150302   977 solver.cpp:542] Iteration 31360, lr = 0.01
I0416 18:19:31.694341   977 solver.cpp:221] Iteration 31380, loss = 0.0593765
I0416 18:19:31.694368   977 solver.cpp:236]     Train net output #0: loss = 0.0343318 (* 1 = 0.0343318 loss)
I0416 18:19:31.694373   977 solver.cpp:542] Iteration 31380, lr = 0.01
I0416 18:19:44.587102   977 solver.cpp:316] Iteration 31400, Testing net (#0)
I0416 18:19:56.129252   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 18:19:56.129276   977 solver.cpp:373]     Test net output #1: loss = 0.0398315 (* 1 = 0.0398315 loss)
I0416 18:19:56.798928   977 solver.cpp:221] Iteration 31400, loss = 0.0675474
I0416 18:19:56.798957   977 solver.cpp:236]     Train net output #0: loss = 0.0860883 (* 1 = 0.0860883 loss)
I0416 18:19:56.798962   977 solver.cpp:542] Iteration 31400, lr = 0.01
I0416 18:20:10.348248   977 solver.cpp:221] Iteration 31420, loss = 0.0670889
I0416 18:20:10.348275   977 solver.cpp:236]     Train net output #0: loss = 0.0924176 (* 1 = 0.0924176 loss)
I0416 18:20:10.348280   977 solver.cpp:542] Iteration 31420, lr = 0.01
I0416 18:20:23.895797   977 solver.cpp:221] Iteration 31440, loss = 0.0702322
I0416 18:20:23.895824   977 solver.cpp:236]     Train net output #0: loss = 0.0729723 (* 1 = 0.0729723 loss)
I0416 18:20:23.895829   977 solver.cpp:542] Iteration 31440, lr = 0.01
I0416 18:20:37.428782   977 solver.cpp:221] Iteration 31460, loss = 0.0621696
I0416 18:20:37.428810   977 solver.cpp:236]     Train net output #0: loss = 0.0860502 (* 1 = 0.0860502 loss)
I0416 18:20:37.428815   977 solver.cpp:542] Iteration 31460, lr = 0.01
I0416 18:20:50.990401   977 solver.cpp:221] Iteration 31480, loss = 0.0630002
I0416 18:20:50.990428   977 solver.cpp:236]     Train net output #0: loss = 0.07773 (* 1 = 0.07773 loss)
I0416 18:20:50.990432   977 solver.cpp:542] Iteration 31480, lr = 0.01
I0416 18:21:04.553112   977 solver.cpp:221] Iteration 31500, loss = 0.0595209
I0416 18:21:04.553138   977 solver.cpp:236]     Train net output #0: loss = 0.0589056 (* 1 = 0.0589056 loss)
I0416 18:21:04.553143   977 solver.cpp:542] Iteration 31500, lr = 0.01
I0416 18:21:18.104980   977 solver.cpp:221] Iteration 31520, loss = 0.0576093
I0416 18:21:18.105007   977 solver.cpp:236]     Train net output #0: loss = 0.0712764 (* 1 = 0.0712764 loss)
I0416 18:21:18.105011   977 solver.cpp:542] Iteration 31520, lr = 0.01
I0416 18:21:31.651813   977 solver.cpp:221] Iteration 31540, loss = 0.0594353
I0416 18:21:31.651840   977 solver.cpp:236]     Train net output #0: loss = 0.0247804 (* 1 = 0.0247804 loss)
I0416 18:21:31.651844   977 solver.cpp:542] Iteration 31540, lr = 0.01
I0416 18:21:45.179785   977 solver.cpp:221] Iteration 31560, loss = 0.0600186
I0416 18:21:45.179813   977 solver.cpp:236]     Train net output #0: loss = 0.06216 (* 1 = 0.06216 loss)
I0416 18:21:45.179817   977 solver.cpp:542] Iteration 31560, lr = 0.01
I0416 18:21:58.723235   977 solver.cpp:221] Iteration 31580, loss = 0.0625949
I0416 18:21:58.723263   977 solver.cpp:236]     Train net output #0: loss = 0.0689255 (* 1 = 0.0689255 loss)
I0416 18:21:58.723268   977 solver.cpp:542] Iteration 31580, lr = 0.01
I0416 18:22:11.604346   977 solver.cpp:316] Iteration 31600, Testing net (#0)
I0416 18:22:23.149022   977 solver.cpp:373]     Test net output #0: accuracy = 0.991635
I0416 18:22:23.149047   977 solver.cpp:373]     Test net output #1: loss = 0.0395769 (* 1 = 0.0395769 loss)
I0416 18:22:23.819299   977 solver.cpp:221] Iteration 31600, loss = 0.0612399
I0416 18:22:23.819326   977 solver.cpp:236]     Train net output #0: loss = 0.0692927 (* 1 = 0.0692927 loss)
I0416 18:22:23.819330   977 solver.cpp:542] Iteration 31600, lr = 0.01
I0416 18:22:37.347157   977 solver.cpp:221] Iteration 31620, loss = 0.0634716
I0416 18:22:37.347185   977 solver.cpp:236]     Train net output #0: loss = 0.0544097 (* 1 = 0.0544097 loss)
I0416 18:22:37.347190   977 solver.cpp:542] Iteration 31620, lr = 0.01
I0416 18:22:50.892978   977 solver.cpp:221] Iteration 31640, loss = 0.0629583
I0416 18:22:50.893005   977 solver.cpp:236]     Train net output #0: loss = 0.0747148 (* 1 = 0.0747148 loss)
I0416 18:22:50.893009   977 solver.cpp:542] Iteration 31640, lr = 0.01
I0416 18:23:04.443171   977 solver.cpp:221] Iteration 31660, loss = 0.0554036
I0416 18:23:04.443199   977 solver.cpp:236]     Train net output #0: loss = 0.0905706 (* 1 = 0.0905706 loss)
I0416 18:23:04.443204   977 solver.cpp:542] Iteration 31660, lr = 0.01
I0416 18:23:18.015774   977 solver.cpp:221] Iteration 31680, loss = 0.0572826
I0416 18:23:18.015801   977 solver.cpp:236]     Train net output #0: loss = 0.040849 (* 1 = 0.040849 loss)
I0416 18:23:18.015806   977 solver.cpp:542] Iteration 31680, lr = 0.01
I0416 18:23:31.584045   977 solver.cpp:221] Iteration 31700, loss = 0.0642939
I0416 18:23:31.584072   977 solver.cpp:236]     Train net output #0: loss = 0.0690835 (* 1 = 0.0690835 loss)
I0416 18:23:31.584077   977 solver.cpp:542] Iteration 31700, lr = 0.01
I0416 18:23:45.110177   977 solver.cpp:221] Iteration 31720, loss = 0.0607633
I0416 18:23:45.110203   977 solver.cpp:236]     Train net output #0: loss = 0.143314 (* 1 = 0.143314 loss)
I0416 18:23:45.110208   977 solver.cpp:542] Iteration 31720, lr = 0.01
I0416 18:23:58.631338   977 solver.cpp:221] Iteration 31740, loss = 0.0592389
I0416 18:23:58.631364   977 solver.cpp:236]     Train net output #0: loss = 0.0751619 (* 1 = 0.0751619 loss)
I0416 18:23:58.631369   977 solver.cpp:542] Iteration 31740, lr = 0.01
I0416 18:24:12.167659   977 solver.cpp:221] Iteration 31760, loss = 0.0676293
I0416 18:24:12.167686   977 solver.cpp:236]     Train net output #0: loss = 0.1216 (* 1 = 0.1216 loss)
I0416 18:24:12.167690   977 solver.cpp:542] Iteration 31760, lr = 0.01
I0416 18:24:25.715597   977 solver.cpp:221] Iteration 31780, loss = 0.0635834
I0416 18:24:25.715626   977 solver.cpp:236]     Train net output #0: loss = 0.0490138 (* 1 = 0.0490138 loss)
I0416 18:24:25.715631   977 solver.cpp:542] Iteration 31780, lr = 0.01
I0416 18:24:38.585629   977 solver.cpp:316] Iteration 31800, Testing net (#0)
I0416 18:24:50.130995   977 solver.cpp:373]     Test net output #0: accuracy = 0.991445
I0416 18:24:50.131016   977 solver.cpp:373]     Test net output #1: loss = 0.0393079 (* 1 = 0.0393079 loss)
I0416 18:24:50.802119   977 solver.cpp:221] Iteration 31800, loss = 0.063591
I0416 18:24:50.802146   977 solver.cpp:236]     Train net output #0: loss = 0.0450512 (* 1 = 0.0450512 loss)
I0416 18:24:50.802151   977 solver.cpp:542] Iteration 31800, lr = 0.01
I0416 18:25:04.308683   977 solver.cpp:221] Iteration 31820, loss = 0.0664643
I0416 18:25:04.308712   977 solver.cpp:236]     Train net output #0: loss = 0.070122 (* 1 = 0.070122 loss)
I0416 18:25:04.308715   977 solver.cpp:542] Iteration 31820, lr = 0.01
I0416 18:25:17.815508   977 solver.cpp:221] Iteration 31840, loss = 0.064679
I0416 18:25:17.815536   977 solver.cpp:236]     Train net output #0: loss = 0.0741473 (* 1 = 0.0741473 loss)
I0416 18:25:17.815541   977 solver.cpp:542] Iteration 31840, lr = 0.01
I0416 18:25:31.335657   977 solver.cpp:221] Iteration 31860, loss = 0.0657692
I0416 18:25:31.335691   977 solver.cpp:236]     Train net output #0: loss = 0.122698 (* 1 = 0.122698 loss)
I0416 18:25:31.335696   977 solver.cpp:542] Iteration 31860, lr = 0.01
I0416 18:25:44.890980   977 solver.cpp:221] Iteration 31880, loss = 0.0575693
I0416 18:25:44.891008   977 solver.cpp:236]     Train net output #0: loss = 0.0732881 (* 1 = 0.0732881 loss)
I0416 18:25:44.891012   977 solver.cpp:542] Iteration 31880, lr = 0.01
I0416 18:25:58.443635   977 solver.cpp:221] Iteration 31900, loss = 0.0668659
I0416 18:25:58.443663   977 solver.cpp:236]     Train net output #0: loss = 0.102954 (* 1 = 0.102954 loss)
I0416 18:25:58.443667   977 solver.cpp:542] Iteration 31900, lr = 0.01
I0416 18:26:12.003448   977 solver.cpp:221] Iteration 31920, loss = 0.0578765
I0416 18:26:12.003475   977 solver.cpp:236]     Train net output #0: loss = 0.0295665 (* 1 = 0.0295665 loss)
I0416 18:26:12.003480   977 solver.cpp:542] Iteration 31920, lr = 0.01
I0416 18:26:25.558965   977 solver.cpp:221] Iteration 31940, loss = 0.065195
I0416 18:26:25.558995   977 solver.cpp:236]     Train net output #0: loss = 0.0916151 (* 1 = 0.0916151 loss)
I0416 18:26:25.558998   977 solver.cpp:542] Iteration 31940, lr = 0.01
I0416 18:26:39.114889   977 solver.cpp:221] Iteration 31960, loss = 0.0636325
I0416 18:26:39.114917   977 solver.cpp:236]     Train net output #0: loss = 0.0693054 (* 1 = 0.0693054 loss)
I0416 18:26:39.114922   977 solver.cpp:542] Iteration 31960, lr = 0.01
I0416 18:26:52.670763   977 solver.cpp:221] Iteration 31980, loss = 0.0594087
I0416 18:26:52.670790   977 solver.cpp:236]     Train net output #0: loss = 0.0416175 (* 1 = 0.0416175 loss)
I0416 18:26:52.670795   977 solver.cpp:542] Iteration 31980, lr = 0.01
I0416 18:27:05.576696   977 solver.cpp:316] Iteration 32000, Testing net (#0)
I0416 18:27:17.119408   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 18:27:17.119431   977 solver.cpp:373]     Test net output #1: loss = 0.0375337 (* 1 = 0.0375337 loss)
I0416 18:27:17.791273   977 solver.cpp:221] Iteration 32000, loss = 0.0666264
I0416 18:27:17.791301   977 solver.cpp:236]     Train net output #0: loss = 0.0683266 (* 1 = 0.0683266 loss)
I0416 18:27:17.791306   977 solver.cpp:542] Iteration 32000, lr = 0.01
I0416 18:27:31.340365   977 solver.cpp:221] Iteration 32020, loss = 0.0641048
I0416 18:27:31.340394   977 solver.cpp:236]     Train net output #0: loss = 0.0837854 (* 1 = 0.0837854 loss)
I0416 18:27:31.340399   977 solver.cpp:542] Iteration 32020, lr = 0.01
I0416 18:27:44.909343   977 solver.cpp:221] Iteration 32040, loss = 0.0670471
I0416 18:27:44.909369   977 solver.cpp:236]     Train net output #0: loss = 0.0635191 (* 1 = 0.0635191 loss)
I0416 18:27:44.909374   977 solver.cpp:542] Iteration 32040, lr = 0.01
I0416 18:27:58.458155   977 solver.cpp:221] Iteration 32060, loss = 0.0667918
I0416 18:27:58.458184   977 solver.cpp:236]     Train net output #0: loss = 0.0600138 (* 1 = 0.0600138 loss)
I0416 18:27:58.458189   977 solver.cpp:542] Iteration 32060, lr = 0.01
I0416 18:28:11.999253   977 solver.cpp:221] Iteration 32080, loss = 0.0613177
I0416 18:28:11.999279   977 solver.cpp:236]     Train net output #0: loss = 0.0453999 (* 1 = 0.0453999 loss)
I0416 18:28:11.999284   977 solver.cpp:542] Iteration 32080, lr = 0.01
I0416 18:28:25.537957   977 solver.cpp:221] Iteration 32100, loss = 0.0575356
I0416 18:28:25.537984   977 solver.cpp:236]     Train net output #0: loss = 0.0665193 (* 1 = 0.0665193 loss)
I0416 18:28:25.537989   977 solver.cpp:542] Iteration 32100, lr = 0.01
I0416 18:28:39.057299   977 solver.cpp:221] Iteration 32120, loss = 0.0537379
I0416 18:28:39.057327   977 solver.cpp:236]     Train net output #0: loss = 0.0298808 (* 1 = 0.0298808 loss)
I0416 18:28:39.057330   977 solver.cpp:542] Iteration 32120, lr = 0.01
I0416 18:28:52.576758   977 solver.cpp:221] Iteration 32140, loss = 0.059841
I0416 18:28:52.576786   977 solver.cpp:236]     Train net output #0: loss = 0.0764623 (* 1 = 0.0764623 loss)
I0416 18:28:52.576792   977 solver.cpp:542] Iteration 32140, lr = 0.01
I0416 18:29:06.138387   977 solver.cpp:221] Iteration 32160, loss = 0.0609867
I0416 18:29:06.138416   977 solver.cpp:236]     Train net output #0: loss = 0.0599747 (* 1 = 0.0599747 loss)
I0416 18:29:06.138420   977 solver.cpp:542] Iteration 32160, lr = 0.01
I0416 18:29:19.669667   977 solver.cpp:221] Iteration 32180, loss = 0.0638147
I0416 18:29:19.669695   977 solver.cpp:236]     Train net output #0: loss = 0.0897697 (* 1 = 0.0897697 loss)
I0416 18:29:19.669700   977 solver.cpp:542] Iteration 32180, lr = 0.01
I0416 18:29:32.541584   977 solver.cpp:316] Iteration 32200, Testing net (#0)
I0416 18:29:44.083052   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 18:29:44.083073   977 solver.cpp:373]     Test net output #1: loss = 0.0373274 (* 1 = 0.0373274 loss)
I0416 18:29:44.753125   977 solver.cpp:221] Iteration 32200, loss = 0.0580815
I0416 18:29:44.753154   977 solver.cpp:236]     Train net output #0: loss = 0.0390449 (* 1 = 0.0390449 loss)
I0416 18:29:44.753159   977 solver.cpp:542] Iteration 32200, lr = 0.01
I0416 18:29:58.281180   977 solver.cpp:221] Iteration 32220, loss = 0.064385
I0416 18:29:58.281208   977 solver.cpp:236]     Train net output #0: loss = 0.0657115 (* 1 = 0.0657115 loss)
I0416 18:29:58.281213   977 solver.cpp:542] Iteration 32220, lr = 0.01
I0416 18:30:11.808166   977 solver.cpp:221] Iteration 32240, loss = 0.0678639
I0416 18:30:11.808192   977 solver.cpp:236]     Train net output #0: loss = 0.0704207 (* 1 = 0.0704207 loss)
I0416 18:30:11.808197   977 solver.cpp:542] Iteration 32240, lr = 0.01
I0416 18:30:25.332909   977 solver.cpp:221] Iteration 32260, loss = 0.0643336
I0416 18:30:25.332937   977 solver.cpp:236]     Train net output #0: loss = 0.0565434 (* 1 = 0.0565434 loss)
I0416 18:30:25.332940   977 solver.cpp:542] Iteration 32260, lr = 0.01
I0416 18:30:38.879421   977 solver.cpp:221] Iteration 32280, loss = 0.0688495
I0416 18:30:38.879448   977 solver.cpp:236]     Train net output #0: loss = 0.0685189 (* 1 = 0.0685189 loss)
I0416 18:30:38.879453   977 solver.cpp:542] Iteration 32280, lr = 0.01
I0416 18:30:52.423149   977 solver.cpp:221] Iteration 32300, loss = 0.0570166
I0416 18:30:52.423177   977 solver.cpp:236]     Train net output #0: loss = 0.0693375 (* 1 = 0.0693375 loss)
I0416 18:30:52.423182   977 solver.cpp:542] Iteration 32300, lr = 0.01
I0416 18:31:05.975754   977 solver.cpp:221] Iteration 32320, loss = 0.0606131
I0416 18:31:05.975780   977 solver.cpp:236]     Train net output #0: loss = 0.0971786 (* 1 = 0.0971786 loss)
I0416 18:31:05.975785   977 solver.cpp:542] Iteration 32320, lr = 0.01
I0416 18:31:19.537325   977 solver.cpp:221] Iteration 32340, loss = 0.056972
I0416 18:31:19.537353   977 solver.cpp:236]     Train net output #0: loss = 0.0588631 (* 1 = 0.0588631 loss)
I0416 18:31:19.537356   977 solver.cpp:542] Iteration 32340, lr = 0.01
I0416 18:31:33.090947   977 solver.cpp:221] Iteration 32360, loss = 0.0585355
I0416 18:31:33.090975   977 solver.cpp:236]     Train net output #0: loss = 0.0201368 (* 1 = 0.0201368 loss)
I0416 18:31:33.090981   977 solver.cpp:542] Iteration 32360, lr = 0.01
I0416 18:31:46.644587   977 solver.cpp:221] Iteration 32380, loss = 0.0654074
I0416 18:31:46.644615   977 solver.cpp:236]     Train net output #0: loss = 0.0331509 (* 1 = 0.0331509 loss)
I0416 18:31:46.644620   977 solver.cpp:542] Iteration 32380, lr = 0.01
I0416 18:31:59.518559   977 solver.cpp:316] Iteration 32400, Testing net (#0)
I0416 18:32:11.050691   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 18:32:11.050714   977 solver.cpp:373]     Test net output #1: loss = 0.0379616 (* 1 = 0.0379616 loss)
I0416 18:32:11.719383   977 solver.cpp:221] Iteration 32400, loss = 0.057313
I0416 18:32:11.719411   977 solver.cpp:236]     Train net output #0: loss = 0.061239 (* 1 = 0.061239 loss)
I0416 18:32:11.719418   977 solver.cpp:542] Iteration 32400, lr = 0.01
I0416 18:32:25.302139   977 solver.cpp:221] Iteration 32420, loss = 0.0611908
I0416 18:32:25.302166   977 solver.cpp:236]     Train net output #0: loss = 0.0775354 (* 1 = 0.0775354 loss)
I0416 18:32:25.302171   977 solver.cpp:542] Iteration 32420, lr = 0.01
I0416 18:32:38.865546   977 solver.cpp:221] Iteration 32440, loss = 0.0568437
I0416 18:32:38.865574   977 solver.cpp:236]     Train net output #0: loss = 0.0811318 (* 1 = 0.0811318 loss)
I0416 18:32:38.865579   977 solver.cpp:542] Iteration 32440, lr = 0.01
I0416 18:32:52.403038   977 solver.cpp:221] Iteration 32460, loss = 0.0605612
I0416 18:32:52.403064   977 solver.cpp:236]     Train net output #0: loss = 0.0872172 (* 1 = 0.0872172 loss)
I0416 18:32:52.403069   977 solver.cpp:542] Iteration 32460, lr = 0.01
I0416 18:33:05.951705   977 solver.cpp:221] Iteration 32480, loss = 0.0608144
I0416 18:33:05.951731   977 solver.cpp:236]     Train net output #0: loss = 0.107618 (* 1 = 0.107618 loss)
I0416 18:33:05.951736   977 solver.cpp:542] Iteration 32480, lr = 0.01
I0416 18:33:19.492743   977 solver.cpp:221] Iteration 32500, loss = 0.0667504
I0416 18:33:19.492770   977 solver.cpp:236]     Train net output #0: loss = 0.0697612 (* 1 = 0.0697612 loss)
I0416 18:33:19.492775   977 solver.cpp:542] Iteration 32500, lr = 0.01
I0416 18:33:33.069052   977 solver.cpp:221] Iteration 32520, loss = 0.0589053
I0416 18:33:33.069079   977 solver.cpp:236]     Train net output #0: loss = 0.0239563 (* 1 = 0.0239563 loss)
I0416 18:33:33.069087   977 solver.cpp:542] Iteration 32520, lr = 0.01
I0416 18:33:46.610527   977 solver.cpp:221] Iteration 32540, loss = 0.0626355
I0416 18:33:46.610550   977 solver.cpp:236]     Train net output #0: loss = 0.0642666 (* 1 = 0.0642666 loss)
I0416 18:33:46.610555   977 solver.cpp:542] Iteration 32540, lr = 0.01
I0416 18:34:00.151803   977 solver.cpp:221] Iteration 32560, loss = 0.0581585
I0416 18:34:00.151831   977 solver.cpp:236]     Train net output #0: loss = 0.0594925 (* 1 = 0.0594925 loss)
I0416 18:34:00.151837   977 solver.cpp:542] Iteration 32560, lr = 0.01
I0416 18:34:13.679761   977 solver.cpp:221] Iteration 32580, loss = 0.0635376
I0416 18:34:13.679790   977 solver.cpp:236]     Train net output #0: loss = 0.0580029 (* 1 = 0.0580029 loss)
I0416 18:34:13.679793   977 solver.cpp:542] Iteration 32580, lr = 0.01
I0416 18:34:26.554752   977 solver.cpp:316] Iteration 32600, Testing net (#0)
I0416 18:34:38.085903   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 18:34:38.085925   977 solver.cpp:373]     Test net output #1: loss = 0.0395782 (* 1 = 0.0395782 loss)
I0416 18:34:38.753243   977 solver.cpp:221] Iteration 32600, loss = 0.0675862
I0416 18:34:38.753270   977 solver.cpp:236]     Train net output #0: loss = 0.0620825 (* 1 = 0.0620825 loss)
I0416 18:34:38.753276   977 solver.cpp:542] Iteration 32600, lr = 0.01
I0416 18:34:52.311633   977 solver.cpp:221] Iteration 32620, loss = 0.0544559
I0416 18:34:52.311661   977 solver.cpp:236]     Train net output #0: loss = 0.0985275 (* 1 = 0.0985275 loss)
I0416 18:34:52.311666   977 solver.cpp:542] Iteration 32620, lr = 0.01
I0416 18:35:05.849699   977 solver.cpp:221] Iteration 32640, loss = 0.0520248
I0416 18:35:05.849726   977 solver.cpp:236]     Train net output #0: loss = 0.0273168 (* 1 = 0.0273168 loss)
I0416 18:35:05.849731   977 solver.cpp:542] Iteration 32640, lr = 0.01
I0416 18:35:19.380558   977 solver.cpp:221] Iteration 32660, loss = 0.0639102
I0416 18:35:19.380584   977 solver.cpp:236]     Train net output #0: loss = 0.052586 (* 1 = 0.052586 loss)
I0416 18:35:19.380589   977 solver.cpp:542] Iteration 32660, lr = 0.01
I0416 18:35:32.893085   977 solver.cpp:221] Iteration 32680, loss = 0.0591664
I0416 18:35:32.893112   977 solver.cpp:236]     Train net output #0: loss = 0.0436102 (* 1 = 0.0436102 loss)
I0416 18:35:32.893117   977 solver.cpp:542] Iteration 32680, lr = 0.01
I0416 18:35:46.425931   977 solver.cpp:221] Iteration 32700, loss = 0.0613836
I0416 18:35:46.425958   977 solver.cpp:236]     Train net output #0: loss = 0.058719 (* 1 = 0.058719 loss)
I0416 18:35:46.425962   977 solver.cpp:542] Iteration 32700, lr = 0.01
I0416 18:35:59.942958   977 solver.cpp:221] Iteration 32720, loss = 0.060546
I0416 18:35:59.942986   977 solver.cpp:236]     Train net output #0: loss = 0.042145 (* 1 = 0.042145 loss)
I0416 18:35:59.942991   977 solver.cpp:542] Iteration 32720, lr = 0.01
I0416 18:36:13.497066   977 solver.cpp:221] Iteration 32740, loss = 0.0578076
I0416 18:36:13.497092   977 solver.cpp:236]     Train net output #0: loss = 0.028441 (* 1 = 0.028441 loss)
I0416 18:36:13.497097   977 solver.cpp:542] Iteration 32740, lr = 0.01
I0416 18:36:27.032222   977 solver.cpp:221] Iteration 32760, loss = 0.0587878
I0416 18:36:27.032249   977 solver.cpp:236]     Train net output #0: loss = 0.072765 (* 1 = 0.072765 loss)
I0416 18:36:27.032254   977 solver.cpp:542] Iteration 32760, lr = 0.01
I0416 18:36:40.574554   977 solver.cpp:221] Iteration 32780, loss = 0.0588407
I0416 18:36:40.574581   977 solver.cpp:236]     Train net output #0: loss = 0.113122 (* 1 = 0.113122 loss)
I0416 18:36:40.574586   977 solver.cpp:542] Iteration 32780, lr = 0.01
I0416 18:36:53.442782   977 solver.cpp:316] Iteration 32800, Testing net (#0)
I0416 18:37:04.973708   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 18:37:04.973729   977 solver.cpp:373]     Test net output #1: loss = 0.0385154 (* 1 = 0.0385154 loss)
I0416 18:37:05.642664   977 solver.cpp:221] Iteration 32800, loss = 0.0626037
I0416 18:37:05.642693   977 solver.cpp:236]     Train net output #0: loss = 0.116147 (* 1 = 0.116147 loss)
I0416 18:37:05.642698   977 solver.cpp:542] Iteration 32800, lr = 0.01
I0416 18:37:19.175315   977 solver.cpp:221] Iteration 32820, loss = 0.0631071
I0416 18:37:19.175343   977 solver.cpp:236]     Train net output #0: loss = 0.034435 (* 1 = 0.034435 loss)
I0416 18:37:19.175348   977 solver.cpp:542] Iteration 32820, lr = 0.01
I0416 18:37:32.749835   977 solver.cpp:221] Iteration 32840, loss = 0.0596836
I0416 18:37:32.749863   977 solver.cpp:236]     Train net output #0: loss = 0.0669646 (* 1 = 0.0669646 loss)
I0416 18:37:32.749867   977 solver.cpp:542] Iteration 32840, lr = 0.01
I0416 18:37:46.322176   977 solver.cpp:221] Iteration 32860, loss = 0.0606327
I0416 18:37:46.322204   977 solver.cpp:236]     Train net output #0: loss = 0.0514471 (* 1 = 0.0514471 loss)
I0416 18:37:46.322208   977 solver.cpp:542] Iteration 32860, lr = 0.01
I0416 18:37:59.852749   977 solver.cpp:221] Iteration 32880, loss = 0.05965
I0416 18:37:59.852777   977 solver.cpp:236]     Train net output #0: loss = 0.0900178 (* 1 = 0.0900178 loss)
I0416 18:37:59.852782   977 solver.cpp:542] Iteration 32880, lr = 0.01
I0416 18:38:13.363229   977 solver.cpp:221] Iteration 32900, loss = 0.0599478
I0416 18:38:13.363256   977 solver.cpp:236]     Train net output #0: loss = 0.0590672 (* 1 = 0.0590672 loss)
I0416 18:38:13.363261   977 solver.cpp:542] Iteration 32900, lr = 0.01
I0416 18:38:26.900652   977 solver.cpp:221] Iteration 32920, loss = 0.055495
I0416 18:38:26.900681   977 solver.cpp:236]     Train net output #0: loss = 0.0453644 (* 1 = 0.0453644 loss)
I0416 18:38:26.900684   977 solver.cpp:542] Iteration 32920, lr = 0.01
I0416 18:38:40.415555   977 solver.cpp:221] Iteration 32940, loss = 0.0603992
I0416 18:38:40.415582   977 solver.cpp:236]     Train net output #0: loss = 0.0605623 (* 1 = 0.0605623 loss)
I0416 18:38:40.415587   977 solver.cpp:542] Iteration 32940, lr = 0.01
I0416 18:38:53.941293   977 solver.cpp:221] Iteration 32960, loss = 0.0596184
I0416 18:38:53.941323   977 solver.cpp:236]     Train net output #0: loss = 0.036945 (* 1 = 0.036945 loss)
I0416 18:38:53.941328   977 solver.cpp:542] Iteration 32960, lr = 0.01
I0416 18:39:07.522774   977 solver.cpp:221] Iteration 32980, loss = 0.062762
I0416 18:39:07.522802   977 solver.cpp:236]     Train net output #0: loss = 0.0407983 (* 1 = 0.0407983 loss)
I0416 18:39:07.522807   977 solver.cpp:542] Iteration 32980, lr = 0.01
I0416 18:39:20.411314   977 solver.cpp:316] Iteration 33000, Testing net (#0)
I0416 18:39:31.940660   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:39:31.940682   977 solver.cpp:373]     Test net output #1: loss = 0.0386927 (* 1 = 0.0386927 loss)
I0416 18:39:32.610344   977 solver.cpp:221] Iteration 33000, loss = 0.056509
I0416 18:39:32.610373   977 solver.cpp:236]     Train net output #0: loss = 0.0416949 (* 1 = 0.0416949 loss)
I0416 18:39:32.610378   977 solver.cpp:542] Iteration 33000, lr = 0.01
I0416 18:39:46.162681   977 solver.cpp:221] Iteration 33020, loss = 0.0604525
I0416 18:39:46.162708   977 solver.cpp:236]     Train net output #0: loss = 0.0632323 (* 1 = 0.0632323 loss)
I0416 18:39:46.162714   977 solver.cpp:542] Iteration 33020, lr = 0.01
I0416 18:39:59.695335   977 solver.cpp:221] Iteration 33040, loss = 0.0558387
I0416 18:39:59.695363   977 solver.cpp:236]     Train net output #0: loss = 0.0722056 (* 1 = 0.0722056 loss)
I0416 18:39:59.695368   977 solver.cpp:542] Iteration 33040, lr = 0.01
I0416 18:40:13.224483   977 solver.cpp:221] Iteration 33060, loss = 0.0588375
I0416 18:40:13.224509   977 solver.cpp:236]     Train net output #0: loss = 0.0910626 (* 1 = 0.0910626 loss)
I0416 18:40:13.224514   977 solver.cpp:542] Iteration 33060, lr = 0.01
I0416 18:40:26.788894   977 solver.cpp:221] Iteration 33080, loss = 0.0610518
I0416 18:40:26.788921   977 solver.cpp:236]     Train net output #0: loss = 0.0377757 (* 1 = 0.0377757 loss)
I0416 18:40:26.788926   977 solver.cpp:542] Iteration 33080, lr = 0.01
I0416 18:40:40.364274   977 solver.cpp:221] Iteration 33100, loss = 0.0593963
I0416 18:40:40.364302   977 solver.cpp:236]     Train net output #0: loss = 0.0785061 (* 1 = 0.0785061 loss)
I0416 18:40:40.364307   977 solver.cpp:542] Iteration 33100, lr = 0.01
I0416 18:40:53.899899   977 solver.cpp:221] Iteration 33120, loss = 0.0619634
I0416 18:40:53.899926   977 solver.cpp:236]     Train net output #0: loss = 0.0358744 (* 1 = 0.0358744 loss)
I0416 18:40:53.899931   977 solver.cpp:542] Iteration 33120, lr = 0.01
I0416 18:41:07.416638   977 solver.cpp:221] Iteration 33140, loss = 0.0647566
I0416 18:41:07.416664   977 solver.cpp:236]     Train net output #0: loss = 0.0761769 (* 1 = 0.0761769 loss)
I0416 18:41:07.416669   977 solver.cpp:542] Iteration 33140, lr = 0.01
I0416 18:41:20.936851   977 solver.cpp:221] Iteration 33160, loss = 0.0601231
I0416 18:41:20.936879   977 solver.cpp:236]     Train net output #0: loss = 0.0695794 (* 1 = 0.0695794 loss)
I0416 18:41:20.936884   977 solver.cpp:542] Iteration 33160, lr = 0.01
I0416 18:41:34.460948   977 solver.cpp:221] Iteration 33180, loss = 0.058284
I0416 18:41:34.460975   977 solver.cpp:236]     Train net output #0: loss = 0.0341466 (* 1 = 0.0341466 loss)
I0416 18:41:34.460981   977 solver.cpp:542] Iteration 33180, lr = 0.01
I0416 18:41:47.330016   977 solver.cpp:316] Iteration 33200, Testing net (#0)
I0416 18:41:58.869438   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 18:41:58.869460   977 solver.cpp:373]     Test net output #1: loss = 0.0419268 (* 1 = 0.0419268 loss)
I0416 18:41:59.540824   977 solver.cpp:221] Iteration 33200, loss = 0.0565241
I0416 18:41:59.540851   977 solver.cpp:236]     Train net output #0: loss = 0.0427957 (* 1 = 0.0427957 loss)
I0416 18:41:59.540856   977 solver.cpp:542] Iteration 33200, lr = 0.01
I0416 18:42:13.073940   977 solver.cpp:221] Iteration 33220, loss = 0.0573768
I0416 18:42:13.073967   977 solver.cpp:236]     Train net output #0: loss = 0.0354418 (* 1 = 0.0354418 loss)
I0416 18:42:13.073972   977 solver.cpp:542] Iteration 33220, lr = 0.01
I0416 18:42:26.615056   977 solver.cpp:221] Iteration 33240, loss = 0.0559777
I0416 18:42:26.615083   977 solver.cpp:236]     Train net output #0: loss = 0.0529122 (* 1 = 0.0529122 loss)
I0416 18:42:26.615088   977 solver.cpp:542] Iteration 33240, lr = 0.01
I0416 18:42:40.166914   977 solver.cpp:221] Iteration 33260, loss = 0.0585387
I0416 18:42:40.166941   977 solver.cpp:236]     Train net output #0: loss = 0.0344232 (* 1 = 0.0344232 loss)
I0416 18:42:40.166946   977 solver.cpp:542] Iteration 33260, lr = 0.01
I0416 18:42:53.705701   977 solver.cpp:221] Iteration 33280, loss = 0.0585347
I0416 18:42:53.705729   977 solver.cpp:236]     Train net output #0: loss = 0.0643564 (* 1 = 0.0643564 loss)
I0416 18:42:53.705734   977 solver.cpp:542] Iteration 33280, lr = 0.01
I0416 18:43:07.253657   977 solver.cpp:221] Iteration 33300, loss = 0.0627895
I0416 18:43:07.253685   977 solver.cpp:236]     Train net output #0: loss = 0.0423598 (* 1 = 0.0423598 loss)
I0416 18:43:07.253690   977 solver.cpp:542] Iteration 33300, lr = 0.01
I0416 18:43:20.803424   977 solver.cpp:221] Iteration 33320, loss = 0.062802
I0416 18:43:20.803453   977 solver.cpp:236]     Train net output #0: loss = 0.0247318 (* 1 = 0.0247318 loss)
I0416 18:43:20.803458   977 solver.cpp:542] Iteration 33320, lr = 0.01
I0416 18:43:34.379868   977 solver.cpp:221] Iteration 33340, loss = 0.0604777
I0416 18:43:34.379895   977 solver.cpp:236]     Train net output #0: loss = 0.0483437 (* 1 = 0.0483437 loss)
I0416 18:43:34.379900   977 solver.cpp:542] Iteration 33340, lr = 0.01
I0416 18:43:47.911785   977 solver.cpp:221] Iteration 33360, loss = 0.0587231
I0416 18:43:47.911813   977 solver.cpp:236]     Train net output #0: loss = 0.0867549 (* 1 = 0.0867549 loss)
I0416 18:43:47.911816   977 solver.cpp:542] Iteration 33360, lr = 0.01
I0416 18:44:01.426424   977 solver.cpp:221] Iteration 33380, loss = 0.0584852
I0416 18:44:01.426450   977 solver.cpp:236]     Train net output #0: loss = 0.0479615 (* 1 = 0.0479615 loss)
I0416 18:44:01.426455   977 solver.cpp:542] Iteration 33380, lr = 0.01
I0416 18:44:14.282557   977 solver.cpp:316] Iteration 33400, Testing net (#0)
I0416 18:44:25.812072   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 18:44:25.812093   977 solver.cpp:373]     Test net output #1: loss = 0.0395317 (* 1 = 0.0395317 loss)
I0416 18:44:26.481554   977 solver.cpp:221] Iteration 33400, loss = 0.0552964
I0416 18:44:26.481582   977 solver.cpp:236]     Train net output #0: loss = 0.0588502 (* 1 = 0.0588502 loss)
I0416 18:44:26.481588   977 solver.cpp:542] Iteration 33400, lr = 0.01
I0416 18:44:40.034770   977 solver.cpp:221] Iteration 33420, loss = 0.0608612
I0416 18:44:40.034796   977 solver.cpp:236]     Train net output #0: loss = 0.0692786 (* 1 = 0.0692786 loss)
I0416 18:44:40.034801   977 solver.cpp:542] Iteration 33420, lr = 0.01
I0416 18:44:53.596037   977 solver.cpp:221] Iteration 33440, loss = 0.0602662
I0416 18:44:53.596065   977 solver.cpp:236]     Train net output #0: loss = 0.0786907 (* 1 = 0.0786907 loss)
I0416 18:44:53.596070   977 solver.cpp:542] Iteration 33440, lr = 0.01
I0416 18:45:07.151803   977 solver.cpp:221] Iteration 33460, loss = 0.0536035
I0416 18:45:07.151831   977 solver.cpp:236]     Train net output #0: loss = 0.0836025 (* 1 = 0.0836025 loss)
I0416 18:45:07.151836   977 solver.cpp:542] Iteration 33460, lr = 0.01
I0416 18:45:20.674706   977 solver.cpp:221] Iteration 33480, loss = 0.0577847
I0416 18:45:20.674736   977 solver.cpp:236]     Train net output #0: loss = 0.083971 (* 1 = 0.083971 loss)
I0416 18:45:20.674739   977 solver.cpp:542] Iteration 33480, lr = 0.01
I0416 18:45:34.241808   977 solver.cpp:221] Iteration 33500, loss = 0.0586316
I0416 18:45:34.241837   977 solver.cpp:236]     Train net output #0: loss = 0.065588 (* 1 = 0.065588 loss)
I0416 18:45:34.241842   977 solver.cpp:542] Iteration 33500, lr = 0.01
I0416 18:45:47.781424   977 solver.cpp:221] Iteration 33520, loss = 0.0601704
I0416 18:45:47.781450   977 solver.cpp:236]     Train net output #0: loss = 0.0832992 (* 1 = 0.0832992 loss)
I0416 18:45:47.781455   977 solver.cpp:542] Iteration 33520, lr = 0.01
I0416 18:46:01.325952   977 solver.cpp:221] Iteration 33540, loss = 0.0679834
I0416 18:46:01.325979   977 solver.cpp:236]     Train net output #0: loss = 0.110699 (* 1 = 0.110699 loss)
I0416 18:46:01.325984   977 solver.cpp:542] Iteration 33540, lr = 0.01
I0416 18:46:14.875910   977 solver.cpp:221] Iteration 33560, loss = 0.0617082
I0416 18:46:14.875937   977 solver.cpp:236]     Train net output #0: loss = 0.0433774 (* 1 = 0.0433774 loss)
I0416 18:46:14.875942   977 solver.cpp:542] Iteration 33560, lr = 0.01
I0416 18:46:28.399104   977 solver.cpp:221] Iteration 33580, loss = 0.0591205
I0416 18:46:28.399132   977 solver.cpp:236]     Train net output #0: loss = 0.0497687 (* 1 = 0.0497687 loss)
I0416 18:46:28.399137   977 solver.cpp:542] Iteration 33580, lr = 0.01
I0416 18:46:41.267047   977 solver.cpp:316] Iteration 33600, Testing net (#0)
I0416 18:46:52.796769   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 18:46:52.796792   977 solver.cpp:373]     Test net output #1: loss = 0.03964 (* 1 = 0.03964 loss)
I0416 18:46:53.464251   977 solver.cpp:221] Iteration 33600, loss = 0.0556153
I0416 18:46:53.464279   977 solver.cpp:236]     Train net output #0: loss = 0.0305087 (* 1 = 0.0305087 loss)
I0416 18:46:53.464283   977 solver.cpp:542] Iteration 33600, lr = 0.01
I0416 18:47:07.003631   977 solver.cpp:221] Iteration 33620, loss = 0.0631348
I0416 18:47:07.003659   977 solver.cpp:236]     Train net output #0: loss = 0.0462491 (* 1 = 0.0462491 loss)
I0416 18:47:07.003664   977 solver.cpp:542] Iteration 33620, lr = 0.01
I0416 18:47:20.548985   977 solver.cpp:221] Iteration 33640, loss = 0.0591486
I0416 18:47:20.549011   977 solver.cpp:236]     Train net output #0: loss = 0.0521578 (* 1 = 0.0521578 loss)
I0416 18:47:20.549016   977 solver.cpp:542] Iteration 33640, lr = 0.01
I0416 18:47:34.098606   977 solver.cpp:221] Iteration 33660, loss = 0.0570339
I0416 18:47:34.098634   977 solver.cpp:236]     Train net output #0: loss = 0.0816513 (* 1 = 0.0816513 loss)
I0416 18:47:34.098640   977 solver.cpp:542] Iteration 33660, lr = 0.01
I0416 18:47:47.635470   977 solver.cpp:221] Iteration 33680, loss = 0.0552943
I0416 18:47:47.635498   977 solver.cpp:236]     Train net output #0: loss = 0.0717486 (* 1 = 0.0717486 loss)
I0416 18:47:47.635502   977 solver.cpp:542] Iteration 33680, lr = 0.01
I0416 18:48:01.178374   977 solver.cpp:221] Iteration 33700, loss = 0.0605099
I0416 18:48:01.178400   977 solver.cpp:236]     Train net output #0: loss = 0.0629986 (* 1 = 0.0629986 loss)
I0416 18:48:01.178406   977 solver.cpp:542] Iteration 33700, lr = 0.01
I0416 18:48:14.694385   977 solver.cpp:221] Iteration 33720, loss = 0.0580663
I0416 18:48:14.694411   977 solver.cpp:236]     Train net output #0: loss = 0.0406961 (* 1 = 0.0406961 loss)
I0416 18:48:14.694416   977 solver.cpp:542] Iteration 33720, lr = 0.01
I0416 18:48:28.218663   977 solver.cpp:221] Iteration 33740, loss = 0.0648364
I0416 18:48:28.218690   977 solver.cpp:236]     Train net output #0: loss = 0.0546482 (* 1 = 0.0546482 loss)
I0416 18:48:28.218695   977 solver.cpp:542] Iteration 33740, lr = 0.01
I0416 18:48:41.787462   977 solver.cpp:221] Iteration 33760, loss = 0.0647106
I0416 18:48:41.787490   977 solver.cpp:236]     Train net output #0: loss = 0.0601046 (* 1 = 0.0601046 loss)
I0416 18:48:41.787495   977 solver.cpp:542] Iteration 33760, lr = 0.01
I0416 18:48:55.351976   977 solver.cpp:221] Iteration 33780, loss = 0.0587088
I0416 18:48:55.352005   977 solver.cpp:236]     Train net output #0: loss = 0.11067 (* 1 = 0.11067 loss)
I0416 18:48:55.352008   977 solver.cpp:542] Iteration 33780, lr = 0.01
I0416 18:49:08.221580   977 solver.cpp:316] Iteration 33800, Testing net (#0)
I0416 18:49:19.763157   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:49:19.763180   977 solver.cpp:373]     Test net output #1: loss = 0.0419713 (* 1 = 0.0419713 loss)
I0416 18:49:20.433120   977 solver.cpp:221] Iteration 33800, loss = 0.0601953
I0416 18:49:20.433148   977 solver.cpp:236]     Train net output #0: loss = 0.0689647 (* 1 = 0.0689647 loss)
I0416 18:49:20.433153   977 solver.cpp:542] Iteration 33800, lr = 0.01
I0416 18:49:33.949004   977 solver.cpp:221] Iteration 33820, loss = 0.059215
I0416 18:49:33.949033   977 solver.cpp:236]     Train net output #0: loss = 0.0662306 (* 1 = 0.0662306 loss)
I0416 18:49:33.949038   977 solver.cpp:542] Iteration 33820, lr = 0.01
I0416 18:49:47.474723   977 solver.cpp:221] Iteration 33840, loss = 0.06404
I0416 18:49:47.474751   977 solver.cpp:236]     Train net output #0: loss = 0.0584558 (* 1 = 0.0584558 loss)
I0416 18:49:47.474756   977 solver.cpp:542] Iteration 33840, lr = 0.01
I0416 18:50:00.999331   977 solver.cpp:221] Iteration 33860, loss = 0.0656853
I0416 18:50:00.999359   977 solver.cpp:236]     Train net output #0: loss = 0.070446 (* 1 = 0.070446 loss)
I0416 18:50:00.999366   977 solver.cpp:542] Iteration 33860, lr = 0.01
I0416 18:50:14.537250   977 solver.cpp:221] Iteration 33880, loss = 0.0510729
I0416 18:50:14.537276   977 solver.cpp:236]     Train net output #0: loss = 0.0358862 (* 1 = 0.0358862 loss)
I0416 18:50:14.537281   977 solver.cpp:542] Iteration 33880, lr = 0.01
I0416 18:50:28.090276   977 solver.cpp:221] Iteration 33900, loss = 0.0582797
I0416 18:50:28.090303   977 solver.cpp:236]     Train net output #0: loss = 0.0656013 (* 1 = 0.0656013 loss)
I0416 18:50:28.090307   977 solver.cpp:542] Iteration 33900, lr = 0.01
I0416 18:50:41.635200   977 solver.cpp:221] Iteration 33920, loss = 0.0683146
I0416 18:50:41.635227   977 solver.cpp:236]     Train net output #0: loss = 0.0470381 (* 1 = 0.0470381 loss)
I0416 18:50:41.635232   977 solver.cpp:542] Iteration 33920, lr = 0.01
I0416 18:50:55.176110   977 solver.cpp:221] Iteration 33940, loss = 0.0611701
I0416 18:50:55.176136   977 solver.cpp:236]     Train net output #0: loss = 0.0662501 (* 1 = 0.0662501 loss)
I0416 18:50:55.176141   977 solver.cpp:542] Iteration 33940, lr = 0.01
I0416 18:51:08.719786   977 solver.cpp:221] Iteration 33960, loss = 0.0643637
I0416 18:51:08.719813   977 solver.cpp:236]     Train net output #0: loss = 0.0998624 (* 1 = 0.0998624 loss)
I0416 18:51:08.719818   977 solver.cpp:542] Iteration 33960, lr = 0.01
I0416 18:51:22.279289   977 solver.cpp:221] Iteration 33980, loss = 0.0576652
I0416 18:51:22.279316   977 solver.cpp:236]     Train net output #0: loss = 0.0878162 (* 1 = 0.0878162 loss)
I0416 18:51:22.279321   977 solver.cpp:542] Iteration 33980, lr = 0.01
I0416 18:51:35.161803   977 solver.cpp:316] Iteration 34000, Testing net (#0)
I0416 18:51:46.693207   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 18:51:46.693228   977 solver.cpp:373]     Test net output #1: loss = 0.0389391 (* 1 = 0.0389391 loss)
I0416 18:51:47.361932   977 solver.cpp:221] Iteration 34000, loss = 0.0555423
I0416 18:51:47.361959   977 solver.cpp:236]     Train net output #0: loss = 0.0365105 (* 1 = 0.0365105 loss)
I0416 18:51:47.361963   977 solver.cpp:542] Iteration 34000, lr = 0.01
I0416 18:52:00.878317   977 solver.cpp:221] Iteration 34020, loss = 0.0603062
I0416 18:52:00.878345   977 solver.cpp:236]     Train net output #0: loss = 0.0543487 (* 1 = 0.0543487 loss)
I0416 18:52:00.878350   977 solver.cpp:542] Iteration 34020, lr = 0.01
I0416 18:52:14.404608   977 solver.cpp:221] Iteration 34040, loss = 0.0578101
I0416 18:52:14.404635   977 solver.cpp:236]     Train net output #0: loss = 0.0646051 (* 1 = 0.0646051 loss)
I0416 18:52:14.404640   977 solver.cpp:542] Iteration 34040, lr = 0.01
I0416 18:52:27.945214   977 solver.cpp:221] Iteration 34060, loss = 0.0589195
I0416 18:52:27.945241   977 solver.cpp:236]     Train net output #0: loss = 0.0473626 (* 1 = 0.0473626 loss)
I0416 18:52:27.945246   977 solver.cpp:542] Iteration 34060, lr = 0.01
I0416 18:52:41.494570   977 solver.cpp:221] Iteration 34080, loss = 0.0532211
I0416 18:52:41.494596   977 solver.cpp:236]     Train net output #0: loss = 0.047338 (* 1 = 0.047338 loss)
I0416 18:52:41.494601   977 solver.cpp:542] Iteration 34080, lr = 0.01
I0416 18:52:55.027492   977 solver.cpp:221] Iteration 34100, loss = 0.0574051
I0416 18:52:55.027518   977 solver.cpp:236]     Train net output #0: loss = 0.0990195 (* 1 = 0.0990195 loss)
I0416 18:52:55.027523   977 solver.cpp:542] Iteration 34100, lr = 0.01
I0416 18:53:08.552692   977 solver.cpp:221] Iteration 34120, loss = 0.0602177
I0416 18:53:08.552721   977 solver.cpp:236]     Train net output #0: loss = 0.0743836 (* 1 = 0.0743836 loss)
I0416 18:53:08.552726   977 solver.cpp:542] Iteration 34120, lr = 0.01
I0416 18:53:22.075538   977 solver.cpp:221] Iteration 34140, loss = 0.0628293
I0416 18:53:22.075565   977 solver.cpp:236]     Train net output #0: loss = 0.0827669 (* 1 = 0.0827669 loss)
I0416 18:53:22.075570   977 solver.cpp:542] Iteration 34140, lr = 0.01
I0416 18:53:35.633893   977 solver.cpp:221] Iteration 34160, loss = 0.0603967
I0416 18:53:35.633921   977 solver.cpp:236]     Train net output #0: loss = 0.0937428 (* 1 = 0.0937428 loss)
I0416 18:53:35.633926   977 solver.cpp:542] Iteration 34160, lr = 0.01
I0416 18:53:49.183185   977 solver.cpp:221] Iteration 34180, loss = 0.059656
I0416 18:53:49.183213   977 solver.cpp:236]     Train net output #0: loss = 0.0686041 (* 1 = 0.0686041 loss)
I0416 18:53:49.183218   977 solver.cpp:542] Iteration 34180, lr = 0.01
I0416 18:54:02.057503   977 solver.cpp:316] Iteration 34200, Testing net (#0)
I0416 18:54:13.598526   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 18:54:13.598547   977 solver.cpp:373]     Test net output #1: loss = 0.0396281 (* 1 = 0.0396281 loss)
I0416 18:54:14.268765   977 solver.cpp:221] Iteration 34200, loss = 0.0608142
I0416 18:54:14.268793   977 solver.cpp:236]     Train net output #0: loss = 0.0860796 (* 1 = 0.0860796 loss)
I0416 18:54:14.268798   977 solver.cpp:542] Iteration 34200, lr = 0.01
I0416 18:54:27.797384   977 solver.cpp:221] Iteration 34220, loss = 0.0577706
I0416 18:54:27.797410   977 solver.cpp:236]     Train net output #0: loss = 0.0616904 (* 1 = 0.0616904 loss)
I0416 18:54:27.797415   977 solver.cpp:542] Iteration 34220, lr = 0.01
I0416 18:54:41.370929   977 solver.cpp:221] Iteration 34240, loss = 0.0570412
I0416 18:54:41.370955   977 solver.cpp:236]     Train net output #0: loss = 0.0721132 (* 1 = 0.0721132 loss)
I0416 18:54:41.370960   977 solver.cpp:542] Iteration 34240, lr = 0.01
I0416 18:54:54.920662   977 solver.cpp:221] Iteration 34260, loss = 0.0590795
I0416 18:54:54.920691   977 solver.cpp:236]     Train net output #0: loss = 0.0601704 (* 1 = 0.0601704 loss)
I0416 18:54:54.920696   977 solver.cpp:542] Iteration 34260, lr = 0.01
I0416 18:55:08.439898   977 solver.cpp:221] Iteration 34280, loss = 0.0547782
I0416 18:55:08.439924   977 solver.cpp:236]     Train net output #0: loss = 0.0621932 (* 1 = 0.0621932 loss)
I0416 18:55:08.439929   977 solver.cpp:542] Iteration 34280, lr = 0.01
I0416 18:55:21.963058   977 solver.cpp:221] Iteration 34300, loss = 0.0529343
I0416 18:55:21.963086   977 solver.cpp:236]     Train net output #0: loss = 0.031102 (* 1 = 0.031102 loss)
I0416 18:55:21.963090   977 solver.cpp:542] Iteration 34300, lr = 0.01
I0416 18:55:35.473167   977 solver.cpp:221] Iteration 34320, loss = 0.0568387
I0416 18:55:35.473196   977 solver.cpp:236]     Train net output #0: loss = 0.049213 (* 1 = 0.049213 loss)
I0416 18:55:35.473201   977 solver.cpp:542] Iteration 34320, lr = 0.01
I0416 18:55:48.993394   977 solver.cpp:221] Iteration 34340, loss = 0.0642004
I0416 18:55:48.993422   977 solver.cpp:236]     Train net output #0: loss = 0.0745186 (* 1 = 0.0745186 loss)
I0416 18:55:48.993427   977 solver.cpp:542] Iteration 34340, lr = 0.01
I0416 18:56:02.527812   977 solver.cpp:221] Iteration 34360, loss = 0.0625242
I0416 18:56:02.527838   977 solver.cpp:236]     Train net output #0: loss = 0.0689934 (* 1 = 0.0689934 loss)
I0416 18:56:02.527843   977 solver.cpp:542] Iteration 34360, lr = 0.01
I0416 18:56:16.050312   977 solver.cpp:221] Iteration 34380, loss = 0.061812
I0416 18:56:16.050339   977 solver.cpp:236]     Train net output #0: loss = 0.0699726 (* 1 = 0.0699726 loss)
I0416 18:56:16.050343   977 solver.cpp:542] Iteration 34380, lr = 0.01
I0416 18:56:28.927183   977 solver.cpp:316] Iteration 34400, Testing net (#0)
I0416 18:56:40.470157   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 18:56:40.470178   977 solver.cpp:373]     Test net output #1: loss = 0.0412664 (* 1 = 0.0412664 loss)
I0416 18:56:41.139911   977 solver.cpp:221] Iteration 34400, loss = 0.0602205
I0416 18:56:41.139938   977 solver.cpp:236]     Train net output #0: loss = 0.0326559 (* 1 = 0.0326559 loss)
I0416 18:56:41.139943   977 solver.cpp:542] Iteration 34400, lr = 0.01
I0416 18:56:54.657066   977 solver.cpp:221] Iteration 34420, loss = 0.0639945
I0416 18:56:54.657094   977 solver.cpp:236]     Train net output #0: loss = 0.0474078 (* 1 = 0.0474078 loss)
I0416 18:56:54.657099   977 solver.cpp:542] Iteration 34420, lr = 0.01
I0416 18:57:08.172205   977 solver.cpp:221] Iteration 34440, loss = 0.0555939
I0416 18:57:08.172232   977 solver.cpp:236]     Train net output #0: loss = 0.0544388 (* 1 = 0.0544388 loss)
I0416 18:57:08.172237   977 solver.cpp:542] Iteration 34440, lr = 0.01
I0416 18:57:21.706135   977 solver.cpp:221] Iteration 34460, loss = 0.0603579
I0416 18:57:21.706162   977 solver.cpp:236]     Train net output #0: loss = 0.0733268 (* 1 = 0.0733268 loss)
I0416 18:57:21.706166   977 solver.cpp:542] Iteration 34460, lr = 0.01
I0416 18:57:35.226861   977 solver.cpp:221] Iteration 34480, loss = 0.0509448
I0416 18:57:35.226887   977 solver.cpp:236]     Train net output #0: loss = 0.0368068 (* 1 = 0.0368068 loss)
I0416 18:57:35.226892   977 solver.cpp:542] Iteration 34480, lr = 0.01
I0416 18:57:48.769374   977 solver.cpp:221] Iteration 34500, loss = 0.0564482
I0416 18:57:48.769402   977 solver.cpp:236]     Train net output #0: loss = 0.0410345 (* 1 = 0.0410345 loss)
I0416 18:57:48.769407   977 solver.cpp:542] Iteration 34500, lr = 0.01
I0416 18:58:02.311838   977 solver.cpp:221] Iteration 34520, loss = 0.0529523
I0416 18:58:02.311866   977 solver.cpp:236]     Train net output #0: loss = 0.046839 (* 1 = 0.046839 loss)
I0416 18:58:02.311871   977 solver.cpp:542] Iteration 34520, lr = 0.01
I0416 18:58:15.829589   977 solver.cpp:221] Iteration 34540, loss = 0.0579545
I0416 18:58:15.829617   977 solver.cpp:236]     Train net output #0: loss = 0.0707384 (* 1 = 0.0707384 loss)
I0416 18:58:15.829622   977 solver.cpp:542] Iteration 34540, lr = 0.01
I0416 18:58:29.372608   977 solver.cpp:221] Iteration 34560, loss = 0.0627791
I0416 18:58:29.372635   977 solver.cpp:236]     Train net output #0: loss = 0.0608834 (* 1 = 0.0608834 loss)
I0416 18:58:29.372639   977 solver.cpp:542] Iteration 34560, lr = 0.01
I0416 18:58:42.882721   977 solver.cpp:221] Iteration 34580, loss = 0.0600637
I0416 18:58:42.882748   977 solver.cpp:236]     Train net output #0: loss = 0.0614877 (* 1 = 0.0614877 loss)
I0416 18:58:42.882753   977 solver.cpp:542] Iteration 34580, lr = 0.01
I0416 18:58:55.756247   977 solver.cpp:316] Iteration 34600, Testing net (#0)
I0416 18:59:07.289144   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 18:59:07.289165   977 solver.cpp:373]     Test net output #1: loss = 0.0385961 (* 1 = 0.0385961 loss)
I0416 18:59:07.958369   977 solver.cpp:221] Iteration 34600, loss = 0.0648885
I0416 18:59:07.958396   977 solver.cpp:236]     Train net output #0: loss = 0.0414577 (* 1 = 0.0414577 loss)
I0416 18:59:07.958401   977 solver.cpp:542] Iteration 34600, lr = 0.01
I0416 18:59:21.523743   977 solver.cpp:221] Iteration 34620, loss = 0.0585197
I0416 18:59:21.523772   977 solver.cpp:236]     Train net output #0: loss = 0.0541557 (* 1 = 0.0541557 loss)
I0416 18:59:21.523775   977 solver.cpp:542] Iteration 34620, lr = 0.01
I0416 18:59:35.069986   977 solver.cpp:221] Iteration 34640, loss = 0.0560339
I0416 18:59:35.070013   977 solver.cpp:236]     Train net output #0: loss = 0.03571 (* 1 = 0.03571 loss)
I0416 18:59:35.070019   977 solver.cpp:542] Iteration 34640, lr = 0.01
I0416 18:59:48.603828   977 solver.cpp:221] Iteration 34660, loss = 0.0561686
I0416 18:59:48.603855   977 solver.cpp:236]     Train net output #0: loss = 0.0607217 (* 1 = 0.0607217 loss)
I0416 18:59:48.603860   977 solver.cpp:542] Iteration 34660, lr = 0.01
I0416 19:00:02.127490   977 solver.cpp:221] Iteration 34680, loss = 0.0620666
I0416 19:00:02.127518   977 solver.cpp:236]     Train net output #0: loss = 0.0540434 (* 1 = 0.0540434 loss)
I0416 19:00:02.127523   977 solver.cpp:542] Iteration 34680, lr = 0.01
I0416 19:00:15.636986   977 solver.cpp:221] Iteration 34700, loss = 0.0532652
I0416 19:00:15.637013   977 solver.cpp:236]     Train net output #0: loss = 0.0648099 (* 1 = 0.0648099 loss)
I0416 19:00:15.637018   977 solver.cpp:542] Iteration 34700, lr = 0.01
I0416 19:00:29.165962   977 solver.cpp:221] Iteration 34720, loss = 0.0560345
I0416 19:00:29.165990   977 solver.cpp:236]     Train net output #0: loss = 0.0511245 (* 1 = 0.0511245 loss)
I0416 19:00:29.165995   977 solver.cpp:542] Iteration 34720, lr = 0.01
I0416 19:00:42.691889   977 solver.cpp:221] Iteration 34740, loss = 0.0563466
I0416 19:00:42.691916   977 solver.cpp:236]     Train net output #0: loss = 0.0453031 (* 1 = 0.0453031 loss)
I0416 19:00:42.691922   977 solver.cpp:542] Iteration 34740, lr = 0.01
I0416 19:00:56.234056   977 solver.cpp:221] Iteration 34760, loss = 0.0570264
I0416 19:00:56.234084   977 solver.cpp:236]     Train net output #0: loss = 0.0830114 (* 1 = 0.0830114 loss)
I0416 19:00:56.234088   977 solver.cpp:542] Iteration 34760, lr = 0.01
I0416 19:01:09.758641   977 solver.cpp:221] Iteration 34780, loss = 0.0609117
I0416 19:01:09.758669   977 solver.cpp:236]     Train net output #0: loss = 0.0452077 (* 1 = 0.0452077 loss)
I0416 19:01:09.758674   977 solver.cpp:542] Iteration 34780, lr = 0.01
I0416 19:01:22.629796   977 solver.cpp:316] Iteration 34800, Testing net (#0)
I0416 19:01:34.172291   977 solver.cpp:373]     Test net output #0: accuracy = 0.992395
I0416 19:01:34.172312   977 solver.cpp:373]     Test net output #1: loss = 0.0398248 (* 1 = 0.0398248 loss)
I0416 19:01:34.842736   977 solver.cpp:221] Iteration 34800, loss = 0.0573827
I0416 19:01:34.842764   977 solver.cpp:236]     Train net output #0: loss = 0.0445741 (* 1 = 0.0445741 loss)
I0416 19:01:34.842768   977 solver.cpp:542] Iteration 34800, lr = 0.01
I0416 19:01:48.389454   977 solver.cpp:221] Iteration 34820, loss = 0.0589629
I0416 19:01:48.389482   977 solver.cpp:236]     Train net output #0: loss = 0.0522584 (* 1 = 0.0522584 loss)
I0416 19:01:48.389487   977 solver.cpp:542] Iteration 34820, lr = 0.01
I0416 19:02:01.950971   977 solver.cpp:221] Iteration 34840, loss = 0.056005
I0416 19:02:01.950999   977 solver.cpp:236]     Train net output #0: loss = 0.0252064 (* 1 = 0.0252064 loss)
I0416 19:02:01.951004   977 solver.cpp:542] Iteration 34840, lr = 0.01
I0416 19:02:15.488854   977 solver.cpp:221] Iteration 34860, loss = 0.0531678
I0416 19:02:15.488883   977 solver.cpp:236]     Train net output #0: loss = 0.03114 (* 1 = 0.03114 loss)
I0416 19:02:15.488888   977 solver.cpp:542] Iteration 34860, lr = 0.01
I0416 19:02:29.023664   977 solver.cpp:221] Iteration 34880, loss = 0.0598624
I0416 19:02:29.023692   977 solver.cpp:236]     Train net output #0: loss = 0.0597941 (* 1 = 0.0597941 loss)
I0416 19:02:29.023697   977 solver.cpp:542] Iteration 34880, lr = 0.01
I0416 19:02:42.562448   977 solver.cpp:221] Iteration 34900, loss = 0.0516436
I0416 19:02:42.562476   977 solver.cpp:236]     Train net output #0: loss = 0.048715 (* 1 = 0.048715 loss)
I0416 19:02:42.562481   977 solver.cpp:542] Iteration 34900, lr = 0.01
I0416 19:02:56.103721   977 solver.cpp:221] Iteration 34920, loss = 0.0576361
I0416 19:02:56.103749   977 solver.cpp:236]     Train net output #0: loss = 0.045805 (* 1 = 0.045805 loss)
I0416 19:02:56.103754   977 solver.cpp:542] Iteration 34920, lr = 0.01
I0416 19:03:09.676565   977 solver.cpp:221] Iteration 34940, loss = 0.0577715
I0416 19:03:09.676594   977 solver.cpp:236]     Train net output #0: loss = 0.0613908 (* 1 = 0.0613908 loss)
I0416 19:03:09.676599   977 solver.cpp:542] Iteration 34940, lr = 0.01
I0416 19:03:23.199508   977 solver.cpp:221] Iteration 34960, loss = 0.0638136
I0416 19:03:23.199535   977 solver.cpp:236]     Train net output #0: loss = 0.0786221 (* 1 = 0.0786221 loss)
I0416 19:03:23.199540   977 solver.cpp:542] Iteration 34960, lr = 0.01
I0416 19:03:36.741734   977 solver.cpp:221] Iteration 34980, loss = 0.0594878
I0416 19:03:36.741761   977 solver.cpp:236]     Train net output #0: loss = 0.0442711 (* 1 = 0.0442711 loss)
I0416 19:03:36.741766   977 solver.cpp:542] Iteration 34980, lr = 0.01
I0416 19:03:49.629643   977 solver.cpp:316] Iteration 35000, Testing net (#0)
I0416 19:04:01.171808   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 19:04:01.171830   977 solver.cpp:373]     Test net output #1: loss = 0.0389208 (* 1 = 0.0389208 loss)
I0416 19:04:01.842154   977 solver.cpp:221] Iteration 35000, loss = 0.0569178
I0416 19:04:01.842181   977 solver.cpp:236]     Train net output #0: loss = 0.041196 (* 1 = 0.041196 loss)
I0416 19:04:01.842186   977 solver.cpp:542] Iteration 35000, lr = 0.01
I0416 19:04:15.369393   977 solver.cpp:221] Iteration 35020, loss = 0.061565
I0416 19:04:15.369421   977 solver.cpp:236]     Train net output #0: loss = 0.0616131 (* 1 = 0.0616131 loss)
I0416 19:04:15.369426   977 solver.cpp:542] Iteration 35020, lr = 0.01
I0416 19:04:28.897294   977 solver.cpp:221] Iteration 35040, loss = 0.0540223
I0416 19:04:28.897322   977 solver.cpp:236]     Train net output #0: loss = 0.0337584 (* 1 = 0.0337584 loss)
I0416 19:04:28.897327   977 solver.cpp:542] Iteration 35040, lr = 0.01
I0416 19:04:42.431284   977 solver.cpp:221] Iteration 35060, loss = 0.0574526
I0416 19:04:42.431313   977 solver.cpp:236]     Train net output #0: loss = 0.0871829 (* 1 = 0.0871829 loss)
I0416 19:04:42.431316   977 solver.cpp:542] Iteration 35060, lr = 0.01
I0416 19:04:55.966910   977 solver.cpp:221] Iteration 35080, loss = 0.0608041
I0416 19:04:55.966938   977 solver.cpp:236]     Train net output #0: loss = 0.0677033 (* 1 = 0.0677033 loss)
I0416 19:04:55.966943   977 solver.cpp:542] Iteration 35080, lr = 0.01
I0416 19:05:09.512534   977 solver.cpp:221] Iteration 35100, loss = 0.0597149
I0416 19:05:09.512562   977 solver.cpp:236]     Train net output #0: loss = 0.0345489 (* 1 = 0.0345489 loss)
I0416 19:05:09.512567   977 solver.cpp:542] Iteration 35100, lr = 0.01
I0416 19:05:23.021726   977 solver.cpp:221] Iteration 35120, loss = 0.0585898
I0416 19:05:23.021754   977 solver.cpp:236]     Train net output #0: loss = 0.0311742 (* 1 = 0.0311742 loss)
I0416 19:05:23.021759   977 solver.cpp:542] Iteration 35120, lr = 0.01
I0416 19:05:36.535745   977 solver.cpp:221] Iteration 35140, loss = 0.0539623
I0416 19:05:36.535771   977 solver.cpp:236]     Train net output #0: loss = 0.0781136 (* 1 = 0.0781136 loss)
I0416 19:05:36.535776   977 solver.cpp:542] Iteration 35140, lr = 0.01
I0416 19:05:50.076118   977 solver.cpp:221] Iteration 35160, loss = 0.0571067
I0416 19:05:50.076148   977 solver.cpp:236]     Train net output #0: loss = 0.0470936 (* 1 = 0.0470936 loss)
I0416 19:05:50.076153   977 solver.cpp:542] Iteration 35160, lr = 0.01
I0416 19:06:03.600637   977 solver.cpp:221] Iteration 35180, loss = 0.0565054
I0416 19:06:03.600664   977 solver.cpp:236]     Train net output #0: loss = 0.0495218 (* 1 = 0.0495218 loss)
I0416 19:06:03.600669   977 solver.cpp:542] Iteration 35180, lr = 0.01
I0416 19:06:16.497957   977 solver.cpp:316] Iteration 35200, Testing net (#0)
I0416 19:06:28.041461   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 19:06:28.041482   977 solver.cpp:373]     Test net output #1: loss = 0.0394911 (* 1 = 0.0394911 loss)
I0416 19:06:28.713150   977 solver.cpp:221] Iteration 35200, loss = 0.0609329
I0416 19:06:28.713177   977 solver.cpp:236]     Train net output #0: loss = 0.0386823 (* 1 = 0.0386823 loss)
I0416 19:06:28.713182   977 solver.cpp:542] Iteration 35200, lr = 0.01
I0416 19:06:42.253211   977 solver.cpp:221] Iteration 35220, loss = 0.0532809
I0416 19:06:42.253237   977 solver.cpp:236]     Train net output #0: loss = 0.0529236 (* 1 = 0.0529236 loss)
I0416 19:06:42.253242   977 solver.cpp:542] Iteration 35220, lr = 0.01
I0416 19:06:55.767357   977 solver.cpp:221] Iteration 35240, loss = 0.0586573
I0416 19:06:55.767385   977 solver.cpp:236]     Train net output #0: loss = 0.0485021 (* 1 = 0.0485021 loss)
I0416 19:06:55.767390   977 solver.cpp:542] Iteration 35240, lr = 0.01
I0416 19:07:09.270063   977 solver.cpp:221] Iteration 35260, loss = 0.0502022
I0416 19:07:09.270090   977 solver.cpp:236]     Train net output #0: loss = 0.0560751 (* 1 = 0.0560751 loss)
I0416 19:07:09.270095   977 solver.cpp:542] Iteration 35260, lr = 0.01
I0416 19:07:22.800385   977 solver.cpp:221] Iteration 35280, loss = 0.0562223
I0416 19:07:22.800412   977 solver.cpp:236]     Train net output #0: loss = 0.060336 (* 1 = 0.060336 loss)
I0416 19:07:22.800417   977 solver.cpp:542] Iteration 35280, lr = 0.01
I0416 19:07:36.365602   977 solver.cpp:221] Iteration 35300, loss = 0.0553824
I0416 19:07:36.365628   977 solver.cpp:236]     Train net output #0: loss = 0.0528548 (* 1 = 0.0528548 loss)
I0416 19:07:36.365633   977 solver.cpp:542] Iteration 35300, lr = 0.01
I0416 19:07:49.902672   977 solver.cpp:221] Iteration 35320, loss = 0.0523381
I0416 19:07:49.902698   977 solver.cpp:236]     Train net output #0: loss = 0.0304972 (* 1 = 0.0304972 loss)
I0416 19:07:49.902704   977 solver.cpp:542] Iteration 35320, lr = 0.01
I0416 19:08:03.446537   977 solver.cpp:221] Iteration 35340, loss = 0.0555244
I0416 19:08:03.446564   977 solver.cpp:236]     Train net output #0: loss = 0.059571 (* 1 = 0.059571 loss)
I0416 19:08:03.446568   977 solver.cpp:542] Iteration 35340, lr = 0.01
I0416 19:08:16.999411   977 solver.cpp:221] Iteration 35360, loss = 0.0534286
I0416 19:08:16.999439   977 solver.cpp:236]     Train net output #0: loss = 0.0722822 (* 1 = 0.0722822 loss)
I0416 19:08:16.999444   977 solver.cpp:542] Iteration 35360, lr = 0.01
I0416 19:08:30.567407   977 solver.cpp:221] Iteration 35380, loss = 0.0599492
I0416 19:08:30.567435   977 solver.cpp:236]     Train net output #0: loss = 0.0410421 (* 1 = 0.0410421 loss)
I0416 19:08:30.567440   977 solver.cpp:542] Iteration 35380, lr = 0.01
I0416 19:08:43.469903   977 solver.cpp:316] Iteration 35400, Testing net (#0)
I0416 19:08:55.013419   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 19:08:55.013440   977 solver.cpp:373]     Test net output #1: loss = 0.0376806 (* 1 = 0.0376806 loss)
I0416 19:08:55.683079   977 solver.cpp:221] Iteration 35400, loss = 0.0633104
I0416 19:08:55.683105   977 solver.cpp:236]     Train net output #0: loss = 0.0496027 (* 1 = 0.0496027 loss)
I0416 19:08:55.683110   977 solver.cpp:542] Iteration 35400, lr = 0.01
I0416 19:09:09.210278   977 solver.cpp:221] Iteration 35420, loss = 0.0606934
I0416 19:09:09.210304   977 solver.cpp:236]     Train net output #0: loss = 0.0843825 (* 1 = 0.0843825 loss)
I0416 19:09:09.210309   977 solver.cpp:542] Iteration 35420, lr = 0.01
I0416 19:09:22.739522   977 solver.cpp:221] Iteration 35440, loss = 0.0624942
I0416 19:09:22.739550   977 solver.cpp:236]     Train net output #0: loss = 0.0521232 (* 1 = 0.0521232 loss)
I0416 19:09:22.739554   977 solver.cpp:542] Iteration 35440, lr = 0.01
I0416 19:09:36.253834   977 solver.cpp:221] Iteration 35460, loss = 0.0593241
I0416 19:09:36.253860   977 solver.cpp:236]     Train net output #0: loss = 0.0382231 (* 1 = 0.0382231 loss)
I0416 19:09:36.253865   977 solver.cpp:542] Iteration 35460, lr = 0.01
I0416 19:09:49.813771   977 solver.cpp:221] Iteration 35480, loss = 0.0582879
I0416 19:09:49.813798   977 solver.cpp:236]     Train net output #0: loss = 0.0648488 (* 1 = 0.0648488 loss)
I0416 19:09:49.813802   977 solver.cpp:542] Iteration 35480, lr = 0.01
I0416 19:10:03.364295   977 solver.cpp:221] Iteration 35500, loss = 0.0508767
I0416 19:10:03.364322   977 solver.cpp:236]     Train net output #0: loss = 0.0485603 (* 1 = 0.0485603 loss)
I0416 19:10:03.364327   977 solver.cpp:542] Iteration 35500, lr = 0.01
I0416 19:10:16.929481   977 solver.cpp:221] Iteration 35520, loss = 0.0584052
I0416 19:10:16.929508   977 solver.cpp:236]     Train net output #0: loss = 0.0534698 (* 1 = 0.0534698 loss)
I0416 19:10:16.929512   977 solver.cpp:542] Iteration 35520, lr = 0.01
I0416 19:10:30.490097   977 solver.cpp:221] Iteration 35540, loss = 0.0586239
I0416 19:10:30.490124   977 solver.cpp:236]     Train net output #0: loss = 0.0560887 (* 1 = 0.0560887 loss)
I0416 19:10:30.490128   977 solver.cpp:542] Iteration 35540, lr = 0.01
I0416 19:10:44.038041   977 solver.cpp:221] Iteration 35560, loss = 0.0577946
I0416 19:10:44.038069   977 solver.cpp:236]     Train net output #0: loss = 0.0522015 (* 1 = 0.0522015 loss)
I0416 19:10:44.038074   977 solver.cpp:542] Iteration 35560, lr = 0.01
I0416 19:10:57.551153   977 solver.cpp:221] Iteration 35580, loss = 0.0551001
I0416 19:10:57.551180   977 solver.cpp:236]     Train net output #0: loss = 0.0353785 (* 1 = 0.0353785 loss)
I0416 19:10:57.551185   977 solver.cpp:542] Iteration 35580, lr = 0.01
I0416 19:11:10.411257   977 solver.cpp:316] Iteration 35600, Testing net (#0)
I0416 19:11:21.940755   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 19:11:21.940776   977 solver.cpp:373]     Test net output #1: loss = 0.0377465 (* 1 = 0.0377465 loss)
I0416 19:11:22.607650   977 solver.cpp:221] Iteration 35600, loss = 0.0624512
I0416 19:11:22.607678   977 solver.cpp:236]     Train net output #0: loss = 0.059731 (* 1 = 0.059731 loss)
I0416 19:11:22.607683   977 solver.cpp:542] Iteration 35600, lr = 0.01
I0416 19:11:36.151689   977 solver.cpp:221] Iteration 35620, loss = 0.0582329
I0416 19:11:36.151716   977 solver.cpp:236]     Train net output #0: loss = 0.0304482 (* 1 = 0.0304482 loss)
I0416 19:11:36.151721   977 solver.cpp:542] Iteration 35620, lr = 0.01
I0416 19:11:49.680120   977 solver.cpp:221] Iteration 35640, loss = 0.0609294
I0416 19:11:49.680147   977 solver.cpp:236]     Train net output #0: loss = 0.0523514 (* 1 = 0.0523514 loss)
I0416 19:11:49.680152   977 solver.cpp:542] Iteration 35640, lr = 0.01
I0416 19:12:03.190212   977 solver.cpp:221] Iteration 35660, loss = 0.0587792
I0416 19:12:03.190238   977 solver.cpp:236]     Train net output #0: loss = 0.0468571 (* 1 = 0.0468571 loss)
I0416 19:12:03.190243   977 solver.cpp:542] Iteration 35660, lr = 0.01
I0416 19:12:16.746919   977 solver.cpp:221] Iteration 35680, loss = 0.0579918
I0416 19:12:16.746947   977 solver.cpp:236]     Train net output #0: loss = 0.0399651 (* 1 = 0.0399651 loss)
I0416 19:12:16.746951   977 solver.cpp:542] Iteration 35680, lr = 0.01
I0416 19:12:30.291575   977 solver.cpp:221] Iteration 35700, loss = 0.0584463
I0416 19:12:30.291604   977 solver.cpp:236]     Train net output #0: loss = 0.0950837 (* 1 = 0.0950837 loss)
I0416 19:12:30.291609   977 solver.cpp:542] Iteration 35700, lr = 0.01
I0416 19:12:43.815780   977 solver.cpp:221] Iteration 35720, loss = 0.0590555
I0416 19:12:43.815806   977 solver.cpp:236]     Train net output #0: loss = 0.105261 (* 1 = 0.105261 loss)
I0416 19:12:43.815811   977 solver.cpp:542] Iteration 35720, lr = 0.01
I0416 19:12:57.329735   977 solver.cpp:221] Iteration 35740, loss = 0.0619127
I0416 19:12:57.329761   977 solver.cpp:236]     Train net output #0: loss = 0.0681529 (* 1 = 0.0681529 loss)
I0416 19:12:57.329766   977 solver.cpp:542] Iteration 35740, lr = 0.01
I0416 19:13:10.859329   977 solver.cpp:221] Iteration 35760, loss = 0.0601086
I0416 19:13:10.859357   977 solver.cpp:236]     Train net output #0: loss = 0.0444078 (* 1 = 0.0444078 loss)
I0416 19:13:10.859362   977 solver.cpp:542] Iteration 35760, lr = 0.01
I0416 19:13:24.371598   977 solver.cpp:221] Iteration 35780, loss = 0.0553309
I0416 19:13:24.371624   977 solver.cpp:236]     Train net output #0: loss = 0.0560498 (* 1 = 0.0560498 loss)
I0416 19:13:24.371629   977 solver.cpp:542] Iteration 35780, lr = 0.01
I0416 19:13:37.224632   977 solver.cpp:316] Iteration 35800, Testing net (#0)
I0416 19:13:48.756734   977 solver.cpp:373]     Test net output #0: accuracy = 0.992015
I0416 19:13:48.756755   977 solver.cpp:373]     Test net output #1: loss = 0.0390497 (* 1 = 0.0390497 loss)
I0416 19:13:49.426101   977 solver.cpp:221] Iteration 35800, loss = 0.0569496
I0416 19:13:49.426129   977 solver.cpp:236]     Train net output #0: loss = 0.0629425 (* 1 = 0.0629425 loss)
I0416 19:13:49.426134   977 solver.cpp:542] Iteration 35800, lr = 0.01
I0416 19:14:02.949637   977 solver.cpp:221] Iteration 35820, loss = 0.0591197
I0416 19:14:02.949663   977 solver.cpp:236]     Train net output #0: loss = 0.0259745 (* 1 = 0.0259745 loss)
I0416 19:14:02.949668   977 solver.cpp:542] Iteration 35820, lr = 0.01
I0416 19:14:16.488610   977 solver.cpp:221] Iteration 35840, loss = 0.0575006
I0416 19:14:16.488636   977 solver.cpp:236]     Train net output #0: loss = 0.0464881 (* 1 = 0.0464881 loss)
I0416 19:14:16.488641   977 solver.cpp:542] Iteration 35840, lr = 0.01
I0416 19:14:30.019970   977 solver.cpp:221] Iteration 35860, loss = 0.056988
I0416 19:14:30.019999   977 solver.cpp:236]     Train net output #0: loss = 0.0892901 (* 1 = 0.0892901 loss)
I0416 19:14:30.020002   977 solver.cpp:542] Iteration 35860, lr = 0.01
I0416 19:14:43.549736   977 solver.cpp:221] Iteration 35880, loss = 0.054621
I0416 19:14:43.549764   977 solver.cpp:236]     Train net output #0: loss = 0.0718489 (* 1 = 0.0718489 loss)
I0416 19:14:43.549769   977 solver.cpp:542] Iteration 35880, lr = 0.01
I0416 19:14:57.077272   977 solver.cpp:221] Iteration 35900, loss = 0.0541867
I0416 19:14:57.077301   977 solver.cpp:236]     Train net output #0: loss = 0.0824888 (* 1 = 0.0824888 loss)
I0416 19:14:57.077304   977 solver.cpp:542] Iteration 35900, lr = 0.01
I0416 19:15:10.589920   977 solver.cpp:221] Iteration 35920, loss = 0.0553159
I0416 19:15:10.589947   977 solver.cpp:236]     Train net output #0: loss = 0.0380499 (* 1 = 0.0380499 loss)
I0416 19:15:10.589952   977 solver.cpp:542] Iteration 35920, lr = 0.01
I0416 19:15:24.126757   977 solver.cpp:221] Iteration 35940, loss = 0.0601207
I0416 19:15:24.126783   977 solver.cpp:236]     Train net output #0: loss = 0.0268268 (* 1 = 0.0268268 loss)
I0416 19:15:24.126788   977 solver.cpp:542] Iteration 35940, lr = 0.01
I0416 19:15:37.671478   977 solver.cpp:221] Iteration 35960, loss = 0.0531586
I0416 19:15:37.671506   977 solver.cpp:236]     Train net output #0: loss = 0.0700974 (* 1 = 0.0700974 loss)
I0416 19:15:37.671511   977 solver.cpp:542] Iteration 35960, lr = 0.01
I0416 19:15:51.214079   977 solver.cpp:221] Iteration 35980, loss = 0.0559988
I0416 19:15:51.214107   977 solver.cpp:236]     Train net output #0: loss = 0.0512212 (* 1 = 0.0512212 loss)
I0416 19:15:51.214112   977 solver.cpp:542] Iteration 35980, lr = 0.01
I0416 19:16:04.080651   977 solver.cpp:316] Iteration 36000, Testing net (#0)
I0416 19:16:15.621348   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 19:16:15.621369   977 solver.cpp:373]     Test net output #1: loss = 0.0379676 (* 1 = 0.0379676 loss)
I0416 19:16:16.289314   977 solver.cpp:221] Iteration 36000, loss = 0.0566568
I0416 19:16:16.289340   977 solver.cpp:236]     Train net output #0: loss = 0.0630155 (* 1 = 0.0630155 loss)
I0416 19:16:16.289345   977 solver.cpp:542] Iteration 36000, lr = 0.01
I0416 19:16:29.802503   977 solver.cpp:221] Iteration 36020, loss = 0.0549585
I0416 19:16:29.802531   977 solver.cpp:236]     Train net output #0: loss = 0.0399123 (* 1 = 0.0399123 loss)
I0416 19:16:29.802536   977 solver.cpp:542] Iteration 36020, lr = 0.01
I0416 19:16:43.335611   977 solver.cpp:221] Iteration 36040, loss = 0.0527615
I0416 19:16:43.335639   977 solver.cpp:236]     Train net output #0: loss = 0.0628468 (* 1 = 0.0628468 loss)
I0416 19:16:43.335644   977 solver.cpp:542] Iteration 36040, lr = 0.01
I0416 19:16:56.848695   977 solver.cpp:221] Iteration 36060, loss = 0.0561531
I0416 19:16:56.848731   977 solver.cpp:236]     Train net output #0: loss = 0.0537798 (* 1 = 0.0537798 loss)
I0416 19:16:56.848734   977 solver.cpp:542] Iteration 36060, lr = 0.01
I0416 19:17:10.368490   977 solver.cpp:221] Iteration 36080, loss = 0.0602202
I0416 19:17:10.368518   977 solver.cpp:236]     Train net output #0: loss = 0.0974838 (* 1 = 0.0974838 loss)
I0416 19:17:10.368523   977 solver.cpp:542] Iteration 36080, lr = 0.01
I0416 19:17:23.886471   977 solver.cpp:221] Iteration 36100, loss = 0.0528112
I0416 19:17:23.886498   977 solver.cpp:236]     Train net output #0: loss = 0.0412735 (* 1 = 0.0412735 loss)
I0416 19:17:23.886503   977 solver.cpp:542] Iteration 36100, lr = 0.01
I0416 19:17:37.409240   977 solver.cpp:221] Iteration 36120, loss = 0.0585188
I0416 19:17:37.409266   977 solver.cpp:236]     Train net output #0: loss = 0.0365542 (* 1 = 0.0365542 loss)
I0416 19:17:37.409271   977 solver.cpp:542] Iteration 36120, lr = 0.01
I0416 19:17:50.952579   977 solver.cpp:221] Iteration 36140, loss = 0.0574673
I0416 19:17:50.952607   977 solver.cpp:236]     Train net output #0: loss = 0.0687191 (* 1 = 0.0687191 loss)
I0416 19:17:50.952612   977 solver.cpp:542] Iteration 36140, lr = 0.01
I0416 19:18:04.496852   977 solver.cpp:221] Iteration 36160, loss = 0.0527873
I0416 19:18:04.496879   977 solver.cpp:236]     Train net output #0: loss = 0.0640353 (* 1 = 0.0640353 loss)
I0416 19:18:04.496884   977 solver.cpp:542] Iteration 36160, lr = 0.01
I0416 19:18:18.038090   977 solver.cpp:221] Iteration 36180, loss = 0.0538576
I0416 19:18:18.038118   977 solver.cpp:236]     Train net output #0: loss = 0.0354804 (* 1 = 0.0354804 loss)
I0416 19:18:18.038122   977 solver.cpp:542] Iteration 36180, lr = 0.01
I0416 19:18:30.905769   977 solver.cpp:316] Iteration 36200, Testing net (#0)
I0416 19:18:42.435318   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 19:18:42.435340   977 solver.cpp:373]     Test net output #1: loss = 0.0399577 (* 1 = 0.0399577 loss)
I0416 19:18:43.103960   977 solver.cpp:221] Iteration 36200, loss = 0.0566178
I0416 19:18:43.103989   977 solver.cpp:236]     Train net output #0: loss = 0.0335601 (* 1 = 0.0335601 loss)
I0416 19:18:43.103994   977 solver.cpp:542] Iteration 36200, lr = 0.01
I0416 19:18:56.642366   977 solver.cpp:221] Iteration 36220, loss = 0.0571869
I0416 19:18:56.642393   977 solver.cpp:236]     Train net output #0: loss = 0.0380505 (* 1 = 0.0380505 loss)
I0416 19:18:56.642398   977 solver.cpp:542] Iteration 36220, lr = 0.01
I0416 19:19:10.188155   977 solver.cpp:221] Iteration 36240, loss = 0.0576297
I0416 19:19:10.188184   977 solver.cpp:236]     Train net output #0: loss = 0.0529022 (* 1 = 0.0529022 loss)
I0416 19:19:10.188189   977 solver.cpp:542] Iteration 36240, lr = 0.01
I0416 19:19:23.731636   977 solver.cpp:221] Iteration 36260, loss = 0.0549659
I0416 19:19:23.731662   977 solver.cpp:236]     Train net output #0: loss = 0.0679235 (* 1 = 0.0679235 loss)
I0416 19:19:23.731667   977 solver.cpp:542] Iteration 36260, lr = 0.01
I0416 19:19:37.254271   977 solver.cpp:221] Iteration 36280, loss = 0.0599536
I0416 19:19:37.254299   977 solver.cpp:236]     Train net output #0: loss = 0.0479565 (* 1 = 0.0479565 loss)
I0416 19:19:37.254303   977 solver.cpp:542] Iteration 36280, lr = 0.01
I0416 19:19:50.788785   977 solver.cpp:221] Iteration 36300, loss = 0.0578335
I0416 19:19:50.788813   977 solver.cpp:236]     Train net output #0: loss = 0.0593718 (* 1 = 0.0593718 loss)
I0416 19:19:50.788817   977 solver.cpp:542] Iteration 36300, lr = 0.01
I0416 19:20:04.307832   977 solver.cpp:221] Iteration 36320, loss = 0.05494
I0416 19:20:04.307859   977 solver.cpp:236]     Train net output #0: loss = 0.0808617 (* 1 = 0.0808617 loss)
I0416 19:20:04.307864   977 solver.cpp:542] Iteration 36320, lr = 0.01
I0416 19:20:17.852825   977 solver.cpp:221] Iteration 36340, loss = 0.0521463
I0416 19:20:17.852854   977 solver.cpp:236]     Train net output #0: loss = 0.111459 (* 1 = 0.111459 loss)
I0416 19:20:17.852859   977 solver.cpp:542] Iteration 36340, lr = 0.01
I0416 19:20:31.399430   977 solver.cpp:221] Iteration 36360, loss = 0.0558928
I0416 19:20:31.399456   977 solver.cpp:236]     Train net output #0: loss = 0.0296854 (* 1 = 0.0296854 loss)
I0416 19:20:31.399461   977 solver.cpp:542] Iteration 36360, lr = 0.01
I0416 19:20:44.961575   977 solver.cpp:221] Iteration 36380, loss = 0.0595764
I0416 19:20:44.961602   977 solver.cpp:236]     Train net output #0: loss = 0.0616842 (* 1 = 0.0616842 loss)
I0416 19:20:44.961607   977 solver.cpp:542] Iteration 36380, lr = 0.01
I0416 19:20:57.847789   977 solver.cpp:316] Iteration 36400, Testing net (#0)
I0416 19:21:09.377555   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 19:21:09.377576   977 solver.cpp:373]     Test net output #1: loss = 0.0383409 (* 1 = 0.0383409 loss)
I0416 19:21:10.046581   977 solver.cpp:221] Iteration 36400, loss = 0.0608753
I0416 19:21:10.046609   977 solver.cpp:236]     Train net output #0: loss = 0.0613521 (* 1 = 0.0613521 loss)
I0416 19:21:10.046614   977 solver.cpp:542] Iteration 36400, lr = 0.01
I0416 19:21:23.584781   977 solver.cpp:221] Iteration 36420, loss = 0.0596439
I0416 19:21:23.584810   977 solver.cpp:236]     Train net output #0: loss = 0.0573742 (* 1 = 0.0573742 loss)
I0416 19:21:23.584815   977 solver.cpp:542] Iteration 36420, lr = 0.01
I0416 19:21:37.108551   977 solver.cpp:221] Iteration 36440, loss = 0.0580718
I0416 19:21:37.108577   977 solver.cpp:236]     Train net output #0: loss = 0.0482141 (* 1 = 0.0482141 loss)
I0416 19:21:37.108582   977 solver.cpp:542] Iteration 36440, lr = 0.01
I0416 19:21:50.627758   977 solver.cpp:221] Iteration 36460, loss = 0.0583629
I0416 19:21:50.627784   977 solver.cpp:236]     Train net output #0: loss = 0.036797 (* 1 = 0.036797 loss)
I0416 19:21:50.627789   977 solver.cpp:542] Iteration 36460, lr = 0.01
I0416 19:22:04.171346   977 solver.cpp:221] Iteration 36480, loss = 0.0554123
I0416 19:22:04.171375   977 solver.cpp:236]     Train net output #0: loss = 0.0477272 (* 1 = 0.0477272 loss)
I0416 19:22:04.171380   977 solver.cpp:542] Iteration 36480, lr = 0.01
I0416 19:22:17.693361   977 solver.cpp:221] Iteration 36500, loss = 0.0611137
I0416 19:22:17.693389   977 solver.cpp:236]     Train net output #0: loss = 0.0720453 (* 1 = 0.0720453 loss)
I0416 19:22:17.693394   977 solver.cpp:542] Iteration 36500, lr = 0.01
I0416 19:22:31.215425   977 solver.cpp:221] Iteration 36520, loss = 0.0535456
I0416 19:22:31.215452   977 solver.cpp:236]     Train net output #0: loss = 0.0590645 (* 1 = 0.0590645 loss)
I0416 19:22:31.215457   977 solver.cpp:542] Iteration 36520, lr = 0.01
I0416 19:22:44.756523   977 solver.cpp:221] Iteration 36540, loss = 0.0607155
I0416 19:22:44.756551   977 solver.cpp:236]     Train net output #0: loss = 0.0582669 (* 1 = 0.0582669 loss)
I0416 19:22:44.756556   977 solver.cpp:542] Iteration 36540, lr = 0.01
I0416 19:22:58.299944   977 solver.cpp:221] Iteration 36560, loss = 0.0529236
I0416 19:22:58.299971   977 solver.cpp:236]     Train net output #0: loss = 0.067403 (* 1 = 0.067403 loss)
I0416 19:22:58.299975   977 solver.cpp:542] Iteration 36560, lr = 0.01
I0416 19:23:11.819197   977 solver.cpp:221] Iteration 36580, loss = 0.0531441
I0416 19:23:11.819226   977 solver.cpp:236]     Train net output #0: loss = 0.0368865 (* 1 = 0.0368865 loss)
I0416 19:23:11.819231   977 solver.cpp:542] Iteration 36580, lr = 0.01
I0416 19:23:24.691968   977 solver.cpp:316] Iteration 36600, Testing net (#0)
I0416 19:23:36.232806   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 19:23:36.232828   977 solver.cpp:373]     Test net output #1: loss = 0.0380429 (* 1 = 0.0380429 loss)
I0416 19:23:36.903235   977 solver.cpp:221] Iteration 36600, loss = 0.0583043
I0416 19:23:36.903264   977 solver.cpp:236]     Train net output #0: loss = 0.0425975 (* 1 = 0.0425975 loss)
I0416 19:23:36.903270   977 solver.cpp:542] Iteration 36600, lr = 0.01
I0416 19:23:50.444998   977 solver.cpp:221] Iteration 36620, loss = 0.050386
I0416 19:23:50.445024   977 solver.cpp:236]     Train net output #0: loss = 0.0437617 (* 1 = 0.0437617 loss)
I0416 19:23:50.445029   977 solver.cpp:542] Iteration 36620, lr = 0.01
I0416 19:24:03.975378   977 solver.cpp:221] Iteration 36640, loss = 0.0607857
I0416 19:24:03.975406   977 solver.cpp:236]     Train net output #0: loss = 0.0383481 (* 1 = 0.0383481 loss)
I0416 19:24:03.975410   977 solver.cpp:542] Iteration 36640, lr = 0.01
I0416 19:24:17.500219   977 solver.cpp:221] Iteration 36660, loss = 0.0586911
I0416 19:24:17.500247   977 solver.cpp:236]     Train net output #0: loss = 0.0378496 (* 1 = 0.0378496 loss)
I0416 19:24:17.500252   977 solver.cpp:542] Iteration 36660, lr = 0.01
I0416 19:24:31.004667   977 solver.cpp:221] Iteration 36680, loss = 0.0568975
I0416 19:24:31.004694   977 solver.cpp:236]     Train net output #0: loss = 0.0292788 (* 1 = 0.0292788 loss)
I0416 19:24:31.004699   977 solver.cpp:542] Iteration 36680, lr = 0.01
I0416 19:24:44.523952   977 solver.cpp:221] Iteration 36700, loss = 0.0591812
I0416 19:24:44.523978   977 solver.cpp:236]     Train net output #0: loss = 0.0422664 (* 1 = 0.0422664 loss)
I0416 19:24:44.523983   977 solver.cpp:542] Iteration 36700, lr = 0.01
I0416 19:24:58.058221   977 solver.cpp:221] Iteration 36720, loss = 0.0525365
I0416 19:24:58.058249   977 solver.cpp:236]     Train net output #0: loss = 0.0299841 (* 1 = 0.0299841 loss)
I0416 19:24:58.058255   977 solver.cpp:542] Iteration 36720, lr = 0.01
I0416 19:25:11.613780   977 solver.cpp:221] Iteration 36740, loss = 0.0580101
I0416 19:25:11.613806   977 solver.cpp:236]     Train net output #0: loss = 0.0446565 (* 1 = 0.0446565 loss)
I0416 19:25:11.613811   977 solver.cpp:542] Iteration 36740, lr = 0.01
I0416 19:25:25.182265   977 solver.cpp:221] Iteration 36760, loss = 0.0534917
I0416 19:25:25.182292   977 solver.cpp:236]     Train net output #0: loss = 0.0581581 (* 1 = 0.0581581 loss)
I0416 19:25:25.182297   977 solver.cpp:542] Iteration 36760, lr = 0.01
I0416 19:25:38.738821   977 solver.cpp:221] Iteration 36780, loss = 0.0564227
I0416 19:25:38.738849   977 solver.cpp:236]     Train net output #0: loss = 0.0628323 (* 1 = 0.0628323 loss)
I0416 19:25:38.738853   977 solver.cpp:542] Iteration 36780, lr = 0.01
I0416 19:25:51.635138   977 solver.cpp:316] Iteration 36800, Testing net (#0)
I0416 19:26:03.167064   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 19:26:03.167086   977 solver.cpp:373]     Test net output #1: loss = 0.0375829 (* 1 = 0.0375829 loss)
I0416 19:26:03.835669   977 solver.cpp:221] Iteration 36800, loss = 0.0554188
I0416 19:26:03.835697   977 solver.cpp:236]     Train net output #0: loss = 0.081171 (* 1 = 0.081171 loss)
I0416 19:26:03.835702   977 solver.cpp:542] Iteration 36800, lr = 0.01
I0416 19:26:17.352924   977 solver.cpp:221] Iteration 36820, loss = 0.0581716
I0416 19:26:17.352952   977 solver.cpp:236]     Train net output #0: loss = 0.137941 (* 1 = 0.137941 loss)
I0416 19:26:17.352955   977 solver.cpp:542] Iteration 36820, lr = 0.01
I0416 19:26:30.864644   977 solver.cpp:221] Iteration 36840, loss = 0.0564334
I0416 19:26:30.864670   977 solver.cpp:236]     Train net output #0: loss = 0.0608927 (* 1 = 0.0608927 loss)
I0416 19:26:30.864676   977 solver.cpp:542] Iteration 36840, lr = 0.01
I0416 19:26:44.374897   977 solver.cpp:221] Iteration 36860, loss = 0.0552161
I0416 19:26:44.374923   977 solver.cpp:236]     Train net output #0: loss = 0.0682456 (* 1 = 0.0682456 loss)
I0416 19:26:44.374927   977 solver.cpp:542] Iteration 36860, lr = 0.01
I0416 19:26:57.898133   977 solver.cpp:221] Iteration 36880, loss = 0.0552815
I0416 19:26:57.898160   977 solver.cpp:236]     Train net output #0: loss = 0.0694911 (* 1 = 0.0694911 loss)
I0416 19:26:57.898165   977 solver.cpp:542] Iteration 36880, lr = 0.01
I0416 19:27:11.444154   977 solver.cpp:221] Iteration 36900, loss = 0.0580125
I0416 19:27:11.444181   977 solver.cpp:236]     Train net output #0: loss = 0.0779038 (* 1 = 0.0779038 loss)
I0416 19:27:11.444186   977 solver.cpp:542] Iteration 36900, lr = 0.01
I0416 19:27:24.998443   977 solver.cpp:221] Iteration 36920, loss = 0.0622632
I0416 19:27:24.998472   977 solver.cpp:236]     Train net output #0: loss = 0.0604737 (* 1 = 0.0604737 loss)
I0416 19:27:24.998477   977 solver.cpp:542] Iteration 36920, lr = 0.01
I0416 19:27:38.562258   977 solver.cpp:221] Iteration 36940, loss = 0.0575177
I0416 19:27:38.562285   977 solver.cpp:236]     Train net output #0: loss = 0.107464 (* 1 = 0.107464 loss)
I0416 19:27:38.562290   977 solver.cpp:542] Iteration 36940, lr = 0.01
I0416 19:27:52.117013   977 solver.cpp:221] Iteration 36960, loss = 0.0522305
I0416 19:27:52.117040   977 solver.cpp:236]     Train net output #0: loss = 0.0872278 (* 1 = 0.0872278 loss)
I0416 19:27:52.117045   977 solver.cpp:542] Iteration 36960, lr = 0.01
I0416 19:28:05.643937   977 solver.cpp:221] Iteration 36980, loss = 0.0564974
I0416 19:28:05.643965   977 solver.cpp:236]     Train net output #0: loss = 0.0558029 (* 1 = 0.0558029 loss)
I0416 19:28:05.643970   977 solver.cpp:542] Iteration 36980, lr = 0.01
I0416 19:28:18.507949   977 solver.cpp:316] Iteration 37000, Testing net (#0)
I0416 19:28:30.038996   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 19:28:30.039018   977 solver.cpp:373]     Test net output #1: loss = 0.0383458 (* 1 = 0.0383458 loss)
I0416 19:28:30.706118   977 solver.cpp:221] Iteration 37000, loss = 0.0561785
I0416 19:28:30.706146   977 solver.cpp:236]     Train net output #0: loss = 0.0367284 (* 1 = 0.0367284 loss)
I0416 19:28:30.706152   977 solver.cpp:542] Iteration 37000, lr = 0.01
I0416 19:28:44.255934   977 solver.cpp:221] Iteration 37020, loss = 0.0547934
I0416 19:28:44.255961   977 solver.cpp:236]     Train net output #0: loss = 0.0362825 (* 1 = 0.0362825 loss)
I0416 19:28:44.255966   977 solver.cpp:542] Iteration 37020, lr = 0.01
I0416 19:28:57.815917   977 solver.cpp:221] Iteration 37040, loss = 0.0564144
I0416 19:28:57.815945   977 solver.cpp:236]     Train net output #0: loss = 0.0361225 (* 1 = 0.0361225 loss)
I0416 19:28:57.815949   977 solver.cpp:542] Iteration 37040, lr = 0.01
I0416 19:29:11.346863   977 solver.cpp:221] Iteration 37060, loss = 0.0505675
I0416 19:29:11.346890   977 solver.cpp:236]     Train net output #0: loss = 0.0478546 (* 1 = 0.0478546 loss)
I0416 19:29:11.346894   977 solver.cpp:542] Iteration 37060, lr = 0.01
I0416 19:29:24.870054   977 solver.cpp:221] Iteration 37080, loss = 0.0610528
I0416 19:29:24.870082   977 solver.cpp:236]     Train net output #0: loss = 0.0910979 (* 1 = 0.0910979 loss)
I0416 19:29:24.870086   977 solver.cpp:542] Iteration 37080, lr = 0.01
I0416 19:29:38.389112   977 solver.cpp:221] Iteration 37100, loss = 0.0558202
I0416 19:29:38.389139   977 solver.cpp:236]     Train net output #0: loss = 0.0451792 (* 1 = 0.0451792 loss)
I0416 19:29:38.389144   977 solver.cpp:542] Iteration 37100, lr = 0.01
I0416 19:29:51.900321   977 solver.cpp:221] Iteration 37120, loss = 0.0619049
I0416 19:29:51.900349   977 solver.cpp:236]     Train net output #0: loss = 0.0444183 (* 1 = 0.0444183 loss)
I0416 19:29:51.900353   977 solver.cpp:542] Iteration 37120, lr = 0.01
I0416 19:30:05.412950   977 solver.cpp:221] Iteration 37140, loss = 0.0562661
I0416 19:30:05.412977   977 solver.cpp:236]     Train net output #0: loss = 0.0489657 (* 1 = 0.0489657 loss)
I0416 19:30:05.412981   977 solver.cpp:542] Iteration 37140, lr = 0.01
I0416 19:30:18.949005   977 solver.cpp:221] Iteration 37160, loss = 0.0557341
I0416 19:30:18.949033   977 solver.cpp:236]     Train net output #0: loss = 0.057369 (* 1 = 0.057369 loss)
I0416 19:30:18.949038   977 solver.cpp:542] Iteration 37160, lr = 0.01
I0416 19:30:32.476248   977 solver.cpp:221] Iteration 37180, loss = 0.0538686
I0416 19:30:32.476275   977 solver.cpp:236]     Train net output #0: loss = 0.0488142 (* 1 = 0.0488142 loss)
I0416 19:30:32.476280   977 solver.cpp:542] Iteration 37180, lr = 0.01
I0416 19:30:45.371755   977 solver.cpp:316] Iteration 37200, Testing net (#0)
I0416 19:30:56.915465   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 19:30:56.915487   977 solver.cpp:373]     Test net output #1: loss = 0.038728 (* 1 = 0.038728 loss)
I0416 19:30:57.585588   977 solver.cpp:221] Iteration 37200, loss = 0.0541149
I0416 19:30:57.585614   977 solver.cpp:236]     Train net output #0: loss = 0.0674781 (* 1 = 0.0674781 loss)
I0416 19:30:57.585619   977 solver.cpp:542] Iteration 37200, lr = 0.01
I0416 19:31:11.122205   977 solver.cpp:221] Iteration 37220, loss = 0.0533811
I0416 19:31:11.122233   977 solver.cpp:236]     Train net output #0: loss = 0.0786595 (* 1 = 0.0786595 loss)
I0416 19:31:11.122239   977 solver.cpp:542] Iteration 37220, lr = 0.01
I0416 19:31:24.678032   977 solver.cpp:221] Iteration 37240, loss = 0.0562387
I0416 19:31:24.678059   977 solver.cpp:236]     Train net output #0: loss = 0.0430224 (* 1 = 0.0430224 loss)
I0416 19:31:24.678064   977 solver.cpp:542] Iteration 37240, lr = 0.01
I0416 19:31:38.184963   977 solver.cpp:221] Iteration 37260, loss = 0.0568745
I0416 19:31:38.184991   977 solver.cpp:236]     Train net output #0: loss = 0.0767446 (* 1 = 0.0767446 loss)
I0416 19:31:38.184996   977 solver.cpp:542] Iteration 37260, lr = 0.01
I0416 19:31:51.712905   977 solver.cpp:221] Iteration 37280, loss = 0.0581721
I0416 19:31:51.712932   977 solver.cpp:236]     Train net output #0: loss = 0.0624706 (* 1 = 0.0624706 loss)
I0416 19:31:51.712937   977 solver.cpp:542] Iteration 37280, lr = 0.01
I0416 19:32:05.252252   977 solver.cpp:221] Iteration 37300, loss = 0.0514576
I0416 19:32:05.252279   977 solver.cpp:236]     Train net output #0: loss = 0.0474252 (* 1 = 0.0474252 loss)
I0416 19:32:05.252285   977 solver.cpp:542] Iteration 37300, lr = 0.01
I0416 19:32:18.810554   977 solver.cpp:221] Iteration 37320, loss = 0.0595033
I0416 19:32:18.810581   977 solver.cpp:236]     Train net output #0: loss = 0.0998788 (* 1 = 0.0998788 loss)
I0416 19:32:18.810586   977 solver.cpp:542] Iteration 37320, lr = 0.01
I0416 19:32:32.385457   977 solver.cpp:221] Iteration 37340, loss = 0.0567361
I0416 19:32:32.385483   977 solver.cpp:236]     Train net output #0: loss = 0.0425095 (* 1 = 0.0425095 loss)
I0416 19:32:32.385488   977 solver.cpp:542] Iteration 37340, lr = 0.01
I0416 19:32:45.945652   977 solver.cpp:221] Iteration 37360, loss = 0.0534434
I0416 19:32:45.945679   977 solver.cpp:236]     Train net output #0: loss = 0.0611805 (* 1 = 0.0611805 loss)
I0416 19:32:45.945684   977 solver.cpp:542] Iteration 37360, lr = 0.01
I0416 19:32:59.472568   977 solver.cpp:221] Iteration 37380, loss = 0.0555622
I0416 19:32:59.472596   977 solver.cpp:236]     Train net output #0: loss = 0.0756487 (* 1 = 0.0756487 loss)
I0416 19:32:59.472601   977 solver.cpp:542] Iteration 37380, lr = 0.01
I0416 19:33:12.346915   977 solver.cpp:316] Iteration 37400, Testing net (#0)
I0416 19:33:23.878942   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 19:33:23.878964   977 solver.cpp:373]     Test net output #1: loss = 0.0373047 (* 1 = 0.0373047 loss)
I0416 19:33:24.547353   977 solver.cpp:221] Iteration 37400, loss = 0.0492328
I0416 19:33:24.547380   977 solver.cpp:236]     Train net output #0: loss = 0.036604 (* 1 = 0.036604 loss)
I0416 19:33:24.547385   977 solver.cpp:542] Iteration 37400, lr = 0.01
I0416 19:33:38.112092   977 solver.cpp:221] Iteration 37420, loss = 0.0557676
I0416 19:33:38.112120   977 solver.cpp:236]     Train net output #0: loss = 0.0534834 (* 1 = 0.0534834 loss)
I0416 19:33:38.112124   977 solver.cpp:542] Iteration 37420, lr = 0.01
I0416 19:33:51.665309   977 solver.cpp:221] Iteration 37440, loss = 0.0518807
I0416 19:33:51.665338   977 solver.cpp:236]     Train net output #0: loss = 0.106744 (* 1 = 0.106744 loss)
I0416 19:33:51.665343   977 solver.cpp:542] Iteration 37440, lr = 0.01
I0416 19:34:05.209765   977 solver.cpp:221] Iteration 37460, loss = 0.0558025
I0416 19:34:05.209792   977 solver.cpp:236]     Train net output #0: loss = 0.0910642 (* 1 = 0.0910642 loss)
I0416 19:34:05.209797   977 solver.cpp:542] Iteration 37460, lr = 0.01
I0416 19:34:18.764696   977 solver.cpp:221] Iteration 37480, loss = 0.0541523
I0416 19:34:18.764724   977 solver.cpp:236]     Train net output #0: loss = 0.0617338 (* 1 = 0.0617338 loss)
I0416 19:34:18.764729   977 solver.cpp:542] Iteration 37480, lr = 0.01
I0416 19:34:32.296733   977 solver.cpp:221] Iteration 37500, loss = 0.0534672
I0416 19:34:32.296761   977 solver.cpp:236]     Train net output #0: loss = 0.034523 (* 1 = 0.034523 loss)
I0416 19:34:32.296766   977 solver.cpp:542] Iteration 37500, lr = 0.01
I0416 19:34:45.818861   977 solver.cpp:221] Iteration 37520, loss = 0.0580015
I0416 19:34:45.818889   977 solver.cpp:236]     Train net output #0: loss = 0.0696645 (* 1 = 0.0696645 loss)
I0416 19:34:45.818894   977 solver.cpp:542] Iteration 37520, lr = 0.01
I0416 19:34:59.363603   977 solver.cpp:221] Iteration 37540, loss = 0.0543149
I0416 19:34:59.363631   977 solver.cpp:236]     Train net output #0: loss = 0.0489631 (* 1 = 0.0489631 loss)
I0416 19:34:59.363636   977 solver.cpp:542] Iteration 37540, lr = 0.01
I0416 19:35:12.878542   977 solver.cpp:221] Iteration 37560, loss = 0.0635422
I0416 19:35:12.878569   977 solver.cpp:236]     Train net output #0: loss = 0.0752841 (* 1 = 0.0752841 loss)
I0416 19:35:12.878574   977 solver.cpp:542] Iteration 37560, lr = 0.01
I0416 19:35:26.379500   977 solver.cpp:221] Iteration 37580, loss = 0.0567304
I0416 19:35:26.379528   977 solver.cpp:236]     Train net output #0: loss = 0.0245908 (* 1 = 0.0245908 loss)
I0416 19:35:26.379533   977 solver.cpp:542] Iteration 37580, lr = 0.01
I0416 19:35:39.249366   977 solver.cpp:316] Iteration 37600, Testing net (#0)
I0416 19:35:50.780169   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 19:35:50.780191   977 solver.cpp:373]     Test net output #1: loss = 0.0388632 (* 1 = 0.0388632 loss)
I0416 19:35:51.447743   977 solver.cpp:221] Iteration 37600, loss = 0.0519204
I0416 19:35:51.447772   977 solver.cpp:236]     Train net output #0: loss = 0.0729043 (* 1 = 0.0729043 loss)
I0416 19:35:51.447775   977 solver.cpp:542] Iteration 37600, lr = 0.01
I0416 19:36:04.985397   977 solver.cpp:221] Iteration 37620, loss = 0.0601228
I0416 19:36:04.985424   977 solver.cpp:236]     Train net output #0: loss = 0.0561225 (* 1 = 0.0561225 loss)
I0416 19:36:04.985429   977 solver.cpp:542] Iteration 37620, lr = 0.01
I0416 19:36:18.527847   977 solver.cpp:221] Iteration 37640, loss = 0.0521873
I0416 19:36:18.527873   977 solver.cpp:236]     Train net output #0: loss = 0.051557 (* 1 = 0.051557 loss)
I0416 19:36:18.527878   977 solver.cpp:542] Iteration 37640, lr = 0.01
I0416 19:36:32.078618   977 solver.cpp:221] Iteration 37660, loss = 0.0565807
I0416 19:36:32.078645   977 solver.cpp:236]     Train net output #0: loss = 0.0394771 (* 1 = 0.0394771 loss)
I0416 19:36:32.078649   977 solver.cpp:542] Iteration 37660, lr = 0.01
I0416 19:36:45.609432   977 solver.cpp:221] Iteration 37680, loss = 0.052573
I0416 19:36:45.609459   977 solver.cpp:236]     Train net output #0: loss = 0.087658 (* 1 = 0.087658 loss)
I0416 19:36:45.609465   977 solver.cpp:542] Iteration 37680, lr = 0.01
I0416 19:36:59.138262   977 solver.cpp:221] Iteration 37700, loss = 0.0564914
I0416 19:36:59.138289   977 solver.cpp:236]     Train net output #0: loss = 0.0838196 (* 1 = 0.0838196 loss)
I0416 19:36:59.138294   977 solver.cpp:542] Iteration 37700, lr = 0.01
I0416 19:37:12.641768   977 solver.cpp:221] Iteration 37720, loss = 0.0581623
I0416 19:37:12.641795   977 solver.cpp:236]     Train net output #0: loss = 0.0685729 (* 1 = 0.0685729 loss)
I0416 19:37:12.641800   977 solver.cpp:542] Iteration 37720, lr = 0.01
I0416 19:37:26.143501   977 solver.cpp:221] Iteration 37740, loss = 0.056032
I0416 19:37:26.143527   977 solver.cpp:236]     Train net output #0: loss = 0.0506774 (* 1 = 0.0506774 loss)
I0416 19:37:26.143532   977 solver.cpp:542] Iteration 37740, lr = 0.01
I0416 19:37:39.651751   977 solver.cpp:221] Iteration 37760, loss = 0.0529124
I0416 19:37:39.651777   977 solver.cpp:236]     Train net output #0: loss = 0.0325398 (* 1 = 0.0325398 loss)
I0416 19:37:39.651782   977 solver.cpp:542] Iteration 37760, lr = 0.01
I0416 19:37:53.158829   977 solver.cpp:221] Iteration 37780, loss = 0.0573857
I0416 19:37:53.158857   977 solver.cpp:236]     Train net output #0: loss = 0.0369767 (* 1 = 0.0369767 loss)
I0416 19:37:53.158862   977 solver.cpp:542] Iteration 37780, lr = 0.01
I0416 19:38:06.014019   977 solver.cpp:316] Iteration 37800, Testing net (#0)
I0416 19:38:17.543988   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 19:38:17.544009   977 solver.cpp:373]     Test net output #1: loss = 0.039445 (* 1 = 0.039445 loss)
I0416 19:38:18.212816   977 solver.cpp:221] Iteration 37800, loss = 0.0564383
I0416 19:38:18.212843   977 solver.cpp:236]     Train net output #0: loss = 0.0627351 (* 1 = 0.0627351 loss)
I0416 19:38:18.212849   977 solver.cpp:542] Iteration 37800, lr = 0.01
I0416 19:38:31.743083   977 solver.cpp:221] Iteration 37820, loss = 0.0560111
I0416 19:38:31.743110   977 solver.cpp:236]     Train net output #0: loss = 0.0604153 (* 1 = 0.0604153 loss)
I0416 19:38:31.743115   977 solver.cpp:542] Iteration 37820, lr = 0.01
I0416 19:38:45.252347   977 solver.cpp:221] Iteration 37840, loss = 0.0531783
I0416 19:38:45.252373   977 solver.cpp:236]     Train net output #0: loss = 0.0659156 (* 1 = 0.0659156 loss)
I0416 19:38:45.252378   977 solver.cpp:542] Iteration 37840, lr = 0.01
I0416 19:38:58.766420   977 solver.cpp:221] Iteration 37860, loss = 0.0523295
I0416 19:38:58.766448   977 solver.cpp:236]     Train net output #0: loss = 0.0555047 (* 1 = 0.0555047 loss)
I0416 19:38:58.766453   977 solver.cpp:542] Iteration 37860, lr = 0.01
I0416 19:39:12.281539   977 solver.cpp:221] Iteration 37880, loss = 0.0544414
I0416 19:39:12.281568   977 solver.cpp:236]     Train net output #0: loss = 0.0429485 (* 1 = 0.0429485 loss)
I0416 19:39:12.281571   977 solver.cpp:542] Iteration 37880, lr = 0.01
I0416 19:39:25.804518   977 solver.cpp:221] Iteration 37900, loss = 0.0546983
I0416 19:39:25.804545   977 solver.cpp:236]     Train net output #0: loss = 0.0328384 (* 1 = 0.0328384 loss)
I0416 19:39:25.804550   977 solver.cpp:542] Iteration 37900, lr = 0.01
I0416 19:39:39.322944   977 solver.cpp:221] Iteration 37920, loss = 0.0543044
I0416 19:39:39.322971   977 solver.cpp:236]     Train net output #0: loss = 0.0536313 (* 1 = 0.0536313 loss)
I0416 19:39:39.322976   977 solver.cpp:542] Iteration 37920, lr = 0.01
I0416 19:39:52.844648   977 solver.cpp:221] Iteration 37940, loss = 0.060527
I0416 19:39:52.844676   977 solver.cpp:236]     Train net output #0: loss = 0.0477258 (* 1 = 0.0477258 loss)
I0416 19:39:52.844681   977 solver.cpp:542] Iteration 37940, lr = 0.01
I0416 19:40:06.387477   977 solver.cpp:221] Iteration 37960, loss = 0.059566
I0416 19:40:06.387506   977 solver.cpp:236]     Train net output #0: loss = 0.0700418 (* 1 = 0.0700418 loss)
I0416 19:40:06.387509   977 solver.cpp:542] Iteration 37960, lr = 0.01
I0416 19:40:19.912677   977 solver.cpp:221] Iteration 37980, loss = 0.0559969
I0416 19:40:19.912704   977 solver.cpp:236]     Train net output #0: loss = 0.0852004 (* 1 = 0.0852004 loss)
I0416 19:40:19.912709   977 solver.cpp:542] Iteration 37980, lr = 0.01
I0416 19:40:32.779685   977 solver.cpp:316] Iteration 38000, Testing net (#0)
I0416 19:40:44.310055   977 solver.cpp:373]     Test net output #0: accuracy = 0.992395
I0416 19:40:44.310076   977 solver.cpp:373]     Test net output #1: loss = 0.039305 (* 1 = 0.039305 loss)
I0416 19:40:44.977687   977 solver.cpp:221] Iteration 38000, loss = 0.0553141
I0416 19:40:44.977715   977 solver.cpp:236]     Train net output #0: loss = 0.101111 (* 1 = 0.101111 loss)
I0416 19:40:44.977720   977 solver.cpp:542] Iteration 38000, lr = 0.01
I0416 19:40:58.495220   977 solver.cpp:221] Iteration 38020, loss = 0.0520807
I0416 19:40:58.495256   977 solver.cpp:236]     Train net output #0: loss = 0.087121 (* 1 = 0.087121 loss)
I0416 19:40:58.495261   977 solver.cpp:542] Iteration 38020, lr = 0.01
I0416 19:41:12.007217   977 solver.cpp:221] Iteration 38040, loss = 0.0562678
I0416 19:41:12.007244   977 solver.cpp:236]     Train net output #0: loss = 0.0523569 (* 1 = 0.0523569 loss)
I0416 19:41:12.007249   977 solver.cpp:542] Iteration 38040, lr = 0.01
I0416 19:41:25.533634   977 solver.cpp:221] Iteration 38060, loss = 0.0578507
I0416 19:41:25.533660   977 solver.cpp:236]     Train net output #0: loss = 0.0397481 (* 1 = 0.0397481 loss)
I0416 19:41:25.533665   977 solver.cpp:542] Iteration 38060, lr = 0.01
I0416 19:41:39.048998   977 solver.cpp:221] Iteration 38080, loss = 0.0570487
I0416 19:41:39.049026   977 solver.cpp:236]     Train net output #0: loss = 0.0573099 (* 1 = 0.0573099 loss)
I0416 19:41:39.049031   977 solver.cpp:542] Iteration 38080, lr = 0.01
I0416 19:41:52.583869   977 solver.cpp:221] Iteration 38100, loss = 0.0528864
I0416 19:41:52.583897   977 solver.cpp:236]     Train net output #0: loss = 0.0407933 (* 1 = 0.0407933 loss)
I0416 19:41:52.583901   977 solver.cpp:542] Iteration 38100, lr = 0.01
I0416 19:42:06.109841   977 solver.cpp:221] Iteration 38120, loss = 0.0549811
I0416 19:42:06.109869   977 solver.cpp:236]     Train net output #0: loss = 0.05361 (* 1 = 0.05361 loss)
I0416 19:42:06.109874   977 solver.cpp:542] Iteration 38120, lr = 0.01
I0416 19:42:19.623973   977 solver.cpp:221] Iteration 38140, loss = 0.0573892
I0416 19:42:19.623999   977 solver.cpp:236]     Train net output #0: loss = 0.0875594 (* 1 = 0.0875594 loss)
I0416 19:42:19.624004   977 solver.cpp:542] Iteration 38140, lr = 0.01
I0416 19:42:33.136207   977 solver.cpp:221] Iteration 38160, loss = 0.0531168
I0416 19:42:33.136234   977 solver.cpp:236]     Train net output #0: loss = 0.0991797 (* 1 = 0.0991797 loss)
I0416 19:42:33.136240   977 solver.cpp:542] Iteration 38160, lr = 0.01
I0416 19:42:46.673957   977 solver.cpp:221] Iteration 38180, loss = 0.0566961
I0416 19:42:46.673985   977 solver.cpp:236]     Train net output #0: loss = 0.0586508 (* 1 = 0.0586508 loss)
I0416 19:42:46.673990   977 solver.cpp:542] Iteration 38180, lr = 0.01
I0416 19:42:59.552415   977 solver.cpp:316] Iteration 38200, Testing net (#0)
I0416 19:43:11.096375   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 19:43:11.096397   977 solver.cpp:373]     Test net output #1: loss = 0.0405519 (* 1 = 0.0405519 loss)
I0416 19:43:11.767139   977 solver.cpp:221] Iteration 38200, loss = 0.0553993
I0416 19:43:11.767166   977 solver.cpp:236]     Train net output #0: loss = 0.0598819 (* 1 = 0.0598819 loss)
I0416 19:43:11.767171   977 solver.cpp:542] Iteration 38200, lr = 0.01
I0416 19:43:25.301101   977 solver.cpp:221] Iteration 38220, loss = 0.0582189
I0416 19:43:25.301129   977 solver.cpp:236]     Train net output #0: loss = 0.0522931 (* 1 = 0.0522931 loss)
I0416 19:43:25.301134   977 solver.cpp:542] Iteration 38220, lr = 0.01
I0416 19:43:38.814867   977 solver.cpp:221] Iteration 38240, loss = 0.0538867
I0416 19:43:38.814895   977 solver.cpp:236]     Train net output #0: loss = 0.0680219 (* 1 = 0.0680219 loss)
I0416 19:43:38.814899   977 solver.cpp:542] Iteration 38240, lr = 0.01
I0416 19:43:52.329568   977 solver.cpp:221] Iteration 38260, loss = 0.0569234
I0416 19:43:52.329596   977 solver.cpp:236]     Train net output #0: loss = 0.053876 (* 1 = 0.053876 loss)
I0416 19:43:52.329602   977 solver.cpp:542] Iteration 38260, lr = 0.01
I0416 19:44:05.837972   977 solver.cpp:221] Iteration 38280, loss = 0.0542234
I0416 19:44:05.838001   977 solver.cpp:236]     Train net output #0: loss = 0.0552064 (* 1 = 0.0552064 loss)
I0416 19:44:05.838006   977 solver.cpp:542] Iteration 38280, lr = 0.01
I0416 19:44:19.364063   977 solver.cpp:221] Iteration 38300, loss = 0.0549616
I0416 19:44:19.364091   977 solver.cpp:236]     Train net output #0: loss = 0.0737544 (* 1 = 0.0737544 loss)
I0416 19:44:19.364096   977 solver.cpp:542] Iteration 38300, lr = 0.01
I0416 19:44:32.875497   977 solver.cpp:221] Iteration 38320, loss = 0.0549349
I0416 19:44:32.875525   977 solver.cpp:236]     Train net output #0: loss = 0.0257422 (* 1 = 0.0257422 loss)
I0416 19:44:32.875530   977 solver.cpp:542] Iteration 38320, lr = 0.01
I0416 19:44:46.408354   977 solver.cpp:221] Iteration 38340, loss = 0.0622263
I0416 19:44:46.408381   977 solver.cpp:236]     Train net output #0: loss = 0.0690639 (* 1 = 0.0690639 loss)
I0416 19:44:46.408385   977 solver.cpp:542] Iteration 38340, lr = 0.01
I0416 19:44:59.932626   977 solver.cpp:221] Iteration 38360, loss = 0.0616668
I0416 19:44:59.932652   977 solver.cpp:236]     Train net output #0: loss = 0.0765395 (* 1 = 0.0765395 loss)
I0416 19:44:59.932657   977 solver.cpp:542] Iteration 38360, lr = 0.01
I0416 19:45:13.449152   977 solver.cpp:221] Iteration 38380, loss = 0.0569356
I0416 19:45:13.449182   977 solver.cpp:236]     Train net output #0: loss = 0.0412467 (* 1 = 0.0412467 loss)
I0416 19:45:13.449185   977 solver.cpp:542] Iteration 38380, lr = 0.01
I0416 19:45:26.329171   977 solver.cpp:316] Iteration 38400, Testing net (#0)
I0416 19:45:37.872715   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 19:45:37.872737   977 solver.cpp:373]     Test net output #1: loss = 0.038431 (* 1 = 0.038431 loss)
I0416 19:45:38.541836   977 solver.cpp:221] Iteration 38400, loss = 0.0508593
I0416 19:45:38.541864   977 solver.cpp:236]     Train net output #0: loss = 0.0511434 (* 1 = 0.0511434 loss)
I0416 19:45:38.541877   977 solver.cpp:542] Iteration 38400, lr = 0.01
I0416 19:45:52.085727   977 solver.cpp:221] Iteration 38420, loss = 0.0580614
I0416 19:45:52.085753   977 solver.cpp:236]     Train net output #0: loss = 0.0746987 (* 1 = 0.0746987 loss)
I0416 19:45:52.085757   977 solver.cpp:542] Iteration 38420, lr = 0.01
I0416 19:46:05.637755   977 solver.cpp:221] Iteration 38440, loss = 0.0529868
I0416 19:46:05.637783   977 solver.cpp:236]     Train net output #0: loss = 0.0691993 (* 1 = 0.0691993 loss)
I0416 19:46:05.637787   977 solver.cpp:542] Iteration 38440, lr = 0.01
I0416 19:46:19.189237   977 solver.cpp:221] Iteration 38460, loss = 0.0568886
I0416 19:46:19.189265   977 solver.cpp:236]     Train net output #0: loss = 0.0256539 (* 1 = 0.0256539 loss)
I0416 19:46:19.189270   977 solver.cpp:542] Iteration 38460, lr = 0.01
I0416 19:46:32.732725   977 solver.cpp:221] Iteration 38480, loss = 0.0470924
I0416 19:46:32.732753   977 solver.cpp:236]     Train net output #0: loss = 0.0252909 (* 1 = 0.0252909 loss)
I0416 19:46:32.732758   977 solver.cpp:542] Iteration 38480, lr = 0.01
I0416 19:46:46.301369   977 solver.cpp:221] Iteration 38500, loss = 0.0554515
I0416 19:46:46.301398   977 solver.cpp:236]     Train net output #0: loss = 0.0387769 (* 1 = 0.0387769 loss)
I0416 19:46:46.301403   977 solver.cpp:542] Iteration 38500, lr = 0.01
I0416 19:46:59.886826   977 solver.cpp:221] Iteration 38520, loss = 0.0533812
I0416 19:46:59.886854   977 solver.cpp:236]     Train net output #0: loss = 0.05065 (* 1 = 0.05065 loss)
I0416 19:46:59.886859   977 solver.cpp:542] Iteration 38520, lr = 0.01
I0416 19:47:13.469624   977 solver.cpp:221] Iteration 38540, loss = 0.0544046
I0416 19:47:13.469652   977 solver.cpp:236]     Train net output #0: loss = 0.0589954 (* 1 = 0.0589954 loss)
I0416 19:47:13.469656   977 solver.cpp:542] Iteration 38540, lr = 0.01
I0416 19:47:27.046239   977 solver.cpp:221] Iteration 38560, loss = 0.0551169
I0416 19:47:27.046267   977 solver.cpp:236]     Train net output #0: loss = 0.0491468 (* 1 = 0.0491468 loss)
I0416 19:47:27.046272   977 solver.cpp:542] Iteration 38560, lr = 0.01
I0416 19:47:40.621882   977 solver.cpp:221] Iteration 38580, loss = 0.0543104
I0416 19:47:40.621911   977 solver.cpp:236]     Train net output #0: loss = 0.0526032 (* 1 = 0.0526032 loss)
I0416 19:47:40.621914   977 solver.cpp:542] Iteration 38580, lr = 0.01
I0416 19:47:53.505897   977 solver.cpp:316] Iteration 38600, Testing net (#0)
I0416 19:48:05.041147   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 19:48:05.041168   977 solver.cpp:373]     Test net output #1: loss = 0.0417645 (* 1 = 0.0417645 loss)
I0416 19:48:05.709362   977 solver.cpp:221] Iteration 38600, loss = 0.0587204
I0416 19:48:05.709389   977 solver.cpp:236]     Train net output #0: loss = 0.0555487 (* 1 = 0.0555487 loss)
I0416 19:48:05.709394   977 solver.cpp:542] Iteration 38600, lr = 0.01
I0416 19:48:19.291431   977 solver.cpp:221] Iteration 38620, loss = 0.0559944
I0416 19:48:19.291460   977 solver.cpp:236]     Train net output #0: loss = 0.0622495 (* 1 = 0.0622495 loss)
I0416 19:48:19.291465   977 solver.cpp:542] Iteration 38620, lr = 0.01
I0416 19:48:32.860651   977 solver.cpp:221] Iteration 38640, loss = 0.0548787
I0416 19:48:32.860679   977 solver.cpp:236]     Train net output #0: loss = 0.0574104 (* 1 = 0.0574104 loss)
I0416 19:48:32.860684   977 solver.cpp:542] Iteration 38640, lr = 0.01
I0416 19:48:46.395428   977 solver.cpp:221] Iteration 38660, loss = 0.0510381
I0416 19:48:46.395457   977 solver.cpp:236]     Train net output #0: loss = 0.0751995 (* 1 = 0.0751995 loss)
I0416 19:48:46.395460   977 solver.cpp:542] Iteration 38660, lr = 0.01
I0416 19:48:59.951460   977 solver.cpp:221] Iteration 38680, loss = 0.0576022
I0416 19:48:59.951488   977 solver.cpp:236]     Train net output #0: loss = 0.043137 (* 1 = 0.043137 loss)
I0416 19:48:59.951493   977 solver.cpp:542] Iteration 38680, lr = 0.01
I0416 19:49:13.480104   977 solver.cpp:221] Iteration 38700, loss = 0.0562335
I0416 19:49:13.480131   977 solver.cpp:236]     Train net output #0: loss = 0.0251087 (* 1 = 0.0251087 loss)
I0416 19:49:13.480136   977 solver.cpp:542] Iteration 38700, lr = 0.01
I0416 19:49:27.026801   977 solver.cpp:221] Iteration 38720, loss = 0.0514334
I0416 19:49:27.026829   977 solver.cpp:236]     Train net output #0: loss = 0.0462973 (* 1 = 0.0462973 loss)
I0416 19:49:27.026834   977 solver.cpp:542] Iteration 38720, lr = 0.01
I0416 19:49:40.575414   977 solver.cpp:221] Iteration 38740, loss = 0.0539065
I0416 19:49:40.575440   977 solver.cpp:236]     Train net output #0: loss = 0.0286421 (* 1 = 0.0286421 loss)
I0416 19:49:40.575445   977 solver.cpp:542] Iteration 38740, lr = 0.01
I0416 19:49:54.125190   977 solver.cpp:221] Iteration 38760, loss = 0.056268
I0416 19:49:54.125216   977 solver.cpp:236]     Train net output #0: loss = 0.162684 (* 1 = 0.162684 loss)
I0416 19:49:54.125221   977 solver.cpp:542] Iteration 38760, lr = 0.01
I0416 19:50:07.658130   977 solver.cpp:221] Iteration 38780, loss = 0.0549775
I0416 19:50:07.658159   977 solver.cpp:236]     Train net output #0: loss = 0.0812291 (* 1 = 0.0812291 loss)
I0416 19:50:07.658165   977 solver.cpp:542] Iteration 38780, lr = 0.01
I0416 19:50:20.564926   977 solver.cpp:316] Iteration 38800, Testing net (#0)
I0416 19:50:32.097482   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 19:50:32.097504   977 solver.cpp:373]     Test net output #1: loss = 0.0385161 (* 1 = 0.0385161 loss)
I0416 19:50:32.766402   977 solver.cpp:221] Iteration 38800, loss = 0.0526212
I0416 19:50:32.766430   977 solver.cpp:236]     Train net output #0: loss = 0.0525397 (* 1 = 0.0525397 loss)
I0416 19:50:32.766435   977 solver.cpp:542] Iteration 38800, lr = 0.01
I0416 19:50:46.304442   977 solver.cpp:221] Iteration 38820, loss = 0.0561932
I0416 19:50:46.304471   977 solver.cpp:236]     Train net output #0: loss = 0.0587474 (* 1 = 0.0587474 loss)
I0416 19:50:46.304476   977 solver.cpp:542] Iteration 38820, lr = 0.01
I0416 19:50:59.846817   977 solver.cpp:221] Iteration 38840, loss = 0.0552931
I0416 19:50:59.846843   977 solver.cpp:236]     Train net output #0: loss = 0.0680368 (* 1 = 0.0680368 loss)
I0416 19:50:59.846848   977 solver.cpp:542] Iteration 38840, lr = 0.01
I0416 19:51:13.383419   977 solver.cpp:221] Iteration 38860, loss = 0.0553314
I0416 19:51:13.383446   977 solver.cpp:236]     Train net output #0: loss = 0.0662507 (* 1 = 0.0662507 loss)
I0416 19:51:13.383451   977 solver.cpp:542] Iteration 38860, lr = 0.01
I0416 19:51:26.896816   977 solver.cpp:221] Iteration 38880, loss = 0.0552702
I0416 19:51:26.896844   977 solver.cpp:236]     Train net output #0: loss = 0.0834221 (* 1 = 0.0834221 loss)
I0416 19:51:26.896849   977 solver.cpp:542] Iteration 38880, lr = 0.01
I0416 19:51:40.457082   977 solver.cpp:221] Iteration 38900, loss = 0.0540178
I0416 19:51:40.457109   977 solver.cpp:236]     Train net output #0: loss = 0.0419111 (* 1 = 0.0419111 loss)
I0416 19:51:40.457113   977 solver.cpp:542] Iteration 38900, lr = 0.01
I0416 19:51:54.018069   977 solver.cpp:221] Iteration 38920, loss = 0.0560862
I0416 19:51:54.018095   977 solver.cpp:236]     Train net output #0: loss = 0.0551908 (* 1 = 0.0551908 loss)
I0416 19:51:54.018100   977 solver.cpp:542] Iteration 38920, lr = 0.01
I0416 19:52:07.550170   977 solver.cpp:221] Iteration 38940, loss = 0.0533621
I0416 19:52:07.550199   977 solver.cpp:236]     Train net output #0: loss = 0.0664378 (* 1 = 0.0664378 loss)
I0416 19:52:07.550204   977 solver.cpp:542] Iteration 38940, lr = 0.01
I0416 19:52:21.100633   977 solver.cpp:221] Iteration 38960, loss = 0.0512688
I0416 19:52:21.100661   977 solver.cpp:236]     Train net output #0: loss = 0.0715162 (* 1 = 0.0715162 loss)
I0416 19:52:21.100666   977 solver.cpp:542] Iteration 38960, lr = 0.01
I0416 19:52:34.648728   977 solver.cpp:221] Iteration 38980, loss = 0.0515931
I0416 19:52:34.648759   977 solver.cpp:236]     Train net output #0: loss = 0.0382874 (* 1 = 0.0382874 loss)
I0416 19:52:34.648766   977 solver.cpp:542] Iteration 38980, lr = 0.01
I0416 19:52:47.525699   977 solver.cpp:316] Iteration 39000, Testing net (#0)
I0416 19:52:59.072199   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 19:52:59.072221   977 solver.cpp:373]     Test net output #1: loss = 0.0376994 (* 1 = 0.0376994 loss)
I0416 19:52:59.741716   977 solver.cpp:221] Iteration 39000, loss = 0.0541761
I0416 19:52:59.741744   977 solver.cpp:236]     Train net output #0: loss = 0.0470399 (* 1 = 0.0470399 loss)
I0416 19:52:59.741750   977 solver.cpp:542] Iteration 39000, lr = 0.01
I0416 19:53:13.281968   977 solver.cpp:221] Iteration 39020, loss = 0.0552259
I0416 19:53:13.281996   977 solver.cpp:236]     Train net output #0: loss = 0.0309801 (* 1 = 0.0309801 loss)
I0416 19:53:13.282001   977 solver.cpp:542] Iteration 39020, lr = 0.01
I0416 19:53:26.815538   977 solver.cpp:221] Iteration 39040, loss = 0.0555313
I0416 19:53:26.815567   977 solver.cpp:236]     Train net output #0: loss = 0.0388644 (* 1 = 0.0388644 loss)
I0416 19:53:26.815572   977 solver.cpp:542] Iteration 39040, lr = 0.01
I0416 19:53:40.367120   977 solver.cpp:221] Iteration 39060, loss = 0.0533329
I0416 19:53:40.367146   977 solver.cpp:236]     Train net output #0: loss = 0.045937 (* 1 = 0.045937 loss)
I0416 19:53:40.367151   977 solver.cpp:542] Iteration 39060, lr = 0.01
I0416 19:53:53.960360   977 solver.cpp:221] Iteration 39080, loss = 0.0551683
I0416 19:53:53.960387   977 solver.cpp:236]     Train net output #0: loss = 0.0660982 (* 1 = 0.0660982 loss)
I0416 19:53:53.960392   977 solver.cpp:542] Iteration 39080, lr = 0.01
I0416 19:54:07.521878   977 solver.cpp:221] Iteration 39100, loss = 0.0495857
I0416 19:54:07.521905   977 solver.cpp:236]     Train net output #0: loss = 0.0370128 (* 1 = 0.0370128 loss)
I0416 19:54:07.521909   977 solver.cpp:542] Iteration 39100, lr = 0.01
I0416 19:54:21.080071   977 solver.cpp:221] Iteration 39120, loss = 0.0496841
I0416 19:54:21.080099   977 solver.cpp:236]     Train net output #0: loss = 0.0270605 (* 1 = 0.0270605 loss)
I0416 19:54:21.080104   977 solver.cpp:542] Iteration 39120, lr = 0.01
I0416 19:54:34.608093   977 solver.cpp:221] Iteration 39140, loss = 0.0544217
I0416 19:54:34.608120   977 solver.cpp:236]     Train net output #0: loss = 0.053194 (* 1 = 0.053194 loss)
I0416 19:54:34.608125   977 solver.cpp:542] Iteration 39140, lr = 0.01
I0416 19:54:48.176234   977 solver.cpp:221] Iteration 39160, loss = 0.0519331
I0416 19:54:48.176261   977 solver.cpp:236]     Train net output #0: loss = 0.0364023 (* 1 = 0.0364023 loss)
I0416 19:54:48.176266   977 solver.cpp:542] Iteration 39160, lr = 0.01
I0416 19:55:01.703268   977 solver.cpp:221] Iteration 39180, loss = 0.052636
I0416 19:55:01.703294   977 solver.cpp:236]     Train net output #0: loss = 0.0396387 (* 1 = 0.0396387 loss)
I0416 19:55:01.703300   977 solver.cpp:542] Iteration 39180, lr = 0.01
I0416 19:55:14.577322   977 solver.cpp:316] Iteration 39200, Testing net (#0)
I0416 19:55:26.111506   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 19:55:26.111528   977 solver.cpp:373]     Test net output #1: loss = 0.0402531 (* 1 = 0.0402531 loss)
I0416 19:55:26.780405   977 solver.cpp:221] Iteration 39200, loss = 0.0520138
I0416 19:55:26.780431   977 solver.cpp:236]     Train net output #0: loss = 0.0526166 (* 1 = 0.0526166 loss)
I0416 19:55:26.780436   977 solver.cpp:542] Iteration 39200, lr = 0.01
I0416 19:55:40.320380   977 solver.cpp:221] Iteration 39220, loss = 0.055001
I0416 19:55:40.320408   977 solver.cpp:236]     Train net output #0: loss = 0.0581573 (* 1 = 0.0581573 loss)
I0416 19:55:40.320412   977 solver.cpp:542] Iteration 39220, lr = 0.01
I0416 19:55:53.881595   977 solver.cpp:221] Iteration 39240, loss = 0.0547161
I0416 19:55:53.881623   977 solver.cpp:236]     Train net output #0: loss = 0.051345 (* 1 = 0.051345 loss)
I0416 19:55:53.881628   977 solver.cpp:542] Iteration 39240, lr = 0.01
I0416 19:56:07.448613   977 solver.cpp:221] Iteration 39260, loss = 0.0539062
I0416 19:56:07.448640   977 solver.cpp:236]     Train net output #0: loss = 0.0426444 (* 1 = 0.0426444 loss)
I0416 19:56:07.448645   977 solver.cpp:542] Iteration 39260, lr = 0.01
I0416 19:56:20.986721   977 solver.cpp:221] Iteration 39280, loss = 0.0571965
I0416 19:56:20.986747   977 solver.cpp:236]     Train net output #0: loss = 0.0299528 (* 1 = 0.0299528 loss)
I0416 19:56:20.986752   977 solver.cpp:542] Iteration 39280, lr = 0.01
I0416 19:56:34.531935   977 solver.cpp:221] Iteration 39300, loss = 0.0544604
I0416 19:56:34.531962   977 solver.cpp:236]     Train net output #0: loss = 0.05159 (* 1 = 0.05159 loss)
I0416 19:56:34.531967   977 solver.cpp:542] Iteration 39300, lr = 0.01
I0416 19:56:48.060138   977 solver.cpp:221] Iteration 39320, loss = 0.050498
I0416 19:56:48.060164   977 solver.cpp:236]     Train net output #0: loss = 0.0535453 (* 1 = 0.0535453 loss)
I0416 19:56:48.060169   977 solver.cpp:542] Iteration 39320, lr = 0.01
I0416 19:57:01.595381   977 solver.cpp:221] Iteration 39340, loss = 0.0559799
I0416 19:57:01.595408   977 solver.cpp:236]     Train net output #0: loss = 0.0648389 (* 1 = 0.0648389 loss)
I0416 19:57:01.595412   977 solver.cpp:542] Iteration 39340, lr = 0.01
I0416 19:57:15.159976   977 solver.cpp:221] Iteration 39360, loss = 0.0551101
I0416 19:57:15.160003   977 solver.cpp:236]     Train net output #0: loss = 0.0409989 (* 1 = 0.0409989 loss)
I0416 19:57:15.160008   977 solver.cpp:542] Iteration 39360, lr = 0.01
I0416 19:57:28.726249   977 solver.cpp:221] Iteration 39380, loss = 0.0524329
I0416 19:57:28.726277   977 solver.cpp:236]     Train net output #0: loss = 0.0533389 (* 1 = 0.0533389 loss)
I0416 19:57:28.726282   977 solver.cpp:542] Iteration 39380, lr = 0.01
I0416 19:57:41.636549   977 solver.cpp:316] Iteration 39400, Testing net (#0)
I0416 19:57:53.184085   977 solver.cpp:373]     Test net output #0: accuracy = 0.994106
I0416 19:57:53.184106   977 solver.cpp:373]     Test net output #1: loss = 0.0395671 (* 1 = 0.0395671 loss)
I0416 19:57:53.851263   977 solver.cpp:221] Iteration 39400, loss = 0.0551231
I0416 19:57:53.851291   977 solver.cpp:236]     Train net output #0: loss = 0.0422505 (* 1 = 0.0422505 loss)
I0416 19:57:53.851296   977 solver.cpp:542] Iteration 39400, lr = 0.01
I0416 19:58:07.399739   977 solver.cpp:221] Iteration 39420, loss = 0.0592282
I0416 19:58:07.399767   977 solver.cpp:236]     Train net output #0: loss = 0.0865754 (* 1 = 0.0865754 loss)
I0416 19:58:07.399771   977 solver.cpp:542] Iteration 39420, lr = 0.01
I0416 19:58:20.929625   977 solver.cpp:221] Iteration 39440, loss = 0.0567158
I0416 19:58:20.929653   977 solver.cpp:236]     Train net output #0: loss = 0.056921 (* 1 = 0.056921 loss)
I0416 19:58:20.929657   977 solver.cpp:542] Iteration 39440, lr = 0.01
I0416 19:58:34.446076   977 solver.cpp:221] Iteration 39460, loss = 0.0488609
I0416 19:58:34.446104   977 solver.cpp:236]     Train net output #0: loss = 0.034324 (* 1 = 0.034324 loss)
I0416 19:58:34.446108   977 solver.cpp:542] Iteration 39460, lr = 0.01
I0416 19:58:47.961871   977 solver.cpp:221] Iteration 39480, loss = 0.0554645
I0416 19:58:47.961899   977 solver.cpp:236]     Train net output #0: loss = 0.0508977 (* 1 = 0.0508977 loss)
I0416 19:58:47.961902   977 solver.cpp:542] Iteration 39480, lr = 0.01
I0416 19:59:01.500507   977 solver.cpp:221] Iteration 39500, loss = 0.0516246
I0416 19:59:01.500535   977 solver.cpp:236]     Train net output #0: loss = 0.0508687 (* 1 = 0.0508687 loss)
I0416 19:59:01.500541   977 solver.cpp:542] Iteration 39500, lr = 0.01
I0416 19:59:15.063843   977 solver.cpp:221] Iteration 39520, loss = 0.0529409
I0416 19:59:15.063870   977 solver.cpp:236]     Train net output #0: loss = 0.061744 (* 1 = 0.061744 loss)
I0416 19:59:15.063875   977 solver.cpp:542] Iteration 39520, lr = 0.01
I0416 19:59:28.589134   977 solver.cpp:221] Iteration 39540, loss = 0.0467228
I0416 19:59:28.589161   977 solver.cpp:236]     Train net output #0: loss = 0.0308959 (* 1 = 0.0308959 loss)
I0416 19:59:28.589166   977 solver.cpp:542] Iteration 39540, lr = 0.01
I0416 19:59:42.105928   977 solver.cpp:221] Iteration 39560, loss = 0.0543642
I0416 19:59:42.105955   977 solver.cpp:236]     Train net output #0: loss = 0.024514 (* 1 = 0.024514 loss)
I0416 19:59:42.105960   977 solver.cpp:542] Iteration 39560, lr = 0.01
I0416 19:59:55.638643   977 solver.cpp:221] Iteration 39580, loss = 0.0559691
I0416 19:59:55.638670   977 solver.cpp:236]     Train net output #0: loss = 0.0600745 (* 1 = 0.0600745 loss)
I0416 19:59:55.638675   977 solver.cpp:542] Iteration 39580, lr = 0.01
I0416 20:00:08.516369   977 solver.cpp:316] Iteration 39600, Testing net (#0)
I0416 20:00:20.050838   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 20:00:20.050860   977 solver.cpp:373]     Test net output #1: loss = 0.0387367 (* 1 = 0.0387367 loss)
I0416 20:00:20.718801   977 solver.cpp:221] Iteration 39600, loss = 0.0582323
I0416 20:00:20.718829   977 solver.cpp:236]     Train net output #0: loss = 0.0678071 (* 1 = 0.0678071 loss)
I0416 20:00:20.718833   977 solver.cpp:542] Iteration 39600, lr = 0.01
I0416 20:00:34.269315   977 solver.cpp:221] Iteration 39620, loss = 0.0576091
I0416 20:00:34.269343   977 solver.cpp:236]     Train net output #0: loss = 0.0592091 (* 1 = 0.0592091 loss)
I0416 20:00:34.269347   977 solver.cpp:542] Iteration 39620, lr = 0.01
I0416 20:00:47.820825   977 solver.cpp:221] Iteration 39640, loss = 0.05155
I0416 20:00:47.820852   977 solver.cpp:236]     Train net output #0: loss = 0.0271951 (* 1 = 0.0271951 loss)
I0416 20:00:47.820858   977 solver.cpp:542] Iteration 39640, lr = 0.01
I0416 20:01:01.373634   977 solver.cpp:221] Iteration 39660, loss = 0.0532611
I0416 20:01:01.373661   977 solver.cpp:236]     Train net output #0: loss = 0.0501141 (* 1 = 0.0501141 loss)
I0416 20:01:01.373667   977 solver.cpp:542] Iteration 39660, lr = 0.01
I0416 20:01:14.895628   977 solver.cpp:221] Iteration 39680, loss = 0.0544819
I0416 20:01:14.895656   977 solver.cpp:236]     Train net output #0: loss = 0.0356518 (* 1 = 0.0356518 loss)
I0416 20:01:14.895661   977 solver.cpp:542] Iteration 39680, lr = 0.01
I0416 20:01:28.422857   977 solver.cpp:221] Iteration 39700, loss = 0.0508904
I0416 20:01:28.422885   977 solver.cpp:236]     Train net output #0: loss = 0.0315069 (* 1 = 0.0315069 loss)
I0416 20:01:28.422889   977 solver.cpp:542] Iteration 39700, lr = 0.01
I0416 20:01:41.967625   977 solver.cpp:221] Iteration 39720, loss = 0.0523194
I0416 20:01:41.967653   977 solver.cpp:236]     Train net output #0: loss = 0.0402514 (* 1 = 0.0402514 loss)
I0416 20:01:41.967658   977 solver.cpp:542] Iteration 39720, lr = 0.01
I0416 20:01:55.521304   977 solver.cpp:221] Iteration 39740, loss = 0.0554947
I0416 20:01:55.521332   977 solver.cpp:236]     Train net output #0: loss = 0.049155 (* 1 = 0.049155 loss)
I0416 20:01:55.521337   977 solver.cpp:542] Iteration 39740, lr = 0.01
I0416 20:02:09.067414   977 solver.cpp:221] Iteration 39760, loss = 0.0566787
I0416 20:02:09.067442   977 solver.cpp:236]     Train net output #0: loss = 0.0485176 (* 1 = 0.0485176 loss)
I0416 20:02:09.067448   977 solver.cpp:542] Iteration 39760, lr = 0.01
I0416 20:02:22.621876   977 solver.cpp:221] Iteration 39780, loss = 0.0506698
I0416 20:02:22.621903   977 solver.cpp:236]     Train net output #0: loss = 0.0522825 (* 1 = 0.0522825 loss)
I0416 20:02:22.621908   977 solver.cpp:542] Iteration 39780, lr = 0.01
I0416 20:02:35.548578   977 solver.cpp:316] Iteration 39800, Testing net (#0)
I0416 20:02:47.096418   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:02:47.096441   977 solver.cpp:373]     Test net output #1: loss = 0.0377189 (* 1 = 0.0377189 loss)
I0416 20:02:47.767109   977 solver.cpp:221] Iteration 39800, loss = 0.0518104
I0416 20:02:47.767138   977 solver.cpp:236]     Train net output #0: loss = 0.0539157 (* 1 = 0.0539157 loss)
I0416 20:02:47.767143   977 solver.cpp:542] Iteration 39800, lr = 0.01
I0416 20:03:01.316246   977 solver.cpp:221] Iteration 39820, loss = 0.0637517
I0416 20:03:01.316273   977 solver.cpp:236]     Train net output #0: loss = 0.0538173 (* 1 = 0.0538173 loss)
I0416 20:03:01.316277   977 solver.cpp:542] Iteration 39820, lr = 0.01
I0416 20:03:14.859237   977 solver.cpp:221] Iteration 39840, loss = 0.0525625
I0416 20:03:14.859266   977 solver.cpp:236]     Train net output #0: loss = 0.0502845 (* 1 = 0.0502845 loss)
I0416 20:03:14.859269   977 solver.cpp:542] Iteration 39840, lr = 0.01
I0416 20:03:28.407997   977 solver.cpp:221] Iteration 39860, loss = 0.0579194
I0416 20:03:28.408025   977 solver.cpp:236]     Train net output #0: loss = 0.0373381 (* 1 = 0.0373381 loss)
I0416 20:03:28.408030   977 solver.cpp:542] Iteration 39860, lr = 0.01
I0416 20:03:41.961043   977 solver.cpp:221] Iteration 39880, loss = 0.0503375
I0416 20:03:41.961071   977 solver.cpp:236]     Train net output #0: loss = 0.0557081 (* 1 = 0.0557081 loss)
I0416 20:03:41.961076   977 solver.cpp:542] Iteration 39880, lr = 0.01
I0416 20:03:55.519383   977 solver.cpp:221] Iteration 39900, loss = 0.055284
I0416 20:03:55.519412   977 solver.cpp:236]     Train net output #0: loss = 0.0425506 (* 1 = 0.0425506 loss)
I0416 20:03:55.519415   977 solver.cpp:542] Iteration 39900, lr = 0.01
I0416 20:04:09.079983   977 solver.cpp:221] Iteration 39920, loss = 0.0560059
I0416 20:04:09.080011   977 solver.cpp:236]     Train net output #0: loss = 0.0420942 (* 1 = 0.0420942 loss)
I0416 20:04:09.080015   977 solver.cpp:542] Iteration 39920, lr = 0.01
I0416 20:04:22.597091   977 solver.cpp:221] Iteration 39940, loss = 0.0521392
I0416 20:04:22.597121   977 solver.cpp:236]     Train net output #0: loss = 0.0399441 (* 1 = 0.0399441 loss)
I0416 20:04:22.597126   977 solver.cpp:542] Iteration 39940, lr = 0.01
I0416 20:04:36.124160   977 solver.cpp:221] Iteration 39960, loss = 0.0597048
I0416 20:04:36.124187   977 solver.cpp:236]     Train net output #0: loss = 0.0607955 (* 1 = 0.0607955 loss)
I0416 20:04:36.124192   977 solver.cpp:542] Iteration 39960, lr = 0.01
I0416 20:04:49.670416   977 solver.cpp:221] Iteration 39980, loss = 0.0518284
I0416 20:04:49.670444   977 solver.cpp:236]     Train net output #0: loss = 0.0367275 (* 1 = 0.0367275 loss)
I0416 20:04:49.670449   977 solver.cpp:542] Iteration 39980, lr = 0.01
I0416 20:05:02.564177   977 solver.cpp:410] Snapshotting to binary proto file external/exp/snapshots/individually/cuhk03_iter_40000.caffemodel
I0416 20:05:02.629544   977 solver.cpp:705] Snapshotting solver state to binary proto fileexternal/exp/snapshots/individually/cuhk03_iter_40000.solverstate
I0416 20:05:02.657517   977 solver.cpp:316] Iteration 40000, Testing net (#0)
I0416 20:05:14.202599   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 20:05:14.202621   977 solver.cpp:373]     Test net output #1: loss = 0.0392467 (* 1 = 0.0392467 loss)
I0416 20:05:14.874020   977 solver.cpp:221] Iteration 40000, loss = 0.0516085
I0416 20:05:14.874047   977 solver.cpp:236]     Train net output #0: loss = 0.104414 (* 1 = 0.104414 loss)
I0416 20:05:14.874053   977 solver.cpp:542] Iteration 40000, lr = 0.001
I0416 20:05:28.429198   977 solver.cpp:221] Iteration 40020, loss = 0.0543227
I0416 20:05:28.429225   977 solver.cpp:236]     Train net output #0: loss = 0.0828505 (* 1 = 0.0828505 loss)
I0416 20:05:28.429230   977 solver.cpp:542] Iteration 40020, lr = 0.001
I0416 20:05:41.995023   977 solver.cpp:221] Iteration 40040, loss = 0.0616146
I0416 20:05:41.995049   977 solver.cpp:236]     Train net output #0: loss = 0.0323488 (* 1 = 0.0323488 loss)
I0416 20:05:41.995054   977 solver.cpp:542] Iteration 40040, lr = 0.001
I0416 20:05:55.557148   977 solver.cpp:221] Iteration 40060, loss = 0.0570858
I0416 20:05:55.557175   977 solver.cpp:236]     Train net output #0: loss = 0.037326 (* 1 = 0.037326 loss)
I0416 20:05:55.557180   977 solver.cpp:542] Iteration 40060, lr = 0.001
I0416 20:06:09.093927   977 solver.cpp:221] Iteration 40080, loss = 0.0574868
I0416 20:06:09.093955   977 solver.cpp:236]     Train net output #0: loss = 0.0446957 (* 1 = 0.0446957 loss)
I0416 20:06:09.093960   977 solver.cpp:542] Iteration 40080, lr = 0.001
I0416 20:06:22.630354   977 solver.cpp:221] Iteration 40100, loss = 0.0484448
I0416 20:06:22.630381   977 solver.cpp:236]     Train net output #0: loss = 0.0445947 (* 1 = 0.0445947 loss)
I0416 20:06:22.630386   977 solver.cpp:542] Iteration 40100, lr = 0.001
I0416 20:06:36.151648   977 solver.cpp:221] Iteration 40120, loss = 0.0483735
I0416 20:06:36.151676   977 solver.cpp:236]     Train net output #0: loss = 0.038986 (* 1 = 0.038986 loss)
I0416 20:06:36.151681   977 solver.cpp:542] Iteration 40120, lr = 0.001
I0416 20:06:49.701808   977 solver.cpp:221] Iteration 40140, loss = 0.0480435
I0416 20:06:49.701834   977 solver.cpp:236]     Train net output #0: loss = 0.0583816 (* 1 = 0.0583816 loss)
I0416 20:06:49.701839   977 solver.cpp:542] Iteration 40140, lr = 0.001
I0416 20:07:03.255380   977 solver.cpp:221] Iteration 40160, loss = 0.0488341
I0416 20:07:03.255409   977 solver.cpp:236]     Train net output #0: loss = 0.0314124 (* 1 = 0.0314124 loss)
I0416 20:07:03.255414   977 solver.cpp:542] Iteration 40160, lr = 0.001
I0416 20:07:16.788347   977 solver.cpp:221] Iteration 40180, loss = 0.0470727
I0416 20:07:16.788375   977 solver.cpp:236]     Train net output #0: loss = 0.0482647 (* 1 = 0.0482647 loss)
I0416 20:07:16.788380   977 solver.cpp:542] Iteration 40180, lr = 0.001
I0416 20:07:29.661628   977 solver.cpp:316] Iteration 40200, Testing net (#0)
I0416 20:07:41.197165   977 solver.cpp:373]     Test net output #0: accuracy = 0.991825
I0416 20:07:41.197187   977 solver.cpp:373]     Test net output #1: loss = 0.0387469 (* 1 = 0.0387469 loss)
I0416 20:07:41.864300   977 solver.cpp:221] Iteration 40200, loss = 0.0463459
I0416 20:07:41.864327   977 solver.cpp:236]     Train net output #0: loss = 0.0471603 (* 1 = 0.0471603 loss)
I0416 20:07:41.864332   977 solver.cpp:542] Iteration 40200, lr = 0.001
I0416 20:07:55.388314   977 solver.cpp:221] Iteration 40220, loss = 0.0482034
I0416 20:07:55.388341   977 solver.cpp:236]     Train net output #0: loss = 0.0483514 (* 1 = 0.0483514 loss)
I0416 20:07:55.388346   977 solver.cpp:542] Iteration 40220, lr = 0.001
I0416 20:08:08.908344   977 solver.cpp:221] Iteration 40240, loss = 0.053665
I0416 20:08:08.908371   977 solver.cpp:236]     Train net output #0: loss = 0.0365922 (* 1 = 0.0365922 loss)
I0416 20:08:08.908376   977 solver.cpp:542] Iteration 40240, lr = 0.001
I0416 20:08:22.429738   977 solver.cpp:221] Iteration 40260, loss = 0.050633
I0416 20:08:22.429765   977 solver.cpp:236]     Train net output #0: loss = 0.0491018 (* 1 = 0.0491018 loss)
I0416 20:08:22.429770   977 solver.cpp:542] Iteration 40260, lr = 0.001
I0416 20:08:35.962308   977 solver.cpp:221] Iteration 40280, loss = 0.053299
I0416 20:08:35.962335   977 solver.cpp:236]     Train net output #0: loss = 0.0609769 (* 1 = 0.0609769 loss)
I0416 20:08:35.962340   977 solver.cpp:542] Iteration 40280, lr = 0.001
I0416 20:08:49.486948   977 solver.cpp:221] Iteration 40300, loss = 0.0469301
I0416 20:08:49.486975   977 solver.cpp:236]     Train net output #0: loss = 0.0682066 (* 1 = 0.0682066 loss)
I0416 20:08:49.486979   977 solver.cpp:542] Iteration 40300, lr = 0.001
I0416 20:09:03.009685   977 solver.cpp:221] Iteration 40320, loss = 0.0450575
I0416 20:09:03.009711   977 solver.cpp:236]     Train net output #0: loss = 0.0374736 (* 1 = 0.0374736 loss)
I0416 20:09:03.009716   977 solver.cpp:542] Iteration 40320, lr = 0.001
I0416 20:09:16.533677   977 solver.cpp:221] Iteration 40340, loss = 0.0424827
I0416 20:09:16.533705   977 solver.cpp:236]     Train net output #0: loss = 0.0610855 (* 1 = 0.0610855 loss)
I0416 20:09:16.533710   977 solver.cpp:542] Iteration 40340, lr = 0.001
I0416 20:09:30.048851   977 solver.cpp:221] Iteration 40360, loss = 0.0444894
I0416 20:09:30.048879   977 solver.cpp:236]     Train net output #0: loss = 0.0421572 (* 1 = 0.0421572 loss)
I0416 20:09:30.048883   977 solver.cpp:542] Iteration 40360, lr = 0.001
I0416 20:09:43.582674   977 solver.cpp:221] Iteration 40380, loss = 0.0446156
I0416 20:09:43.582701   977 solver.cpp:236]     Train net output #0: loss = 0.0521361 (* 1 = 0.0521361 loss)
I0416 20:09:43.582706   977 solver.cpp:542] Iteration 40380, lr = 0.001
I0416 20:09:56.453930   977 solver.cpp:316] Iteration 40400, Testing net (#0)
I0416 20:10:07.999580   977 solver.cpp:373]     Test net output #0: accuracy = 0.992395
I0416 20:10:07.999601   977 solver.cpp:373]     Test net output #1: loss = 0.0379375 (* 1 = 0.0379375 loss)
I0416 20:10:08.666954   977 solver.cpp:221] Iteration 40400, loss = 0.04808
I0416 20:10:08.666980   977 solver.cpp:236]     Train net output #0: loss = 0.0426705 (* 1 = 0.0426705 loss)
I0416 20:10:08.666985   977 solver.cpp:542] Iteration 40400, lr = 0.001
I0416 20:10:22.223662   977 solver.cpp:221] Iteration 40420, loss = 0.0471311
I0416 20:10:22.223690   977 solver.cpp:236]     Train net output #0: loss = 0.04869 (* 1 = 0.04869 loss)
I0416 20:10:22.223695   977 solver.cpp:542] Iteration 40420, lr = 0.001
I0416 20:10:35.786661   977 solver.cpp:221] Iteration 40440, loss = 0.0530531
I0416 20:10:35.786689   977 solver.cpp:236]     Train net output #0: loss = 0.0284719 (* 1 = 0.0284719 loss)
I0416 20:10:35.786694   977 solver.cpp:542] Iteration 40440, lr = 0.001
I0416 20:10:49.327711   977 solver.cpp:221] Iteration 40460, loss = 0.0410344
I0416 20:10:49.327739   977 solver.cpp:236]     Train net output #0: loss = 0.0482174 (* 1 = 0.0482174 loss)
I0416 20:10:49.327744   977 solver.cpp:542] Iteration 40460, lr = 0.001
I0416 20:11:02.852483   977 solver.cpp:221] Iteration 40480, loss = 0.0482864
I0416 20:11:02.852509   977 solver.cpp:236]     Train net output #0: loss = 0.0483769 (* 1 = 0.0483769 loss)
I0416 20:11:02.852514   977 solver.cpp:542] Iteration 40480, lr = 0.001
I0416 20:11:16.371587   977 solver.cpp:221] Iteration 40500, loss = 0.0514604
I0416 20:11:16.371614   977 solver.cpp:236]     Train net output #0: loss = 0.0698599 (* 1 = 0.0698599 loss)
I0416 20:11:16.371619   977 solver.cpp:542] Iteration 40500, lr = 0.001
I0416 20:11:29.888531   977 solver.cpp:221] Iteration 40520, loss = 0.0463241
I0416 20:11:29.888558   977 solver.cpp:236]     Train net output #0: loss = 0.0502277 (* 1 = 0.0502277 loss)
I0416 20:11:29.888563   977 solver.cpp:542] Iteration 40520, lr = 0.001
I0416 20:11:43.416885   977 solver.cpp:221] Iteration 40540, loss = 0.0443373
I0416 20:11:43.416913   977 solver.cpp:236]     Train net output #0: loss = 0.0233696 (* 1 = 0.0233696 loss)
I0416 20:11:43.416918   977 solver.cpp:542] Iteration 40540, lr = 0.001
I0416 20:11:56.951952   977 solver.cpp:221] Iteration 40560, loss = 0.0465992
I0416 20:11:56.951980   977 solver.cpp:236]     Train net output #0: loss = 0.038437 (* 1 = 0.038437 loss)
I0416 20:11:56.951985   977 solver.cpp:542] Iteration 40560, lr = 0.001
I0416 20:12:10.497485   977 solver.cpp:221] Iteration 40580, loss = 0.0477137
I0416 20:12:10.497512   977 solver.cpp:236]     Train net output #0: loss = 0.0351149 (* 1 = 0.0351149 loss)
I0416 20:12:10.497516   977 solver.cpp:542] Iteration 40580, lr = 0.001
I0416 20:12:23.402681   977 solver.cpp:316] Iteration 40600, Testing net (#0)
I0416 20:12:34.947733   977 solver.cpp:373]     Test net output #0: accuracy = 0.992395
I0416 20:12:34.947756   977 solver.cpp:373]     Test net output #1: loss = 0.0368525 (* 1 = 0.0368525 loss)
I0416 20:12:35.615640   977 solver.cpp:221] Iteration 40600, loss = 0.0472302
I0416 20:12:35.615669   977 solver.cpp:236]     Train net output #0: loss = 0.036869 (* 1 = 0.036869 loss)
I0416 20:12:35.615674   977 solver.cpp:542] Iteration 40600, lr = 0.001
I0416 20:12:49.173553   977 solver.cpp:221] Iteration 40620, loss = 0.0472696
I0416 20:12:49.173580   977 solver.cpp:236]     Train net output #0: loss = 0.0433043 (* 1 = 0.0433043 loss)
I0416 20:12:49.173585   977 solver.cpp:542] Iteration 40620, lr = 0.001
I0416 20:13:02.703131   977 solver.cpp:221] Iteration 40640, loss = 0.0458618
I0416 20:13:02.703158   977 solver.cpp:236]     Train net output #0: loss = 0.0486353 (* 1 = 0.0486353 loss)
I0416 20:13:02.703162   977 solver.cpp:542] Iteration 40640, lr = 0.001
I0416 20:13:16.236915   977 solver.cpp:221] Iteration 40660, loss = 0.0509516
I0416 20:13:16.236943   977 solver.cpp:236]     Train net output #0: loss = 0.0400454 (* 1 = 0.0400454 loss)
I0416 20:13:16.236948   977 solver.cpp:542] Iteration 40660, lr = 0.001
I0416 20:13:29.793632   977 solver.cpp:221] Iteration 40680, loss = 0.0476961
I0416 20:13:29.793659   977 solver.cpp:236]     Train net output #0: loss = 0.0527453 (* 1 = 0.0527453 loss)
I0416 20:13:29.793664   977 solver.cpp:542] Iteration 40680, lr = 0.001
I0416 20:13:43.345222   977 solver.cpp:221] Iteration 40700, loss = 0.0447862
I0416 20:13:43.345249   977 solver.cpp:236]     Train net output #0: loss = 0.0606674 (* 1 = 0.0606674 loss)
I0416 20:13:43.345254   977 solver.cpp:542] Iteration 40700, lr = 0.001
I0416 20:13:56.895110   977 solver.cpp:221] Iteration 40720, loss = 0.0471473
I0416 20:13:56.895138   977 solver.cpp:236]     Train net output #0: loss = 0.0291488 (* 1 = 0.0291488 loss)
I0416 20:13:56.895143   977 solver.cpp:542] Iteration 40720, lr = 0.001
I0416 20:14:10.445309   977 solver.cpp:221] Iteration 40740, loss = 0.0467491
I0416 20:14:10.445338   977 solver.cpp:236]     Train net output #0: loss = 0.0393518 (* 1 = 0.0393518 loss)
I0416 20:14:10.445343   977 solver.cpp:542] Iteration 40740, lr = 0.001
I0416 20:14:23.982683   977 solver.cpp:221] Iteration 40760, loss = 0.0433421
I0416 20:14:23.982712   977 solver.cpp:236]     Train net output #0: loss = 0.0625715 (* 1 = 0.0625715 loss)
I0416 20:14:23.982715   977 solver.cpp:542] Iteration 40760, lr = 0.001
I0416 20:14:37.509378   977 solver.cpp:221] Iteration 40780, loss = 0.0486019
I0416 20:14:37.509407   977 solver.cpp:236]     Train net output #0: loss = 0.0261994 (* 1 = 0.0261994 loss)
I0416 20:14:37.509412   977 solver.cpp:542] Iteration 40780, lr = 0.001
I0416 20:14:50.379686   977 solver.cpp:316] Iteration 40800, Testing net (#0)
I0416 20:15:01.916373   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 20:15:01.916393   977 solver.cpp:373]     Test net output #1: loss = 0.0364816 (* 1 = 0.0364816 loss)
I0416 20:15:02.584003   977 solver.cpp:221] Iteration 40800, loss = 0.0463891
I0416 20:15:02.584031   977 solver.cpp:236]     Train net output #0: loss = 0.0548013 (* 1 = 0.0548013 loss)
I0416 20:15:02.584036   977 solver.cpp:542] Iteration 40800, lr = 0.001
I0416 20:15:16.152317   977 solver.cpp:221] Iteration 40820, loss = 0.0435107
I0416 20:15:16.152345   977 solver.cpp:236]     Train net output #0: loss = 0.0481153 (* 1 = 0.0481153 loss)
I0416 20:15:16.152350   977 solver.cpp:542] Iteration 40820, lr = 0.001
I0416 20:15:29.707070   977 solver.cpp:221] Iteration 40840, loss = 0.044038
I0416 20:15:29.707098   977 solver.cpp:236]     Train net output #0: loss = 0.0316084 (* 1 = 0.0316084 loss)
I0416 20:15:29.707103   977 solver.cpp:542] Iteration 40840, lr = 0.001
I0416 20:15:43.278965   977 solver.cpp:221] Iteration 40860, loss = 0.0483899
I0416 20:15:43.278991   977 solver.cpp:236]     Train net output #0: loss = 0.0435794 (* 1 = 0.0435794 loss)
I0416 20:15:43.278995   977 solver.cpp:542] Iteration 40860, lr = 0.001
I0416 20:15:56.829038   977 solver.cpp:221] Iteration 40880, loss = 0.0499622
I0416 20:15:56.829066   977 solver.cpp:236]     Train net output #0: loss = 0.0329313 (* 1 = 0.0329313 loss)
I0416 20:15:56.829069   977 solver.cpp:542] Iteration 40880, lr = 0.001
I0416 20:16:10.360697   977 solver.cpp:221] Iteration 40900, loss = 0.0496
I0416 20:16:10.360725   977 solver.cpp:236]     Train net output #0: loss = 0.0794761 (* 1 = 0.0794761 loss)
I0416 20:16:10.360730   977 solver.cpp:542] Iteration 40900, lr = 0.001
I0416 20:16:23.903147   977 solver.cpp:221] Iteration 40920, loss = 0.0437959
I0416 20:16:23.903174   977 solver.cpp:236]     Train net output #0: loss = 0.0471239 (* 1 = 0.0471239 loss)
I0416 20:16:23.903179   977 solver.cpp:542] Iteration 40920, lr = 0.001
I0416 20:16:37.477501   977 solver.cpp:221] Iteration 40940, loss = 0.0479949
I0416 20:16:37.477527   977 solver.cpp:236]     Train net output #0: loss = 0.0249706 (* 1 = 0.0249706 loss)
I0416 20:16:37.477531   977 solver.cpp:542] Iteration 40940, lr = 0.001
I0416 20:16:51.034574   977 solver.cpp:221] Iteration 40960, loss = 0.0444024
I0416 20:16:51.034601   977 solver.cpp:236]     Train net output #0: loss = 0.0472687 (* 1 = 0.0472687 loss)
I0416 20:16:51.034606   977 solver.cpp:542] Iteration 40960, lr = 0.001
I0416 20:17:04.587559   977 solver.cpp:221] Iteration 40980, loss = 0.046941
I0416 20:17:04.587586   977 solver.cpp:236]     Train net output #0: loss = 0.0724946 (* 1 = 0.0724946 loss)
I0416 20:17:04.587591   977 solver.cpp:542] Iteration 40980, lr = 0.001
I0416 20:17:17.487249   977 solver.cpp:316] Iteration 41000, Testing net (#0)
I0416 20:17:29.025981   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 20:17:29.026003   977 solver.cpp:373]     Test net output #1: loss = 0.0371597 (* 1 = 0.0371597 loss)
I0416 20:17:29.696559   977 solver.cpp:221] Iteration 41000, loss = 0.0463255
I0416 20:17:29.696588   977 solver.cpp:236]     Train net output #0: loss = 0.0722108 (* 1 = 0.0722108 loss)
I0416 20:17:29.696593   977 solver.cpp:542] Iteration 41000, lr = 0.001
I0416 20:17:43.258558   977 solver.cpp:221] Iteration 41020, loss = 0.0439961
I0416 20:17:43.258585   977 solver.cpp:236]     Train net output #0: loss = 0.0831884 (* 1 = 0.0831884 loss)
I0416 20:17:43.258589   977 solver.cpp:542] Iteration 41020, lr = 0.001
I0416 20:17:56.822228   977 solver.cpp:221] Iteration 41040, loss = 0.0447759
I0416 20:17:56.822257   977 solver.cpp:236]     Train net output #0: loss = 0.0299571 (* 1 = 0.0299571 loss)
I0416 20:17:56.822262   977 solver.cpp:542] Iteration 41040, lr = 0.001
I0416 20:18:10.406468   977 solver.cpp:221] Iteration 41060, loss = 0.0476947
I0416 20:18:10.406497   977 solver.cpp:236]     Train net output #0: loss = 0.0341017 (* 1 = 0.0341017 loss)
I0416 20:18:10.406502   977 solver.cpp:542] Iteration 41060, lr = 0.001
I0416 20:18:23.975267   977 solver.cpp:221] Iteration 41080, loss = 0.0438252
I0416 20:18:23.975296   977 solver.cpp:236]     Train net output #0: loss = 0.0331835 (* 1 = 0.0331835 loss)
I0416 20:18:23.975299   977 solver.cpp:542] Iteration 41080, lr = 0.001
I0416 20:18:37.544004   977 solver.cpp:221] Iteration 41100, loss = 0.0499079
I0416 20:18:37.544031   977 solver.cpp:236]     Train net output #0: loss = 0.0704626 (* 1 = 0.0704626 loss)
I0416 20:18:37.544036   977 solver.cpp:542] Iteration 41100, lr = 0.001
I0416 20:18:51.112666   977 solver.cpp:221] Iteration 41120, loss = 0.0477474
I0416 20:18:51.112694   977 solver.cpp:236]     Train net output #0: loss = 0.0503224 (* 1 = 0.0503224 loss)
I0416 20:18:51.112699   977 solver.cpp:542] Iteration 41120, lr = 0.001
I0416 20:19:04.685969   977 solver.cpp:221] Iteration 41140, loss = 0.0439876
I0416 20:19:04.685997   977 solver.cpp:236]     Train net output #0: loss = 0.0365476 (* 1 = 0.0365476 loss)
I0416 20:19:04.686002   977 solver.cpp:542] Iteration 41140, lr = 0.001
I0416 20:19:18.256242   977 solver.cpp:221] Iteration 41160, loss = 0.0502229
I0416 20:19:18.256268   977 solver.cpp:236]     Train net output #0: loss = 0.0358687 (* 1 = 0.0358687 loss)
I0416 20:19:18.256273   977 solver.cpp:542] Iteration 41160, lr = 0.001
I0416 20:19:31.818150   977 solver.cpp:221] Iteration 41180, loss = 0.0410672
I0416 20:19:31.818181   977 solver.cpp:236]     Train net output #0: loss = 0.0311342 (* 1 = 0.0311342 loss)
I0416 20:19:31.818186   977 solver.cpp:542] Iteration 41180, lr = 0.001
I0416 20:19:44.692205   977 solver.cpp:316] Iteration 41200, Testing net (#0)
I0416 20:19:56.225747   977 solver.cpp:373]     Test net output #0: accuracy = 0.992205
I0416 20:19:56.225769   977 solver.cpp:373]     Test net output #1: loss = 0.0378989 (* 1 = 0.0378989 loss)
I0416 20:19:56.894299   977 solver.cpp:221] Iteration 41200, loss = 0.042981
I0416 20:19:56.894326   977 solver.cpp:236]     Train net output #0: loss = 0.0495493 (* 1 = 0.0495493 loss)
I0416 20:19:56.894331   977 solver.cpp:542] Iteration 41200, lr = 0.001
I0416 20:20:10.449672   977 solver.cpp:221] Iteration 41220, loss = 0.0456159
I0416 20:20:10.449700   977 solver.cpp:236]     Train net output #0: loss = 0.0716471 (* 1 = 0.0716471 loss)
I0416 20:20:10.449705   977 solver.cpp:542] Iteration 41220, lr = 0.001
I0416 20:20:24.009701   977 solver.cpp:221] Iteration 41240, loss = 0.0428908
I0416 20:20:24.009729   977 solver.cpp:236]     Train net output #0: loss = 0.0583542 (* 1 = 0.0583542 loss)
I0416 20:20:24.009734   977 solver.cpp:542] Iteration 41240, lr = 0.001
I0416 20:20:37.567576   977 solver.cpp:221] Iteration 41260, loss = 0.0458362
I0416 20:20:37.567605   977 solver.cpp:236]     Train net output #0: loss = 0.0439885 (* 1 = 0.0439885 loss)
I0416 20:20:37.567610   977 solver.cpp:542] Iteration 41260, lr = 0.001
I0416 20:20:51.113452   977 solver.cpp:221] Iteration 41280, loss = 0.0483132
I0416 20:20:51.113481   977 solver.cpp:236]     Train net output #0: loss = 0.0354084 (* 1 = 0.0354084 loss)
I0416 20:20:51.113486   977 solver.cpp:542] Iteration 41280, lr = 0.001
I0416 20:21:04.654103   977 solver.cpp:221] Iteration 41300, loss = 0.049363
I0416 20:21:04.654130   977 solver.cpp:236]     Train net output #0: loss = 0.0544574 (* 1 = 0.0544574 loss)
I0416 20:21:04.654134   977 solver.cpp:542] Iteration 41300, lr = 0.001
I0416 20:21:18.208735   977 solver.cpp:221] Iteration 41320, loss = 0.044512
I0416 20:21:18.208765   977 solver.cpp:236]     Train net output #0: loss = 0.0520552 (* 1 = 0.0520552 loss)
I0416 20:21:18.208770   977 solver.cpp:542] Iteration 41320, lr = 0.001
I0416 20:21:31.769224   977 solver.cpp:221] Iteration 41340, loss = 0.0434505
I0416 20:21:31.769253   977 solver.cpp:236]     Train net output #0: loss = 0.0561058 (* 1 = 0.0561058 loss)
I0416 20:21:31.769258   977 solver.cpp:542] Iteration 41340, lr = 0.001
I0416 20:21:45.291064   977 solver.cpp:221] Iteration 41360, loss = 0.0448821
I0416 20:21:45.291091   977 solver.cpp:236]     Train net output #0: loss = 0.0374922 (* 1 = 0.0374922 loss)
I0416 20:21:45.291096   977 solver.cpp:542] Iteration 41360, lr = 0.001
I0416 20:21:58.830610   977 solver.cpp:221] Iteration 41380, loss = 0.0429635
I0416 20:21:58.830637   977 solver.cpp:236]     Train net output #0: loss = 0.0340166 (* 1 = 0.0340166 loss)
I0416 20:21:58.830642   977 solver.cpp:542] Iteration 41380, lr = 0.001
I0416 20:22:11.708523   977 solver.cpp:316] Iteration 41400, Testing net (#0)
I0416 20:22:23.244997   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:22:23.245018   977 solver.cpp:373]     Test net output #1: loss = 0.0369627 (* 1 = 0.0369627 loss)
I0416 20:22:23.915395   977 solver.cpp:221] Iteration 41400, loss = 0.0399452
I0416 20:22:23.915422   977 solver.cpp:236]     Train net output #0: loss = 0.0344646 (* 1 = 0.0344646 loss)
I0416 20:22:23.915428   977 solver.cpp:542] Iteration 41400, lr = 0.001
I0416 20:22:37.452322   977 solver.cpp:221] Iteration 41420, loss = 0.0449372
I0416 20:22:37.452349   977 solver.cpp:236]     Train net output #0: loss = 0.0420898 (* 1 = 0.0420898 loss)
I0416 20:22:37.452354   977 solver.cpp:542] Iteration 41420, lr = 0.001
I0416 20:22:50.996042   977 solver.cpp:221] Iteration 41440, loss = 0.0424727
I0416 20:22:50.996069   977 solver.cpp:236]     Train net output #0: loss = 0.0528096 (* 1 = 0.0528096 loss)
I0416 20:22:50.996074   977 solver.cpp:542] Iteration 41440, lr = 0.001
I0416 20:23:04.540402   977 solver.cpp:221] Iteration 41460, loss = 0.0429866
I0416 20:23:04.540429   977 solver.cpp:236]     Train net output #0: loss = 0.0427077 (* 1 = 0.0427077 loss)
I0416 20:23:04.540434   977 solver.cpp:542] Iteration 41460, lr = 0.001
I0416 20:23:18.081789   977 solver.cpp:221] Iteration 41480, loss = 0.0413405
I0416 20:23:18.081816   977 solver.cpp:236]     Train net output #0: loss = 0.0442203 (* 1 = 0.0442203 loss)
I0416 20:23:18.081820   977 solver.cpp:542] Iteration 41480, lr = 0.001
I0416 20:23:31.605989   977 solver.cpp:221] Iteration 41500, loss = 0.0489102
I0416 20:23:31.606017   977 solver.cpp:236]     Train net output #0: loss = 0.0408137 (* 1 = 0.0408137 loss)
I0416 20:23:31.606022   977 solver.cpp:542] Iteration 41500, lr = 0.001
I0416 20:23:45.157652   977 solver.cpp:221] Iteration 41520, loss = 0.0428351
I0416 20:23:45.157681   977 solver.cpp:236]     Train net output #0: loss = 0.0441397 (* 1 = 0.0441397 loss)
I0416 20:23:45.157685   977 solver.cpp:542] Iteration 41520, lr = 0.001
I0416 20:23:58.738657   977 solver.cpp:221] Iteration 41540, loss = 0.0441441
I0416 20:23:58.738683   977 solver.cpp:236]     Train net output #0: loss = 0.0321624 (* 1 = 0.0321624 loss)
I0416 20:23:58.738688   977 solver.cpp:542] Iteration 41540, lr = 0.001
I0416 20:24:12.260386   977 solver.cpp:221] Iteration 41560, loss = 0.040432
I0416 20:24:12.260412   977 solver.cpp:236]     Train net output #0: loss = 0.0222236 (* 1 = 0.0222236 loss)
I0416 20:24:12.260417   977 solver.cpp:542] Iteration 41560, lr = 0.001
I0416 20:24:25.815418   977 solver.cpp:221] Iteration 41580, loss = 0.0413215
I0416 20:24:25.815445   977 solver.cpp:236]     Train net output #0: loss = 0.035034 (* 1 = 0.035034 loss)
I0416 20:24:25.815450   977 solver.cpp:542] Iteration 41580, lr = 0.001
I0416 20:24:38.726680   977 solver.cpp:316] Iteration 41600, Testing net (#0)
I0416 20:24:50.260278   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:24:50.260300   977 solver.cpp:373]     Test net output #1: loss = 0.0368448 (* 1 = 0.0368448 loss)
I0416 20:24:50.928663   977 solver.cpp:221] Iteration 41600, loss = 0.0449005
I0416 20:24:50.928690   977 solver.cpp:236]     Train net output #0: loss = 0.0307979 (* 1 = 0.0307979 loss)
I0416 20:24:50.928695   977 solver.cpp:542] Iteration 41600, lr = 0.001
I0416 20:25:04.475870   977 solver.cpp:221] Iteration 41620, loss = 0.0468607
I0416 20:25:04.475898   977 solver.cpp:236]     Train net output #0: loss = 0.0396451 (* 1 = 0.0396451 loss)
I0416 20:25:04.475904   977 solver.cpp:542] Iteration 41620, lr = 0.001
I0416 20:25:18.031556   977 solver.cpp:221] Iteration 41640, loss = 0.0434827
I0416 20:25:18.031584   977 solver.cpp:236]     Train net output #0: loss = 0.0297622 (* 1 = 0.0297622 loss)
I0416 20:25:18.031589   977 solver.cpp:542] Iteration 41640, lr = 0.001
I0416 20:25:31.584724   977 solver.cpp:221] Iteration 41660, loss = 0.0418639
I0416 20:25:31.584753   977 solver.cpp:236]     Train net output #0: loss = 0.0445297 (* 1 = 0.0445297 loss)
I0416 20:25:31.584758   977 solver.cpp:542] Iteration 41660, lr = 0.001
I0416 20:25:45.143215   977 solver.cpp:221] Iteration 41680, loss = 0.0361142
I0416 20:25:45.143242   977 solver.cpp:236]     Train net output #0: loss = 0.0433423 (* 1 = 0.0433423 loss)
I0416 20:25:45.143247   977 solver.cpp:542] Iteration 41680, lr = 0.001
I0416 20:25:58.692111   977 solver.cpp:221] Iteration 41700, loss = 0.0453224
I0416 20:25:58.692139   977 solver.cpp:236]     Train net output #0: loss = 0.0435465 (* 1 = 0.0435465 loss)
I0416 20:25:58.692144   977 solver.cpp:542] Iteration 41700, lr = 0.001
I0416 20:26:12.215744   977 solver.cpp:221] Iteration 41720, loss = 0.0457213
I0416 20:26:12.215771   977 solver.cpp:236]     Train net output #0: loss = 0.0288512 (* 1 = 0.0288512 loss)
I0416 20:26:12.215776   977 solver.cpp:542] Iteration 41720, lr = 0.001
I0416 20:26:25.770797   977 solver.cpp:221] Iteration 41740, loss = 0.0430495
I0416 20:26:25.770823   977 solver.cpp:236]     Train net output #0: loss = 0.044257 (* 1 = 0.044257 loss)
I0416 20:26:25.770828   977 solver.cpp:542] Iteration 41740, lr = 0.001
I0416 20:26:39.331168   977 solver.cpp:221] Iteration 41760, loss = 0.0476279
I0416 20:26:39.331195   977 solver.cpp:236]     Train net output #0: loss = 0.0330626 (* 1 = 0.0330626 loss)
I0416 20:26:39.331200   977 solver.cpp:542] Iteration 41760, lr = 0.001
I0416 20:26:52.862843   977 solver.cpp:221] Iteration 41780, loss = 0.0432631
I0416 20:26:52.862869   977 solver.cpp:236]     Train net output #0: loss = 0.035675 (* 1 = 0.035675 loss)
I0416 20:26:52.862874   977 solver.cpp:542] Iteration 41780, lr = 0.001
I0416 20:27:05.742152   977 solver.cpp:316] Iteration 41800, Testing net (#0)
I0416 20:27:17.276988   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:27:17.277009   977 solver.cpp:373]     Test net output #1: loss = 0.0373395 (* 1 = 0.0373395 loss)
I0416 20:27:17.945081   977 solver.cpp:221] Iteration 41800, loss = 0.0426224
I0416 20:27:17.945109   977 solver.cpp:236]     Train net output #0: loss = 0.0586833 (* 1 = 0.0586833 loss)
I0416 20:27:17.945114   977 solver.cpp:542] Iteration 41800, lr = 0.001
I0416 20:27:31.489038   977 solver.cpp:221] Iteration 41820, loss = 0.0457242
I0416 20:27:31.489068   977 solver.cpp:236]     Train net output #0: loss = 0.0435148 (* 1 = 0.0435148 loss)
I0416 20:27:31.489073   977 solver.cpp:542] Iteration 41820, lr = 0.001
I0416 20:27:45.059962   977 solver.cpp:221] Iteration 41840, loss = 0.0408136
I0416 20:27:45.059990   977 solver.cpp:236]     Train net output #0: loss = 0.034415 (* 1 = 0.034415 loss)
I0416 20:27:45.059995   977 solver.cpp:542] Iteration 41840, lr = 0.001
I0416 20:27:58.615797   977 solver.cpp:221] Iteration 41860, loss = 0.0445543
I0416 20:27:58.615823   977 solver.cpp:236]     Train net output #0: loss = 0.0498821 (* 1 = 0.0498821 loss)
I0416 20:27:58.615828   977 solver.cpp:542] Iteration 41860, lr = 0.001
I0416 20:28:12.163218   977 solver.cpp:221] Iteration 41880, loss = 0.0425549
I0416 20:28:12.163244   977 solver.cpp:236]     Train net output #0: loss = 0.0504763 (* 1 = 0.0504763 loss)
I0416 20:28:12.163249   977 solver.cpp:542] Iteration 41880, lr = 0.001
I0416 20:28:25.706945   977 solver.cpp:221] Iteration 41900, loss = 0.0465795
I0416 20:28:25.706974   977 solver.cpp:236]     Train net output #0: loss = 0.0224188 (* 1 = 0.0224188 loss)
I0416 20:28:25.706977   977 solver.cpp:542] Iteration 41900, lr = 0.001
I0416 20:28:39.247269   977 solver.cpp:221] Iteration 41920, loss = 0.0476114
I0416 20:28:39.247298   977 solver.cpp:236]     Train net output #0: loss = 0.0282932 (* 1 = 0.0282932 loss)
I0416 20:28:39.247303   977 solver.cpp:542] Iteration 41920, lr = 0.001
I0416 20:28:52.797657   977 solver.cpp:221] Iteration 41940, loss = 0.0404064
I0416 20:28:52.797685   977 solver.cpp:236]     Train net output #0: loss = 0.0279198 (* 1 = 0.0279198 loss)
I0416 20:28:52.797690   977 solver.cpp:542] Iteration 41940, lr = 0.001
I0416 20:29:06.354976   977 solver.cpp:221] Iteration 41960, loss = 0.0448876
I0416 20:29:06.355003   977 solver.cpp:236]     Train net output #0: loss = 0.0429101 (* 1 = 0.0429101 loss)
I0416 20:29:06.355008   977 solver.cpp:542] Iteration 41960, lr = 0.001
I0416 20:29:19.899104   977 solver.cpp:221] Iteration 41980, loss = 0.0420669
I0416 20:29:19.899132   977 solver.cpp:236]     Train net output #0: loss = 0.0404565 (* 1 = 0.0404565 loss)
I0416 20:29:19.899137   977 solver.cpp:542] Iteration 41980, lr = 0.001
I0416 20:29:32.810199   977 solver.cpp:316] Iteration 42000, Testing net (#0)
I0416 20:29:44.357589   977 solver.cpp:373]     Test net output #0: accuracy = 0.992585
I0416 20:29:44.357611   977 solver.cpp:373]     Test net output #1: loss = 0.0370597 (* 1 = 0.0370597 loss)
I0416 20:29:45.028846   977 solver.cpp:221] Iteration 42000, loss = 0.0428376
I0416 20:29:45.028874   977 solver.cpp:236]     Train net output #0: loss = 0.0358533 (* 1 = 0.0358533 loss)
I0416 20:29:45.028879   977 solver.cpp:542] Iteration 42000, lr = 0.001
I0416 20:29:58.553716   977 solver.cpp:221] Iteration 42020, loss = 0.0439029
I0416 20:29:58.553745   977 solver.cpp:236]     Train net output #0: loss = 0.0463138 (* 1 = 0.0463138 loss)
I0416 20:29:58.553750   977 solver.cpp:542] Iteration 42020, lr = 0.001
I0416 20:30:12.106055   977 solver.cpp:221] Iteration 42040, loss = 0.0431074
I0416 20:30:12.106081   977 solver.cpp:236]     Train net output #0: loss = 0.0390302 (* 1 = 0.0390302 loss)
I0416 20:30:12.106086   977 solver.cpp:542] Iteration 42040, lr = 0.001
I0416 20:30:25.642283   977 solver.cpp:221] Iteration 42060, loss = 0.0459482
I0416 20:30:25.642312   977 solver.cpp:236]     Train net output #0: loss = 0.0664658 (* 1 = 0.0664658 loss)
I0416 20:30:25.642315   977 solver.cpp:542] Iteration 42060, lr = 0.001
I0416 20:30:39.189152   977 solver.cpp:221] Iteration 42080, loss = 0.0461212
I0416 20:30:39.189178   977 solver.cpp:236]     Train net output #0: loss = 0.100359 (* 1 = 0.100359 loss)
I0416 20:30:39.189183   977 solver.cpp:542] Iteration 42080, lr = 0.001
I0416 20:30:52.730093   977 solver.cpp:221] Iteration 42100, loss = 0.0390076
I0416 20:30:52.730120   977 solver.cpp:236]     Train net output #0: loss = 0.0415046 (* 1 = 0.0415046 loss)
I0416 20:30:52.730124   977 solver.cpp:542] Iteration 42100, lr = 0.001
I0416 20:31:06.250268   977 solver.cpp:221] Iteration 42120, loss = 0.0434996
I0416 20:31:06.250294   977 solver.cpp:236]     Train net output #0: loss = 0.0483819 (* 1 = 0.0483819 loss)
I0416 20:31:06.250299   977 solver.cpp:542] Iteration 42120, lr = 0.001
I0416 20:31:19.775351   977 solver.cpp:221] Iteration 42140, loss = 0.0490675
I0416 20:31:19.775378   977 solver.cpp:236]     Train net output #0: loss = 0.0321467 (* 1 = 0.0321467 loss)
I0416 20:31:19.775382   977 solver.cpp:542] Iteration 42140, lr = 0.001
I0416 20:31:33.323683   977 solver.cpp:221] Iteration 42160, loss = 0.0462668
I0416 20:31:33.323710   977 solver.cpp:236]     Train net output #0: loss = 0.066269 (* 1 = 0.066269 loss)
I0416 20:31:33.323715   977 solver.cpp:542] Iteration 42160, lr = 0.001
I0416 20:31:46.867421   977 solver.cpp:221] Iteration 42180, loss = 0.0401272
I0416 20:31:46.867449   977 solver.cpp:236]     Train net output #0: loss = 0.0372311 (* 1 = 0.0372311 loss)
I0416 20:31:46.867452   977 solver.cpp:542] Iteration 42180, lr = 0.001
I0416 20:31:59.766368   977 solver.cpp:316] Iteration 42200, Testing net (#0)
I0416 20:32:11.314324   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:32:11.314347   977 solver.cpp:373]     Test net output #1: loss = 0.0369869 (* 1 = 0.0369869 loss)
I0416 20:32:11.986443   977 solver.cpp:221] Iteration 42200, loss = 0.0432529
I0416 20:32:11.986469   977 solver.cpp:236]     Train net output #0: loss = 0.0361304 (* 1 = 0.0361304 loss)
I0416 20:32:11.986474   977 solver.cpp:542] Iteration 42200, lr = 0.001
I0416 20:32:25.566433   977 solver.cpp:221] Iteration 42220, loss = 0.039821
I0416 20:32:25.566462   977 solver.cpp:236]     Train net output #0: loss = 0.0306147 (* 1 = 0.0306147 loss)
I0416 20:32:25.566467   977 solver.cpp:542] Iteration 42220, lr = 0.001
I0416 20:32:39.151201   977 solver.cpp:221] Iteration 42240, loss = 0.0423064
I0416 20:32:39.151227   977 solver.cpp:236]     Train net output #0: loss = 0.0389261 (* 1 = 0.0389261 loss)
I0416 20:32:39.151232   977 solver.cpp:542] Iteration 42240, lr = 0.001
I0416 20:32:52.677695   977 solver.cpp:221] Iteration 42260, loss = 0.0418503
I0416 20:32:52.677721   977 solver.cpp:236]     Train net output #0: loss = 0.0459383 (* 1 = 0.0459383 loss)
I0416 20:32:52.677726   977 solver.cpp:542] Iteration 42260, lr = 0.001
I0416 20:33:06.192023   977 solver.cpp:221] Iteration 42280, loss = 0.0433232
I0416 20:33:06.192049   977 solver.cpp:236]     Train net output #0: loss = 0.0396981 (* 1 = 0.0396981 loss)
I0416 20:33:06.192054   977 solver.cpp:542] Iteration 42280, lr = 0.001
I0416 20:33:19.730243   977 solver.cpp:221] Iteration 42300, loss = 0.0381288
I0416 20:33:19.730271   977 solver.cpp:236]     Train net output #0: loss = 0.0374153 (* 1 = 0.0374153 loss)
I0416 20:33:19.730276   977 solver.cpp:542] Iteration 42300, lr = 0.001
I0416 20:33:33.287987   977 solver.cpp:221] Iteration 42320, loss = 0.0426689
I0416 20:33:33.288015   977 solver.cpp:236]     Train net output #0: loss = 0.0342733 (* 1 = 0.0342733 loss)
I0416 20:33:33.288020   977 solver.cpp:542] Iteration 42320, lr = 0.001
I0416 20:33:46.855394   977 solver.cpp:221] Iteration 42340, loss = 0.0474822
I0416 20:33:46.855422   977 solver.cpp:236]     Train net output #0: loss = 0.035266 (* 1 = 0.035266 loss)
I0416 20:33:46.855427   977 solver.cpp:542] Iteration 42340, lr = 0.001
I0416 20:34:00.416803   977 solver.cpp:221] Iteration 42360, loss = 0.0425737
I0416 20:34:00.416831   977 solver.cpp:236]     Train net output #0: loss = 0.0367334 (* 1 = 0.0367334 loss)
I0416 20:34:00.416836   977 solver.cpp:542] Iteration 42360, lr = 0.001
I0416 20:34:13.974380   977 solver.cpp:221] Iteration 42380, loss = 0.0431323
I0416 20:34:13.974407   977 solver.cpp:236]     Train net output #0: loss = 0.0480613 (* 1 = 0.0480613 loss)
I0416 20:34:13.974412   977 solver.cpp:542] Iteration 42380, lr = 0.001
I0416 20:34:26.856091   977 solver.cpp:316] Iteration 42400, Testing net (#0)
I0416 20:34:38.399495   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 20:34:38.399518   977 solver.cpp:373]     Test net output #1: loss = 0.0369157 (* 1 = 0.0369157 loss)
I0416 20:34:39.070968   977 solver.cpp:221] Iteration 42400, loss = 0.0433793
I0416 20:34:39.070996   977 solver.cpp:236]     Train net output #0: loss = 0.0448329 (* 1 = 0.0448329 loss)
I0416 20:34:39.071001   977 solver.cpp:542] Iteration 42400, lr = 0.001
I0416 20:34:52.628790   977 solver.cpp:221] Iteration 42420, loss = 0.0423015
I0416 20:34:52.628818   977 solver.cpp:236]     Train net output #0: loss = 0.0421032 (* 1 = 0.0421032 loss)
I0416 20:34:52.628823   977 solver.cpp:542] Iteration 42420, lr = 0.001
I0416 20:35:06.186465   977 solver.cpp:221] Iteration 42440, loss = 0.045305
I0416 20:35:06.186491   977 solver.cpp:236]     Train net output #0: loss = 0.0427115 (* 1 = 0.0427115 loss)
I0416 20:35:06.186496   977 solver.cpp:542] Iteration 42440, lr = 0.001
I0416 20:35:19.754978   977 solver.cpp:221] Iteration 42460, loss = 0.0433544
I0416 20:35:19.755005   977 solver.cpp:236]     Train net output #0: loss = 0.0687221 (* 1 = 0.0687221 loss)
I0416 20:35:19.755010   977 solver.cpp:542] Iteration 42460, lr = 0.001
I0416 20:35:33.315661   977 solver.cpp:221] Iteration 42480, loss = 0.0410018
I0416 20:35:33.315688   977 solver.cpp:236]     Train net output #0: loss = 0.0283304 (* 1 = 0.0283304 loss)
I0416 20:35:33.315693   977 solver.cpp:542] Iteration 42480, lr = 0.001
I0416 20:35:46.855288   977 solver.cpp:221] Iteration 42500, loss = 0.0403626
I0416 20:35:46.855317   977 solver.cpp:236]     Train net output #0: loss = 0.0473486 (* 1 = 0.0473486 loss)
I0416 20:35:46.855322   977 solver.cpp:542] Iteration 42500, lr = 0.001
I0416 20:36:00.393412   977 solver.cpp:221] Iteration 42520, loss = 0.041938
I0416 20:36:00.393440   977 solver.cpp:236]     Train net output #0: loss = 0.0472295 (* 1 = 0.0472295 loss)
I0416 20:36:00.393445   977 solver.cpp:542] Iteration 42520, lr = 0.001
I0416 20:36:13.943356   977 solver.cpp:221] Iteration 42540, loss = 0.0421827
I0416 20:36:13.943382   977 solver.cpp:236]     Train net output #0: loss = 0.0566301 (* 1 = 0.0566301 loss)
I0416 20:36:13.943387   977 solver.cpp:542] Iteration 42540, lr = 0.001
I0416 20:36:27.492951   977 solver.cpp:221] Iteration 42560, loss = 0.0471697
I0416 20:36:27.492980   977 solver.cpp:236]     Train net output #0: loss = 0.022398 (* 1 = 0.022398 loss)
I0416 20:36:27.492985   977 solver.cpp:542] Iteration 42560, lr = 0.001
I0416 20:36:41.016016   977 solver.cpp:221] Iteration 42580, loss = 0.0472417
I0416 20:36:41.016044   977 solver.cpp:236]     Train net output #0: loss = 0.0634999 (* 1 = 0.0634999 loss)
I0416 20:36:41.016049   977 solver.cpp:542] Iteration 42580, lr = 0.001
I0416 20:36:53.907961   977 solver.cpp:316] Iteration 42600, Testing net (#0)
I0416 20:37:05.444957   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 20:37:05.444977   977 solver.cpp:373]     Test net output #1: loss = 0.035973 (* 1 = 0.035973 loss)
I0416 20:37:06.114333   977 solver.cpp:221] Iteration 42600, loss = 0.0449289
I0416 20:37:06.114362   977 solver.cpp:236]     Train net output #0: loss = 0.0781327 (* 1 = 0.0781327 loss)
I0416 20:37:06.114367   977 solver.cpp:542] Iteration 42600, lr = 0.001
I0416 20:37:19.662312   977 solver.cpp:221] Iteration 42620, loss = 0.044703
I0416 20:37:19.662338   977 solver.cpp:236]     Train net output #0: loss = 0.0504627 (* 1 = 0.0504627 loss)
I0416 20:37:19.662343   977 solver.cpp:542] Iteration 42620, lr = 0.001
I0416 20:37:33.212357   977 solver.cpp:221] Iteration 42640, loss = 0.0438541
I0416 20:37:33.212385   977 solver.cpp:236]     Train net output #0: loss = 0.0412934 (* 1 = 0.0412934 loss)
I0416 20:37:33.212390   977 solver.cpp:542] Iteration 42640, lr = 0.001
I0416 20:37:46.739387   977 solver.cpp:221] Iteration 42660, loss = 0.0401007
I0416 20:37:46.739414   977 solver.cpp:236]     Train net output #0: loss = 0.0335757 (* 1 = 0.0335757 loss)
I0416 20:37:46.739419   977 solver.cpp:542] Iteration 42660, lr = 0.001
I0416 20:38:00.299646   977 solver.cpp:221] Iteration 42680, loss = 0.04222
I0416 20:38:00.299674   977 solver.cpp:236]     Train net output #0: loss = 0.0688395 (* 1 = 0.0688395 loss)
I0416 20:38:00.299679   977 solver.cpp:542] Iteration 42680, lr = 0.001
I0416 20:38:13.866430   977 solver.cpp:221] Iteration 42700, loss = 0.0434576
I0416 20:38:13.866457   977 solver.cpp:236]     Train net output #0: loss = 0.0392217 (* 1 = 0.0392217 loss)
I0416 20:38:13.866461   977 solver.cpp:542] Iteration 42700, lr = 0.001
I0416 20:38:27.426278   977 solver.cpp:221] Iteration 42720, loss = 0.0415347
I0416 20:38:27.426306   977 solver.cpp:236]     Train net output #0: loss = 0.0503207 (* 1 = 0.0503207 loss)
I0416 20:38:27.426311   977 solver.cpp:542] Iteration 42720, lr = 0.001
I0416 20:38:40.978030   977 solver.cpp:221] Iteration 42740, loss = 0.0369789
I0416 20:38:40.978057   977 solver.cpp:236]     Train net output #0: loss = 0.0454752 (* 1 = 0.0454752 loss)
I0416 20:38:40.978062   977 solver.cpp:542] Iteration 42740, lr = 0.001
I0416 20:38:54.538368   977 solver.cpp:221] Iteration 42760, loss = 0.0408532
I0416 20:38:54.538396   977 solver.cpp:236]     Train net output #0: loss = 0.0529332 (* 1 = 0.0529332 loss)
I0416 20:38:54.538400   977 solver.cpp:542] Iteration 42760, lr = 0.001
I0416 20:39:08.081521   977 solver.cpp:221] Iteration 42780, loss = 0.0430987
I0416 20:39:08.081557   977 solver.cpp:236]     Train net output #0: loss = 0.0453976 (* 1 = 0.0453976 loss)
I0416 20:39:08.081562   977 solver.cpp:542] Iteration 42780, lr = 0.001
I0416 20:39:20.954093   977 solver.cpp:316] Iteration 42800, Testing net (#0)
I0416 20:39:32.488595   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 20:39:32.488617   977 solver.cpp:373]     Test net output #1: loss = 0.0358529 (* 1 = 0.0358529 loss)
I0416 20:39:33.158202   977 solver.cpp:221] Iteration 42800, loss = 0.0437759
I0416 20:39:33.158236   977 solver.cpp:236]     Train net output #0: loss = 0.0370827 (* 1 = 0.0370827 loss)
I0416 20:39:33.158241   977 solver.cpp:542] Iteration 42800, lr = 0.001
I0416 20:39:46.703178   977 solver.cpp:221] Iteration 42820, loss = 0.0432758
I0416 20:39:46.703205   977 solver.cpp:236]     Train net output #0: loss = 0.0386286 (* 1 = 0.0386286 loss)
I0416 20:39:46.703210   977 solver.cpp:542] Iteration 42820, lr = 0.001
I0416 20:40:00.248870   977 solver.cpp:221] Iteration 42840, loss = 0.0383513
I0416 20:40:00.248898   977 solver.cpp:236]     Train net output #0: loss = 0.02121 (* 1 = 0.02121 loss)
I0416 20:40:00.248903   977 solver.cpp:542] Iteration 42840, lr = 0.001
I0416 20:40:13.815287   977 solver.cpp:221] Iteration 42860, loss = 0.038972
I0416 20:40:13.815315   977 solver.cpp:236]     Train net output #0: loss = 0.0643536 (* 1 = 0.0643536 loss)
I0416 20:40:13.815320   977 solver.cpp:542] Iteration 42860, lr = 0.001
I0416 20:40:27.374236   977 solver.cpp:221] Iteration 42880, loss = 0.0398628
I0416 20:40:27.374264   977 solver.cpp:236]     Train net output #0: loss = 0.0477038 (* 1 = 0.0477038 loss)
I0416 20:40:27.374269   977 solver.cpp:542] Iteration 42880, lr = 0.001
I0416 20:40:40.911285   977 solver.cpp:221] Iteration 42900, loss = 0.0439302
I0416 20:40:40.911312   977 solver.cpp:236]     Train net output #0: loss = 0.0495307 (* 1 = 0.0495307 loss)
I0416 20:40:40.911317   977 solver.cpp:542] Iteration 42900, lr = 0.001
I0416 20:40:54.437464   977 solver.cpp:221] Iteration 42920, loss = 0.0429968
I0416 20:40:54.437491   977 solver.cpp:236]     Train net output #0: loss = 0.0781752 (* 1 = 0.0781752 loss)
I0416 20:40:54.437496   977 solver.cpp:542] Iteration 42920, lr = 0.001
I0416 20:41:07.986214   977 solver.cpp:221] Iteration 42940, loss = 0.0393481
I0416 20:41:07.986240   977 solver.cpp:236]     Train net output #0: loss = 0.0308461 (* 1 = 0.0308461 loss)
I0416 20:41:07.986245   977 solver.cpp:542] Iteration 42940, lr = 0.001
I0416 20:41:21.543174   977 solver.cpp:221] Iteration 42960, loss = 0.04207
I0416 20:41:21.543200   977 solver.cpp:236]     Train net output #0: loss = 0.0961052 (* 1 = 0.0961052 loss)
I0416 20:41:21.543205   977 solver.cpp:542] Iteration 42960, lr = 0.001
I0416 20:41:35.077657   977 solver.cpp:221] Iteration 42980, loss = 0.0444796
I0416 20:41:35.077684   977 solver.cpp:236]     Train net output #0: loss = 0.049999 (* 1 = 0.049999 loss)
I0416 20:41:35.077688   977 solver.cpp:542] Iteration 42980, lr = 0.001
I0416 20:41:47.945513   977 solver.cpp:316] Iteration 43000, Testing net (#0)
I0416 20:41:59.482727   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 20:41:59.482748   977 solver.cpp:373]     Test net output #1: loss = 0.0359904 (* 1 = 0.0359904 loss)
I0416 20:42:00.150697   977 solver.cpp:221] Iteration 43000, loss = 0.0398015
I0416 20:42:00.150725   977 solver.cpp:236]     Train net output #0: loss = 0.0408354 (* 1 = 0.0408354 loss)
I0416 20:42:00.150730   977 solver.cpp:542] Iteration 43000, lr = 0.001
I0416 20:42:13.678216   977 solver.cpp:221] Iteration 43020, loss = 0.0432735
I0416 20:42:13.678244   977 solver.cpp:236]     Train net output #0: loss = 0.0327268 (* 1 = 0.0327268 loss)
I0416 20:42:13.678248   977 solver.cpp:542] Iteration 43020, lr = 0.001
I0416 20:42:27.204154   977 solver.cpp:221] Iteration 43040, loss = 0.0432344
I0416 20:42:27.204180   977 solver.cpp:236]     Train net output #0: loss = 0.0587542 (* 1 = 0.0587542 loss)
I0416 20:42:27.204185   977 solver.cpp:542] Iteration 43040, lr = 0.001
I0416 20:42:40.753921   977 solver.cpp:221] Iteration 43060, loss = 0.040226
I0416 20:42:40.753947   977 solver.cpp:236]     Train net output #0: loss = 0.0485884 (* 1 = 0.0485884 loss)
I0416 20:42:40.753952   977 solver.cpp:542] Iteration 43060, lr = 0.001
I0416 20:42:54.299329   977 solver.cpp:221] Iteration 43080, loss = 0.0435396
I0416 20:42:54.299356   977 solver.cpp:236]     Train net output #0: loss = 0.0477561 (* 1 = 0.0477561 loss)
I0416 20:42:54.299361   977 solver.cpp:542] Iteration 43080, lr = 0.001
I0416 20:43:07.838599   977 solver.cpp:221] Iteration 43100, loss = 0.0456893
I0416 20:43:07.838629   977 solver.cpp:236]     Train net output #0: loss = 0.0324997 (* 1 = 0.0324997 loss)
I0416 20:43:07.838632   977 solver.cpp:542] Iteration 43100, lr = 0.001
I0416 20:43:21.364637   977 solver.cpp:221] Iteration 43120, loss = 0.0429861
I0416 20:43:21.364665   977 solver.cpp:236]     Train net output #0: loss = 0.0424338 (* 1 = 0.0424338 loss)
I0416 20:43:21.364670   977 solver.cpp:542] Iteration 43120, lr = 0.001
I0416 20:43:34.909364   977 solver.cpp:221] Iteration 43140, loss = 0.0375081
I0416 20:43:34.909392   977 solver.cpp:236]     Train net output #0: loss = 0.0143242 (* 1 = 0.0143242 loss)
I0416 20:43:34.909396   977 solver.cpp:542] Iteration 43140, lr = 0.001
I0416 20:43:48.461931   977 solver.cpp:221] Iteration 43160, loss = 0.043936
I0416 20:43:48.461961   977 solver.cpp:236]     Train net output #0: loss = 0.0682436 (* 1 = 0.0682436 loss)
I0416 20:43:48.461964   977 solver.cpp:542] Iteration 43160, lr = 0.001
I0416 20:44:01.997273   977 solver.cpp:221] Iteration 43180, loss = 0.0434943
I0416 20:44:01.997301   977 solver.cpp:236]     Train net output #0: loss = 0.0418652 (* 1 = 0.0418652 loss)
I0416 20:44:01.997306   977 solver.cpp:542] Iteration 43180, lr = 0.001
I0416 20:44:14.870297   977 solver.cpp:316] Iteration 43200, Testing net (#0)
I0416 20:44:26.407111   977 solver.cpp:373]     Test net output #0: accuracy = 0.992965
I0416 20:44:26.407132   977 solver.cpp:373]     Test net output #1: loss = 0.035899 (* 1 = 0.035899 loss)
I0416 20:44:27.076424   977 solver.cpp:221] Iteration 43200, loss = 0.0446135
I0416 20:44:27.076452   977 solver.cpp:236]     Train net output #0: loss = 0.0427793 (* 1 = 0.0427793 loss)
I0416 20:44:27.076457   977 solver.cpp:542] Iteration 43200, lr = 0.001
I0416 20:44:40.606112   977 solver.cpp:221] Iteration 43220, loss = 0.0403624
I0416 20:44:40.606139   977 solver.cpp:236]     Train net output #0: loss = 0.0385679 (* 1 = 0.0385679 loss)
I0416 20:44:40.606143   977 solver.cpp:542] Iteration 43220, lr = 0.001
I0416 20:44:54.128099   977 solver.cpp:221] Iteration 43240, loss = 0.0427269
I0416 20:44:54.128126   977 solver.cpp:236]     Train net output #0: loss = 0.0384202 (* 1 = 0.0384202 loss)
I0416 20:44:54.128131   977 solver.cpp:542] Iteration 43240, lr = 0.001
I0416 20:45:07.650010   977 solver.cpp:221] Iteration 43260, loss = 0.0411144
I0416 20:45:07.650038   977 solver.cpp:236]     Train net output #0: loss = 0.031703 (* 1 = 0.031703 loss)
I0416 20:45:07.650043   977 solver.cpp:542] Iteration 43260, lr = 0.001
I0416 20:45:21.173693   977 solver.cpp:221] Iteration 43280, loss = 0.0410756
I0416 20:45:21.173722   977 solver.cpp:236]     Train net output #0: loss = 0.0341819 (* 1 = 0.0341819 loss)
I0416 20:45:21.173725   977 solver.cpp:542] Iteration 43280, lr = 0.001
I0416 20:45:34.700120   977 solver.cpp:221] Iteration 43300, loss = 0.039828
I0416 20:45:34.700147   977 solver.cpp:236]     Train net output #0: loss = 0.0277834 (* 1 = 0.0277834 loss)
I0416 20:45:34.700152   977 solver.cpp:542] Iteration 43300, lr = 0.001
I0416 20:45:48.223944   977 solver.cpp:221] Iteration 43320, loss = 0.0415748
I0416 20:45:48.223973   977 solver.cpp:236]     Train net output #0: loss = 0.0530977 (* 1 = 0.0530977 loss)
I0416 20:45:48.223978   977 solver.cpp:542] Iteration 43320, lr = 0.001
I0416 20:46:01.745674   977 solver.cpp:221] Iteration 43340, loss = 0.0393447
I0416 20:46:01.745702   977 solver.cpp:236]     Train net output #0: loss = 0.0395861 (* 1 = 0.0395861 loss)
I0416 20:46:01.745707   977 solver.cpp:542] Iteration 43340, lr = 0.001
I0416 20:46:15.309803   977 solver.cpp:221] Iteration 43360, loss = 0.0421615
I0416 20:46:15.309830   977 solver.cpp:236]     Train net output #0: loss = 0.0267745 (* 1 = 0.0267745 loss)
I0416 20:46:15.309835   977 solver.cpp:542] Iteration 43360, lr = 0.001
I0416 20:46:28.857337   977 solver.cpp:221] Iteration 43380, loss = 0.0436187
I0416 20:46:28.857364   977 solver.cpp:236]     Train net output #0: loss = 0.0265886 (* 1 = 0.0265886 loss)
I0416 20:46:28.857369   977 solver.cpp:542] Iteration 43380, lr = 0.001
I0416 20:46:41.725569   977 solver.cpp:316] Iteration 43400, Testing net (#0)
I0416 20:46:53.262718   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 20:46:53.262740   977 solver.cpp:373]     Test net output #1: loss = 0.0360006 (* 1 = 0.0360006 loss)
I0416 20:46:53.932286   977 solver.cpp:221] Iteration 43400, loss = 0.042121
I0416 20:46:53.932314   977 solver.cpp:236]     Train net output #0: loss = 0.0351533 (* 1 = 0.0351533 loss)
I0416 20:46:53.932319   977 solver.cpp:542] Iteration 43400, lr = 0.001
I0416 20:47:07.452018   977 solver.cpp:221] Iteration 43420, loss = 0.0455999
I0416 20:47:07.452047   977 solver.cpp:236]     Train net output #0: loss = 0.0559393 (* 1 = 0.0559393 loss)
I0416 20:47:07.452051   977 solver.cpp:542] Iteration 43420, lr = 0.001
I0416 20:47:20.991854   977 solver.cpp:221] Iteration 43440, loss = 0.0425988
I0416 20:47:20.991880   977 solver.cpp:236]     Train net output #0: loss = 0.0179075 (* 1 = 0.0179075 loss)
I0416 20:47:20.991884   977 solver.cpp:542] Iteration 43440, lr = 0.001
I0416 20:47:34.523015   977 solver.cpp:221] Iteration 43460, loss = 0.0413093
I0416 20:47:34.523043   977 solver.cpp:236]     Train net output #0: loss = 0.0381814 (* 1 = 0.0381814 loss)
I0416 20:47:34.523048   977 solver.cpp:542] Iteration 43460, lr = 0.001
I0416 20:47:48.055619   977 solver.cpp:221] Iteration 43480, loss = 0.0408516
I0416 20:47:48.055647   977 solver.cpp:236]     Train net output #0: loss = 0.0281846 (* 1 = 0.0281846 loss)
I0416 20:47:48.055652   977 solver.cpp:542] Iteration 43480, lr = 0.001
I0416 20:48:01.588991   977 solver.cpp:221] Iteration 43500, loss = 0.0457822
I0416 20:48:01.589018   977 solver.cpp:236]     Train net output #0: loss = 0.0821138 (* 1 = 0.0821138 loss)
I0416 20:48:01.589022   977 solver.cpp:542] Iteration 43500, lr = 0.001
I0416 20:48:15.116653   977 solver.cpp:221] Iteration 43520, loss = 0.0431914
I0416 20:48:15.116680   977 solver.cpp:236]     Train net output #0: loss = 0.0313633 (* 1 = 0.0313633 loss)
I0416 20:48:15.116684   977 solver.cpp:542] Iteration 43520, lr = 0.001
I0416 20:48:28.657214   977 solver.cpp:221] Iteration 43540, loss = 0.0394766
I0416 20:48:28.657241   977 solver.cpp:236]     Train net output #0: loss = 0.0226207 (* 1 = 0.0226207 loss)
I0416 20:48:28.657246   977 solver.cpp:542] Iteration 43540, lr = 0.001
I0416 20:48:42.198233   977 solver.cpp:221] Iteration 43560, loss = 0.0378244
I0416 20:48:42.198261   977 solver.cpp:236]     Train net output #0: loss = 0.0335216 (* 1 = 0.0335216 loss)
I0416 20:48:42.198266   977 solver.cpp:542] Iteration 43560, lr = 0.001
I0416 20:48:55.721055   977 solver.cpp:221] Iteration 43580, loss = 0.0398907
I0416 20:48:55.721083   977 solver.cpp:236]     Train net output #0: loss = 0.0391907 (* 1 = 0.0391907 loss)
I0416 20:48:55.721087   977 solver.cpp:542] Iteration 43580, lr = 0.001
I0416 20:49:08.584484   977 solver.cpp:316] Iteration 43600, Testing net (#0)
I0416 20:49:20.118551   977 solver.cpp:373]     Test net output #0: accuracy = 0.992775
I0416 20:49:20.118572   977 solver.cpp:373]     Test net output #1: loss = 0.035785 (* 1 = 0.035785 loss)
I0416 20:49:20.786015   977 solver.cpp:221] Iteration 43600, loss = 0.0469429
I0416 20:49:20.786042   977 solver.cpp:236]     Train net output #0: loss = 0.0577929 (* 1 = 0.0577929 loss)
I0416 20:49:20.786047   977 solver.cpp:542] Iteration 43600, lr = 0.001
I0416 20:49:34.339359   977 solver.cpp:221] Iteration 43620, loss = 0.0431649
I0416 20:49:34.339387   977 solver.cpp:236]     Train net output #0: loss = 0.0490034 (* 1 = 0.0490034 loss)
I0416 20:49:34.339391   977 solver.cpp:542] Iteration 43620, lr = 0.001
I0416 20:49:47.894217   977 solver.cpp:221] Iteration 43640, loss = 0.044423
I0416 20:49:47.894244   977 solver.cpp:236]     Train net output #0: loss = 0.0318123 (* 1 = 0.0318123 loss)
I0416 20:49:47.894248   977 solver.cpp:542] Iteration 43640, lr = 0.001
I0416 20:50:01.436094   977 solver.cpp:221] Iteration 43660, loss = 0.03936
I0416 20:50:01.436120   977 solver.cpp:236]     Train net output #0: loss = 0.0382311 (* 1 = 0.0382311 loss)
I0416 20:50:01.436125   977 solver.cpp:542] Iteration 43660, lr = 0.001
I0416 20:50:15.002602   977 solver.cpp:221] Iteration 43680, loss = 0.0431804
I0416 20:50:15.002630   977 solver.cpp:236]     Train net output #0: loss = 0.0255382 (* 1 = 0.0255382 loss)
I0416 20:50:15.002635   977 solver.cpp:542] Iteration 43680, lr = 0.001
I0416 20:50:28.543591   977 solver.cpp:221] Iteration 43700, loss = 0.0400185
I0416 20:50:28.543618   977 solver.cpp:236]     Train net output #0: loss = 0.0307195 (* 1 = 0.0307195 loss)
I0416 20:50:28.543622   977 solver.cpp:542] Iteration 43700, lr = 0.001
I0416 20:50:42.079378   977 solver.cpp:221] Iteration 43720, loss = 0.043226
I0416 20:50:42.079406   977 solver.cpp:236]     Train net output #0: loss = 0.0386181 (* 1 = 0.0386181 loss)
I0416 20:50:42.079411   977 solver.cpp:542] Iteration 43720, lr = 0.001
I0416 20:50:55.608306   977 solver.cpp:221] Iteration 43740, loss = 0.0388423
I0416 20:50:55.608332   977 solver.cpp:236]     Train net output #0: loss = 0.0332717 (* 1 = 0.0332717 loss)
I0416 20:50:55.608337   977 solver.cpp:542] Iteration 43740, lr = 0.001
I0416 20:51:09.177249   977 solver.cpp:221] Iteration 43760, loss = 0.0393972
I0416 20:51:09.177278   977 solver.cpp:236]     Train net output #0: loss = 0.027194 (* 1 = 0.027194 loss)
I0416 20:51:09.177283   977 solver.cpp:542] Iteration 43760, lr = 0.001
I0416 20:51:22.733098   977 solver.cpp:221] Iteration 43780, loss = 0.0431404
I0416 20:51:22.733125   977 solver.cpp:236]     Train net output #0: loss = 0.0422444 (* 1 = 0.0422444 loss)
I0416 20:51:22.733130   977 solver.cpp:542] Iteration 43780, lr = 0.001
I0416 20:51:35.620738   977 solver.cpp:316] Iteration 43800, Testing net (#0)
I0416 20:51:47.154398   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 20:51:47.154420   977 solver.cpp:373]     Test net output #1: loss = 0.0356465 (* 1 = 0.0356465 loss)
I0416 20:51:47.824056   977 solver.cpp:221] Iteration 43800, loss = 0.0429294
I0416 20:51:47.824085   977 solver.cpp:236]     Train net output #0: loss = 0.0304288 (* 1 = 0.0304288 loss)
I0416 20:51:47.824090   977 solver.cpp:542] Iteration 43800, lr = 0.001
I0416 20:52:01.352536   977 solver.cpp:221] Iteration 43820, loss = 0.0473242
I0416 20:52:01.352563   977 solver.cpp:236]     Train net output #0: loss = 0.0341343 (* 1 = 0.0341343 loss)
I0416 20:52:01.352568   977 solver.cpp:542] Iteration 43820, lr = 0.001
I0416 20:52:14.882822   977 solver.cpp:221] Iteration 43840, loss = 0.0419258
I0416 20:52:14.882848   977 solver.cpp:236]     Train net output #0: loss = 0.0281427 (* 1 = 0.0281427 loss)
I0416 20:52:14.882853   977 solver.cpp:542] Iteration 43840, lr = 0.001
I0416 20:52:28.419093   977 solver.cpp:221] Iteration 43860, loss = 0.0392041
I0416 20:52:28.419121   977 solver.cpp:236]     Train net output #0: loss = 0.0314508 (* 1 = 0.0314508 loss)
I0416 20:52:28.419126   977 solver.cpp:542] Iteration 43860, lr = 0.001
I0416 20:52:41.954443   977 solver.cpp:221] Iteration 43880, loss = 0.0436642
I0416 20:52:41.954471   977 solver.cpp:236]     Train net output #0: loss = 0.0392784 (* 1 = 0.0392784 loss)
I0416 20:52:41.954475   977 solver.cpp:542] Iteration 43880, lr = 0.001
I0416 20:52:55.515770   977 solver.cpp:221] Iteration 43900, loss = 0.0431078
I0416 20:52:55.515799   977 solver.cpp:236]     Train net output #0: loss = 0.0655347 (* 1 = 0.0655347 loss)
I0416 20:52:55.515804   977 solver.cpp:542] Iteration 43900, lr = 0.001
I0416 20:53:09.057986   977 solver.cpp:221] Iteration 43920, loss = 0.0396149
I0416 20:53:09.058012   977 solver.cpp:236]     Train net output #0: loss = 0.0343674 (* 1 = 0.0343674 loss)
I0416 20:53:09.058017   977 solver.cpp:542] Iteration 43920, lr = 0.001
I0416 20:53:22.589527   977 solver.cpp:221] Iteration 43940, loss = 0.0389737
I0416 20:53:22.589556   977 solver.cpp:236]     Train net output #0: loss = 0.0550115 (* 1 = 0.0550115 loss)
I0416 20:53:22.589560   977 solver.cpp:542] Iteration 43940, lr = 0.001
I0416 20:53:36.126741   977 solver.cpp:221] Iteration 43960, loss = 0.0416038
I0416 20:53:36.126770   977 solver.cpp:236]     Train net output #0: loss = 0.0445614 (* 1 = 0.0445614 loss)
I0416 20:53:36.126775   977 solver.cpp:542] Iteration 43960, lr = 0.001
I0416 20:53:49.651324   977 solver.cpp:221] Iteration 43980, loss = 0.0421174
I0416 20:53:49.651352   977 solver.cpp:236]     Train net output #0: loss = 0.0670348 (* 1 = 0.0670348 loss)
I0416 20:53:49.651357   977 solver.cpp:542] Iteration 43980, lr = 0.001
I0416 20:54:02.518443   977 solver.cpp:316] Iteration 44000, Testing net (#0)
I0416 20:54:14.052685   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 20:54:14.052707   977 solver.cpp:373]     Test net output #1: loss = 0.0361268 (* 1 = 0.0361268 loss)
I0416 20:54:14.721515   977 solver.cpp:221] Iteration 44000, loss = 0.0383958
I0416 20:54:14.721542   977 solver.cpp:236]     Train net output #0: loss = 0.0334751 (* 1 = 0.0334751 loss)
I0416 20:54:14.721547   977 solver.cpp:542] Iteration 44000, lr = 0.001
I0416 20:54:28.248723   977 solver.cpp:221] Iteration 44020, loss = 0.0428421
I0416 20:54:28.248751   977 solver.cpp:236]     Train net output #0: loss = 0.0302805 (* 1 = 0.0302805 loss)
I0416 20:54:28.248755   977 solver.cpp:542] Iteration 44020, lr = 0.001
I0416 20:54:41.775408   977 solver.cpp:221] Iteration 44040, loss = 0.0427103
I0416 20:54:41.775435   977 solver.cpp:236]     Train net output #0: loss = 0.0331492 (* 1 = 0.0331492 loss)
I0416 20:54:41.775440   977 solver.cpp:542] Iteration 44040, lr = 0.001
I0416 20:54:55.311112   977 solver.cpp:221] Iteration 44060, loss = 0.0409551
I0416 20:54:55.311139   977 solver.cpp:236]     Train net output #0: loss = 0.0389056 (* 1 = 0.0389056 loss)
I0416 20:54:55.311144   977 solver.cpp:542] Iteration 44060, lr = 0.001
I0416 20:55:08.849115   977 solver.cpp:221] Iteration 44080, loss = 0.0417547
I0416 20:55:08.849143   977 solver.cpp:236]     Train net output #0: loss = 0.0467829 (* 1 = 0.0467829 loss)
I0416 20:55:08.849146   977 solver.cpp:542] Iteration 44080, lr = 0.001
I0416 20:55:22.404234   977 solver.cpp:221] Iteration 44100, loss = 0.0408955
I0416 20:55:22.404263   977 solver.cpp:236]     Train net output #0: loss = 0.0558572 (* 1 = 0.0558572 loss)
I0416 20:55:22.404268   977 solver.cpp:542] Iteration 44100, lr = 0.001
I0416 20:55:35.983464   977 solver.cpp:221] Iteration 44120, loss = 0.0384607
I0416 20:55:35.983492   977 solver.cpp:236]     Train net output #0: loss = 0.0330616 (* 1 = 0.0330616 loss)
I0416 20:55:35.983497   977 solver.cpp:542] Iteration 44120, lr = 0.001
I0416 20:55:49.529330   977 solver.cpp:221] Iteration 44140, loss = 0.0424424
I0416 20:55:49.529357   977 solver.cpp:236]     Train net output #0: loss = 0.0467817 (* 1 = 0.0467817 loss)
I0416 20:55:49.529362   977 solver.cpp:542] Iteration 44140, lr = 0.001
I0416 20:56:03.071421   977 solver.cpp:221] Iteration 44160, loss = 0.0391947
I0416 20:56:03.071456   977 solver.cpp:236]     Train net output #0: loss = 0.0474789 (* 1 = 0.0474789 loss)
I0416 20:56:03.071462   977 solver.cpp:542] Iteration 44160, lr = 0.001
I0416 20:56:16.610501   977 solver.cpp:221] Iteration 44180, loss = 0.0376891
I0416 20:56:16.610528   977 solver.cpp:236]     Train net output #0: loss = 0.0226076 (* 1 = 0.0226076 loss)
I0416 20:56:16.610533   977 solver.cpp:542] Iteration 44180, lr = 0.001
I0416 20:56:29.498610   977 solver.cpp:316] Iteration 44200, Testing net (#0)
I0416 20:56:41.044365   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 20:56:41.044387   977 solver.cpp:373]     Test net output #1: loss = 0.0355694 (* 1 = 0.0355694 loss)
I0416 20:56:41.714375   977 solver.cpp:221] Iteration 44200, loss = 0.0432868
I0416 20:56:41.714403   977 solver.cpp:236]     Train net output #0: loss = 0.0330445 (* 1 = 0.0330445 loss)
I0416 20:56:41.714409   977 solver.cpp:542] Iteration 44200, lr = 0.001
I0416 20:56:55.285405   977 solver.cpp:221] Iteration 44220, loss = 0.0399914
I0416 20:56:55.285432   977 solver.cpp:236]     Train net output #0: loss = 0.0332558 (* 1 = 0.0332558 loss)
I0416 20:56:55.285436   977 solver.cpp:542] Iteration 44220, lr = 0.001
I0416 20:57:08.860383   977 solver.cpp:221] Iteration 44240, loss = 0.0461282
I0416 20:57:08.860410   977 solver.cpp:236]     Train net output #0: loss = 0.0361825 (* 1 = 0.0361825 loss)
I0416 20:57:08.860415   977 solver.cpp:542] Iteration 44240, lr = 0.001
I0416 20:57:22.421435   977 solver.cpp:221] Iteration 44260, loss = 0.0418439
I0416 20:57:22.421469   977 solver.cpp:236]     Train net output #0: loss = 0.0236579 (* 1 = 0.0236579 loss)
I0416 20:57:22.421473   977 solver.cpp:542] Iteration 44260, lr = 0.001
I0416 20:57:35.970394   977 solver.cpp:221] Iteration 44280, loss = 0.0420561
I0416 20:57:35.970422   977 solver.cpp:236]     Train net output #0: loss = 0.0418168 (* 1 = 0.0418168 loss)
I0416 20:57:35.970427   977 solver.cpp:542] Iteration 44280, lr = 0.001
I0416 20:57:49.510884   977 solver.cpp:221] Iteration 44300, loss = 0.0445791
I0416 20:57:49.510911   977 solver.cpp:236]     Train net output #0: loss = 0.029714 (* 1 = 0.029714 loss)
I0416 20:57:49.510915   977 solver.cpp:542] Iteration 44300, lr = 0.001
I0416 20:58:03.042958   977 solver.cpp:221] Iteration 44320, loss = 0.044937
I0416 20:58:03.042985   977 solver.cpp:236]     Train net output #0: loss = 0.0422029 (* 1 = 0.0422029 loss)
I0416 20:58:03.042990   977 solver.cpp:542] Iteration 44320, lr = 0.001
I0416 20:58:16.590589   977 solver.cpp:221] Iteration 44340, loss = 0.0371364
I0416 20:58:16.590615   977 solver.cpp:236]     Train net output #0: loss = 0.0329408 (* 1 = 0.0329408 loss)
I0416 20:58:16.590620   977 solver.cpp:542] Iteration 44340, lr = 0.001
I0416 20:58:30.150239   977 solver.cpp:221] Iteration 44360, loss = 0.0410525
I0416 20:58:30.150266   977 solver.cpp:236]     Train net output #0: loss = 0.022428 (* 1 = 0.022428 loss)
I0416 20:58:30.150271   977 solver.cpp:542] Iteration 44360, lr = 0.001
I0416 20:58:43.700448   977 solver.cpp:221] Iteration 44380, loss = 0.0380785
I0416 20:58:43.700474   977 solver.cpp:236]     Train net output #0: loss = 0.0606473 (* 1 = 0.0606473 loss)
I0416 20:58:43.700479   977 solver.cpp:542] Iteration 44380, lr = 0.001
I0416 20:58:56.583353   977 solver.cpp:316] Iteration 44400, Testing net (#0)
I0416 20:59:08.116456   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 20:59:08.116478   977 solver.cpp:373]     Test net output #1: loss = 0.035649 (* 1 = 0.035649 loss)
I0416 20:59:08.784757   977 solver.cpp:221] Iteration 44400, loss = 0.0429113
I0416 20:59:08.784791   977 solver.cpp:236]     Train net output #0: loss = 0.036207 (* 1 = 0.036207 loss)
I0416 20:59:08.784796   977 solver.cpp:542] Iteration 44400, lr = 0.001
I0416 20:59:22.322378   977 solver.cpp:221] Iteration 44420, loss = 0.0430796
I0416 20:59:22.322407   977 solver.cpp:236]     Train net output #0: loss = 0.0333474 (* 1 = 0.0333474 loss)
I0416 20:59:22.322412   977 solver.cpp:542] Iteration 44420, lr = 0.001
I0416 20:59:35.871960   977 solver.cpp:221] Iteration 44440, loss = 0.0430249
I0416 20:59:35.871987   977 solver.cpp:236]     Train net output #0: loss = 0.0559956 (* 1 = 0.0559956 loss)
I0416 20:59:35.871992   977 solver.cpp:542] Iteration 44440, lr = 0.001
I0416 20:59:49.389185   977 solver.cpp:221] Iteration 44460, loss = 0.0427714
I0416 20:59:49.389212   977 solver.cpp:236]     Train net output #0: loss = 0.0428397 (* 1 = 0.0428397 loss)
I0416 20:59:49.389217   977 solver.cpp:542] Iteration 44460, lr = 0.001
I0416 21:00:02.915105   977 solver.cpp:221] Iteration 44480, loss = 0.0388107
I0416 21:00:02.915133   977 solver.cpp:236]     Train net output #0: loss = 0.0299578 (* 1 = 0.0299578 loss)
I0416 21:00:02.915138   977 solver.cpp:542] Iteration 44480, lr = 0.001
I0416 21:00:16.445332   977 solver.cpp:221] Iteration 44500, loss = 0.0417862
I0416 21:00:16.445360   977 solver.cpp:236]     Train net output #0: loss = 0.039231 (* 1 = 0.039231 loss)
I0416 21:00:16.445364   977 solver.cpp:542] Iteration 44500, lr = 0.001
I0416 21:00:29.996096   977 solver.cpp:221] Iteration 44520, loss = 0.0374603
I0416 21:00:29.996124   977 solver.cpp:236]     Train net output #0: loss = 0.0430218 (* 1 = 0.0430218 loss)
I0416 21:00:29.996127   977 solver.cpp:542] Iteration 44520, lr = 0.001
I0416 21:00:43.546710   977 solver.cpp:221] Iteration 44540, loss = 0.0398655
I0416 21:00:43.546737   977 solver.cpp:236]     Train net output #0: loss = 0.0317714 (* 1 = 0.0317714 loss)
I0416 21:00:43.546743   977 solver.cpp:542] Iteration 44540, lr = 0.001
I0416 21:00:57.111898   977 solver.cpp:221] Iteration 44560, loss = 0.041539
I0416 21:00:57.111925   977 solver.cpp:236]     Train net output #0: loss = 0.0420689 (* 1 = 0.0420689 loss)
I0416 21:00:57.111930   977 solver.cpp:542] Iteration 44560, lr = 0.001
I0416 21:01:10.663096   977 solver.cpp:221] Iteration 44580, loss = 0.0380779
I0416 21:01:10.663123   977 solver.cpp:236]     Train net output #0: loss = 0.0266459 (* 1 = 0.0266459 loss)
I0416 21:01:10.663127   977 solver.cpp:542] Iteration 44580, lr = 0.001
I0416 21:01:23.545738   977 solver.cpp:316] Iteration 44600, Testing net (#0)
I0416 21:01:35.078745   977 solver.cpp:373]     Test net output #0: accuracy = 0.993156
I0416 21:01:35.078766   977 solver.cpp:373]     Test net output #1: loss = 0.0362709 (* 1 = 0.0362709 loss)
I0416 21:01:35.748265   977 solver.cpp:221] Iteration 44600, loss = 0.0406615
I0416 21:01:35.748292   977 solver.cpp:236]     Train net output #0: loss = 0.0378794 (* 1 = 0.0378794 loss)
I0416 21:01:35.748296   977 solver.cpp:542] Iteration 44600, lr = 0.001
I0416 21:01:49.308786   977 solver.cpp:221] Iteration 44620, loss = 0.0371773
I0416 21:01:49.308815   977 solver.cpp:236]     Train net output #0: loss = 0.0380222 (* 1 = 0.0380222 loss)
I0416 21:01:49.308820   977 solver.cpp:542] Iteration 44620, lr = 0.001
I0416 21:02:02.861858   977 solver.cpp:221] Iteration 44640, loss = 0.039637
I0416 21:02:02.861886   977 solver.cpp:236]     Train net output #0: loss = 0.0399503 (* 1 = 0.0399503 loss)
I0416 21:02:02.861891   977 solver.cpp:542] Iteration 44640, lr = 0.001
I0416 21:02:16.392681   977 solver.cpp:221] Iteration 44660, loss = 0.0435482
I0416 21:02:16.392709   977 solver.cpp:236]     Train net output #0: loss = 0.0407946 (* 1 = 0.0407946 loss)
I0416 21:02:16.392714   977 solver.cpp:542] Iteration 44660, lr = 0.001
I0416 21:02:29.911525   977 solver.cpp:221] Iteration 44680, loss = 0.0451026
I0416 21:02:29.911552   977 solver.cpp:236]     Train net output #0: loss = 0.0633264 (* 1 = 0.0633264 loss)
I0416 21:02:29.911557   977 solver.cpp:542] Iteration 44680, lr = 0.001
I0416 21:02:43.462112   977 solver.cpp:221] Iteration 44700, loss = 0.0437531
I0416 21:02:43.462139   977 solver.cpp:236]     Train net output #0: loss = 0.0384413 (* 1 = 0.0384413 loss)
I0416 21:02:43.462144   977 solver.cpp:542] Iteration 44700, lr = 0.001
I0416 21:02:57.015954   977 solver.cpp:221] Iteration 44720, loss = 0.0412609
I0416 21:02:57.015980   977 solver.cpp:236]     Train net output #0: loss = 0.0330549 (* 1 = 0.0330549 loss)
I0416 21:02:57.015985   977 solver.cpp:542] Iteration 44720, lr = 0.001
I0416 21:03:10.580308   977 solver.cpp:221] Iteration 44740, loss = 0.0422409
I0416 21:03:10.580335   977 solver.cpp:236]     Train net output #0: loss = 0.0537574 (* 1 = 0.0537574 loss)
I0416 21:03:10.580340   977 solver.cpp:542] Iteration 44740, lr = 0.001
I0416 21:03:24.122395   977 solver.cpp:221] Iteration 44760, loss = 0.0411939
I0416 21:03:24.122422   977 solver.cpp:236]     Train net output #0: loss = 0.0436489 (* 1 = 0.0436489 loss)
I0416 21:03:24.122427   977 solver.cpp:542] Iteration 44760, lr = 0.001
I0416 21:03:37.641916   977 solver.cpp:221] Iteration 44780, loss = 0.0419591
I0416 21:03:37.641943   977 solver.cpp:236]     Train net output #0: loss = 0.0462483 (* 1 = 0.0462483 loss)
I0416 21:03:37.641948   977 solver.cpp:542] Iteration 44780, lr = 0.001
I0416 21:03:50.506069   977 solver.cpp:316] Iteration 44800, Testing net (#0)
I0416 21:04:02.043164   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 21:04:02.043185   977 solver.cpp:373]     Test net output #1: loss = 0.035633 (* 1 = 0.035633 loss)
I0416 21:04:02.712227   977 solver.cpp:221] Iteration 44800, loss = 0.0391393
I0416 21:04:02.712255   977 solver.cpp:236]     Train net output #0: loss = 0.0355051 (* 1 = 0.0355051 loss)
I0416 21:04:02.712260   977 solver.cpp:542] Iteration 44800, lr = 0.001
I0416 21:04:16.240939   977 solver.cpp:221] Iteration 44820, loss = 0.0367734
I0416 21:04:16.240968   977 solver.cpp:236]     Train net output #0: loss = 0.0165378 (* 1 = 0.0165378 loss)
I0416 21:04:16.240973   977 solver.cpp:542] Iteration 44820, lr = 0.001
I0416 21:04:29.771176   977 solver.cpp:221] Iteration 44840, loss = 0.0420446
I0416 21:04:29.771203   977 solver.cpp:236]     Train net output #0: loss = 0.0690563 (* 1 = 0.0690563 loss)
I0416 21:04:29.771208   977 solver.cpp:542] Iteration 44840, lr = 0.001
I0416 21:04:43.309412   977 solver.cpp:221] Iteration 44860, loss = 0.0454779
I0416 21:04:43.309438   977 solver.cpp:236]     Train net output #0: loss = 0.0506524 (* 1 = 0.0506524 loss)
I0416 21:04:43.309444   977 solver.cpp:542] Iteration 44860, lr = 0.001
I0416 21:04:56.844599   977 solver.cpp:221] Iteration 44880, loss = 0.0439395
I0416 21:04:56.844627   977 solver.cpp:236]     Train net output #0: loss = 0.0416384 (* 1 = 0.0416384 loss)
I0416 21:04:56.844632   977 solver.cpp:542] Iteration 44880, lr = 0.001
I0416 21:05:10.371934   977 solver.cpp:221] Iteration 44900, loss = 0.0449485
I0416 21:05:10.371963   977 solver.cpp:236]     Train net output #0: loss = 0.0645497 (* 1 = 0.0645497 loss)
I0416 21:05:10.371966   977 solver.cpp:542] Iteration 44900, lr = 0.001
I0416 21:05:23.885944   977 solver.cpp:221] Iteration 44920, loss = 0.0383393
I0416 21:05:23.885972   977 solver.cpp:236]     Train net output #0: loss = 0.0317217 (* 1 = 0.0317217 loss)
I0416 21:05:23.885977   977 solver.cpp:542] Iteration 44920, lr = 0.001
I0416 21:05:37.402047   977 solver.cpp:221] Iteration 44940, loss = 0.0397403
I0416 21:05:37.402073   977 solver.cpp:236]     Train net output #0: loss = 0.0326247 (* 1 = 0.0326247 loss)
I0416 21:05:37.402078   977 solver.cpp:542] Iteration 44940, lr = 0.001
I0416 21:05:50.936764   977 solver.cpp:221] Iteration 44960, loss = 0.0398246
I0416 21:05:50.936791   977 solver.cpp:236]     Train net output #0: loss = 0.0442235 (* 1 = 0.0442235 loss)
I0416 21:05:50.936796   977 solver.cpp:542] Iteration 44960, lr = 0.001
I0416 21:06:04.501355   977 solver.cpp:221] Iteration 44980, loss = 0.0430978
I0416 21:06:04.501384   977 solver.cpp:236]     Train net output #0: loss = 0.0444687 (* 1 = 0.0444687 loss)
I0416 21:06:04.501395   977 solver.cpp:542] Iteration 44980, lr = 0.001
I0416 21:06:17.391443   977 solver.cpp:316] Iteration 45000, Testing net (#0)
I0416 21:06:28.928963   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:06:28.928984   977 solver.cpp:373]     Test net output #1: loss = 0.0359051 (* 1 = 0.0359051 loss)
I0416 21:06:29.597772   977 solver.cpp:221] Iteration 45000, loss = 0.0396816
I0416 21:06:29.597800   977 solver.cpp:236]     Train net output #0: loss = 0.0334964 (* 1 = 0.0334964 loss)
I0416 21:06:29.597806   977 solver.cpp:542] Iteration 45000, lr = 0.001
I0416 21:06:43.133607   977 solver.cpp:221] Iteration 45020, loss = 0.0440517
I0416 21:06:43.133635   977 solver.cpp:236]     Train net output #0: loss = 0.0457739 (* 1 = 0.0457739 loss)
I0416 21:06:43.133640   977 solver.cpp:542] Iteration 45020, lr = 0.001
I0416 21:06:56.681943   977 solver.cpp:221] Iteration 45040, loss = 0.0394066
I0416 21:06:56.681972   977 solver.cpp:236]     Train net output #0: loss = 0.0170884 (* 1 = 0.0170884 loss)
I0416 21:06:56.681975   977 solver.cpp:542] Iteration 45040, lr = 0.001
I0416 21:07:10.262562   977 solver.cpp:221] Iteration 45060, loss = 0.0405497
I0416 21:07:10.262588   977 solver.cpp:236]     Train net output #0: loss = 0.0739836 (* 1 = 0.0739836 loss)
I0416 21:07:10.262593   977 solver.cpp:542] Iteration 45060, lr = 0.001
I0416 21:07:23.785228   977 solver.cpp:221] Iteration 45080, loss = 0.044996
I0416 21:07:23.785254   977 solver.cpp:236]     Train net output #0: loss = 0.0406467 (* 1 = 0.0406467 loss)
I0416 21:07:23.785259   977 solver.cpp:542] Iteration 45080, lr = 0.001
I0416 21:07:37.320267   977 solver.cpp:221] Iteration 45100, loss = 0.0391672
I0416 21:07:37.320294   977 solver.cpp:236]     Train net output #0: loss = 0.024658 (* 1 = 0.024658 loss)
I0416 21:07:37.320299   977 solver.cpp:542] Iteration 45100, lr = 0.001
I0416 21:07:50.866906   977 solver.cpp:221] Iteration 45120, loss = 0.0385509
I0416 21:07:50.866933   977 solver.cpp:236]     Train net output #0: loss = 0.0691501 (* 1 = 0.0691501 loss)
I0416 21:07:50.866938   977 solver.cpp:542] Iteration 45120, lr = 0.001
I0416 21:08:04.432101   977 solver.cpp:221] Iteration 45140, loss = 0.0404512
I0416 21:08:04.432132   977 solver.cpp:236]     Train net output #0: loss = 0.0375056 (* 1 = 0.0375056 loss)
I0416 21:08:04.432137   977 solver.cpp:542] Iteration 45140, lr = 0.001
I0416 21:08:17.995822   977 solver.cpp:221] Iteration 45160, loss = 0.0441869
I0416 21:08:17.995849   977 solver.cpp:236]     Train net output #0: loss = 0.0396884 (* 1 = 0.0396884 loss)
I0416 21:08:17.995854   977 solver.cpp:542] Iteration 45160, lr = 0.001
I0416 21:08:31.539257   977 solver.cpp:221] Iteration 45180, loss = 0.0374568
I0416 21:08:31.539284   977 solver.cpp:236]     Train net output #0: loss = 0.0379104 (* 1 = 0.0379104 loss)
I0416 21:08:31.539289   977 solver.cpp:542] Iteration 45180, lr = 0.001
I0416 21:08:44.438889   977 solver.cpp:316] Iteration 45200, Testing net (#0)
I0416 21:08:55.987262   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:08:55.987284   977 solver.cpp:373]     Test net output #1: loss = 0.0356991 (* 1 = 0.0356991 loss)
I0416 21:08:56.658542   977 solver.cpp:221] Iteration 45200, loss = 0.038662
I0416 21:08:56.658571   977 solver.cpp:236]     Train net output #0: loss = 0.0221042 (* 1 = 0.0221042 loss)
I0416 21:08:56.658576   977 solver.cpp:542] Iteration 45200, lr = 0.001
I0416 21:09:10.198781   977 solver.cpp:221] Iteration 45220, loss = 0.0379772
I0416 21:09:10.198807   977 solver.cpp:236]     Train net output #0: loss = 0.0512696 (* 1 = 0.0512696 loss)
I0416 21:09:10.198812   977 solver.cpp:542] Iteration 45220, lr = 0.001
I0416 21:09:23.751966   977 solver.cpp:221] Iteration 45240, loss = 0.0404033
I0416 21:09:23.751993   977 solver.cpp:236]     Train net output #0: loss = 0.0179141 (* 1 = 0.0179141 loss)
I0416 21:09:23.751998   977 solver.cpp:542] Iteration 45240, lr = 0.001
I0416 21:09:37.302969   977 solver.cpp:221] Iteration 45260, loss = 0.0408228
I0416 21:09:37.302996   977 solver.cpp:236]     Train net output #0: loss = 0.0766486 (* 1 = 0.0766486 loss)
I0416 21:09:37.303001   977 solver.cpp:542] Iteration 45260, lr = 0.001
I0416 21:09:50.858441   977 solver.cpp:221] Iteration 45280, loss = 0.0462029
I0416 21:09:50.858469   977 solver.cpp:236]     Train net output #0: loss = 0.0408141 (* 1 = 0.0408141 loss)
I0416 21:09:50.858474   977 solver.cpp:542] Iteration 45280, lr = 0.001
I0416 21:10:04.394729   977 solver.cpp:221] Iteration 45300, loss = 0.0425972
I0416 21:10:04.394757   977 solver.cpp:236]     Train net output #0: loss = 0.077674 (* 1 = 0.077674 loss)
I0416 21:10:04.394762   977 solver.cpp:542] Iteration 45300, lr = 0.001
I0416 21:10:17.941092   977 solver.cpp:221] Iteration 45320, loss = 0.0419303
I0416 21:10:17.941120   977 solver.cpp:236]     Train net output #0: loss = 0.0327959 (* 1 = 0.0327959 loss)
I0416 21:10:17.941125   977 solver.cpp:542] Iteration 45320, lr = 0.001
I0416 21:10:31.482889   977 solver.cpp:221] Iteration 45340, loss = 0.0413721
I0416 21:10:31.482918   977 solver.cpp:236]     Train net output #0: loss = 0.0337167 (* 1 = 0.0337167 loss)
I0416 21:10:31.482923   977 solver.cpp:542] Iteration 45340, lr = 0.001
I0416 21:10:45.047298   977 solver.cpp:221] Iteration 45360, loss = 0.0415937
I0416 21:10:45.047327   977 solver.cpp:236]     Train net output #0: loss = 0.0272556 (* 1 = 0.0272556 loss)
I0416 21:10:45.047332   977 solver.cpp:542] Iteration 45360, lr = 0.001
I0416 21:10:58.584945   977 solver.cpp:221] Iteration 45380, loss = 0.0406499
I0416 21:10:58.584972   977 solver.cpp:236]     Train net output #0: loss = 0.0343931 (* 1 = 0.0343931 loss)
I0416 21:10:58.584977   977 solver.cpp:542] Iteration 45380, lr = 0.001
I0416 21:11:11.454723   977 solver.cpp:316] Iteration 45400, Testing net (#0)
I0416 21:11:22.991444   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:11:22.991466   977 solver.cpp:373]     Test net output #1: loss = 0.0358781 (* 1 = 0.0358781 loss)
I0416 21:11:23.658149   977 solver.cpp:221] Iteration 45400, loss = 0.04348
I0416 21:11:23.658177   977 solver.cpp:236]     Train net output #0: loss = 0.0413145 (* 1 = 0.0413145 loss)
I0416 21:11:23.658182   977 solver.cpp:542] Iteration 45400, lr = 0.001
I0416 21:11:37.216778   977 solver.cpp:221] Iteration 45420, loss = 0.0397174
I0416 21:11:37.216805   977 solver.cpp:236]     Train net output #0: loss = 0.0247578 (* 1 = 0.0247578 loss)
I0416 21:11:37.216810   977 solver.cpp:542] Iteration 45420, lr = 0.001
I0416 21:11:50.767969   977 solver.cpp:221] Iteration 45440, loss = 0.0379446
I0416 21:11:50.767997   977 solver.cpp:236]     Train net output #0: loss = 0.0262658 (* 1 = 0.0262658 loss)
I0416 21:11:50.768002   977 solver.cpp:542] Iteration 45440, lr = 0.001
I0416 21:12:04.324618   977 solver.cpp:221] Iteration 45460, loss = 0.0385874
I0416 21:12:04.324646   977 solver.cpp:236]     Train net output #0: loss = 0.0364748 (* 1 = 0.0364748 loss)
I0416 21:12:04.324651   977 solver.cpp:542] Iteration 45460, lr = 0.001
I0416 21:12:17.854428   977 solver.cpp:221] Iteration 45480, loss = 0.0418101
I0416 21:12:17.854455   977 solver.cpp:236]     Train net output #0: loss = 0.0618256 (* 1 = 0.0618256 loss)
I0416 21:12:17.854460   977 solver.cpp:542] Iteration 45480, lr = 0.001
I0416 21:12:31.370919   977 solver.cpp:221] Iteration 45500, loss = 0.0440756
I0416 21:12:31.370947   977 solver.cpp:236]     Train net output #0: loss = 0.0477377 (* 1 = 0.0477377 loss)
I0416 21:12:31.370952   977 solver.cpp:542] Iteration 45500, lr = 0.001
I0416 21:12:44.910876   977 solver.cpp:221] Iteration 45520, loss = 0.0428404
I0416 21:12:44.910903   977 solver.cpp:236]     Train net output #0: loss = 0.0404597 (* 1 = 0.0404597 loss)
I0416 21:12:44.910907   977 solver.cpp:542] Iteration 45520, lr = 0.001
I0416 21:12:58.431226   977 solver.cpp:221] Iteration 45540, loss = 0.0439498
I0416 21:12:58.431252   977 solver.cpp:236]     Train net output #0: loss = 0.0416137 (* 1 = 0.0416137 loss)
I0416 21:12:58.431257   977 solver.cpp:542] Iteration 45540, lr = 0.001
I0416 21:13:11.946648   977 solver.cpp:221] Iteration 45560, loss = 0.0438462
I0416 21:13:11.946676   977 solver.cpp:236]     Train net output #0: loss = 0.0640272 (* 1 = 0.0640272 loss)
I0416 21:13:11.946681   977 solver.cpp:542] Iteration 45560, lr = 0.001
I0416 21:13:25.479346   977 solver.cpp:221] Iteration 45580, loss = 0.0422527
I0416 21:13:25.479372   977 solver.cpp:236]     Train net output #0: loss = 0.0529541 (* 1 = 0.0529541 loss)
I0416 21:13:25.479377   977 solver.cpp:542] Iteration 45580, lr = 0.001
I0416 21:13:38.384254   977 solver.cpp:316] Iteration 45600, Testing net (#0)
I0416 21:13:49.918660   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:13:49.918683   977 solver.cpp:373]     Test net output #1: loss = 0.0359487 (* 1 = 0.0359487 loss)
I0416 21:13:50.586912   977 solver.cpp:221] Iteration 45600, loss = 0.0382285
I0416 21:13:50.586940   977 solver.cpp:236]     Train net output #0: loss = 0.0310986 (* 1 = 0.0310986 loss)
I0416 21:13:50.586944   977 solver.cpp:542] Iteration 45600, lr = 0.001
I0416 21:14:04.135100   977 solver.cpp:221] Iteration 45620, loss = 0.0417347
I0416 21:14:04.135128   977 solver.cpp:236]     Train net output #0: loss = 0.0292371 (* 1 = 0.0292371 loss)
I0416 21:14:04.135134   977 solver.cpp:542] Iteration 45620, lr = 0.001
I0416 21:14:17.689216   977 solver.cpp:221] Iteration 45640, loss = 0.0427688
I0416 21:14:17.689244   977 solver.cpp:236]     Train net output #0: loss = 0.0339095 (* 1 = 0.0339095 loss)
I0416 21:14:17.689249   977 solver.cpp:542] Iteration 45640, lr = 0.001
I0416 21:14:31.222717   977 solver.cpp:221] Iteration 45660, loss = 0.044567
I0416 21:14:31.222744   977 solver.cpp:236]     Train net output #0: loss = 0.0453101 (* 1 = 0.0453101 loss)
I0416 21:14:31.222749   977 solver.cpp:542] Iteration 45660, lr = 0.001
I0416 21:14:44.786872   977 solver.cpp:221] Iteration 45680, loss = 0.0430326
I0416 21:14:44.786901   977 solver.cpp:236]     Train net output #0: loss = 0.0198982 (* 1 = 0.0198982 loss)
I0416 21:14:44.786906   977 solver.cpp:542] Iteration 45680, lr = 0.001
I0416 21:14:58.335974   977 solver.cpp:221] Iteration 45700, loss = 0.0429049
I0416 21:14:58.336002   977 solver.cpp:236]     Train net output #0: loss = 0.0387105 (* 1 = 0.0387105 loss)
I0416 21:14:58.336007   977 solver.cpp:542] Iteration 45700, lr = 0.001
I0416 21:15:11.898514   977 solver.cpp:221] Iteration 45720, loss = 0.0388027
I0416 21:15:11.898542   977 solver.cpp:236]     Train net output #0: loss = 0.035426 (* 1 = 0.035426 loss)
I0416 21:15:11.898548   977 solver.cpp:542] Iteration 45720, lr = 0.001
I0416 21:15:25.446331   977 solver.cpp:221] Iteration 45740, loss = 0.0400108
I0416 21:15:25.446357   977 solver.cpp:236]     Train net output #0: loss = 0.0253153 (* 1 = 0.0253153 loss)
I0416 21:15:25.446360   977 solver.cpp:542] Iteration 45740, lr = 0.001
I0416 21:15:38.976533   977 solver.cpp:221] Iteration 45760, loss = 0.0384973
I0416 21:15:38.976562   977 solver.cpp:236]     Train net output #0: loss = 0.036954 (* 1 = 0.036954 loss)
I0416 21:15:38.976567   977 solver.cpp:542] Iteration 45760, lr = 0.001
I0416 21:15:52.539762   977 solver.cpp:221] Iteration 45780, loss = 0.0428665
I0416 21:15:52.539789   977 solver.cpp:236]     Train net output #0: loss = 0.0279538 (* 1 = 0.0279538 loss)
I0416 21:15:52.539795   977 solver.cpp:542] Iteration 45780, lr = 0.001
I0416 21:16:05.447187   977 solver.cpp:316] Iteration 45800, Testing net (#0)
I0416 21:16:16.996249   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 21:16:16.996271   977 solver.cpp:373]     Test net output #1: loss = 0.0358556 (* 1 = 0.0358556 loss)
I0416 21:16:17.668336   977 solver.cpp:221] Iteration 45800, loss = 0.0372637
I0416 21:16:17.668364   977 solver.cpp:236]     Train net output #0: loss = 0.0283655 (* 1 = 0.0283655 loss)
I0416 21:16:17.668368   977 solver.cpp:542] Iteration 45800, lr = 0.001
I0416 21:16:31.240039   977 solver.cpp:221] Iteration 45820, loss = 0.0406122
I0416 21:16:31.240067   977 solver.cpp:236]     Train net output #0: loss = 0.0645189 (* 1 = 0.0645189 loss)
I0416 21:16:31.240072   977 solver.cpp:542] Iteration 45820, lr = 0.001
I0416 21:16:44.804182   977 solver.cpp:221] Iteration 45840, loss = 0.0404024
I0416 21:16:44.804209   977 solver.cpp:236]     Train net output #0: loss = 0.0457554 (* 1 = 0.0457554 loss)
I0416 21:16:44.804214   977 solver.cpp:542] Iteration 45840, lr = 0.001
I0416 21:16:58.359243   977 solver.cpp:221] Iteration 45860, loss = 0.0399544
I0416 21:16:58.359271   977 solver.cpp:236]     Train net output #0: loss = 0.0367282 (* 1 = 0.0367282 loss)
I0416 21:16:58.359274   977 solver.cpp:542] Iteration 45860, lr = 0.001
I0416 21:17:11.890130   977 solver.cpp:221] Iteration 45880, loss = 0.0379659
I0416 21:17:11.890158   977 solver.cpp:236]     Train net output #0: loss = 0.0310854 (* 1 = 0.0310854 loss)
I0416 21:17:11.890162   977 solver.cpp:542] Iteration 45880, lr = 0.001
I0416 21:17:25.420505   977 solver.cpp:221] Iteration 45900, loss = 0.041379
I0416 21:17:25.420531   977 solver.cpp:236]     Train net output #0: loss = 0.0736997 (* 1 = 0.0736997 loss)
I0416 21:17:25.420536   977 solver.cpp:542] Iteration 45900, lr = 0.001
I0416 21:17:38.979156   977 solver.cpp:221] Iteration 45920, loss = 0.0457582
I0416 21:17:38.979184   977 solver.cpp:236]     Train net output #0: loss = 0.0216434 (* 1 = 0.0216434 loss)
I0416 21:17:38.979189   977 solver.cpp:542] Iteration 45920, lr = 0.001
I0416 21:17:52.531916   977 solver.cpp:221] Iteration 45940, loss = 0.0429419
I0416 21:17:52.531942   977 solver.cpp:236]     Train net output #0: loss = 0.025182 (* 1 = 0.025182 loss)
I0416 21:17:52.531947   977 solver.cpp:542] Iteration 45940, lr = 0.001
I0416 21:18:06.062923   977 solver.cpp:221] Iteration 45960, loss = 0.0435969
I0416 21:18:06.062950   977 solver.cpp:236]     Train net output #0: loss = 0.031239 (* 1 = 0.031239 loss)
I0416 21:18:06.062955   977 solver.cpp:542] Iteration 45960, lr = 0.001
I0416 21:18:19.589925   977 solver.cpp:221] Iteration 45980, loss = 0.0413282
I0416 21:18:19.589951   977 solver.cpp:236]     Train net output #0: loss = 0.0291026 (* 1 = 0.0291026 loss)
I0416 21:18:19.589956   977 solver.cpp:542] Iteration 45980, lr = 0.001
I0416 21:18:32.499433   977 solver.cpp:316] Iteration 46000, Testing net (#0)
I0416 21:18:44.043237   977 solver.cpp:373]     Test net output #0: accuracy = 0.993916
I0416 21:18:44.043259   977 solver.cpp:373]     Test net output #1: loss = 0.0353734 (* 1 = 0.0353734 loss)
I0416 21:18:44.711611   977 solver.cpp:221] Iteration 46000, loss = 0.0397823
I0416 21:18:44.711638   977 solver.cpp:236]     Train net output #0: loss = 0.0209894 (* 1 = 0.0209894 loss)
I0416 21:18:44.711643   977 solver.cpp:542] Iteration 46000, lr = 0.001
I0416 21:18:58.249203   977 solver.cpp:221] Iteration 46020, loss = 0.0429241
I0416 21:18:58.249230   977 solver.cpp:236]     Train net output #0: loss = 0.0421102 (* 1 = 0.0421102 loss)
I0416 21:18:58.249235   977 solver.cpp:542] Iteration 46020, lr = 0.001
I0416 21:19:11.771359   977 solver.cpp:221] Iteration 46040, loss = 0.0411412
I0416 21:19:11.771387   977 solver.cpp:236]     Train net output #0: loss = 0.0435972 (* 1 = 0.0435972 loss)
I0416 21:19:11.771391   977 solver.cpp:542] Iteration 46040, lr = 0.001
I0416 21:19:25.280278   977 solver.cpp:221] Iteration 46060, loss = 0.0382117
I0416 21:19:25.280306   977 solver.cpp:236]     Train net output #0: loss = 0.0531786 (* 1 = 0.0531786 loss)
I0416 21:19:25.280311   977 solver.cpp:542] Iteration 46060, lr = 0.001
I0416 21:19:38.818717   977 solver.cpp:221] Iteration 46080, loss = 0.0394817
I0416 21:19:38.818743   977 solver.cpp:236]     Train net output #0: loss = 0.0619056 (* 1 = 0.0619056 loss)
I0416 21:19:38.818748   977 solver.cpp:542] Iteration 46080, lr = 0.001
I0416 21:19:52.334115   977 solver.cpp:221] Iteration 46100, loss = 0.0379318
I0416 21:19:52.334144   977 solver.cpp:236]     Train net output #0: loss = 0.0419799 (* 1 = 0.0419799 loss)
I0416 21:19:52.334149   977 solver.cpp:542] Iteration 46100, lr = 0.001
I0416 21:20:05.867846   977 solver.cpp:221] Iteration 46120, loss = 0.0394829
I0416 21:20:05.867873   977 solver.cpp:236]     Train net output #0: loss = 0.0293484 (* 1 = 0.0293484 loss)
I0416 21:20:05.867878   977 solver.cpp:542] Iteration 46120, lr = 0.001
I0416 21:20:19.420747   977 solver.cpp:221] Iteration 46140, loss = 0.0439946
I0416 21:20:19.420774   977 solver.cpp:236]     Train net output #0: loss = 0.0373194 (* 1 = 0.0373194 loss)
I0416 21:20:19.420779   977 solver.cpp:542] Iteration 46140, lr = 0.001
I0416 21:20:32.967156   977 solver.cpp:221] Iteration 46160, loss = 0.0447487
I0416 21:20:32.967183   977 solver.cpp:236]     Train net output #0: loss = 0.0195851 (* 1 = 0.0195851 loss)
I0416 21:20:32.967188   977 solver.cpp:542] Iteration 46160, lr = 0.001
I0416 21:20:46.513487   977 solver.cpp:221] Iteration 46180, loss = 0.0406966
I0416 21:20:46.513515   977 solver.cpp:236]     Train net output #0: loss = 0.0500646 (* 1 = 0.0500646 loss)
I0416 21:20:46.513520   977 solver.cpp:542] Iteration 46180, lr = 0.001
I0416 21:20:59.402809   977 solver.cpp:316] Iteration 46200, Testing net (#0)
I0416 21:21:10.937628   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:21:10.937649   977 solver.cpp:373]     Test net output #1: loss = 0.0352435 (* 1 = 0.0352435 loss)
I0416 21:21:11.605877   977 solver.cpp:221] Iteration 46200, loss = 0.0416284
I0416 21:21:11.605906   977 solver.cpp:236]     Train net output #0: loss = 0.0344617 (* 1 = 0.0344617 loss)
I0416 21:21:11.605912   977 solver.cpp:542] Iteration 46200, lr = 0.001
I0416 21:21:25.159868   977 solver.cpp:221] Iteration 46220, loss = 0.0379985
I0416 21:21:25.159898   977 solver.cpp:236]     Train net output #0: loss = 0.0354662 (* 1 = 0.0354662 loss)
I0416 21:21:25.159903   977 solver.cpp:542] Iteration 46220, lr = 0.001
I0416 21:21:38.698401   977 solver.cpp:221] Iteration 46240, loss = 0.0404077
I0416 21:21:38.698427   977 solver.cpp:236]     Train net output #0: loss = 0.0359094 (* 1 = 0.0359094 loss)
I0416 21:21:38.698432   977 solver.cpp:542] Iteration 46240, lr = 0.001
I0416 21:21:52.238951   977 solver.cpp:221] Iteration 46260, loss = 0.0423061
I0416 21:21:52.238979   977 solver.cpp:236]     Train net output #0: loss = 0.029461 (* 1 = 0.029461 loss)
I0416 21:21:52.238983   977 solver.cpp:542] Iteration 46260, lr = 0.001
I0416 21:22:05.792439   977 solver.cpp:221] Iteration 46280, loss = 0.042284
I0416 21:22:05.792467   977 solver.cpp:236]     Train net output #0: loss = 0.0180909 (* 1 = 0.0180909 loss)
I0416 21:22:05.792471   977 solver.cpp:542] Iteration 46280, lr = 0.001
I0416 21:22:19.349664   977 solver.cpp:221] Iteration 46300, loss = 0.0367599
I0416 21:22:19.349692   977 solver.cpp:236]     Train net output #0: loss = 0.0592245 (* 1 = 0.0592245 loss)
I0416 21:22:19.349696   977 solver.cpp:542] Iteration 46300, lr = 0.001
I0416 21:22:32.884068   977 solver.cpp:221] Iteration 46320, loss = 0.0415853
I0416 21:22:32.884094   977 solver.cpp:236]     Train net output #0: loss = 0.0414354 (* 1 = 0.0414354 loss)
I0416 21:22:32.884099   977 solver.cpp:542] Iteration 46320, lr = 0.001
I0416 21:22:46.403515   977 solver.cpp:221] Iteration 46340, loss = 0.0418904
I0416 21:22:46.403543   977 solver.cpp:236]     Train net output #0: loss = 0.0251464 (* 1 = 0.0251464 loss)
I0416 21:22:46.403548   977 solver.cpp:542] Iteration 46340, lr = 0.001
I0416 21:22:59.932541   977 solver.cpp:221] Iteration 46360, loss = 0.039397
I0416 21:22:59.932569   977 solver.cpp:236]     Train net output #0: loss = 0.0225071 (* 1 = 0.0225071 loss)
I0416 21:22:59.932574   977 solver.cpp:542] Iteration 46360, lr = 0.001
I0416 21:23:13.480383   977 solver.cpp:221] Iteration 46380, loss = 0.0373446
I0416 21:23:13.480409   977 solver.cpp:236]     Train net output #0: loss = 0.0238953 (* 1 = 0.0238953 loss)
I0416 21:23:13.480414   977 solver.cpp:542] Iteration 46380, lr = 0.001
I0416 21:23:26.370756   977 solver.cpp:316] Iteration 46400, Testing net (#0)
I0416 21:23:37.916110   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:23:37.916132   977 solver.cpp:373]     Test net output #1: loss = 0.0353733 (* 1 = 0.0353733 loss)
I0416 21:23:38.585589   977 solver.cpp:221] Iteration 46400, loss = 0.0422291
I0416 21:23:38.585618   977 solver.cpp:236]     Train net output #0: loss = 0.0331383 (* 1 = 0.0331383 loss)
I0416 21:23:38.585621   977 solver.cpp:542] Iteration 46400, lr = 0.001
I0416 21:23:52.142458   977 solver.cpp:221] Iteration 46420, loss = 0.0425258
I0416 21:23:52.142488   977 solver.cpp:236]     Train net output #0: loss = 0.0397458 (* 1 = 0.0397458 loss)
I0416 21:23:52.142493   977 solver.cpp:542] Iteration 46420, lr = 0.001
I0416 21:24:05.681476   977 solver.cpp:221] Iteration 46440, loss = 0.0404817
I0416 21:24:05.681504   977 solver.cpp:236]     Train net output #0: loss = 0.0628757 (* 1 = 0.0628757 loss)
I0416 21:24:05.681510   977 solver.cpp:542] Iteration 46440, lr = 0.001
I0416 21:24:19.238957   977 solver.cpp:221] Iteration 46460, loss = 0.0391281
I0416 21:24:19.238984   977 solver.cpp:236]     Train net output #0: loss = 0.0343845 (* 1 = 0.0343845 loss)
I0416 21:24:19.238989   977 solver.cpp:542] Iteration 46460, lr = 0.001
I0416 21:24:32.792738   977 solver.cpp:221] Iteration 46480, loss = 0.0424347
I0416 21:24:32.792767   977 solver.cpp:236]     Train net output #0: loss = 0.0297057 (* 1 = 0.0297057 loss)
I0416 21:24:32.792770   977 solver.cpp:542] Iteration 46480, lr = 0.001
I0416 21:24:46.360574   977 solver.cpp:221] Iteration 46500, loss = 0.0394475
I0416 21:24:46.360600   977 solver.cpp:236]     Train net output #0: loss = 0.0291598 (* 1 = 0.0291598 loss)
I0416 21:24:46.360605   977 solver.cpp:542] Iteration 46500, lr = 0.001
I0416 21:24:59.909540   977 solver.cpp:221] Iteration 46520, loss = 0.0364895
I0416 21:24:59.909567   977 solver.cpp:236]     Train net output #0: loss = 0.0647337 (* 1 = 0.0647337 loss)
I0416 21:24:59.909572   977 solver.cpp:542] Iteration 46520, lr = 0.001
I0416 21:25:13.426542   977 solver.cpp:221] Iteration 46540, loss = 0.0436873
I0416 21:25:13.426568   977 solver.cpp:236]     Train net output #0: loss = 0.0626757 (* 1 = 0.0626757 loss)
I0416 21:25:13.426573   977 solver.cpp:542] Iteration 46540, lr = 0.001
I0416 21:25:26.942237   977 solver.cpp:221] Iteration 46560, loss = 0.0416145
I0416 21:25:26.942265   977 solver.cpp:236]     Train net output #0: loss = 0.0501147 (* 1 = 0.0501147 loss)
I0416 21:25:26.942270   977 solver.cpp:542] Iteration 46560, lr = 0.001
I0416 21:25:40.478184   977 solver.cpp:221] Iteration 46580, loss = 0.0432674
I0416 21:25:40.478211   977 solver.cpp:236]     Train net output #0: loss = 0.0481109 (* 1 = 0.0481109 loss)
I0416 21:25:40.478215   977 solver.cpp:542] Iteration 46580, lr = 0.001
I0416 21:25:53.354333   977 solver.cpp:316] Iteration 46600, Testing net (#0)
I0416 21:26:04.898970   977 solver.cpp:373]     Test net output #0: accuracy = 0.992966
I0416 21:26:04.898993   977 solver.cpp:373]     Test net output #1: loss = 0.0355285 (* 1 = 0.0355285 loss)
I0416 21:26:05.568893   977 solver.cpp:221] Iteration 46600, loss = 0.0394753
I0416 21:26:05.568922   977 solver.cpp:236]     Train net output #0: loss = 0.0386289 (* 1 = 0.0386289 loss)
I0416 21:26:05.568928   977 solver.cpp:542] Iteration 46600, lr = 0.001
I0416 21:26:19.121572   977 solver.cpp:221] Iteration 46620, loss = 0.03951
I0416 21:26:19.121598   977 solver.cpp:236]     Train net output #0: loss = 0.0296941 (* 1 = 0.0296941 loss)
I0416 21:26:19.121603   977 solver.cpp:542] Iteration 46620, lr = 0.001
I0416 21:26:32.672206   977 solver.cpp:221] Iteration 46640, loss = 0.0429628
I0416 21:26:32.672235   977 solver.cpp:236]     Train net output #0: loss = 0.0572804 (* 1 = 0.0572804 loss)
I0416 21:26:32.672240   977 solver.cpp:542] Iteration 46640, lr = 0.001
I0416 21:26:46.201596   977 solver.cpp:221] Iteration 46660, loss = 0.0416616
I0416 21:26:46.201623   977 solver.cpp:236]     Train net output #0: loss = 0.0425461 (* 1 = 0.0425461 loss)
I0416 21:26:46.201628   977 solver.cpp:542] Iteration 46660, lr = 0.001
I0416 21:26:59.728741   977 solver.cpp:221] Iteration 46680, loss = 0.0406058
I0416 21:26:59.728768   977 solver.cpp:236]     Train net output #0: loss = 0.0346576 (* 1 = 0.0346576 loss)
I0416 21:26:59.728773   977 solver.cpp:542] Iteration 46680, lr = 0.001
I0416 21:27:13.271147   977 solver.cpp:221] Iteration 46700, loss = 0.0374123
I0416 21:27:13.271174   977 solver.cpp:236]     Train net output #0: loss = 0.0385226 (* 1 = 0.0385226 loss)
I0416 21:27:13.271178   977 solver.cpp:542] Iteration 46700, lr = 0.001
I0416 21:27:26.794505   977 solver.cpp:221] Iteration 46720, loss = 0.0370301
I0416 21:27:26.794533   977 solver.cpp:236]     Train net output #0: loss = 0.036132 (* 1 = 0.036132 loss)
I0416 21:27:26.794536   977 solver.cpp:542] Iteration 46720, lr = 0.001
I0416 21:27:40.326694   977 solver.cpp:221] Iteration 46740, loss = 0.0414799
I0416 21:27:40.326720   977 solver.cpp:236]     Train net output #0: loss = 0.0452996 (* 1 = 0.0452996 loss)
I0416 21:27:40.326725   977 solver.cpp:542] Iteration 46740, lr = 0.001
I0416 21:27:53.879317   977 solver.cpp:221] Iteration 46760, loss = 0.0458259
I0416 21:27:53.879344   977 solver.cpp:236]     Train net output #0: loss = 0.0554417 (* 1 = 0.0554417 loss)
I0416 21:27:53.879349   977 solver.cpp:542] Iteration 46760, lr = 0.001
I0416 21:28:07.438621   977 solver.cpp:221] Iteration 46780, loss = 0.0409587
I0416 21:28:07.438647   977 solver.cpp:236]     Train net output #0: loss = 0.0518077 (* 1 = 0.0518077 loss)
I0416 21:28:07.438652   977 solver.cpp:542] Iteration 46780, lr = 0.001
I0416 21:28:20.331236   977 solver.cpp:316] Iteration 46800, Testing net (#0)
I0416 21:28:31.866848   977 solver.cpp:373]     Test net output #0: accuracy = 0.993916
I0416 21:28:31.866870   977 solver.cpp:373]     Test net output #1: loss = 0.035148 (* 1 = 0.035148 loss)
I0416 21:28:32.536331   977 solver.cpp:221] Iteration 46800, loss = 0.0419744
I0416 21:28:32.536358   977 solver.cpp:236]     Train net output #0: loss = 0.0761339 (* 1 = 0.0761339 loss)
I0416 21:28:32.536365   977 solver.cpp:542] Iteration 46800, lr = 0.001
I0416 21:28:46.063742   977 solver.cpp:221] Iteration 46820, loss = 0.0381039
I0416 21:28:46.063769   977 solver.cpp:236]     Train net output #0: loss = 0.0420399 (* 1 = 0.0420399 loss)
I0416 21:28:46.063774   977 solver.cpp:542] Iteration 46820, lr = 0.001
I0416 21:28:59.582011   977 solver.cpp:221] Iteration 46840, loss = 0.0390319
I0416 21:28:59.582038   977 solver.cpp:236]     Train net output #0: loss = 0.0573304 (* 1 = 0.0573304 loss)
I0416 21:28:59.582042   977 solver.cpp:542] Iteration 46840, lr = 0.001
I0416 21:29:13.114279   977 solver.cpp:221] Iteration 46860, loss = 0.0411458
I0416 21:29:13.114308   977 solver.cpp:236]     Train net output #0: loss = 0.0352939 (* 1 = 0.0352939 loss)
I0416 21:29:13.114313   977 solver.cpp:542] Iteration 46860, lr = 0.001
I0416 21:29:26.636626   977 solver.cpp:221] Iteration 46880, loss = 0.0407213
I0416 21:29:26.636653   977 solver.cpp:236]     Train net output #0: loss = 0.0436411 (* 1 = 0.0436411 loss)
I0416 21:29:26.636657   977 solver.cpp:542] Iteration 46880, lr = 0.001
I0416 21:29:40.165755   977 solver.cpp:221] Iteration 46900, loss = 0.0423468
I0416 21:29:40.165781   977 solver.cpp:236]     Train net output #0: loss = 0.0559103 (* 1 = 0.0559103 loss)
I0416 21:29:40.165786   977 solver.cpp:542] Iteration 46900, lr = 0.001
I0416 21:29:53.696059   977 solver.cpp:221] Iteration 46920, loss = 0.0397097
I0416 21:29:53.696087   977 solver.cpp:236]     Train net output #0: loss = 0.0272411 (* 1 = 0.0272411 loss)
I0416 21:29:53.696092   977 solver.cpp:542] Iteration 46920, lr = 0.001
I0416 21:30:07.236260   977 solver.cpp:221] Iteration 46940, loss = 0.0333228
I0416 21:30:07.236289   977 solver.cpp:236]     Train net output #0: loss = 0.0746174 (* 1 = 0.0746174 loss)
I0416 21:30:07.236294   977 solver.cpp:542] Iteration 46940, lr = 0.001
I0416 21:30:20.769192   977 solver.cpp:221] Iteration 46960, loss = 0.0411267
I0416 21:30:20.769222   977 solver.cpp:236]     Train net output #0: loss = 0.0406342 (* 1 = 0.0406342 loss)
I0416 21:30:20.769227   977 solver.cpp:542] Iteration 46960, lr = 0.001
I0416 21:30:34.307188   977 solver.cpp:221] Iteration 46980, loss = 0.0380187
I0416 21:30:34.307216   977 solver.cpp:236]     Train net output #0: loss = 0.0456203 (* 1 = 0.0456203 loss)
I0416 21:30:34.307221   977 solver.cpp:542] Iteration 46980, lr = 0.001
I0416 21:30:47.188285   977 solver.cpp:316] Iteration 47000, Testing net (#0)
I0416 21:30:58.722630   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:30:58.722651   977 solver.cpp:373]     Test net output #1: loss = 0.035251 (* 1 = 0.035251 loss)
I0416 21:30:59.391108   977 solver.cpp:221] Iteration 47000, loss = 0.043931
I0416 21:30:59.391135   977 solver.cpp:236]     Train net output #0: loss = 0.0348298 (* 1 = 0.0348298 loss)
I0416 21:30:59.391140   977 solver.cpp:542] Iteration 47000, lr = 0.001
I0416 21:31:12.920482   977 solver.cpp:221] Iteration 47020, loss = 0.0388991
I0416 21:31:12.920511   977 solver.cpp:236]     Train net output #0: loss = 0.0314231 (* 1 = 0.0314231 loss)
I0416 21:31:12.920516   977 solver.cpp:542] Iteration 47020, lr = 0.001
I0416 21:31:26.493795   977 solver.cpp:221] Iteration 47040, loss = 0.0393485
I0416 21:31:26.493823   977 solver.cpp:236]     Train net output #0: loss = 0.0298351 (* 1 = 0.0298351 loss)
I0416 21:31:26.493827   977 solver.cpp:542] Iteration 47040, lr = 0.001
I0416 21:31:40.047787   977 solver.cpp:221] Iteration 47060, loss = 0.0380847
I0416 21:31:40.047814   977 solver.cpp:236]     Train net output #0: loss = 0.0437442 (* 1 = 0.0437442 loss)
I0416 21:31:40.047819   977 solver.cpp:542] Iteration 47060, lr = 0.001
I0416 21:31:53.567909   977 solver.cpp:221] Iteration 47080, loss = 0.040331
I0416 21:31:53.567936   977 solver.cpp:236]     Train net output #0: loss = 0.0359211 (* 1 = 0.0359211 loss)
I0416 21:31:53.567940   977 solver.cpp:542] Iteration 47080, lr = 0.001
I0416 21:32:07.093051   977 solver.cpp:221] Iteration 47100, loss = 0.0382682
I0416 21:32:07.093078   977 solver.cpp:236]     Train net output #0: loss = 0.0294858 (* 1 = 0.0294858 loss)
I0416 21:32:07.093083   977 solver.cpp:542] Iteration 47100, lr = 0.001
I0416 21:32:20.618590   977 solver.cpp:221] Iteration 47120, loss = 0.04129
I0416 21:32:20.618618   977 solver.cpp:236]     Train net output #0: loss = 0.040646 (* 1 = 0.040646 loss)
I0416 21:32:20.618623   977 solver.cpp:542] Iteration 47120, lr = 0.001
I0416 21:32:34.135123   977 solver.cpp:221] Iteration 47140, loss = 0.0399512
I0416 21:32:34.135148   977 solver.cpp:236]     Train net output #0: loss = 0.0290795 (* 1 = 0.0290795 loss)
I0416 21:32:34.135152   977 solver.cpp:542] Iteration 47140, lr = 0.001
I0416 21:32:47.679090   977 solver.cpp:221] Iteration 47160, loss = 0.0397386
I0416 21:32:47.679118   977 solver.cpp:236]     Train net output #0: loss = 0.042085 (* 1 = 0.042085 loss)
I0416 21:32:47.679122   977 solver.cpp:542] Iteration 47160, lr = 0.001
I0416 21:33:01.218189   977 solver.cpp:221] Iteration 47180, loss = 0.0407674
I0416 21:33:01.218215   977 solver.cpp:236]     Train net output #0: loss = 0.0215925 (* 1 = 0.0215925 loss)
I0416 21:33:01.218219   977 solver.cpp:542] Iteration 47180, lr = 0.001
I0416 21:33:14.088305   977 solver.cpp:316] Iteration 47200, Testing net (#0)
I0416 21:33:25.622405   977 solver.cpp:373]     Test net output #0: accuracy = 0.994106
I0416 21:33:25.622426   977 solver.cpp:373]     Test net output #1: loss = 0.0352091 (* 1 = 0.0352091 loss)
I0416 21:33:26.290383   977 solver.cpp:221] Iteration 47200, loss = 0.0387314
I0416 21:33:26.290411   977 solver.cpp:236]     Train net output #0: loss = 0.075281 (* 1 = 0.075281 loss)
I0416 21:33:26.290416   977 solver.cpp:542] Iteration 47200, lr = 0.001
I0416 21:33:39.858019   977 solver.cpp:221] Iteration 47220, loss = 0.0405272
I0416 21:33:39.858047   977 solver.cpp:236]     Train net output #0: loss = 0.0495423 (* 1 = 0.0495423 loss)
I0416 21:33:39.858052   977 solver.cpp:542] Iteration 47220, lr = 0.001
I0416 21:33:53.395176   977 solver.cpp:221] Iteration 47240, loss = 0.0405037
I0416 21:33:53.395203   977 solver.cpp:236]     Train net output #0: loss = 0.023621 (* 1 = 0.023621 loss)
I0416 21:33:53.395208   977 solver.cpp:542] Iteration 47240, lr = 0.001
I0416 21:34:06.918527   977 solver.cpp:221] Iteration 47260, loss = 0.0424764
I0416 21:34:06.918555   977 solver.cpp:236]     Train net output #0: loss = 0.0426694 (* 1 = 0.0426694 loss)
I0416 21:34:06.918560   977 solver.cpp:542] Iteration 47260, lr = 0.001
I0416 21:34:20.469166   977 solver.cpp:221] Iteration 47280, loss = 0.0404894
I0416 21:34:20.469193   977 solver.cpp:236]     Train net output #0: loss = 0.0668153 (* 1 = 0.0668153 loss)
I0416 21:34:20.469198   977 solver.cpp:542] Iteration 47280, lr = 0.001
I0416 21:34:33.992487   977 solver.cpp:221] Iteration 47300, loss = 0.0418768
I0416 21:34:33.992516   977 solver.cpp:236]     Train net output #0: loss = 0.0210779 (* 1 = 0.0210779 loss)
I0416 21:34:33.992521   977 solver.cpp:542] Iteration 47300, lr = 0.001
I0416 21:34:47.509939   977 solver.cpp:221] Iteration 47320, loss = 0.0385083
I0416 21:34:47.509965   977 solver.cpp:236]     Train net output #0: loss = 0.0247427 (* 1 = 0.0247427 loss)
I0416 21:34:47.509970   977 solver.cpp:542] Iteration 47320, lr = 0.001
I0416 21:35:01.052628   977 solver.cpp:221] Iteration 47340, loss = 0.041119
I0416 21:35:01.052655   977 solver.cpp:236]     Train net output #0: loss = 0.0287353 (* 1 = 0.0287353 loss)
I0416 21:35:01.052661   977 solver.cpp:542] Iteration 47340, lr = 0.001
I0416 21:35:14.584950   977 solver.cpp:221] Iteration 47360, loss = 0.0394189
I0416 21:35:14.584977   977 solver.cpp:236]     Train net output #0: loss = 0.0363133 (* 1 = 0.0363133 loss)
I0416 21:35:14.584981   977 solver.cpp:542] Iteration 47360, lr = 0.001
I0416 21:35:28.112613   977 solver.cpp:221] Iteration 47380, loss = 0.0409508
I0416 21:35:28.112642   977 solver.cpp:236]     Train net output #0: loss = 0.0635731 (* 1 = 0.0635731 loss)
I0416 21:35:28.112646   977 solver.cpp:542] Iteration 47380, lr = 0.001
I0416 21:35:40.986547   977 solver.cpp:316] Iteration 47400, Testing net (#0)
I0416 21:35:52.520473   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:35:52.520493   977 solver.cpp:373]     Test net output #1: loss = 0.035732 (* 1 = 0.035732 loss)
I0416 21:35:53.189080   977 solver.cpp:221] Iteration 47400, loss = 0.0426113
I0416 21:35:53.189108   977 solver.cpp:236]     Train net output #0: loss = 0.0309903 (* 1 = 0.0309903 loss)
I0416 21:35:53.189113   977 solver.cpp:542] Iteration 47400, lr = 0.001
I0416 21:36:06.755429   977 solver.cpp:221] Iteration 47420, loss = 0.0418644
I0416 21:36:06.755456   977 solver.cpp:236]     Train net output #0: loss = 0.0614466 (* 1 = 0.0614466 loss)
I0416 21:36:06.755461   977 solver.cpp:542] Iteration 47420, lr = 0.001
I0416 21:36:20.289495   977 solver.cpp:221] Iteration 47440, loss = 0.038442
I0416 21:36:20.289522   977 solver.cpp:236]     Train net output #0: loss = 0.0308209 (* 1 = 0.0308209 loss)
I0416 21:36:20.289527   977 solver.cpp:542] Iteration 47440, lr = 0.001
I0416 21:36:33.833991   977 solver.cpp:221] Iteration 47460, loss = 0.04148
I0416 21:36:33.834017   977 solver.cpp:236]     Train net output #0: loss = 0.0405763 (* 1 = 0.0405763 loss)
I0416 21:36:33.834022   977 solver.cpp:542] Iteration 47460, lr = 0.001
I0416 21:36:47.387550   977 solver.cpp:221] Iteration 47480, loss = 0.0372817
I0416 21:36:47.387578   977 solver.cpp:236]     Train net output #0: loss = 0.0256395 (* 1 = 0.0256395 loss)
I0416 21:36:47.387583   977 solver.cpp:542] Iteration 47480, lr = 0.001
I0416 21:37:00.934242   977 solver.cpp:221] Iteration 47500, loss = 0.0401818
I0416 21:37:00.934268   977 solver.cpp:236]     Train net output #0: loss = 0.0401685 (* 1 = 0.0401685 loss)
I0416 21:37:00.934273   977 solver.cpp:542] Iteration 47500, lr = 0.001
I0416 21:37:14.495812   977 solver.cpp:221] Iteration 47520, loss = 0.0399847
I0416 21:37:14.495841   977 solver.cpp:236]     Train net output #0: loss = 0.0334108 (* 1 = 0.0334108 loss)
I0416 21:37:14.495844   977 solver.cpp:542] Iteration 47520, lr = 0.001
I0416 21:37:28.073699   977 solver.cpp:221] Iteration 47540, loss = 0.0394001
I0416 21:37:28.073729   977 solver.cpp:236]     Train net output #0: loss = 0.0430796 (* 1 = 0.0430796 loss)
I0416 21:37:28.073734   977 solver.cpp:542] Iteration 47540, lr = 0.001
I0416 21:37:41.600793   977 solver.cpp:221] Iteration 47560, loss = 0.0400811
I0416 21:37:41.600821   977 solver.cpp:236]     Train net output #0: loss = 0.0365748 (* 1 = 0.0365748 loss)
I0416 21:37:41.600826   977 solver.cpp:542] Iteration 47560, lr = 0.001
I0416 21:37:55.127320   977 solver.cpp:221] Iteration 47580, loss = 0.0393716
I0416 21:37:55.127346   977 solver.cpp:236]     Train net output #0: loss = 0.0585349 (* 1 = 0.0585349 loss)
I0416 21:37:55.127351   977 solver.cpp:542] Iteration 47580, lr = 0.001
I0416 21:38:07.989224   977 solver.cpp:316] Iteration 47600, Testing net (#0)
I0416 21:38:19.523681   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:38:19.523704   977 solver.cpp:373]     Test net output #1: loss = 0.0354358 (* 1 = 0.0354358 loss)
I0416 21:38:20.192553   977 solver.cpp:221] Iteration 47600, loss = 0.0425784
I0416 21:38:20.192580   977 solver.cpp:236]     Train net output #0: loss = 0.0400811 (* 1 = 0.0400811 loss)
I0416 21:38:20.192585   977 solver.cpp:542] Iteration 47600, lr = 0.001
I0416 21:38:33.752480   977 solver.cpp:221] Iteration 47620, loss = 0.0398717
I0416 21:38:33.752508   977 solver.cpp:236]     Train net output #0: loss = 0.0598127 (* 1 = 0.0598127 loss)
I0416 21:38:33.752513   977 solver.cpp:542] Iteration 47620, lr = 0.001
I0416 21:38:47.302701   977 solver.cpp:221] Iteration 47640, loss = 0.0412738
I0416 21:38:47.302727   977 solver.cpp:236]     Train net output #0: loss = 0.0329171 (* 1 = 0.0329171 loss)
I0416 21:38:47.302732   977 solver.cpp:542] Iteration 47640, lr = 0.001
I0416 21:39:00.874318   977 solver.cpp:221] Iteration 47660, loss = 0.0394562
I0416 21:39:00.874346   977 solver.cpp:236]     Train net output #0: loss = 0.0288094 (* 1 = 0.0288094 loss)
I0416 21:39:00.874349   977 solver.cpp:542] Iteration 47660, lr = 0.001
I0416 21:39:14.423904   977 solver.cpp:221] Iteration 47680, loss = 0.0372949
I0416 21:39:14.423931   977 solver.cpp:236]     Train net output #0: loss = 0.016428 (* 1 = 0.016428 loss)
I0416 21:39:14.423936   977 solver.cpp:542] Iteration 47680, lr = 0.001
I0416 21:39:27.981529   977 solver.cpp:221] Iteration 47700, loss = 0.0377503
I0416 21:39:27.981556   977 solver.cpp:236]     Train net output #0: loss = 0.0301265 (* 1 = 0.0301265 loss)
I0416 21:39:27.981561   977 solver.cpp:542] Iteration 47700, lr = 0.001
I0416 21:39:41.555119   977 solver.cpp:221] Iteration 47720, loss = 0.0396625
I0416 21:39:41.555145   977 solver.cpp:236]     Train net output #0: loss = 0.0515035 (* 1 = 0.0515035 loss)
I0416 21:39:41.555150   977 solver.cpp:542] Iteration 47720, lr = 0.001
I0416 21:39:55.113308   977 solver.cpp:221] Iteration 47740, loss = 0.0381272
I0416 21:39:55.113337   977 solver.cpp:236]     Train net output #0: loss = 0.0295178 (* 1 = 0.0295178 loss)
I0416 21:39:55.113340   977 solver.cpp:542] Iteration 47740, lr = 0.001
I0416 21:40:08.663672   977 solver.cpp:221] Iteration 47760, loss = 0.0380544
I0416 21:40:08.663699   977 solver.cpp:236]     Train net output #0: loss = 0.0438587 (* 1 = 0.0438587 loss)
I0416 21:40:08.663705   977 solver.cpp:542] Iteration 47760, lr = 0.001
I0416 21:40:22.228327   977 solver.cpp:221] Iteration 47780, loss = 0.0422744
I0416 21:40:22.228354   977 solver.cpp:236]     Train net output #0: loss = 0.0357499 (* 1 = 0.0357499 loss)
I0416 21:40:22.228358   977 solver.cpp:542] Iteration 47780, lr = 0.001
I0416 21:40:35.160456   977 solver.cpp:316] Iteration 47800, Testing net (#0)
I0416 21:40:46.710115   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 21:40:46.710136   977 solver.cpp:373]     Test net output #1: loss = 0.0357005 (* 1 = 0.0357005 loss)
I0416 21:40:47.380498   977 solver.cpp:221] Iteration 47800, loss = 0.0386316
I0416 21:40:47.380527   977 solver.cpp:236]     Train net output #0: loss = 0.0497202 (* 1 = 0.0497202 loss)
I0416 21:40:47.380532   977 solver.cpp:542] Iteration 47800, lr = 0.001
I0416 21:41:00.945968   977 solver.cpp:221] Iteration 47820, loss = 0.0413656
I0416 21:41:00.945997   977 solver.cpp:236]     Train net output #0: loss = 0.0547277 (* 1 = 0.0547277 loss)
I0416 21:41:00.946002   977 solver.cpp:542] Iteration 47820, lr = 0.001
I0416 21:41:14.492841   977 solver.cpp:221] Iteration 47840, loss = 0.0425113
I0416 21:41:14.492867   977 solver.cpp:236]     Train net output #0: loss = 0.0702967 (* 1 = 0.0702967 loss)
I0416 21:41:14.492872   977 solver.cpp:542] Iteration 47840, lr = 0.001
I0416 21:41:28.026882   977 solver.cpp:221] Iteration 47860, loss = 0.0409304
I0416 21:41:28.026909   977 solver.cpp:236]     Train net output #0: loss = 0.0384313 (* 1 = 0.0384313 loss)
I0416 21:41:28.026914   977 solver.cpp:542] Iteration 47860, lr = 0.001
I0416 21:41:41.570533   977 solver.cpp:221] Iteration 47880, loss = 0.0422197
I0416 21:41:41.570560   977 solver.cpp:236]     Train net output #0: loss = 0.0364274 (* 1 = 0.0364274 loss)
I0416 21:41:41.570564   977 solver.cpp:542] Iteration 47880, lr = 0.001
I0416 21:41:55.125493   977 solver.cpp:221] Iteration 47900, loss = 0.0384414
I0416 21:41:55.125519   977 solver.cpp:236]     Train net output #0: loss = 0.0226437 (* 1 = 0.0226437 loss)
I0416 21:41:55.125524   977 solver.cpp:542] Iteration 47900, lr = 0.001
I0416 21:42:08.661406   977 solver.cpp:221] Iteration 47920, loss = 0.0373776
I0416 21:42:08.661434   977 solver.cpp:236]     Train net output #0: loss = 0.0392529 (* 1 = 0.0392529 loss)
I0416 21:42:08.661438   977 solver.cpp:542] Iteration 47920, lr = 0.001
I0416 21:42:22.214390   977 solver.cpp:221] Iteration 47940, loss = 0.0378006
I0416 21:42:22.214416   977 solver.cpp:236]     Train net output #0: loss = 0.0408858 (* 1 = 0.0408858 loss)
I0416 21:42:22.214421   977 solver.cpp:542] Iteration 47940, lr = 0.001
I0416 21:42:35.758508   977 solver.cpp:221] Iteration 47960, loss = 0.0396341
I0416 21:42:35.758536   977 solver.cpp:236]     Train net output #0: loss = 0.0269058 (* 1 = 0.0269058 loss)
I0416 21:42:35.758541   977 solver.cpp:542] Iteration 47960, lr = 0.001
I0416 21:42:49.310657   977 solver.cpp:221] Iteration 47980, loss = 0.0403097
I0416 21:42:49.310683   977 solver.cpp:236]     Train net output #0: loss = 0.0449968 (* 1 = 0.0449968 loss)
I0416 21:42:49.310688   977 solver.cpp:542] Iteration 47980, lr = 0.001
I0416 21:43:02.194700   977 solver.cpp:316] Iteration 48000, Testing net (#0)
I0416 21:43:13.740064   977 solver.cpp:373]     Test net output #0: accuracy = 0.993916
I0416 21:43:13.740085   977 solver.cpp:373]     Test net output #1: loss = 0.03553 (* 1 = 0.03553 loss)
I0416 21:43:14.409534   977 solver.cpp:221] Iteration 48000, loss = 0.0401968
I0416 21:43:14.409562   977 solver.cpp:236]     Train net output #0: loss = 0.0472515 (* 1 = 0.0472515 loss)
I0416 21:43:14.409566   977 solver.cpp:542] Iteration 48000, lr = 0.001
I0416 21:43:27.973305   977 solver.cpp:221] Iteration 48020, loss = 0.0405771
I0416 21:43:27.973333   977 solver.cpp:236]     Train net output #0: loss = 0.0332818 (* 1 = 0.0332818 loss)
I0416 21:43:27.973340   977 solver.cpp:542] Iteration 48020, lr = 0.001
I0416 21:43:41.508513   977 solver.cpp:221] Iteration 48040, loss = 0.041805
I0416 21:43:41.508540   977 solver.cpp:236]     Train net output #0: loss = 0.0370812 (* 1 = 0.0370812 loss)
I0416 21:43:41.508545   977 solver.cpp:542] Iteration 48040, lr = 0.001
I0416 21:43:55.051491   977 solver.cpp:221] Iteration 48060, loss = 0.0426664
I0416 21:43:55.051518   977 solver.cpp:236]     Train net output #0: loss = 0.0505992 (* 1 = 0.0505992 loss)
I0416 21:43:55.051522   977 solver.cpp:542] Iteration 48060, lr = 0.001
I0416 21:44:08.583492   977 solver.cpp:221] Iteration 48080, loss = 0.0387619
I0416 21:44:08.583518   977 solver.cpp:236]     Train net output #0: loss = 0.0337795 (* 1 = 0.0337795 loss)
I0416 21:44:08.583523   977 solver.cpp:542] Iteration 48080, lr = 0.001
I0416 21:44:22.160723   977 solver.cpp:221] Iteration 48100, loss = 0.0390207
I0416 21:44:22.160751   977 solver.cpp:236]     Train net output #0: loss = 0.02392 (* 1 = 0.02392 loss)
I0416 21:44:22.160756   977 solver.cpp:542] Iteration 48100, lr = 0.001
I0416 21:44:35.730546   977 solver.cpp:221] Iteration 48120, loss = 0.0397359
I0416 21:44:35.730573   977 solver.cpp:236]     Train net output #0: loss = 0.0244073 (* 1 = 0.0244073 loss)
I0416 21:44:35.730578   977 solver.cpp:542] Iteration 48120, lr = 0.001
I0416 21:44:49.276533   977 solver.cpp:221] Iteration 48140, loss = 0.0384463
I0416 21:44:49.276561   977 solver.cpp:236]     Train net output #0: loss = 0.0399563 (* 1 = 0.0399563 loss)
I0416 21:44:49.276566   977 solver.cpp:542] Iteration 48140, lr = 0.001
I0416 21:45:02.804289   977 solver.cpp:221] Iteration 48160, loss = 0.0424706
I0416 21:45:02.804316   977 solver.cpp:236]     Train net output #0: loss = 0.0344877 (* 1 = 0.0344877 loss)
I0416 21:45:02.804322   977 solver.cpp:542] Iteration 48160, lr = 0.001
I0416 21:45:16.360222   977 solver.cpp:221] Iteration 48180, loss = 0.0393949
I0416 21:45:16.360250   977 solver.cpp:236]     Train net output #0: loss = 0.0385282 (* 1 = 0.0385282 loss)
I0416 21:45:16.360255   977 solver.cpp:542] Iteration 48180, lr = 0.001
I0416 21:45:29.240185   977 solver.cpp:316] Iteration 48200, Testing net (#0)
I0416 21:45:40.784773   977 solver.cpp:373]     Test net output #0: accuracy = 0.993346
I0416 21:45:40.784795   977 solver.cpp:373]     Test net output #1: loss = 0.0347246 (* 1 = 0.0347246 loss)
I0416 21:45:41.453042   977 solver.cpp:221] Iteration 48200, loss = 0.0410714
I0416 21:45:41.453071   977 solver.cpp:236]     Train net output #0: loss = 0.0417381 (* 1 = 0.0417381 loss)
I0416 21:45:41.453076   977 solver.cpp:542] Iteration 48200, lr = 0.001
I0416 21:45:54.973865   977 solver.cpp:221] Iteration 48220, loss = 0.0412355
I0416 21:45:54.973892   977 solver.cpp:236]     Train net output #0: loss = 0.0391153 (* 1 = 0.0391153 loss)
I0416 21:45:54.973896   977 solver.cpp:542] Iteration 48220, lr = 0.001
I0416 21:46:08.489148   977 solver.cpp:221] Iteration 48240, loss = 0.041351
I0416 21:46:08.489176   977 solver.cpp:236]     Train net output #0: loss = 0.0382993 (* 1 = 0.0382993 loss)
I0416 21:46:08.489181   977 solver.cpp:542] Iteration 48240, lr = 0.001
I0416 21:46:22.000406   977 solver.cpp:221] Iteration 48260, loss = 0.0406471
I0416 21:46:22.000434   977 solver.cpp:236]     Train net output #0: loss = 0.0362282 (* 1 = 0.0362282 loss)
I0416 21:46:22.000439   977 solver.cpp:542] Iteration 48260, lr = 0.001
I0416 21:46:35.544728   977 solver.cpp:221] Iteration 48280, loss = 0.0401357
I0416 21:46:35.544756   977 solver.cpp:236]     Train net output #0: loss = 0.051454 (* 1 = 0.051454 loss)
I0416 21:46:35.544760   977 solver.cpp:542] Iteration 48280, lr = 0.001
I0416 21:46:49.076370   977 solver.cpp:221] Iteration 48300, loss = 0.0402323
I0416 21:46:49.076396   977 solver.cpp:236]     Train net output #0: loss = 0.0517748 (* 1 = 0.0517748 loss)
I0416 21:46:49.076401   977 solver.cpp:542] Iteration 48300, lr = 0.001
I0416 21:47:02.603066   977 solver.cpp:221] Iteration 48320, loss = 0.0370133
I0416 21:47:02.603092   977 solver.cpp:236]     Train net output #0: loss = 0.0264798 (* 1 = 0.0264798 loss)
I0416 21:47:02.603097   977 solver.cpp:542] Iteration 48320, lr = 0.001
I0416 21:47:16.149885   977 solver.cpp:221] Iteration 48340, loss = 0.0390232
I0416 21:47:16.149912   977 solver.cpp:236]     Train net output #0: loss = 0.0325693 (* 1 = 0.0325693 loss)
I0416 21:47:16.149917   977 solver.cpp:542] Iteration 48340, lr = 0.001
I0416 21:47:29.706075   977 solver.cpp:221] Iteration 48360, loss = 0.0404074
I0416 21:47:29.706102   977 solver.cpp:236]     Train net output #0: loss = 0.0865386 (* 1 = 0.0865386 loss)
I0416 21:47:29.706106   977 solver.cpp:542] Iteration 48360, lr = 0.001
I0416 21:47:43.248145   977 solver.cpp:221] Iteration 48380, loss = 0.0385926
I0416 21:47:43.248174   977 solver.cpp:236]     Train net output #0: loss = 0.0456894 (* 1 = 0.0456894 loss)
I0416 21:47:43.248179   977 solver.cpp:542] Iteration 48380, lr = 0.001
I0416 21:47:56.133121   977 solver.cpp:316] Iteration 48400, Testing net (#0)
I0416 21:48:07.678946   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:48:07.678968   977 solver.cpp:373]     Test net output #1: loss = 0.0343477 (* 1 = 0.0343477 loss)
I0416 21:48:08.350095   977 solver.cpp:221] Iteration 48400, loss = 0.0354053
I0416 21:48:08.350122   977 solver.cpp:236]     Train net output #0: loss = 0.0270024 (* 1 = 0.0270024 loss)
I0416 21:48:08.350127   977 solver.cpp:542] Iteration 48400, lr = 0.001
I0416 21:48:21.957388   977 solver.cpp:221] Iteration 48420, loss = 0.0382906
I0416 21:48:21.957417   977 solver.cpp:236]     Train net output #0: loss = 0.0436643 (* 1 = 0.0436643 loss)
I0416 21:48:21.957420   977 solver.cpp:542] Iteration 48420, lr = 0.001
I0416 21:48:35.547332   977 solver.cpp:221] Iteration 48440, loss = 0.0418421
I0416 21:48:35.547358   977 solver.cpp:236]     Train net output #0: loss = 0.0339597 (* 1 = 0.0339597 loss)
I0416 21:48:35.547363   977 solver.cpp:542] Iteration 48440, lr = 0.001
I0416 21:48:49.098353   977 solver.cpp:221] Iteration 48460, loss = 0.0424301
I0416 21:48:49.098381   977 solver.cpp:236]     Train net output #0: loss = 0.0580203 (* 1 = 0.0580203 loss)
I0416 21:48:49.098387   977 solver.cpp:542] Iteration 48460, lr = 0.001
I0416 21:49:02.688280   977 solver.cpp:221] Iteration 48480, loss = 0.0378309
I0416 21:49:02.688308   977 solver.cpp:236]     Train net output #0: loss = 0.0251664 (* 1 = 0.0251664 loss)
I0416 21:49:02.688313   977 solver.cpp:542] Iteration 48480, lr = 0.001
I0416 21:49:16.246496   977 solver.cpp:221] Iteration 48500, loss = 0.0409605
I0416 21:49:16.246525   977 solver.cpp:236]     Train net output #0: loss = 0.0225295 (* 1 = 0.0225295 loss)
I0416 21:49:16.246531   977 solver.cpp:542] Iteration 48500, lr = 0.001
I0416 21:49:29.823407   977 solver.cpp:221] Iteration 48520, loss = 0.0409881
I0416 21:49:29.823434   977 solver.cpp:236]     Train net output #0: loss = 0.0283608 (* 1 = 0.0283608 loss)
I0416 21:49:29.823439   977 solver.cpp:542] Iteration 48520, lr = 0.001
I0416 21:49:43.384093   977 solver.cpp:221] Iteration 48540, loss = 0.037492
I0416 21:49:43.384119   977 solver.cpp:236]     Train net output #0: loss = 0.0365596 (* 1 = 0.0365596 loss)
I0416 21:49:43.384124   977 solver.cpp:542] Iteration 48540, lr = 0.001
I0416 21:49:56.965260   977 solver.cpp:221] Iteration 48560, loss = 0.040002
I0416 21:49:56.965287   977 solver.cpp:236]     Train net output #0: loss = 0.0370973 (* 1 = 0.0370973 loss)
I0416 21:49:56.965292   977 solver.cpp:542] Iteration 48560, lr = 0.001
I0416 21:50:10.514070   977 solver.cpp:221] Iteration 48580, loss = 0.0391444
I0416 21:50:10.514097   977 solver.cpp:236]     Train net output #0: loss = 0.0366983 (* 1 = 0.0366983 loss)
I0416 21:50:10.514102   977 solver.cpp:542] Iteration 48580, lr = 0.001
I0416 21:50:23.431151   977 solver.cpp:316] Iteration 48600, Testing net (#0)
I0416 21:50:34.976176   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:50:34.976197   977 solver.cpp:373]     Test net output #1: loss = 0.0350284 (* 1 = 0.0350284 loss)
I0416 21:50:35.645416   977 solver.cpp:221] Iteration 48600, loss = 0.037526
I0416 21:50:35.645444   977 solver.cpp:236]     Train net output #0: loss = 0.0485306 (* 1 = 0.0485306 loss)
I0416 21:50:35.645449   977 solver.cpp:542] Iteration 48600, lr = 0.001
I0416 21:50:49.195052   977 solver.cpp:221] Iteration 48620, loss = 0.0404867
I0416 21:50:49.195080   977 solver.cpp:236]     Train net output #0: loss = 0.0297901 (* 1 = 0.0297901 loss)
I0416 21:50:49.195086   977 solver.cpp:542] Iteration 48620, lr = 0.001
I0416 21:51:02.740775   977 solver.cpp:221] Iteration 48640, loss = 0.0395383
I0416 21:51:02.740803   977 solver.cpp:236]     Train net output #0: loss = 0.027428 (* 1 = 0.027428 loss)
I0416 21:51:02.740806   977 solver.cpp:542] Iteration 48640, lr = 0.001
I0416 21:51:16.273011   977 solver.cpp:221] Iteration 48660, loss = 0.0413648
I0416 21:51:16.273039   977 solver.cpp:236]     Train net output #0: loss = 0.0516252 (* 1 = 0.0516252 loss)
I0416 21:51:16.273044   977 solver.cpp:542] Iteration 48660, lr = 0.001
I0416 21:51:29.803917   977 solver.cpp:221] Iteration 48680, loss = 0.0393931
I0416 21:51:29.803944   977 solver.cpp:236]     Train net output #0: loss = 0.0385097 (* 1 = 0.0385097 loss)
I0416 21:51:29.803949   977 solver.cpp:542] Iteration 48680, lr = 0.001
I0416 21:51:43.329084   977 solver.cpp:221] Iteration 48700, loss = 0.0390625
I0416 21:51:43.329113   977 solver.cpp:236]     Train net output #0: loss = 0.0255638 (* 1 = 0.0255638 loss)
I0416 21:51:43.329118   977 solver.cpp:542] Iteration 48700, lr = 0.001
I0416 21:51:56.863667   977 solver.cpp:221] Iteration 48720, loss = 0.0408681
I0416 21:51:56.863697   977 solver.cpp:236]     Train net output #0: loss = 0.0376503 (* 1 = 0.0376503 loss)
I0416 21:51:56.863701   977 solver.cpp:542] Iteration 48720, lr = 0.001
I0416 21:52:10.388723   977 solver.cpp:221] Iteration 48740, loss = 0.0395561
I0416 21:52:10.388751   977 solver.cpp:236]     Train net output #0: loss = 0.0364524 (* 1 = 0.0364524 loss)
I0416 21:52:10.388756   977 solver.cpp:542] Iteration 48740, lr = 0.001
I0416 21:52:23.932294   977 solver.cpp:221] Iteration 48760, loss = 0.0400098
I0416 21:52:23.932322   977 solver.cpp:236]     Train net output #0: loss = 0.0223601 (* 1 = 0.0223601 loss)
I0416 21:52:23.932327   977 solver.cpp:542] Iteration 48760, lr = 0.001
I0416 21:52:37.494364   977 solver.cpp:221] Iteration 48780, loss = 0.0419754
I0416 21:52:37.494391   977 solver.cpp:236]     Train net output #0: loss = 0.0347402 (* 1 = 0.0347402 loss)
I0416 21:52:37.494396   977 solver.cpp:542] Iteration 48780, lr = 0.001
I0416 21:52:50.386685   977 solver.cpp:316] Iteration 48800, Testing net (#0)
I0416 21:53:01.932652   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:53:01.932673   977 solver.cpp:373]     Test net output #1: loss = 0.034816 (* 1 = 0.034816 loss)
I0416 21:53:02.604214   977 solver.cpp:221] Iteration 48800, loss = 0.0418212
I0416 21:53:02.604241   977 solver.cpp:236]     Train net output #0: loss = 0.0234328 (* 1 = 0.0234328 loss)
I0416 21:53:02.604246   977 solver.cpp:542] Iteration 48800, lr = 0.001
I0416 21:53:16.151156   977 solver.cpp:221] Iteration 48820, loss = 0.0379408
I0416 21:53:16.151185   977 solver.cpp:236]     Train net output #0: loss = 0.0373939 (* 1 = 0.0373939 loss)
I0416 21:53:16.151188   977 solver.cpp:542] Iteration 48820, lr = 0.001
I0416 21:53:29.702623   977 solver.cpp:221] Iteration 48840, loss = 0.0376085
I0416 21:53:29.702651   977 solver.cpp:236]     Train net output #0: loss = 0.0657078 (* 1 = 0.0657078 loss)
I0416 21:53:29.702656   977 solver.cpp:542] Iteration 48840, lr = 0.001
I0416 21:53:43.259578   977 solver.cpp:221] Iteration 48860, loss = 0.0384289
I0416 21:53:43.259606   977 solver.cpp:236]     Train net output #0: loss = 0.0811269 (* 1 = 0.0811269 loss)
I0416 21:53:43.259611   977 solver.cpp:542] Iteration 48860, lr = 0.001
I0416 21:53:56.815598   977 solver.cpp:221] Iteration 48880, loss = 0.0396601
I0416 21:53:56.815623   977 solver.cpp:236]     Train net output #0: loss = 0.0295645 (* 1 = 0.0295645 loss)
I0416 21:53:56.815629   977 solver.cpp:542] Iteration 48880, lr = 0.001
I0416 21:54:10.376337   977 solver.cpp:221] Iteration 48900, loss = 0.0425245
I0416 21:54:10.376364   977 solver.cpp:236]     Train net output #0: loss = 0.038621 (* 1 = 0.038621 loss)
I0416 21:54:10.376368   977 solver.cpp:542] Iteration 48900, lr = 0.001
I0416 21:54:23.918684   977 solver.cpp:221] Iteration 48920, loss = 0.0414762
I0416 21:54:23.918710   977 solver.cpp:236]     Train net output #0: loss = 0.0357437 (* 1 = 0.0357437 loss)
I0416 21:54:23.918715   977 solver.cpp:542] Iteration 48920, lr = 0.001
I0416 21:54:37.458642   977 solver.cpp:221] Iteration 48940, loss = 0.0386483
I0416 21:54:37.458668   977 solver.cpp:236]     Train net output #0: loss = 0.0480295 (* 1 = 0.0480295 loss)
I0416 21:54:37.458673   977 solver.cpp:542] Iteration 48940, lr = 0.001
I0416 21:54:50.998692   977 solver.cpp:221] Iteration 48960, loss = 0.0372895
I0416 21:54:50.998720   977 solver.cpp:236]     Train net output #0: loss = 0.035084 (* 1 = 0.035084 loss)
I0416 21:54:50.998726   977 solver.cpp:542] Iteration 48960, lr = 0.001
I0416 21:55:04.538636   977 solver.cpp:221] Iteration 48980, loss = 0.0434834
I0416 21:55:04.538664   977 solver.cpp:236]     Train net output #0: loss = 0.0458351 (* 1 = 0.0458351 loss)
I0416 21:55:04.538669   977 solver.cpp:542] Iteration 48980, lr = 0.001
I0416 21:55:17.452935   977 solver.cpp:316] Iteration 49000, Testing net (#0)
I0416 21:55:28.991178   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 21:55:28.991199   977 solver.cpp:373]     Test net output #1: loss = 0.0356147 (* 1 = 0.0356147 loss)
I0416 21:55:29.660837   977 solver.cpp:221] Iteration 49000, loss = 0.0380483
I0416 21:55:29.660866   977 solver.cpp:236]     Train net output #0: loss = 0.0222839 (* 1 = 0.0222839 loss)
I0416 21:55:29.660872   977 solver.cpp:542] Iteration 49000, lr = 0.001
I0416 21:55:43.216405   977 solver.cpp:221] Iteration 49020, loss = 0.0400128
I0416 21:55:43.216434   977 solver.cpp:236]     Train net output #0: loss = 0.0195488 (* 1 = 0.0195488 loss)
I0416 21:55:43.216439   977 solver.cpp:542] Iteration 49020, lr = 0.001
I0416 21:55:56.772333   977 solver.cpp:221] Iteration 49040, loss = 0.0370641
I0416 21:55:56.772359   977 solver.cpp:236]     Train net output #0: loss = 0.0486807 (* 1 = 0.0486807 loss)
I0416 21:55:56.772364   977 solver.cpp:542] Iteration 49040, lr = 0.001
I0416 21:56:10.317821   977 solver.cpp:221] Iteration 49060, loss = 0.0375592
I0416 21:56:10.317847   977 solver.cpp:236]     Train net output #0: loss = 0.028523 (* 1 = 0.028523 loss)
I0416 21:56:10.317852   977 solver.cpp:542] Iteration 49060, lr = 0.001
I0416 21:56:23.848984   977 solver.cpp:221] Iteration 49080, loss = 0.0421546
I0416 21:56:23.849011   977 solver.cpp:236]     Train net output #0: loss = 0.0373405 (* 1 = 0.0373405 loss)
I0416 21:56:23.849016   977 solver.cpp:542] Iteration 49080, lr = 0.001
I0416 21:56:37.381398   977 solver.cpp:221] Iteration 49100, loss = 0.0386224
I0416 21:56:37.381427   977 solver.cpp:236]     Train net output #0: loss = 0.0151975 (* 1 = 0.0151975 loss)
I0416 21:56:37.381430   977 solver.cpp:542] Iteration 49100, lr = 0.001
I0416 21:56:50.937300   977 solver.cpp:221] Iteration 49120, loss = 0.0442244
I0416 21:56:50.937327   977 solver.cpp:236]     Train net output #0: loss = 0.0310425 (* 1 = 0.0310425 loss)
I0416 21:56:50.937331   977 solver.cpp:542] Iteration 49120, lr = 0.001
I0416 21:57:04.491057   977 solver.cpp:221] Iteration 49140, loss = 0.0361787
I0416 21:57:04.491091   977 solver.cpp:236]     Train net output #0: loss = 0.032772 (* 1 = 0.032772 loss)
I0416 21:57:04.491096   977 solver.cpp:542] Iteration 49140, lr = 0.001
I0416 21:57:18.040966   977 solver.cpp:221] Iteration 49160, loss = 0.0377735
I0416 21:57:18.040993   977 solver.cpp:236]     Train net output #0: loss = 0.0452019 (* 1 = 0.0452019 loss)
I0416 21:57:18.040998   977 solver.cpp:542] Iteration 49160, lr = 0.001
I0416 21:57:31.572672   977 solver.cpp:221] Iteration 49180, loss = 0.0390186
I0416 21:57:31.572700   977 solver.cpp:236]     Train net output #0: loss = 0.044268 (* 1 = 0.044268 loss)
I0416 21:57:31.572705   977 solver.cpp:542] Iteration 49180, lr = 0.001
I0416 21:57:44.460654   977 solver.cpp:316] Iteration 49200, Testing net (#0)
I0416 21:57:55.996659   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 21:57:55.996682   977 solver.cpp:373]     Test net output #1: loss = 0.0351605 (* 1 = 0.0351605 loss)
I0416 21:57:56.664280   977 solver.cpp:221] Iteration 49200, loss = 0.0385557
I0416 21:57:56.664309   977 solver.cpp:236]     Train net output #0: loss = 0.0366924 (* 1 = 0.0366924 loss)
I0416 21:57:56.664314   977 solver.cpp:542] Iteration 49200, lr = 0.001
I0416 21:58:10.235498   977 solver.cpp:221] Iteration 49220, loss = 0.0372489
I0416 21:58:10.235525   977 solver.cpp:236]     Train net output #0: loss = 0.0360706 (* 1 = 0.0360706 loss)
I0416 21:58:10.235529   977 solver.cpp:542] Iteration 49220, lr = 0.001
I0416 21:58:23.794919   977 solver.cpp:221] Iteration 49240, loss = 0.036241
I0416 21:58:23.794946   977 solver.cpp:236]     Train net output #0: loss = 0.0374506 (* 1 = 0.0374506 loss)
I0416 21:58:23.794951   977 solver.cpp:542] Iteration 49240, lr = 0.001
I0416 21:58:37.347265   977 solver.cpp:221] Iteration 49260, loss = 0.0391933
I0416 21:58:37.347292   977 solver.cpp:236]     Train net output #0: loss = 0.0261651 (* 1 = 0.0261651 loss)
I0416 21:58:37.347298   977 solver.cpp:542] Iteration 49260, lr = 0.001
I0416 21:58:50.880852   977 solver.cpp:221] Iteration 49280, loss = 0.0410906
I0416 21:58:50.880880   977 solver.cpp:236]     Train net output #0: loss = 0.042506 (* 1 = 0.042506 loss)
I0416 21:58:50.880885   977 solver.cpp:542] Iteration 49280, lr = 0.001
I0416 21:59:04.405069   977 solver.cpp:221] Iteration 49300, loss = 0.0387195
I0416 21:59:04.405097   977 solver.cpp:236]     Train net output #0: loss = 0.061754 (* 1 = 0.061754 loss)
I0416 21:59:04.405102   977 solver.cpp:542] Iteration 49300, lr = 0.001
I0416 21:59:17.955826   977 solver.cpp:221] Iteration 49320, loss = 0.0381016
I0416 21:59:17.955854   977 solver.cpp:236]     Train net output #0: loss = 0.0282662 (* 1 = 0.0282662 loss)
I0416 21:59:17.955859   977 solver.cpp:542] Iteration 49320, lr = 0.001
I0416 21:59:31.493340   977 solver.cpp:221] Iteration 49340, loss = 0.0354936
I0416 21:59:31.493366   977 solver.cpp:236]     Train net output #0: loss = 0.0346603 (* 1 = 0.0346603 loss)
I0416 21:59:31.493369   977 solver.cpp:542] Iteration 49340, lr = 0.001
I0416 21:59:45.048612   977 solver.cpp:221] Iteration 49360, loss = 0.0409909
I0416 21:59:45.048640   977 solver.cpp:236]     Train net output #0: loss = 0.0309973 (* 1 = 0.0309973 loss)
I0416 21:59:45.048645   977 solver.cpp:542] Iteration 49360, lr = 0.001
I0416 21:59:58.577989   977 solver.cpp:221] Iteration 49380, loss = 0.0412522
I0416 21:59:58.578017   977 solver.cpp:236]     Train net output #0: loss = 0.0396171 (* 1 = 0.0396171 loss)
I0416 21:59:58.578022   977 solver.cpp:542] Iteration 49380, lr = 0.001
I0416 22:00:11.494767   977 solver.cpp:316] Iteration 49400, Testing net (#0)
I0416 22:00:23.039717   977 solver.cpp:373]     Test net output #0: accuracy = 0.993536
I0416 22:00:23.039739   977 solver.cpp:373]     Test net output #1: loss = 0.0352658 (* 1 = 0.0352658 loss)
I0416 22:00:23.708760   977 solver.cpp:221] Iteration 49400, loss = 0.0424688
I0416 22:00:23.708789   977 solver.cpp:236]     Train net output #0: loss = 0.0459732 (* 1 = 0.0459732 loss)
I0416 22:00:23.708794   977 solver.cpp:542] Iteration 49400, lr = 0.001
I0416 22:00:37.273051   977 solver.cpp:221] Iteration 49420, loss = 0.0383838
I0416 22:00:37.273077   977 solver.cpp:236]     Train net output #0: loss = 0.0405504 (* 1 = 0.0405504 loss)
I0416 22:00:37.273082   977 solver.cpp:542] Iteration 49420, lr = 0.001
I0416 22:00:50.857151   977 solver.cpp:221] Iteration 49440, loss = 0.0386265
I0416 22:00:50.857177   977 solver.cpp:236]     Train net output #0: loss = 0.0365709 (* 1 = 0.0365709 loss)
I0416 22:00:50.857182   977 solver.cpp:542] Iteration 49440, lr = 0.001
I0416 22:01:04.416946   977 solver.cpp:221] Iteration 49460, loss = 0.041677
I0416 22:01:04.416973   977 solver.cpp:236]     Train net output #0: loss = 0.0747193 (* 1 = 0.0747193 loss)
I0416 22:01:04.416978   977 solver.cpp:542] Iteration 49460, lr = 0.001
I0416 22:01:17.944950   977 solver.cpp:221] Iteration 49480, loss = 0.0404804
I0416 22:01:17.944977   977 solver.cpp:236]     Train net output #0: loss = 0.0356806 (* 1 = 0.0356806 loss)
I0416 22:01:17.944983   977 solver.cpp:542] Iteration 49480, lr = 0.001
I0416 22:01:31.460604   977 solver.cpp:221] Iteration 49500, loss = 0.0416499
I0416 22:01:31.460633   977 solver.cpp:236]     Train net output #0: loss = 0.0433718 (* 1 = 0.0433718 loss)
I0416 22:01:31.460636   977 solver.cpp:542] Iteration 49500, lr = 0.001
I0416 22:01:44.998523   977 solver.cpp:221] Iteration 49520, loss = 0.038377
I0416 22:01:44.998550   977 solver.cpp:236]     Train net output #0: loss = 0.0467648 (* 1 = 0.0467648 loss)
I0416 22:01:44.998554   977 solver.cpp:542] Iteration 49520, lr = 0.001
I0416 22:01:58.559000   977 solver.cpp:221] Iteration 49540, loss = 0.0384347
I0416 22:01:58.559029   977 solver.cpp:236]     Train net output #0: loss = 0.0278914 (* 1 = 0.0278914 loss)
I0416 22:01:58.559033   977 solver.cpp:542] Iteration 49540, lr = 0.001
I0416 22:02:12.128638   977 solver.cpp:221] Iteration 49560, loss = 0.0363952
I0416 22:02:12.128666   977 solver.cpp:236]     Train net output #0: loss = 0.0350052 (* 1 = 0.0350052 loss)
I0416 22:02:12.128670   977 solver.cpp:542] Iteration 49560, lr = 0.001
I0416 22:02:25.657526   977 solver.cpp:221] Iteration 49580, loss = 0.0379419
I0416 22:02:25.657554   977 solver.cpp:236]     Train net output #0: loss = 0.0523915 (* 1 = 0.0523915 loss)
I0416 22:02:25.657559   977 solver.cpp:542] Iteration 49580, lr = 0.001
I0416 22:02:38.537894   977 solver.cpp:316] Iteration 49600, Testing net (#0)
I0416 22:02:50.072136   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 22:02:50.072159   977 solver.cpp:373]     Test net output #1: loss = 0.0351846 (* 1 = 0.0351846 loss)
I0416 22:02:50.740772   977 solver.cpp:221] Iteration 49600, loss = 0.0355609
I0416 22:02:50.740800   977 solver.cpp:236]     Train net output #0: loss = 0.0280299 (* 1 = 0.0280299 loss)
I0416 22:02:50.740805   977 solver.cpp:542] Iteration 49600, lr = 0.001
I0416 22:03:04.298555   977 solver.cpp:221] Iteration 49620, loss = 0.0411808
I0416 22:03:04.298583   977 solver.cpp:236]     Train net output #0: loss = 0.0349105 (* 1 = 0.0349105 loss)
I0416 22:03:04.298588   977 solver.cpp:542] Iteration 49620, lr = 0.001
I0416 22:03:17.858510   977 solver.cpp:221] Iteration 49640, loss = 0.0411321
I0416 22:03:17.858537   977 solver.cpp:236]     Train net output #0: loss = 0.0169123 (* 1 = 0.0169123 loss)
I0416 22:03:17.858542   977 solver.cpp:542] Iteration 49640, lr = 0.001
I0416 22:03:31.394670   977 solver.cpp:221] Iteration 49660, loss = 0.0403435
I0416 22:03:31.394697   977 solver.cpp:236]     Train net output #0: loss = 0.0590111 (* 1 = 0.0590111 loss)
I0416 22:03:31.394701   977 solver.cpp:542] Iteration 49660, lr = 0.001
I0416 22:03:44.924145   977 solver.cpp:221] Iteration 49680, loss = 0.0392733
I0416 22:03:44.924172   977 solver.cpp:236]     Train net output #0: loss = 0.0287881 (* 1 = 0.0287881 loss)
I0416 22:03:44.924177   977 solver.cpp:542] Iteration 49680, lr = 0.001
I0416 22:03:58.462909   977 solver.cpp:221] Iteration 49700, loss = 0.0425048
I0416 22:03:58.462937   977 solver.cpp:236]     Train net output #0: loss = 0.0375785 (* 1 = 0.0375785 loss)
I0416 22:03:58.462941   977 solver.cpp:542] Iteration 49700, lr = 0.001
I0416 22:04:11.997251   977 solver.cpp:221] Iteration 49720, loss = 0.0410579
I0416 22:04:11.997277   977 solver.cpp:236]     Train net output #0: loss = 0.0333821 (* 1 = 0.0333821 loss)
I0416 22:04:11.997282   977 solver.cpp:542] Iteration 49720, lr = 0.001
I0416 22:04:25.530860   977 solver.cpp:221] Iteration 49740, loss = 0.0415363
I0416 22:04:25.530889   977 solver.cpp:236]     Train net output #0: loss = 0.0555276 (* 1 = 0.0555276 loss)
I0416 22:04:25.530894   977 solver.cpp:542] Iteration 49740, lr = 0.001
I0416 22:04:39.083173   977 solver.cpp:221] Iteration 49760, loss = 0.0391293
I0416 22:04:39.083201   977 solver.cpp:236]     Train net output #0: loss = 0.0244532 (* 1 = 0.0244532 loss)
I0416 22:04:39.083205   977 solver.cpp:542] Iteration 49760, lr = 0.001
I0416 22:04:52.656528   977 solver.cpp:221] Iteration 49780, loss = 0.0365898
I0416 22:04:52.656555   977 solver.cpp:236]     Train net output #0: loss = 0.0349807 (* 1 = 0.0349807 loss)
I0416 22:04:52.656560   977 solver.cpp:542] Iteration 49780, lr = 0.001
I0416 22:05:05.557515   977 solver.cpp:316] Iteration 49800, Testing net (#0)
I0416 22:05:17.103150   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 22:05:17.103173   977 solver.cpp:373]     Test net output #1: loss = 0.0353314 (* 1 = 0.0353314 loss)
I0416 22:05:17.772457   977 solver.cpp:221] Iteration 49800, loss = 0.0410174
I0416 22:05:17.772486   977 solver.cpp:236]     Train net output #0: loss = 0.0535751 (* 1 = 0.0535751 loss)
I0416 22:05:17.772492   977 solver.cpp:542] Iteration 49800, lr = 0.001
I0416 22:05:31.320873   977 solver.cpp:221] Iteration 49820, loss = 0.040137
I0416 22:05:31.320899   977 solver.cpp:236]     Train net output #0: loss = 0.0441399 (* 1 = 0.0441399 loss)
I0416 22:05:31.320904   977 solver.cpp:542] Iteration 49820, lr = 0.001
I0416 22:05:44.856248   977 solver.cpp:221] Iteration 49840, loss = 0.0374633
I0416 22:05:44.856274   977 solver.cpp:236]     Train net output #0: loss = 0.027389 (* 1 = 0.027389 loss)
I0416 22:05:44.856279   977 solver.cpp:542] Iteration 49840, lr = 0.001
I0416 22:05:58.394543   977 solver.cpp:221] Iteration 49860, loss = 0.0392242
I0416 22:05:58.394570   977 solver.cpp:236]     Train net output #0: loss = 0.0187066 (* 1 = 0.0187066 loss)
I0416 22:05:58.394575   977 solver.cpp:542] Iteration 49860, lr = 0.001
I0416 22:06:11.945869   977 solver.cpp:221] Iteration 49880, loss = 0.0374528
I0416 22:06:11.945897   977 solver.cpp:236]     Train net output #0: loss = 0.0302088 (* 1 = 0.0302088 loss)
I0416 22:06:11.945902   977 solver.cpp:542] Iteration 49880, lr = 0.001
I0416 22:06:25.492266   977 solver.cpp:221] Iteration 49900, loss = 0.0398291
I0416 22:06:25.492295   977 solver.cpp:236]     Train net output #0: loss = 0.0510864 (* 1 = 0.0510864 loss)
I0416 22:06:25.492298   977 solver.cpp:542] Iteration 49900, lr = 0.001
I0416 22:06:39.059396   977 solver.cpp:221] Iteration 49920, loss = 0.0413932
I0416 22:06:39.059425   977 solver.cpp:236]     Train net output #0: loss = 0.0351571 (* 1 = 0.0351571 loss)
I0416 22:06:39.059430   977 solver.cpp:542] Iteration 49920, lr = 0.001
I0416 22:06:52.592512   977 solver.cpp:221] Iteration 49940, loss = 0.0373058
I0416 22:06:52.592538   977 solver.cpp:236]     Train net output #0: loss = 0.0186396 (* 1 = 0.0186396 loss)
I0416 22:06:52.592543   977 solver.cpp:542] Iteration 49940, lr = 0.001
I0416 22:07:06.129456   977 solver.cpp:221] Iteration 49960, loss = 0.0401818
I0416 22:07:06.129484   977 solver.cpp:236]     Train net output #0: loss = 0.0305058 (* 1 = 0.0305058 loss)
I0416 22:07:06.129489   977 solver.cpp:542] Iteration 49960, lr = 0.001
I0416 22:07:19.713268   977 solver.cpp:221] Iteration 49980, loss = 0.0381522
I0416 22:07:19.713295   977 solver.cpp:236]     Train net output #0: loss = 0.0530389 (* 1 = 0.0530389 loss)
I0416 22:07:19.713300   977 solver.cpp:542] Iteration 49980, lr = 0.001
I0416 22:07:32.576761   977 solver.cpp:410] Snapshotting to binary proto file external/exp/snapshots/individually/cuhk03_iter_50000.caffemodel
I0416 22:07:32.640983   977 solver.cpp:705] Snapshotting solver state to binary proto fileexternal/exp/snapshots/individually/cuhk03_iter_50000.solverstate
I0416 22:07:32.772649   977 solver.cpp:296] Iteration 50000, loss = 0.0222655
I0416 22:07:32.782670   977 solver.cpp:316] Iteration 50000, Testing net (#0)
I0416 22:07:44.324602   977 solver.cpp:373]     Test net output #0: accuracy = 0.993726
I0416 22:07:44.324625   977 solver.cpp:373]     Test net output #1: loss = 0.0351133 (* 1 = 0.0351133 loss)
I0416 22:07:44.324627   977 solver.cpp:301] Optimization Done.
I0416 22:07:44.324630   977 caffe.cpp:191] Optimization Done.
Extracting train set
E0418 15:01:25.153898 10481 extract_features.cpp:54] Using GPU
E0418 15:01:25.154057 10481 extract_features.cpp:60] Using Device_id=0
E0418 15:01:36.812021 10481 extract_features.cpp:135] Extacting Features
E0418 15:01:40.087438 10481 extract_features.cpp:170] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:01:40.238183 10481 extract_features.cpp:170] Extracted features of 1000 query images for feature blob label
E0418 15:01:43.438091 10481 extract_features.cpp:170] Extracted features of 2000 query images for feature blob fc7_bn
E0418 15:01:43.563825 10481 extract_features.cpp:170] Extracted features of 2000 query images for feature blob label
E0418 15:01:46.763763 10481 extract_features.cpp:170] Extracted features of 3000 query images for feature blob fc7_bn
E0418 15:01:46.881170 10481 extract_features.cpp:170] Extracted features of 3000 query images for feature blob label
E0418 15:01:50.139402 10481 extract_features.cpp:170] Extracted features of 4000 query images for feature blob fc7_bn
E0418 15:01:50.340152 10481 extract_features.cpp:170] Extracted features of 4000 query images for feature blob label
E0418 15:01:53.740149 10481 extract_features.cpp:170] Extracted features of 5000 query images for feature blob fc7_bn
E0418 15:01:53.865892 10481 extract_features.cpp:170] Extracted features of 5000 query images for feature blob label
E0418 15:01:57.132467 10481 extract_features.cpp:170] Extracted features of 6000 query images for feature blob fc7_bn
E0418 15:01:57.258188 10481 extract_features.cpp:170] Extracted features of 6000 query images for feature blob label
E0418 15:02:00.541489 10481 extract_features.cpp:170] Extracted features of 7000 query images for feature blob fc7_bn
E0418 15:02:00.758932 10481 extract_features.cpp:170] Extracted features of 7000 query images for feature blob label
E0418 15:02:04.008822 10481 extract_features.cpp:170] Extracted features of 8000 query images for feature blob fc7_bn
E0418 15:02:04.184556 10481 extract_features.cpp:170] Extracted features of 8000 query images for feature blob label
E0418 15:02:07.442870 10481 extract_features.cpp:170] Extracted features of 9000 query images for feature blob fc7_bn
E0418 15:02:07.618610 10481 extract_features.cpp:170] Extracted features of 9000 query images for feature blob label
E0418 15:02:10.893522 10481 extract_features.cpp:170] Extracted features of 10000 query images for feature blob fc7_bn
E0418 15:02:11.069264 10481 extract_features.cpp:170] Extracted features of 10000 query images for feature blob label
E0418 15:02:14.327553 10481 extract_features.cpp:170] Extracted features of 11000 query images for feature blob fc7_bn
E0418 15:02:14.478281 10481 extract_features.cpp:170] Extracted features of 11000 query images for feature blob label
E0418 15:02:17.769881 10481 extract_features.cpp:170] Extracted features of 12000 query images for feature blob fc7_bn
E0418 15:02:17.920635 10481 extract_features.cpp:170] Extracted features of 12000 query images for feature blob label
E0418 15:02:21.178915 10481 extract_features.cpp:170] Extracted features of 13000 query images for feature blob fc7_bn
E0418 15:02:21.354681 10481 extract_features.cpp:170] Extracted features of 13000 query images for feature blob label
E0418 15:02:24.621251 10481 extract_features.cpp:170] Extracted features of 14000 query images for feature blob fc7_bn
E0418 15:02:24.821980 10481 extract_features.cpp:170] Extracted features of 14000 query images for feature blob label
E0418 15:02:28.080286 10481 extract_features.cpp:170] Extracted features of 15000 query images for feature blob fc7_bn
E0418 15:02:28.289377 10481 extract_features.cpp:170] Extracted features of 15000 query images for feature blob label
E0418 15:02:31.464198 10481 extract_features.cpp:170] Extracted features of 16000 query images for feature blob fc7_bn
E0418 15:02:31.556579 10481 extract_features.cpp:170] Extracted features of 16000 query images for feature blob label
E0418 15:02:34.714864 10481 extract_features.cpp:170] Extracted features of 17000 query images for feature blob fc7_bn
E0418 15:02:34.790593 10481 extract_features.cpp:170] Extracted features of 17000 query images for feature blob label
E0418 15:02:38.065502 10481 extract_features.cpp:170] Extracted features of 18000 query images for feature blob fc7_bn
E0418 15:02:38.141216 10481 extract_features.cpp:170] Extracted features of 18000 query images for feature blob label
E0418 15:02:41.549545 10481 extract_features.cpp:170] Extracted features of 19000 query images for feature blob fc7_bn
E0418 15:02:41.633616 10481 extract_features.cpp:170] Extracted features of 19000 query images for feature blob label
E0418 15:02:45.058552 10481 extract_features.cpp:170] Extracted features of 20000 query images for feature blob fc7_bn
E0418 15:02:45.117599 10481 extract_features.cpp:170] Extracted features of 20000 query images for feature blob label
E0418 15:02:48.550940 10481 extract_features.cpp:170] Extracted features of 21000 query images for feature blob fc7_bn
E0418 15:02:48.610003 10481 extract_features.cpp:170] Extracted features of 21000 query images for feature blob label
E0418 15:02:49.009330 10481 extract_features.cpp:181] Extracted features of 21100 query images for feature blob fc7_bn
E0418 15:02:49.085046 10481 extract_features.cpp:181] Extracted features of 21100 query images for feature blob label
E0418 15:02:49.085104 10481 extract_features.cpp:186] Successfully extracted the features!
Extracting val set
E0418 15:02:57.361886 10734 extract_features.cpp:54] Using GPU
E0418 15:02:57.362005 10734 extract_features.cpp:60] Using Device_id=0
E0418 15:03:09.115097 10734 extract_features.cpp:135] Extacting Features
E0418 15:03:12.312688 10734 extract_features.cpp:170] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:03:12.381728 10734 extract_features.cpp:170] Extracted features of 1000 query images for feature blob label
E0418 15:03:15.538328 10734 extract_features.cpp:170] Extracted features of 2000 query images for feature blob fc7_bn
E0418 15:03:15.590677 10734 extract_features.cpp:170] Extracted features of 2000 query images for feature blob label
E0418 15:03:18.738981 10734 extract_features.cpp:170] Extracted features of 3000 query images for feature blob fc7_bn
E0418 15:03:18.791329 10734 extract_features.cpp:170] Extracted features of 3000 query images for feature blob label
E0418 15:03:22.172978 10734 extract_features.cpp:170] Extracted features of 4000 query images for feature blob fc7_bn
E0418 15:03:22.250329 10734 extract_features.cpp:170] Extracted features of 4000 query images for feature blob label
E0418 15:03:25.665355 10734 extract_features.cpp:170] Extracted features of 5000 query images for feature blob fc7_bn
E0418 15:03:25.726032 10734 extract_features.cpp:170] Extracted features of 5000 query images for feature blob label
E0418 15:03:26.807178 10734 extract_features.cpp:181] Extracted features of 5300 query images for feature blob fc7_bn
E0418 15:03:26.859549 10734 extract_features.cpp:181] Extracted features of 5300 query images for feature blob label
E0418 15:03:26.859592 10734 extract_features.cpp:186] Successfully extracted the features!
Extracting test_probe set
E0418 15:03:29.723569 10825 extract_features.cpp:54] Using GPU
E0418 15:03:29.723728 10825 extract_features.cpp:60] Using Device_id=0
E0418 15:03:41.652530 10825 extract_features.cpp:135] Extacting Features
E0418 15:03:45.090111 10825 extract_features.cpp:170] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:03:45.163594 10825 extract_features.cpp:170] Extracted features of 1000 query images for feature blob label
E0418 15:03:45.163611 10825 extract_features.cpp:181] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:03:45.163676 10825 extract_features.cpp:181] Extracted features of 1000 query images for feature blob label
E0418 15:03:45.163699 10825 extract_features.cpp:186] Successfully extracted the features!
Extracting test_gallery set
E0418 15:03:46.345492 10873 extract_features.cpp:54] Using GPU
E0418 15:03:46.345610 10873 extract_features.cpp:60] Using Device_id=0
E0418 15:03:58.478889 10873 extract_features.cpp:135] Extacting Features
E0418 15:04:01.932245 10873 extract_features.cpp:170] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:04:02.008970 10873 extract_features.cpp:170] Extracted features of 1000 query images for feature blob label
E0418 15:04:02.008990 10873 extract_features.cpp:181] Extracted features of 1000 query images for feature blob fc7_bn
E0418 15:04:02.009053 10873 extract_features.cpp:181] Extracted features of 1000 query images for feature blob label
E0418 15:04:02.009074 10873 extract_features.cpp:186] Successfully extracted the features!
top-1      76.8%
top-5      93.8%
top-10     96.8%
top-20     98.6%

[exited with status 0.]
